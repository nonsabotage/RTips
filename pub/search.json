[
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/index.html",
    "href": "contents/sql/duckdb/sql-bigdata/index.html",
    "title": "ビッグデータ分析・活用のためのSQLレシピ",
    "section": "",
    "text": "1 はじめに\n\nレシピの勉強ノートです.\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap06_.html",
    "href": "contents/sql/duckdb/sql-bigdata/chap06_.html",
    "title": "Webサイトでの行動を把握するためのデータ抽出",
    "section": "",
    "text": "Code\nrenv::activate(here::here())\nCode\n\ncur_dir &lt;- here::here(\"contents/sql/duckdb/sql-bigdata\")\n\nlibrary(ggplot2)\nlibrary(duckdb)\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(DBI)\nlibrary(dbplyr)\nlibrary(arrow)\nlibrary(showtext)\nlibrary(here)\nshowtext_auto()\nfont_add_google(\"Noto Sans\")"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap06_.html#サンプルデータ",
    "href": "contents/sql/duckdb/sql-bigdata/chap06_.html#サンプルデータ",
    "title": "Webサイトでの行動を把握するためのデータ抽出",
    "section": "2.1 サンプルデータ",
    "text": "2.1 サンプルデータ\n\n\nCode\nSELECT * FROM purchase_log;\n\n\n\n4 records\n\n\nstamp\nshort_session\nlong_session\npurchase_id\namount\n\n\n\n\n2016-10-01 15:00:00\n0CVKaz\n1CwlSX\n1\n1000\n\n\n2016-10-01 16:00:00\n2is8PX\n7Dn99b\n2\n1000\n\n\n2016-10-01 20:00:00\n2is8PX\n7Dn99b\n3\n1000\n\n\n2016-10-02 14:00:00\n2is8PX\n7Dn99b\n4\n1000"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap06_.html#日時の訪問者数訪問回数ページビュー",
    "href": "contents/sql/duckdb/sql-bigdata/chap06_.html#日時の訪問者数訪問回数ページビュー",
    "title": "Webサイトでの行動を把握するためのデータ抽出",
    "section": "2.2 日時の訪問者数・訪問回数・ページビュー",
    "text": "2.2 日時の訪問者数・訪問回数・ページビュー\n\n\nCode\nSELECT\n  substring(stamp, 1, 10) as dt\n  , count(distinct long_session) as access_users\n  \n  , count(distinct short_session) as access_count\n  \n  , count(*) as page_view\n  \n  , 1. * count(*) / NULLIF(count(distinct long_session), 0) as pv_per_user\n  \nfrom\n  \n  access_log\n  \ngroup by\n  \n  dt\n\norder by\n  \n  dt\n  \n;\n\n\n\n3 records\n\n\ndt\naccess_users\naccess_count\npage_view\npv_per_user\n\n\n\n\n2016-10-01\n4\n5\n8\n2.000000\n\n\n2016-10-02\n4\n5\n7\n1.750000\n\n\n2016-10-03\n3\n3\n4\n1.333333"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap06_.html#ページマイの訪問者訪問回数ページビューを集計",
    "href": "contents/sql/duckdb/sql-bigdata/chap06_.html#ページマイの訪問者訪問回数ページビューを集計",
    "title": "Webサイトでの行動を把握するためのデータ抽出",
    "section": "2.3 ページマイの訪問者・訪問回数・ページビューを集計",
    "text": "2.3 ページマイの訪問者・訪問回数・ページビューを集計\n\n2.3.1 URL別に集計\n\n\nCode\nselect\n\n  url\n  , count(distinct short_session) as access_count\n  , count(distinct long_session) as access_usres\n  , count(*) as page_view\n  \nfrom \n\n  access_log\n  \ngroup by\n\n  url\n  \n;\n\n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\nurl\naccess_count\naccess_usres\npage_view\n\n\n\n\nhttp://www.example.com/detail?id=2\n2\n2\n2\n\n\nhttp://www.example.com/?utm_source=google&utm_medium=search\n1\n1\n1\n\n\nhttp://www.example.com/list/cd\n3\n3\n3\n\n\nhttp://www.example.com/list/dvd?utm_source=yahoo&utm_medium=search\n1\n1\n1\n\n\nhttp://www.example.com/list/newly\n3\n2\n3\n\n\nhttp://www.example.com/detail?id=3\n1\n1\n1\n\n\nhttp://www.example.com/?utm_source=mynavi&utm_medium=affiliate\n1\n1\n1\n\n\nhttp://www.example.com/detail?id=1\n2\n2\n2\n\n\nhttp://www.example.com/\n3\n3\n3\n\n\nhttp://www.example.com/list/dvd\n2\n2\n2\n\n\n\n\n\n\n\n2.3.2 パス別に集計する\nクエリパラメータを省略してパス別に集計する。\n\n\nCode\nwith\naccess_log_with_path as (\n  -- urlからパスを抽出する\n  select\n    *\n    \n    , regexp_extract(url, '//[^/]+([^?#]+)', 1) as url_path\n    \n  from access_log\n  \n)\n\nselect \n\n  url_path\n  , count(distinct short_session) as access_count\n  , count(distinct long_session) as access_users\n  , count(*) as page_view\n\nfrom \n\n  access_log_with_path\n  \ngroup by\n\n  url_path\n\n\n\n5 records\n\n\nurl_path\naccess_count\naccess_users\npage_view\n\n\n\n\n/list/cd\n3\n3\n3\n\n\n/list/dvd\n3\n2\n3\n\n\n/detail\n5\n3\n5\n\n\n/\n5\n4\n5\n\n\n/list/newly\n3\n2\n3\n\n\n\n\n\n\n\n2.3.3 URLに大きな意味を持たせて集計する\n\n\nCode\nwith \naccess_log_with_path as (\n\n  select\n    *\n    \n    , regexp_extract(url, '//[^/]+([^?#]+)', 1) as url_path\n    \n  from access_log\n\n)\n, access_log_with_split_path as (\n  select\n  \n    * \n    , split_part(url_path, '/', 2) as path1\n    , split_part(url_path, '/', 3) as path2\n    \n  from access_log_with_path\n  \n)\n, access_log_with_page_name as (\n  select\n  \n    * \n  \n    , case \n        when path1 = 'list' then \n          case \n            when path2 = 'newly' then 'newly_list'\n            else 'category_list'\n          end\n        -- 上記以外はパスを採用する\n        else url_path\n      end as page_name\n      \n  from \n    \n    access_log_with_split_path\n\n)\n\nselect \n\n  page_name\n  \n  , count(distinct short_session) as access_count\n  \n  , count(distinct long_session) as access_users\n  \n  , count(*) as page_view\n  \nfrom \n\n  access_log_with_page_name\n  \ngroup by\n\n  page_name\n  \norder by\n\n  page_name\n  \n  \n;\n\n\n\n4 records\n\n\npage_name\naccess_count\naccess_users\npage_view\n\n\n\n\n/\n5\n4\n5\n\n\n/detail\n5\n3\n5\n\n\ncategory_list\n6\n4\n6\n\n\nnewly_list\n3\n2\n3"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap06_.html#流入元別に訪問回数やcvrを集計する",
    "href": "contents/sql/duckdb/sql-bigdata/chap06_.html#流入元別に訪問回数やcvrを集計する",
    "title": "Webサイトでの行動を把握するためのデータ抽出",
    "section": "2.4 流入元別に訪問回数やCVRを集計する",
    "text": "2.4 流入元別に訪問回数やCVRを集計する\nリファラーに直前のページのURLが保存される。そのリファラーとURLを使用し、下記の方法で流入元を判定する\n\nURLパラメータを元に判断する\nリファラーのドメインやランディングページで判定する\n\n\n\nCode\nwith \naccess_log_with_parse_info as (\n\n  select\n  \n    * \n    , regexp_extract(url, 'https?://([^/]*)',   1) as url_domain\n    , regexp_extract(url, 'utm_source=([^&]*)', 1) as url_utm_source\n    , regexp_extract(url, 'utm_medium=([^&]*)', 1) as url_utm_medium\n    , regexp_extract(referrer, 'https?://([^/]*)', 1) as referrer_domain\n    \n  from access_log\n\n)\n, access_log_with_via_info as (\n  select \n  \n    * \n    , row_number() over(order by stamp) as log_id\n    , case \n        when url_utm_source &lt;&gt; '' and url_utm_medium &lt;&gt; '' then concat_ws('/', url_utm_source, url_utm_medium)\n        when referrer_domain in ('search.yahoo.co.jp', 'www.google.co.jp') then 'search'\n        when referrer_domain in ('twitter.com', 'www.facebook.com') then 'social'\n        else 'other'\n      end as via\n      \n  from \n  \n    access_log_with_parse_info\n    \n  where\n  \n    coalesce(referrer_domain, '') not in ('', url_domain)\n    \n)\n\nselect \n  \n  via, \n  count(1) as access_count\n\nfrom\n  \n  access_log_with_via_info\n  \ngroup by\n\n  via\n  \norder by \n\n  access_count DESC\n\n;\n\n\n\n6 records\n\n\nvia\naccess_count\n\n\n\n\nsocial\n3\n\n\nother\n2\n\n\nsearch\n2\n\n\nmynavi/affiliate\n1\n\n\nyahoo/search\n1\n\n\ngoogle/search\n1\n\n\n\n\n\n\n2.4.1 流入元別にCVRを集計する\n\n\nCode\nwith \naccess_log_with_parse_info as (\n\n  select\n  \n    * \n    , regexp_extract(url, 'https?://([^/]*)',   1) as url_domain\n    , regexp_extract(url, 'utm_source=([^&]*)', 1) as url_utm_source\n    , regexp_extract(url, 'utm_medium=([^&]*)', 1) as url_utm_medium\n    , regexp_extract(referrer, 'https?://([^/]*)', 1) as referrer_domain\n    \n  from access_log\n\n)\n, access_log_with_via_info as (\n  select \n  \n    * \n    , row_number() over(order by stamp) as log_id\n    , case \n        when url_utm_source &lt;&gt; '' and url_utm_medium &lt;&gt; '' then concat_ws('/', url_utm_source, url_utm_medium)\n        when referrer_domain in ('search.yahoo.co.jp', 'www.google.co.jp') then 'search'\n        when referrer_domain in ('twitter.com', 'www.facebook.com') then 'social'\n        else 'other'\n      end as via\n      \n  from \n  \n    access_log_with_parse_info\n    \n  where\n  \n    coalesce(referrer_domain, '') not in ('', url_domain)\n    \n)\n, access_log_with_purchase_amount as (\n\n  select \n  \n    a.log_id\n    , a.via\n    , sum(\n        case \n          when p.stamp::date BETWEEN a.stamp::date and a.stamp::date + '1 day'::interval\n            then amount\n        end \n      ) as amount\n      \n    from \n    \n      access_log_with_via_info as a\n      \n      left outer join \n        \n        purchase_log as p\n        \n        on a.long_session = p.long_session\n        \n    group by\n    \n      a.log_id, a.via\n\n)\n\nselect\n\n  via\n  \n  , count(1) as via_count\n  , count(amount) as conversions\n  , avg(100. * sign(coalesce(amount, 0))) as cvr\n  , sum(coalesce(amount, 0)) as amount\n  , avg(1. * coalesce(amount, 0)) as avg_amount\n  \nfrom \n\n  access_log_with_purchase_amount\n  \n  \ngroup by via\n\norder by cvr desc\n\n;\n\n\n\n6 records\n\n\n\n\n\n\n\n\n\n\nvia\nvia_count\nconversions\ncvr\namount\navg_amount\n\n\n\n\ngoogle/search\n1\n1\n100.00000\n1000\n1000\n\n\nsocial\n3\n1\n33.33333\n3000\n1000\n\n\nother\n2\n0\n0.00000\n0\n0\n\n\nyahoo/search\n1\n0\n0.00000\n0\n0\n\n\nmynavi/affiliate\n1\n0\n0.00000\n0\n0\n\n\nsearch\n2\n0\n0.00000\n0\n0"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap06_.html#アクセスされる曜日時間帯を把握する",
    "href": "contents/sql/duckdb/sql-bigdata/chap06_.html#アクセスされる曜日時間帯を把握する",
    "title": "Webサイトでの行動を把握するためのデータ抽出",
    "section": "2.5 アクセスされる曜日、時間帯を把握する",
    "text": "2.5 アクセスされる曜日、時間帯を把握する\ndowというフォーマットは曜日を整数値で表す。\n\n\nCode\nwith \naccess_log_with_dow as (\n  \n  select\n    \n    stamp\n    \n    , date_part('dow', stamp::timestamp) as dow\n    \n    ,   cast(substring(stamp, 12, 2) as int) * 60 * 60\n      + cast(substring(stamp, 15, 2) as int) * 60\n      + cast(substring(stamp, 18, 2) as int)\n      as whole_seconds\n      \n    , 30 * 60 as interval_seconds\n    \n    \n  from \n    \n    access_log\n\n)\n, access_log_with_floor_seconds as (\n  \n  select\n    stamp\n    , dow\n    , cast((floor(whole_seconds/interval_seconds) * interval_seconds) as int) as floor_seconds\n    \n  from access_log_with_dow\n\n)\n, access_log_with_index as (\n  \n  select\n    stamp\n    , dow\n    ,    lpad(floor(floor_seconds / (60 * 60))::text , 2, '0') || ':'\n      || lpad(floor(floor_seconds % (60 * 60) / 60)::text, 2, '0') || ':'\n      || lpad(floor(floor_seconds % 60)::text , 2, '0') \n      as index_time\n  \n  from access_log_with_floor_seconds\n)\n\n\nselect\n\n  index_time\n  , count(case dow when 0 then 1 end) as sun\n  , count(case dow when 1 then 1 end) as mon\n  , count(case dow when 2 then 1 end) as tue\n  , count(case dow when 3 then 1 end) as wed\n  , count(case dow when 4 then 1 end) as thu\n  , count(case dow when 5 then 1 end) as fri\n  , count(case dow when 6 then 1 end) as sat\n\n\nfrom \n\n  access_log_with_index\n  \ngroup by \n\n  index_time\n  \norder by\n\n  index_time\n  \n;\n\n\n\n7 records\n\n\nindex_time\nsun\nmon\ntue\nwed\nthu\nfri\nsat\n\n\n\n\n12:0.:0.\n1\n1\n0\n0\n0\n0\n1\n\n\n13:0.:0.\n1\n1\n0\n0\n0\n0\n2\n\n\n14:0.:0.\n1\n1\n0\n0\n0\n0\n1\n\n\n15:0.:0.\n1\n1\n0\n0\n0\n0\n1\n\n\n16:0.:0.\n1\n0\n0\n0\n0\n0\n1\n\n\n17:0.:0.\n1\n0\n0\n0\n0\n0\n1\n\n\n18:0.:0.\n1\n0\n0\n0\n0\n0\n1\n\n\n\n\n\n\n\nCode\nselect 30 * 60;\n\n\n\n1 records\n\n\n(30 * 60)\n\n\n\n\n1800"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap06_.html#成果に結びつくページを把握する",
    "href": "contents/sql/duckdb/sql-bigdata/chap06_.html#成果に結びつくページを把握する",
    "title": "Webサイトでの行動を把握するためのデータ抽出",
    "section": "3.1 成果に結びつくページを把握する",
    "text": "3.1 成果に結びつくページを把握する\nあるセッションのページ遷移において/completeにと到達したことあるのかをフラグを立てている。\n\n\nCode\nwith\nactivity_log_with_conversion_flag as (\n  select\n    session\n    , stamp\n    , path\n    , sign(\n        sum(case when path = '/complete' then 1 else 0 end)\n        over(partition by session order by stamp desc\n             rows between unbounded preceding and current row\n             )\n      )  as has_conversion\n  from activity_log \n)\nselect * \nfrom activity_log_with_conversion_flag\norder by session, stamp;\n\n\n\nDisplaying records 1 - 10\n\n\nsession\nstamp\npath\nhas_conversion\n\n\n\n\n0fe39581\n2017-01-09 12:18:43\n/search_list\n0\n\n\n111f2996\n2017-01-09 12:18:43\n/search_list\n0\n\n\n111f2996\n2017-01-09 12:19:11\n/search_input\n0\n\n\n111f2996\n2017-01-09 12:20:10\n/\n0\n\n\n111f2996\n2017-01-09 12:21:14\n/search_input\n0\n\n\n1cf7678e\n2017-01-09 12:18:43\n/detail\n0\n\n\n1cf7678e\n2017-01-09 12:19:04\n/\n0\n\n\n36dd0df7\n2017-01-09 12:18:43\n/search_list\n0\n\n\n36dd0df7\n2017-01-09 12:19:49\n/detail\n0\n\n\n3efe001c\n2017-01-09 12:18:43\n/detail\n0"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap04_.html",
    "href": "contents/sql/duckdb/sql-bigdata/chap04_.html",
    "title": "売上を把握するためのデータ抽出",
    "section": "",
    "text": "Code\nrenv::activate(here::here())\nCode\n\ncur_dir &lt;- here::here(\"contents/sql/duckdb/sql-bigdata\")\n\nlibrary(ggplot2)\nlibrary(duckdb)\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(DBI)\nlibrary(dbplyr)\nlibrary(arrow)\nlibrary(showtext)\nlibrary(here)\nshowtext_auto()\nfont_add_google(\"Noto Sans\")"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap04_.html#日別の売上を集計",
    "href": "contents/sql/duckdb/sql-bigdata/chap04_.html#日別の売上を集計",
    "title": "売上を把握するためのデータ抽出",
    "section": "2.1 日別の売上を集計",
    "text": "2.1 日別の売上を集計\n\n\nCode\nSELECT\n  strptime(dt, '%Y-%m-%d') as dt\n  , COUNT(*) as purchase_count\n  , SUM(purchase_amount) as total_amount\n  , AVG(purchase_amount) as avg_amount\nFROM purchase_log\nGROUP BY dt\nORDER BY dt\n;\n\n\n\n\nCode\nmy_data |&gt; \n  ggplot() + \n  geom_col(aes(dt, total_amount)) + \n  theme_bw()"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap04_.html#移動平均を用いて日別の推移を見る",
    "href": "contents/sql/duckdb/sql-bigdata/chap04_.html#移動平均を用いて日別の推移を見る",
    "title": "売上を把握するためのデータ抽出",
    "section": "2.2 移動平均を用いて日別の推移を見る",
    "text": "2.2 移動平均を用いて日別の推移を見る\nSUM(purchase_amount)はGROUP BYに対しておこなわれて、 その後にAVG() OVER()がおこなわれてる。\nこれはOVERは直前の集約関数に対しておこなわれていると理解しておけば大丈夫である。\n計算結果をみてみると、dtが密になっていないのでこの状態で移動平均を計算するのは意味がない状態なのがわかる。\n\n\nCode\nSELECT\n  dt\n  , SUM(purchase_amount) total_amount\n  , AVG(SUM(purchase_amount))\n    OVER(ORDER BY dt ROWS BETWEEN 6 PRECEDING AND CURRENT ROW)\n    as seven_day_avg\n  , COUNT(*) OVER(ORDER BY dt ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) as pre_days\n  , CASE\n      WHEN\n        COUNT(*) OVER(ORDER BY dt ROWS BETWEEN 6 PRECEDING AND CURRENT ROW)\n        = 7\n      THEN\n        AVG(SUM(purchase_amount))\n        OVER(ORDER BY dt ROWS BETWEEN 6 PRECEDING AND CURRENT ROW)\n      END\n      as seven_day_avg_strict\nFROM purchase_log\nGROUP BY dt\nORDER BY dt\n;\n\n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\n\ndt\ntotal_amount\nseven_day_avg\npre_days\nseven_day_avg_strict\n\n\n\n\n2014-01-01\n13900\n13900.000\n1\nNA\n\n\n2014-02-08\n28469\n21184.500\n2\nNA\n\n\n2014-03-09\n18899\n20422.667\n3\nNA\n\n\n2014-04-11\n12394\n18415.500\n4\nNA\n\n\n2014-05-11\n2282\n15188.800\n5\nNA\n\n\n2014-06-12\n10180\n14354.000\n6\nNA\n\n\n2014-07-11\n4027\n12878.714\n7\n12878.714\n\n\n2014-08-10\n6243\n11784.857\n7\n11784.857\n\n\n2014-09-10\n3832\n8265.286\n7\n8265.286\n\n\n2014-10-11\n6716\n6524.857\n7\n6524.857"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap04_.html#当月売上の累計を求める",
    "href": "contents/sql/duckdb/sql-bigdata/chap04_.html#当月売上の累計を求める",
    "title": "売上を把握するためのデータ抽出",
    "section": "2.3 当月売上の累計を求める",
    "text": "2.3 当月売上の累計を求める\n\n\nCode\nSELECT\n  dt\n  , EXTRACT(YEAR FROM dt::date) as year\n  , sum(purchase_amount) as total_amount\nFROM purchase_log\nGROUP BY dt\nORDER BY dt\n;\n\n\n\nDisplaying records 1 - 10\n\n\ndt\nyear\ntotal_amount\n\n\n\n\n2014-01-01\n2014\n13900\n\n\n2014-02-08\n2014\n28469\n\n\n2014-03-09\n2014\n18899\n\n\n2014-04-11\n2014\n12394\n\n\n2014-05-11\n2014\n2282\n\n\n2014-06-12\n2014\n10180\n\n\n2014-07-11\n2014\n4027\n\n\n2014-08-10\n2014\n6243\n\n\n2014-09-10\n2014\n3832\n\n\n2014-10-11\n2014\n6716"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap04_.html#月別売上の昨対比を求める",
    "href": "contents/sql/duckdb/sql-bigdata/chap04_.html#月別売上の昨対比を求める",
    "title": "売上を把握するためのデータ抽出",
    "section": "2.4 月別売上の昨対比を求める",
    "text": "2.4 月別売上の昨対比を求める\n\n\nCode\nWITH \ndaily_purchase as (\n  SELECT\n    dt\n    , substring(dt, 1, 4) as year\n    , substring(dt, 6, 2) as month\n    , substring(dt, 9, 2) as date\n    , sum(purchase_amount) as purchase_amount\n  FROM purchase_log\n  GROUP BY dt\n)\nSELECT \n  month\n  , SUM(CASE year WHEN '2014' THEN purchase_amount END) as amount_2014\n  , SUM(CASE year WHEN '2015' THEN purchase_amount END) as amount_2015\n  , 100. \n    * SUM(CASE year WHEN '2015' THEN purchase_amount END)\n    / SUM(CASE year WHEN '2014' THEN purchase_amount END)\nFROM daily_purchase\nGROUP BY month\nORDER BY month\n\n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\nmonth\namount_2014\namount_2015\n((100 * sum(CASE WHEN ((“year” = ‘2015’)) THEN (purchase_amount) ELSE NULL END)) / sum(CASE WHEN ((“year” = ‘2014’)) THEN (purchase_amount) ELSE NULL END))\n\n\n\n\n01\n13900\n22111\n159.07194\n\n\n02\n28469\n11965\n42.02817\n\n\n03\n18899\n20215\n106.96333\n\n\n04\n12394\n11792\n95.14281\n\n\n05\n2282\n18087\n792.59422\n\n\n06\n10180\n18859\n185.25540\n\n\n07\n4027\n14919\n370.47430\n\n\n08\n6243\n12906\n206.72753\n\n\n09\n3832\n5696\n148.64301\n\n\n10\n6716\n13398\n199.49375"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap04_.html#zチャートで業績の推移を確認する",
    "href": "contents/sql/duckdb/sql-bigdata/chap04_.html#zチャートで業績の推移を確認する",
    "title": "売上を把握するためのデータ抽出",
    "section": "2.5 Zチャートで業績の推移を確認する",
    "text": "2.5 Zチャートで業績の推移を確認する\nZチャートとは、月次売上、売上累計、移動年計の３つの指標で構成されるグラフである。\n\n\nCode\nWITH \ndaily_purchase as (\n  SELECT\n    dt\n    , substring(dt, 1, 4) as year\n    , substring(dt, 6, 2) as month\n    , substring(dt, 9, 2) as date\n    , sum(purchase_amount) as purchase_amount\n  FROM purchase_log\n  GROUP BY dt\n)\n, monthly_purchase as (\n  SELECT\n    year\n    , month\n    , SUM(purchase_amount) as amount\n  FROM daily_purchase\n  GROUP BY year, month\n)\n, calc_index as (\n  SELECT\n    year\n    , month\n    , amount\n    , SUM(CASE WHEN year = '2015' THEN amount END)\n      OVER(ORDER BY year, month ROWS UNBOUNDED PRECEDING)\n      as agg_amount\n    , SUM(amount)\n      OVER(ORDER BY year, month ROWS BETWEEN 11 PRECEDING AND CURRENT ROW)\n      as year_avg_amount\n  FROM monthly_purchase\n  ORDER BY year, month\n)\nSELECT \n  year || '-' || month as year_month\n  , amount\n  , agg_amount\n  , year_avg_amount\nFROM calc_index\nWHERE year = '2015'\nORDER BY year_month;\n\n\n\nDisplaying records 1 - 10\n\n\nyear_month\namount\nagg_amount\nyear_avg_amount\n\n\n\n\n2015-01\n22111\n22111\n160796\n\n\n2015-02\n11965\n34076\n144292\n\n\n2015-03\n20215\n54291\n145608\n\n\n2015-04\n11792\n66083\n145006\n\n\n2015-05\n18087\n84170\n160811\n\n\n2015-06\n18859\n103029\n169490\n\n\n2015-07\n14919\n117948\n180382\n\n\n2015-08\n12906\n130854\n187045\n\n\n2015-09\n5696\n136550\n188909\n\n\n2015-10\n13398\n149948\n195591"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap04_.html#売上を把握するためのポイント",
    "href": "contents/sql/duckdb/sql-bigdata/chap04_.html#売上を把握するためのポイント",
    "title": "売上を把握するためのデータ抽出",
    "section": "2.6 売上を把握するためのポイント",
    "text": "2.6 売上を把握するためのポイント\n売上のトレンドを描画したら「なぜ」それが起きているのかをわかるようにレポートするのが大事である。\nたとえば「下降トレンド」なのは「販売回数」は同じであるが「平均購入額」が低下している。 ほかにも「定常トレンド」なのは「販売回数」は増えているが「平均購入額」が低下している。\n\n\nCode\nWITH \ndaily_purchase as (\n  SELECT\n    dt\n    , substring(dt, 1, 4) as year\n    , substring(dt, 6, 2) as month\n    , substring(dt, 9, 2) as date\n    , sum(purchase_amount) as purchase_amount\n    , count(*) as orders\n  FROM purchase_log\n  GROUP BY dt\n)\n, monthly_purchase as (\n  SELECT\n    year\n    , month\n    , sum(orders) as orders\n    , avg(purchase_amount) as avg_amount\n    , sum(purchase_amount) as monthly\n  FROM daily_purchase\n  GROUP BY year, month\n)\nSELECT \n  year || '=' || month as year_month\n  , orders\n  , avg_amount\n  , monthly\n  , sum(monthly)\n      over(partition by year order by month rows unbounded preceding)\n      as agg_amount\n  -- 12ヶ月前の売上\n  , LAG(monthly, 12)\n      over(order by year, month)\n      as last_year\n  , 100. * monthly \n    / lag(monthly, 12) over(order by year, month)\n    as rate\nFROM monthly_purchase\nORDER BY year_month;\n\n\n\nDisplaying records 1 - 10\n\n\nyear_month\norders\navg_amount\nmonthly\nagg_amount\nlast_year\nrate\n\n\n\n\n2014=01\n1\n13900\n13900\n13900\nNA\nNA\n\n\n2014=02\n1\n28469\n28469\n42369\nNA\nNA\n\n\n2014=03\n1\n18899\n18899\n61268\nNA\nNA\n\n\n2014=04\n1\n12394\n12394\n73662\nNA\nNA\n\n\n2014=05\n1\n2282\n2282\n75944\nNA\nNA\n\n\n2014=06\n1\n10180\n10180\n86124\nNA\nNA\n\n\n2014=07\n1\n4027\n4027\n90151\nNA\nNA\n\n\n2014=08\n1\n6243\n6243\n96394\nNA\nNA\n\n\n2014=09\n1\n3832\n3832\n100226\nNA\nNA\n\n\n2014=10\n1\n6716\n6716\n106942\nNA\nNA"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap04_.html#カテゴリ別の売上と小計を計算",
    "href": "contents/sql/duckdb/sql-bigdata/chap04_.html#カテゴリ別の売上と小計を計算",
    "title": "売上を把握するためのデータ抽出",
    "section": "3.1 カテゴリ別の売上と小計を計算",
    "text": "3.1 カテゴリ別の売上と小計を計算\nレポートは最初は全体的な数値の概況を伝えた腕、その内訳をさまざまな切り口でレポートすることが わかりやすい流れである。\n\n\nCode\nWITH\nsub_category_amount as (\n  SELECT\n      category     as category\n    , sub_category as sub_category\n    , sum(price)   as amount\n  FROM\n    purchase_detail_log\n  GROUP BY \n    category, sub_category\n)\n, category_amount as (\n  SELECT \n    category\n    , 'all' as sub_category\n    , sum(price) as amount\n  FROM \n    purchase_detail_log\n  GROUP BY \n    category\n)\n, total_amount as (\n  SELECT\n    'all' as category\n    , 'all' as sub_category\n    , SUM(price) as amount\n  FROM\n    purchase_detail_log\n)\n\n          SELECT category, sub_category, amount FROM sub_category_amount\nUNION ALL SELECT category, sub_category, amount FROM category_amount\nUNION ALL SELECT category, sub_category, amount FROM total_amount\n\n;\n\n\n\nDisplaying records 1 - 10\n\n\ncategory\nsub_category\namount\n\n\n\n\nmens_fashion\njacket\n200\n\n\nbook\nbusiness\n400\n\n\nladys_fashion\nbag\n200\n\n\ndvd\ndocumentary\n300\n\n\ncd\nclassic\n400\n\n\nsupplement\nprotain\n200\n\n\ngame\naccessories\n500\n\n\nfood\nmeats\n600\n\n\nfood\nfish\n600\n\n\nladys_fashion\njacket\n800\n\n\n\n\n\nUNION ALLはデータを複数回読み込むためパフォーマンスやコスト面で良好でない。 ROLLUPが実装されている場合には次のように小計を記述することができる。\nこれにより、１つずつ条件付けをおこなうことができる。 注意点としてはグループがないところはNULLになるのでCOALESCEにより置換が必要である。\n\n\nCode\nSELECT\n      COALESCE(category, 'all') as category\n    , COALESCE(sub_category, 'all') as sub_category\n    , SUM(price) as amount\nFROM\n  purchase_detail_log\nGROUP BY \n  ROLLUP(category, sub_category);\n\n\n\nDisplaying records 1 - 10\n\n\ncategory\nsub_category\namount\n\n\n\n\nfood\nall\n1200\n\n\ngame\naccessories\n500\n\n\nfood\nmeats\n600\n\n\nfood\nfish\n600\n\n\nmens_fashion\nall\n200\n\n\nsupplement\nall\n200\n\n\ndvd\nall\n300\n\n\ngame\nall\n500\n\n\nladys_fashion\nall\n1000\n\n\nbook\nall\n400"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap04_.html#abc分析",
    "href": "contents/sql/duckdb/sql-bigdata/chap04_.html#abc分析",
    "title": "売上を把握するためのデータ抽出",
    "section": "3.2 ABC分析",
    "text": "3.2 ABC分析\n\n\nCode\nWITH\nmonthly_sales as (\n  SELECT\n    category\n    , SUM(price) as amount\n  FROM \n    purchase_detail_log\n  WHERE\n    dt BETWEEN '2015-12-01' and '2015-12-31'\n  GROUP BY\n    category\n)\n, sales_composition_ratio as (\n  SELECT\n    category\n    , amount\n    -- 構成比\n    , 100. * amount / SUM(amount) OVER() as composition_ratio\n    -- 累積構成比\n    , 100. * SUM(amount) \n      OVER(ORDER BY amount DESC\n           ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)\n      / SUM(amount) OVER() as cumulative_ratio\n  FROM \n    monthly_sales\n)\n\nSELECT \n  * \n  -- 構成比率の類消えに応じてランク付け\n  , CASE \n      WHEN cumulative_ratio BETWEEN 0 AND 70 THEN 'A'\n      WHEN cumulative_ratio BETWEEN 70 AND 90 THEN 'B'\n      WHEN cumulative_ratio BETWEEN 90 AND 100 THEN 'C'\n    END as abc_rank\nFROM \n  sales_composition_ratio\nORDER BY \n  amount DESC\n;\n\n\n\n8 records\n\n\ncategory\namount\ncomposition_ratio\ncumulative_ratio\nabc_rank\n\n\n\n\nfood\n1200\n28.571429\n28.57143\nA\n\n\nladys_fashion\n1000\n23.809524\n52.38095\nA\n\n\ngame\n500\n11.904762\n64.28571\nA\n\n\ncd\n400\n9.523810\n73.80952\nB\n\n\nbook\n400\n9.523810\n83.33333\nB\n\n\ndvd\n300\n7.142857\n90.47619\nC\n\n\nmens_fashion\n200\n4.761905\n95.23810\nC\n\n\nsupplement\n200\n4.761905\n100.00000\nC"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap04_.html#ファンチャート商品の売れ行きの伸び率",
    "href": "contents/sql/duckdb/sql-bigdata/chap04_.html#ファンチャート商品の売れ行きの伸び率",
    "title": "売上を把握するためのデータ抽出",
    "section": "3.3 ファンチャート商品の売れ行きの伸び率",
    "text": "3.3 ファンチャート商品の売れ行きの伸び率\n\n\nCode\nwith\ndaily_category_amount as (\n    select\n        dt\n        , category\n        , substring( dt, 1, 4 ) as year\n        , substring( dt, 6, 2 ) as month\n        , substring( dt, 9, 2 ) as date\n        , sum( price ) as amount\n    from\n        purchase_detail_log\n    group by\n        dt, category\n)\n, monthly_category_amount as (\n    select\n        concat( year, '-', month ) as year_month\n        , category\n        , sum( amount ) as amount\n    from\n        daily_category_amount\n    group by\n        year, month, category\n)\nselect\n    year_month\n    , category\n    , amount\n    , first_value( amount )\n      over( partition by category order by year_month, category  )\n      as base_amount\n    , 100. * amount / first_value( amount ) \n      over( partition by category order by year_month, category  )\n      as rate\nfrom    \n    monthly_category_amount\norder by\n    year_month, category\n;\n\n\n\n8 records\n\n\nyear_month\ncategory\namount\nbase_amount\nrate\n\n\n\n\n2015-12\nbook\n400\n400\n100\n\n\n2015-12\ncd\n400\n400\n100\n\n\n2015-12\ndvd\n300\n300\n100\n\n\n2015-12\nfood\n1200\n1200\n100\n\n\n2015-12\ngame\n500\n500\n100\n\n\n2015-12\nladys_fashion\n1000\n1000\n100\n\n\n2015-12\nmens_fashion\n200\n200\n100\n\n\n2015-12\nsupplement\n200\n200\n100"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap04_.html#メモタイル化",
    "href": "contents/sql/duckdb/sql-bigdata/chap04_.html#メモタイル化",
    "title": "売上を把握するためのデータ抽出",
    "section": "3.4 メモ：タイル化",
    "text": "3.4 メモ：タイル化\n\n\nCode\n\nSELECT *, ntile(3) OVER() c\nFROM(\n  SELECT unnest(generate_series(10)) a, random() b\n  ORDER BY b\n)\n;\n\n\n\nDisplaying records 1 - 10\n\n\na\nb\nc\n\n\n\n\n4\n0.1124412\n1\n\n\n0\n0.1850280\n1\n\n\n10\n0.3535486\n1\n\n\n6\n0.3607514\n1\n\n\n1\n0.4936704\n2\n\n\n7\n0.5715048\n2\n\n\n5\n0.6519861\n2\n\n\n9\n0.8438557\n2\n\n\n3\n0.8482401\n3\n\n\n8\n0.9529501\n3"
  },
  {
    "objectID": "contents/sql/duckdb/mytips/02_.html",
    "href": "contents/sql/duckdb/mytips/02_.html",
    "title": "クイックメモ",
    "section": "",
    "text": "Code\nrenv::activate(here::here())\n\n\n\n\nCode\ncur_dir &lt;- here::here(\"contents/sql/duckdb/mytips\")\n\nlibrary(ggplot2)\nlibrary(duckdb)\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(DBI)\nlibrary(dbplyr)\nlibrary(arrow)\nlibrary(showtext)\nlibrary(here)\nshowtext_auto()\nfont_add_google(\"Noto Sans\")\n\n\n\n1 Setup\n\n\nCode\ncon &lt;- dbConnect(duckdb(\":memory:\"))\n\n\n\n\nCode\nINSTALL icu;\nINSTALL spatial;\nINSTALL httpfs;\nINSTALL json;\n\n\n\n\nCode\nLOAD icu;\nLOAD spatial;\nLOAD httpfs;\nLOAD json;\n\n\n\n\nCode\nSHOW ALL TABLES;\n\n\n\n0 records\n\n\ndatabase\nschema\nname\ncolumn_names\ncolumn_types\ntemporary\n\n\n\n\n\n\n\n\n\nCode\nSELECT DISTINCT * FROM duckdb_functions() WHERE function_name LIKE 'st_%' ORDER BY function_name;\n\n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndatabase_name\ndatabase_oid\nschema_name\nfunction_name\nfunction_type\ndescription\ncomment\nreturn_type\nparameters\nparameter_types\nvarargs\nmacro_definition\nhas_side_effects\ninternal\nfunction_oid\nexample\nstability\n\n\n\n\nsystem\n0\nmain\nst_read_meta\ntable\nNA\nNA\nNA\ncol0\nVARCHAR\nNA\nNA\nNA\nTRUE\n1531\nNA\nNA\n\n\nsystem\n0\nmain\nst_read_meta\ntable\nNA\nNA\nNA\ncol0\nVARCHAR[]\nNA\nNA\nNA\nTRUE\n1531\nNA\nNA\n\n\nsystem\n0\nmain\nstarts_with\nscalar\nReturns true if string begins with search_string\nNA\nBOOLEAN\nstring , search_string\nVARCHAR, VARCHAR\nNA\nNA\nFALSE\nTRUE\n934\nstarts_with(‘abc’,‘a’)\nCONSISTENT\n\n\nsystem\n0\nmain\nstats\nscalar\nReturns a string with statistics about the expression. Expression can be a column, constant, or SQL expression\nNA\nVARCHAR\nexpression\nANY\nNA\nNA\nTRUE\nTRUE\n936\nstats(5)\nVOLATILE\n\n\nsystem\n0\nmain\nstddev\naggregate\nReturns the sample standard deviation\nNA\nDOUBLE\nx\nDOUBLE\nNA\nNA\nFALSE\nTRUE\n938\nsqrt(var_samp(x))\nCONSISTENT\n\n\nsystem\n0\nmain\nstddev_pop\naggregate\nReturns the population standard deviation.\nNA\nDOUBLE\nx\nDOUBLE\nNA\nNA\nFALSE\nTRUE\n940\nsqrt(var_pop(x))\nCONSISTENT\n\n\nsystem\n0\nmain\nstddev_samp\naggregate\nReturns the sample standard deviation\nNA\nDOUBLE\nx\nDOUBLE\nNA\nNA\nFALSE\nTRUE\n942\nsqrt(var_samp(x))\nCONSISTENT\n\n\nsystem\n0\nmain\nstorage_info\npragma\nNA\nNA\nNA\ncol0\nVARCHAR\nNA\nNA\nNA\nTRUE\n302\nNA\nNA\n\n\nsystem\n0\nmain\nstr_split\nscalar\nSplits the string along the separator\nNA\nVARCHAR[]\nstring , separator\nVARCHAR, VARCHAR\nNA\nNA\nFALSE\nTRUE\n944\nstring_split(‘hello-world’, ‘-’)\nCONSISTENT\n\n\nsystem\n0\nmain\nstr_split_regex\nscalar\nSplits the string along the regex\nNA\nVARCHAR[]\nstring , separator\nVARCHAR, VARCHAR\nNA\nNA\nFALSE\nTRUE\n946\nstring_split_regex(‘hello␣world; 42’, ‘;?␣’)\nCONSISTENT\n\n\n\n\n\n\n\n2 QUALIFY\nWINDOW()関数の結果を使ったクエリができる。データの読込が１度であるため、相関サブクエリでフィルターしているときにはより効率的、高速になることがある。履歴データから最新時間断面を抽出することも簡単にできる。\n\n\nCode\nCREATE OR REPLACE TABLE Temp (x INTEGER, y STRING);\nINSERT INTO Temp VALUES \n(1, 'a'), \n(2, 'a'), \n(3, 'b'), \n(-1, 'b');\n\n\n\n\nCode\nSELECT * FROM Temp;\n\n\n\n4 records\n\n\nx\ny\n\n\n\n\n1\na\n\n\n2\na\n\n\n3\nb\n\n\n-1\nb\n\n\n\n\n\n次の用にQUAFLIFYにつづいてWindow関数を使うことで、Widnow関数の結果に対するフィルタが行える。 これをIdと時間でおこなえばIdごと最新の時間断面データを作成することができる。\n\n\nCode\nSELECT * \nFROM Temp\nQUALIFY ROW_NUMBER() \n  OVER(\n    PARTITION BY y\n    ORDER BY x DESC\n  ) = 1\nORDER BY y\n;\n\n\n\n2 records\n\n\nx\ny\n\n\n\n\n2\na\n\n\n3\nb\n\n\n\n\n\n\n\n3 Disconnect\n\n\nCode\ndbDisconnect(con, shutdown=TRUE)\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/sql/duckdb/documentaion/index.html",
    "href": "contents/sql/duckdb/documentaion/index.html",
    "title": "DuckDB Documentation",
    "section": "",
    "text": "1 はじめに\n\nDuckDBの勉強ノートです.\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/sql/duckdb/documentaion/guide_02_configuration.html",
    "href": "contents/sql/duckdb/documentaion/guide_02_configuration.html",
    "title": "Configuration",
    "section": "",
    "text": "Code\nrenv::activate(here::here())\ncur_dir &lt;- here::here(\"contents/sql/duckdb/documentation\")\nCode\nlibrary(ggplot2)\nlibrary(duckdb)\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(DBI)\nlibrary(dbplyr)\nlibrary(arrow)\nlibrary(showtext)\nshowtext_auto()\nfont_add_google(\"Noto Sans\")"
  },
  {
    "objectID": "contents/sql/duckdb/documentaion/guide_02_configuration.html#list-of-supported-pragma-statements",
    "href": "contents/sql/duckdb/documentaion/guide_02_configuration.html#list-of-supported-pragma-statements",
    "title": "Configuration",
    "section": "3.1 List of Supported PRAGMA Statements",
    "text": "3.1 List of Supported PRAGMA Statements\n\n\nCode\nPRAGMA database_list;\n\n\n\n1 records\n\n\nseq\nname\nfile\n\n\n\n\n1078\nmemory\nNA\n\n\n\n\n\n\n\nCode\nPRAGMA show_tables;\n\n\n\n0 records\n\n\nname\n\n\n\n\n\n\n\nいわゆるDESCRIBEと同じ効果を出す。\n\n\nCode\nPRAGMA show_tables_expanded;\n\n\n\n0 records\n\n\ndatabase\nschema\nname\ncolumn_names\ncolumn_types\ntemporary\n\n\n\n\n\n\n\n\n\nCode\nPRAGMA functions;\n\n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\n\n\nname\ntype\nparameters\nvarargs\nreturn_type\nside_effects\n\n\n\n\n!__postfix\nSCALAR\nINTEGER\nNA\nHUGEINT\nFALSE\n\n\n!~~\nSCALAR\nVARCHAR, VARCHAR\nNA\nBOOLEAN\nFALSE\n\n\n!~~*\nSCALAR\nVARCHAR, VARCHAR\nNA\nBOOLEAN\nFALSE\n\n\n%\nSCALAR\nDOUBLE, DOUBLE\nNA\nDOUBLE\nFALSE\n\n\n%\nSCALAR\nFLOAT, FLOAT\nNA\nFLOAT\nFALSE\n\n\n%\nSCALAR\nHUGEINT, HUGEINT\nNA\nHUGEINT\nFALSE\n\n\n%\nSCALAR\nBIGINT, BIGINT\nNA\nBIGINT\nFALSE\n\n\n%\nSCALAR\nSMALLINT, SMALLINT\nNA\nSMALLINT\nFALSE\n\n\n%\nSCALAR\nTINYINT, TINYINT\nNA\nTINYINT\nFALSE\n\n\n%\nSCALAR\nINTEGER, INTEGER\nNA\nINTEGER\nFALSE"
  },
  {
    "objectID": "contents/sql/duckdb/documentaion/guide_02_configuration.html#table-info",
    "href": "contents/sql/duckdb/documentaion/guide_02_configuration.html#table-info",
    "title": "Configuration",
    "section": "3.2 Table info",
    "text": "3.2 Table info\n\n\nCode\nCREATE OR REPLACE TABLE tbl AS SELECT * FROM read_parquet('./penguins.parquet');\n\n\n\n\nCode\nPRAGMA table_info('tbl');\n\n\n\n8 records\n\n\ncid\nname\ntype\nnotnull\ndflt_value\npk\n\n\n\n\n0\nspecies\nVARCHAR\nFALSE\nNA\nFALSE\n\n\n1\nisland\nVARCHAR\nFALSE\nNA\nFALSE\n\n\n2\nbill_length_mm\nDOUBLE\nFALSE\nNA\nFALSE\n\n\n3\nbill_depth_mm\nDOUBLE\nFALSE\nNA\nFALSE\n\n\n4\nflipper_length_mm\nINTEGER\nFALSE\nNA\nFALSE\n\n\n5\nbody_mass_g\nINTEGER\nFALSE\nNA\nFALSE\n\n\n6\nsex\nVARCHAR\nFALSE\nNA\nFALSE\n\n\n7\nyear\nINTEGER\nFALSE\nNA\nFALSE\n\n\n\n\n\n\n\nCode\nCALL pragma_table_info('tbl');\n\n\n\n8 records\n\n\ncid\nname\ntype\nnotnull\ndflt_value\npk\n\n\n\n\n0\nspecies\nVARCHAR\nFALSE\nNA\nFALSE\n\n\n1\nisland\nVARCHAR\nFALSE\nNA\nFALSE\n\n\n2\nbill_length_mm\nDOUBLE\nFALSE\nNA\nFALSE\n\n\n3\nbill_depth_mm\nDOUBLE\nFALSE\nNA\nFALSE\n\n\n4\nflipper_length_mm\nINTEGER\nFALSE\nNA\nFALSE\n\n\n5\nbody_mass_g\nINTEGER\nFALSE\nNA\nFALSE\n\n\n6\nsex\nVARCHAR\nFALSE\nNA\nFALSE\n\n\n7\nyear\nINTEGER\nFALSE\nNA\nFALSE"
  },
  {
    "objectID": "contents/sql/duckdb/documentaion/guide_02_configuration.html#memoory-limit",
    "href": "contents/sql/duckdb/documentaion/guide_02_configuration.html#memoory-limit",
    "title": "Configuration",
    "section": "3.3 Memoory Limit",
    "text": "3.3 Memoory Limit\n#| connection: con\nSET memory_limit = '1GB';\nSET max_memory = '1GB';"
  },
  {
    "objectID": "contents/sql/duckdb/documentaion/guide_02_configuration.html#threads",
    "href": "contents/sql/duckdb/documentaion/guide_02_configuration.html#threads",
    "title": "Configuration",
    "section": "3.4 Threads",
    "text": "3.4 Threads\n\n\nCode\nSET threads = 4;"
  },
  {
    "objectID": "contents/sql/duckdb/documentaion/guide_02_configuration.html#database-size",
    "href": "contents/sql/duckdb/documentaion/guide_02_configuration.html#database-size",
    "title": "Configuration",
    "section": "3.5 Database Size",
    "text": "3.5 Database Size\n\n\nCode\nCALL pragma_database_size();\n\n\n\n1 records\n\n\n\n\n\n\n\n\n\n\n\n\n\ndatabase_name\ndatabase_size\nblock_size\ntotal_blocks\nused_blocks\nfree_blocks\nwal_size\nmemory_usage\nmemory_limit\n\n\n\n\nmemory\n0 bytes\n0\n0\n0\n0\n0 bytes\n168.0 KiB\n9.3 GiB"
  },
  {
    "objectID": "contents/sql/duckdb/documentaion/guide_02_configuration.html#progress-bar",
    "href": "contents/sql/duckdb/documentaion/guide_02_configuration.html#progress-bar",
    "title": "Configuration",
    "section": "3.6 Progress Bar",
    "text": "3.6 Progress Bar\n\n\nCode\nPRAGMA enable_progress_bar;\n\n\n\n0 records\n\n\nSuccess"
  },
  {
    "objectID": "contents/sql/duckdb/documentaion/guide_02_configuration.html#returning-erros-as-json",
    "href": "contents/sql/duckdb/documentaion/guide_02_configuration.html#returning-erros-as-json",
    "title": "Configuration",
    "section": "3.7 Returning Erros as JSON",
    "text": "3.7 Returning Erros as JSON\n\n\nCode\nSET errors_as_json = true;"
  },
  {
    "objectID": "contents/sql/duckdb/documentaion/guide_02_configuration.html#secrets",
    "href": "contents/sql/duckdb/documentaion/guide_02_configuration.html#secrets",
    "title": "Configuration",
    "section": "3.8 Secrets",
    "text": "3.8 Secrets\nこんな感じで作成するみたい。\nCREATE SECRET secret1 (\n    TYPE S3,\n    KEY_ID 'my_secret_key1',\n    SECRET 'my_secret_value1',\n    SCOPE 's3://my-bucket'\n);\n削除するときには次のようにする。\nDROP PERSISTENT SECRET my_persistent_secret;"
  },
  {
    "objectID": "contents/sql/duckdb/SpatialDataAnalysiswithDuckDB/working.html",
    "href": "contents/sql/duckdb/SpatialDataAnalysiswithDuckDB/working.html",
    "title": "Spatial Data Analytics With Duckdb",
    "section": "",
    "text": "Code\nrenv::activate(here::here())\n\n\n\n\nCode\n\ncur_dir &lt;- here::here(\"contents/sql/duckdb/SpatialDataAnalysiswithDuckDB\")\n\nlibrary(ggplot2)\nlibrary(duckdb)\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(DBI)\nlibrary(dbplyr)\nlibrary(arrow)\nlibrary(showtext)\nlibrary(here)\nshowtext_auto()\nfont_add_google(\"Noto Sans\")\n\n\n\n1 Setup\n\n\nCode\ncon &lt;- dbConnect(duckdb(here(cur_dir, \"data.db\")))\n\n\n\n\nCode\nINSTALL icu;\nINSTALL spatial;\nINSTALL httpfs;\nINSTALL json;\n\n\n\n\nCode\nLOAD icu;\nLOAD spatial;\nLOAD httpfs;\nLOAD json;\nSET s3_region='us-west-2';\n\n\n\n\nCode\nSHOW ALL TABLES;\n\n\n\n4 records\n\n\n\n\n\n\n\n\n\n\ndatabase\nschema\nname\ncolumn_names\ncolumn_types\ntemporary\n\n\n\n\ndata\nmain\npark_ist\nlocality , region , postcode , freeform , categories_main , names , CAST(confidence AS “json”), CAST(bbox AS “json”) , geom\nVARCHAR , VARCHAR , VARCHAR , VARCHAR , VARCHAR , VARCHAR , JSON , JSON , GEOMETRY\nFALSE\n\n\ndata\nmain\nplaces\nid , updatetime, version , names , categories, confidence, websites , socials , emails , phones , brand , addresses , sources , bbox , geometry , theme , type , country\nVARCHAR , VARCHAR , INTEGER , MAP(VARCHAR, MAP(VARCHAR, VARCHAR)[]) , STRUCT(main VARCHAR, alternate VARCHAR[]) , DOUBLE , VARCHAR[] , VARCHAR[] , VARCHAR[] , VARCHAR[] , STRUCT(“names” MAP(VARCHAR, MAP(VARCHAR, VARCHAR)[]), wikidata VARCHAR), MAP(VARCHAR, VARCHAR)[] , MAP(VARCHAR, VARCHAR)[] , STRUCT(minx DOUBLE, maxx DOUBLE, miny DOUBLE, maxy DOUBLE) , BLOB , VARCHAR , VARCHAR , VARCHAR\nFALSE\n\n\ndata\nmain\npoi_ist\nlocality , region , postcode , freeform , categories_main , names , CAST(confidence AS “json”), CAST(bbox AS “json”) , geom\nVARCHAR , VARCHAR , VARCHAR , VARCHAR , VARCHAR , VARCHAR , JSON , JSON , GEOMETRY\nFALSE\n\n\ndata\nmain\nturkey_places\nlocality , region , postcode , freeform , categories_main , names , CAST(confidence AS “json”), CAST(bbox AS “json”) , geom\nVARCHAR , VARCHAR , VARCHAR , VARCHAR , VARCHAR , VARCHAR , JSON , JSON , GEOMETRY\nFALSE\n\n\n\n\n\n\n\n2 はじめに\nここの追試です。 duckdbを使った空間分析です。\n\n\n3 note\n約６０００万件のデータをサンプルデータとして扱う。・・・と思ったけどどうやらメモリ不足になるのでここでは少しだけ抽出する。\n\n\nCode\ncreate or replace table places as \nselect * from read_parquet('s3://overturemaps-us-west-2/release/2023-07-26-alpha.0/theme=places/type=*/*') limit 500000;\n\n\n\n\nCode\ndescribe places;\n\n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\n\n\ncolumn_name\ncolumn_type\nnull\nkey\ndefault\nextra\n\n\n\n\nid\nVARCHAR\nYES\nNA\nNA\nNA\n\n\nupdatetime\nVARCHAR\nYES\nNA\nNA\nNA\n\n\nversion\nINTEGER\nYES\nNA\nNA\nNA\n\n\nnames\nMAP(VARCHAR, MAP(VARCHAR, VARCHAR)[])\nYES\nNA\nNA\nNA\n\n\ncategories\nSTRUCT(main VARCHAR, alternate VARCHAR[])\nYES\nNA\nNA\nNA\n\n\nconfidence\nDOUBLE\nYES\nNA\nNA\nNA\n\n\nwebsites\nVARCHAR[]\nYES\nNA\nNA\nNA\n\n\nsocials\nVARCHAR[]\nYES\nNA\nNA\nNA\n\n\nemails\nVARCHAR[]\nYES\nNA\nNA\nNA\n\n\nphones\nVARCHAR[]\nYES\nNA\nNA\nNA\n\n\n\n\n\n\n\nCode\nselect count(*) as cnt from places;\n\n\n\n1 records\n\n\ncnt\n\n\n\n\n5e+05\n\n\n\n\n\nMAP型を表示することができないので変換する。\n\n\nCode\nselect\n  confidence\n  , cast(names as json) naems\n  , categories\n  , cast(brand as json) brand\n  , cast(addresses as json) addresses\nfrom \n  places\nlimit \n  10;\n\n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\n\nconfidence\nnaems\ncategories\nbrand\naddresses\n\n\n\n\n0.5989174\n{“common”:[{“value”:“Bronwydd Veterinary Surgery”,“language”:“local”}]}\nveterinarian\n{“names”:null,“wikidata”:null}\n[{“postcode”:“LL57 2NX”,“freeform”:“Ffordd Bronwydd”,“country”:“GB”}]\n\n\n0.9108787\n{“common”:[{“value”:“Truchi Kennedy”,“language”:“local”}]}\npark\n{“names”:null,“wikidata”:null}\n[{“country”:“AR”}]\n\n\n0.9628990\n{“common”:[{“value”:“Studio Bella”,“language”:“local”}]}\nbeauty_salon\n{“names”:null,“wikidata”:null}\n[{“locality”:“São Paulo”,“postcode”:“02114-001”,“freeform”:“Rua José Wasth Rodrigues, 134”,“region”:“SP”,“country”:“BR”}]\n\n\n0.4756328\n{“common”:[{“value”:“เต้าหู้นมสด \"แม่หนูชวนชิม\" ทับสะแก”,“language”:“local”}]}\nthai_restaurant\n{“names”:null,“wikidata”:null}\n[{“locality”:“Thap Sakae”,“postcode”:“77130”,“freeform”:“6/3 ม.5 ต.เขาล้าน อ.ทับสะแก จ.ประจวบคีรีขันธ์”,“country”:“TH”}]\n\n\n0.5783658\n{“common”:[{“value”:“ร้านซ่อมรถโกริน”,“language”:“local”}]}\ncommunity_services_non_profits\n{“names”:null,“wikidata”:null}\n[{“locality”:“Krabi”,“freeform”:“ม.2อ่าวลึกเหนือ อ.อ่าวลึก จ.กระบี่”,“country”:“TH”}]\n\n\n0.5397370\n{“common”:[{“value”:“Sunrise Textile Park 2”,“language”:“local”}]}\npark\n{“names”:null,“wikidata”:null}\n[{“locality”:“Olpad”,“postcode”:“394130”,“freeform”:“Kareli”,“country”:“IN”}]\n\n\n0.7074041\n{“common”:[{“value”:“วัดพระธาตุดอยสุเทพราชวรมหาวิหาร จ,เชียงใหม่”,“language”:“local”}]}\ntravel\n{“names”:null,“wikidata”:null}\n[{“locality”:“Chiang Mai”,“country”:“TH”}]\n\n\n0.9865023\n{“common”:[{“value”:“Cornerstone”,“language”:“local”}]}\nchurch_cathedral\n{“names”:null,“wikidata”:null}\n[{“locality”:“Windham”,“postcode”:“04062-4405”,“freeform”:“48 Cottage Rd”,“region”:“ME”,“country”:“US”}]\n\n\n0.2839491\n{“common”:[{“value”:“Reims Rugby Team”,“language”:“local”}]}\nsports_club_and_league\n{“names”:null,“wikidata”:null}\n[{“locality”:“Reims”,“postcode”:“51100”,“freeform”:“59 Rue Pierre Taittinger”,“region”:“null”,“country”:“FR”}]\n\n\n0.4486956\n{“common”:[{“value”:“Better Garden G R A Onitsha”,“language”:“local”}]}\nbeer_garden\n{“names”:null,“wikidata”:null}\n[{“locality”:“Onitsha”,“country”:“NG”}]\n\n\n\n\n\n\n\nCode\nselect\n  replace(json_extract(cast(addresses as json), '$[0].country')::varchar, '\"', '') as country\nfrom \n  places\nlimit 5;\n\n\n\n5 records\n\n\ncountry\n\n\n\n\nGB\n\n\nAR\n\n\nBR\n\n\nTH\n\n\nTH\n\n\n\n\n\nカラムを作成してデータをセットする。\n\n\nCode\nalter table places add column country varchar;\nupdate places set country = replace(json_extract(cast(places.addresses as json), '$[0].country')::varchar, '\"', '')\n\n\nトルコの情報を抽出する。\n\n\nCode\n create or replace table turkey_places as (\n              select\n                     replace(json_extract(places.addresses::json,'$[0].locality'),'\"','')::varchar as locality,\n                     replace(json_extract(places.addresses::json,'$[0].region'),'\"','')::varchar as region,\n                     replace(json_extract(places.addresses::json,'$[0].postcode'),'\"','')::varchar as postcode,\n                     replace(json_extract(places.addresses::json,'$[0].freeform'),'\"','')::varchar as freeform,\n\n                     categories.main as categories_main,\n\n                     replace(json_extract(places.names::json,'$.common[0].value'),'\"','')::varchar as names,\n                     cast(confidence as json),\n                     cast(bbox as json),\n                     st_transform(st_point(st_y(st_geomfromwkb(geometry)),st_x(st_geomfromwkb(geometry))),'EPSG:4326','EPSG:3857') as geom\n\n              from places \n                     where country ='TR' \n       )\n\n\n\n\nCode\nselect * from turkey_places limit 5\n\n\n\n5 records\n\n\n\n\n\n\n\n\n\n\n\n\n\nlocality\nregion\npostcode\nfreeform\ncategories_main\nnames\nCAST(confidence AS “json”)\nCAST(bbox AS “json”)\ngeom\n\n\n\n\nNA\nNA\nNA\nNA\npublic_plaza\nElite Mamak Society\n0.6304769515991211\n{“minx”:32.919501,“maxx”:32.919501,“miny”:39.916317,“maxy”:39.916317}\n00, 00, 18, 00, 00, 00, 00, 00, 00, 00, 00, 00, 01, 00, 00, 00, ae, 98, 53, 0b, 63, f5, 4b, 41, 47, 08, a8, 48, 07, 84, 52, 41\n\n\nKonya\n42\n42120\nİlkay Sokak 8\nprofessional_services\nAGRO TÖKE\n0.655314564704895\n{“minx”:32.522156,“maxx”:32.522156,“miny”:37.93727,“maxy”:37.93727}\n00, 00, 18, 00, 00, 00, 00, 00, 00, 00, 00, 00, 01, 00, 00, 00, 00, b4, 36, ec, fe, 9e, 4b, 41, b5, 55, 0c, fd, 71, 6f, 51, 41\n\n\nKayseri\nNA\n38010\nUfuk Sokak 1\nlocal_and_state_government_offices\nSosyal Güvenlik Kurumu İl Müdürlüğü\n0.6062818169593811\n{“minx”:35.48468,“maxx”:35.48468,“miny”:38.72812,“maxy”:38.72812}\n00, 00, 18, 00, 00, 00, 00, 00, 00, 00, 00, 00, 01, 00, 00, 00, 6f, 91, 18, 41, 1c, 23, 4e, 41, 4e, 9e, 49, 65, 0c, dd, 51, 41\n\n\nAnkara\n06\n06300\n492. Cadde 31/B\ncar_dealer\nEYMEN OTO Kiralama\n0.5934379696846008\n{“minx”:32.8882484,“maxx”:32.8882484,“miny”:39.9881714,“maxy”:39.9881714}\n00, 00, 18, 00, 00, 00, 00, 00, 00, 00, 00, 00, 01, 00, 00, 00, af, f5, 50, 88, 97, ee, 4b, 41, 98, f9, d1, e1, 37, 8e, 52, 41\n\n\nAdana\n01\n01120\n62017. Sokak 13\ncontractor\nGökpınar İnşaat\n0.6233547925949097\n{“minx”:35.3315582,“maxx”:35.3315582,“miny”:36.9957809,“maxy”:36.9957809}\n00, 00, 18, 00, 00, 00, 00, 00, 00, 00, 00, 00, 01, 00, 00, 00, 27, 42, ac, 88, d1, 01, 4e, 41, a8, b3, c9, ad, 7d, ee, 50, 41\n\n\n\n\n\nイスタンブールのPOIデータを作成する。\n\n\nCode\n    create or replace table park_ist as (\n        select * from turkey_places where locality = 'İstanbul' and categories_main='park'   \n    );\n\n    create or replace table poi_ist as (\n        select * from turkey_places where locality = 'İstanbul' and categories_main &lt;&gt; 'park'\n    )\n\n\n\n\nCode\nselect count(*) from poi_ist;\n\n\n\n1 records\n\n\ncount_star()\n\n\n\n\n1557\n\n\n\n\n\n\n\nCode\nselect count(*) from park_ist;\n\n\n\n1 records\n\n\ncount_star()\n\n\n\n\n2\n\n\n\n\n\nPOIのうち半径500メートル以内に公園があるものを抽出する。普通に直積を作ってフィルターしている。\n\n\nCode\nselect  \n  poi_ist.region as poi_ist_region,\n  poi_ist.freeform as poi_ist_freeform,\n  poi_ist.categories_main as poi_ist_categori,\n  park_ist.categories_main as park_categori, \n  park_ist.names as park_names,\n  park_ist.freeform as park_ist_freeform,\n  st_distance(poi_ist.geom,park_ist.geom) as dist,\n  ST_AsText(poi_ist.geom) as geom,\n  ST_AsText(park_ist.geom) as geom2\n\nfrom poi_ist, park_ist \n\nwhere ST_DWithin(poi_ist.geom, park_ist.geom, 500) \n\n\n\n1 records\n\n\n\n\n\n\n\n\n\n\n\n\n\npoi_ist_region\npoi_ist_freeform\npoi_ist_categori\npark_categori\npark_names\npark_ist_freeform\ndist\ngeom\ngeom2\n\n\n\n\n34\nÇakmak Sokak 2\nsocial_service_organizations\npark\nHayat Park Inci Kule\nVeysel Karani Caddesi 16\n393.8883\nPOINT (3211578.185300193 5021454.134304489)\nPOINT (3211587.1019914057 5021060.346982889)\n\n\n\n\n\n\n\n4 Disconnect\n\n\nCode\ndbDisconnect(con, shutdown=TRUE)\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/test/R/sub_directory/renv.html",
    "href": "contents/test/R/sub_directory/renv.html",
    "title": "renv",
    "section": "",
    "text": "1 renvはどのように指定すればいいか\n\nプロジェクトファイルがあるフォルダで指定するときはそのフォルダになる\nプロジェクトファイルがないフォルダで指定するときはルートフォルダになる\n正確には１番近い親フォルダになっているみたい\nなのでこの場合のhereの挙動には注意する\n\n\n\nCode\nhere::here()\n#&gt; [1] \"H:/Dropbox/R/Workspace/RTipsSite/contents/test/R\"\ncur_dir &lt;- here::here(\"contents\", \"test\", \"R\")\nprint(cur_dir)\n#&gt; [1] \"H:/Dropbox/R/Workspace/RTipsSite/contents/test/R/contents/test/R\"\n# renv::init(cur_dir)\n\nprint(getwd())\n#&gt; [1] \"H:/Dropbox/R/Workspace/RTipsSite/contents/test/R/sub_directory\"\nprint(here::here())\n#&gt; [1] \"H:/Dropbox/R/Workspace/RTipsSite/contents/test/R\"\n\n\n\n\nCode\nlibrary(here)\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/test/bash/quick_sample.html",
    "href": "contents/test/bash/quick_sample.html",
    "title": "Quick Sample",
    "section": "",
    "text": "engine: knitrを追加することで動作\nカレントディレクトリはこのファイルがある場所\nルートディレクトリになっていないことに注意\n\n\n\nCode\nls -la | cat\n#&gt; total 0\n#&gt; drwxrwxrwx 1 asozan asozan 4096 Sep 18 22:06 .\n#&gt; drwxrwxrwx 1 asozan asozan 4096 Sep 18 21:52 ..\n#&gt; -rwxrwxrwx 1 asozan asozan  376 Sep 18 22:06 quick_sample.qmd\n#&gt; -rwxrwxrwx 1 asozan asozan  402 Sep 18 22:06 quick_sample.rmarkdown\n#&gt; drwxrwxrwx 1 asozan asozan 4096 Sep 18 22:06 quick_sample_cache\n#&gt; drwxrwxrwx 1 asozan asozan 4096 Sep 18 21:48 日本語フォルダ\n\n\n\n\nCode\nls -la\n#&gt; total 0\n#&gt; drwxrwxrwx 1 asozan asozan 4096 Sep 18 22:06 .\n#&gt; drwxrwxrwx 1 asozan asozan 4096 Sep 18 21:52 ..\n#&gt; -rwxrwxrwx 1 asozan asozan  376 Sep 18 22:06 quick_sample.qmd\n#&gt; -rwxrwxrwx 1 asozan asozan  402 Sep 18 22:06 quick_sample.rmarkdown\n#&gt; drwxrwxrwx 1 asozan asozan 4096 Sep 18 22:06 quick_sample_cache\n#&gt; drwxrwxrwx 1 asozan asozan 4096 Sep 18 21:48 日本語フォルダ\n\n\n\n\nCode\ncat 日本語フォルダ/日本語ファイル.txt\n#&gt; \n#&gt; 日本語テキストです\n\n\npwdで確認するとWSLでマウントしたときのディレクトリが カレントディレクトリになっていることがわかる。\n\n\nCode\npwd\n#&gt; /mnt/h/Dropbox/R/Workspace/RTipsSite/contents/test/bash\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/test/R2/renv.html",
    "href": "contents/test/R2/renv.html",
    "title": "renv",
    "section": "",
    "text": "1 hereでrenvはどのように指定すればいいか\n\nプロジェクトファイルがあるフォルダで指定するときはそのフォルダになる\nプロジェクトファイルがないフォルダで指定するときはルートフォルダになる\n正確には１番近い親フォルダになっているみたい\nなのでこの場合のhereの挙動には注意する\n\n\n\nCode\nhere::here()\n#&gt; [1] \"H:/Dropbox/R/Workspace/RTipsSite\"\ncur_dir &lt;- here::here(\"contents\", \"test\", \"R\")\nprint(cur_dir)\n#&gt; [1] \"H:/Dropbox/R/Workspace/RTipsSite/contents/test/R\"\n# renv::init(cur_dir)\n\nprint(getwd())\n#&gt; [1] \"H:/Dropbox/R/Workspace/RTipsSite/contents/test/R2\"\nprint(here::here())\n#&gt; [1] \"H:/Dropbox/R/Workspace/RTipsSite\"\n\n\n\n\nCode\nlibrary(here)\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/notes/ggplot2/working.html",
    "href": "contents/notes/ggplot2/working.html",
    "title": "ggplot2 Tips",
    "section": "",
    "text": "Code\ncur_dir &lt;- here::here(\"contents/notes/ggplot2\")\n\n\nshowtext::showtext_auto()\nsysfonts::font_add_google(\"Noto Sans JP\")\n\npacman::p_load(\n    tidyverse, \n    here, \n    showtext,\n    ggplot2, \n    ggridges,\n    cowplot, \n    ggsci, \n    GGally,\n    ggprism,\n    palmerpenguins, \n    ggalluvial, \n    waffle,\n    ggokabeito, \n    patchwork\n)"
  },
  {
    "objectID": "contents/notes/ggplot2/working.html#reference",
    "href": "contents/notes/ggplot2/working.html#reference",
    "title": "ggplot2 Tips",
    "section": "1.1 Reference",
    "text": "1.1 Reference\n\nggplot2\nrmarkdown\nggplot2 extensions"
  },
  {
    "objectID": "contents/notes/ggplot2/working.html#リファレンンスラインの配置",
    "href": "contents/notes/ggplot2/working.html#リファレンンスラインの配置",
    "title": "ggplot2 Tips",
    "section": "2.1 リファレンンスラインの配置",
    "text": "2.1 リファレンンスラインの配置\n\n\nCode\niris |&gt; \n    ggplot(aes(Species, Sepal.Width, color = Species)) + \n    geom_jitter() + \n    stat_summary(fun = mean, geom = \"point\", linewidth = 3, size = 10, fill = \"white\") +\n    theme_bw() + \n    scale_color_aaas()\n#&gt; Warning in stat_summary(fun = mean, geom = \"point\", linewidth = 3, size = 10, :\n#&gt; Ignoring unknown parameters: `linewidth`\n\n\n\n\n\n\n\n\n\n\n\nCode\niris |&gt; \n    ggplot(aes(Species, Sepal.Width, color = Species, group = Species)) + \n    geom_jitter() + \n    geom_segment(\n      aes(x = as.numeric(Species)-.3, \n          xend = as.numeric(Species) + .3, \n          y = mean(Sepal.Width),\n          yend = mean(Sepal.Width)), color = \"black\") +\n    theme_bw() + \n    scale_color_aaas()\n\n\n\n\n\n\n\n\n\n\n\nCode\niris |&gt; \n    ggplot(aes(Species, Sepal.Width, color = Species, group = Species)) + \n    geom_jitter() + \n    stat_summary(\n      fun = mean, \n      geom = \"segment\",\n      linewidth = 3, \n      mapping = aes(x = as.numeric(Species)-.3, \n                    xend = as.numeric(Species) + .3, \n                    yend = ..y.. # 統計変換後の値である\n                  )\n    ) + \n    theme_bw() + \n    scale_color_aaas()\n#&gt; Warning: The dot-dot notation (`..y..`) was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `after_stat(y)` instead.\n\n\n\n\n\n\n\n\n\n..y..のような値として他にも次がある。\n\n..count..：データの項目数を表します。たとえば、geom_bar()やgeom_histogram()で使用されると、各ビンに含まれるアイ- テムの総数を示します。\n..density..：密度を表します。geom_histogram()において、yを密度にマッピングすることで、面積の合計が1になるように- 調整されたヒストグラムを表示できます。\n..binwidth..：ヒストグラムのビンの幅を指します。これは、geom_histogram()でビンの幅を調整する際に参照されることが- あります。\n..x..と..y..：統計変換によって計算されたx値やy値を指します。これらは、特にstat_summary()で平均値や中央値などを計- 算する際に使われることがあります。\n..ymin..と..ymax..：エラーバーの下限と上限を表します。geom_errorbar()やgeom_pointrange()で使用され、平均値や中央- 値の信頼区間や範囲を示します。\n..width..と..height..：geom_tile()やgeom_raster()などでタイルやピクセルの幅と高さを調整する際に使用されることが- あります。\n..group..：データをグループ化するために使用される内部変数です。特定のgeomやstat関数で複数のグループを処理する際に使われます。"
  },
  {
    "objectID": "contents/notes/ggplot2/working.html#カーネル密度と経験累積分布関数",
    "href": "contents/notes/ggplot2/working.html#カーネル密度と経験累積分布関数",
    "title": "ggplot2 Tips",
    "section": "2.2 カーネル密度と経験累積分布関数",
    "text": "2.2 カーネル密度と経験累積分布関数\n経験累積分布関数とカーネル密度プロットは常に描画すること. できればそれを組み合わせて描画すること。 経験累積分布関数はさらに目的変数の累積分布関数と比較をすること.\n\n\nCode\ndata &lt;- iris\ng_dens &lt;- \n    data %&gt;%\n    ggplot(aes(Sepal.Length, color = Species)) + \n    geom_line(stat = \"density\", size = 1.5) + \n    theme_bw() + \n    labs(x = \"Sepal.Length\", y = \"density\") + \n    scale_color_aaas()\n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `linewidth` instead.\n\n\n\n\nCode\ng_ecdf &lt;- \n    data %&gt;%\n    ggplot(aes(Sepal.Length, color = Species)) + \n    stat_ecdf(size = 1.5) + \n    theme_bw() + \n    labs(x = \"Sepal.Length\", y = \"density\") + \n    scale_color_aaas() +\n    guides(color = \"none\")\n\n\n\n\nCode\n\nplot_grid(\n    g_dens + labs(x = NULL), \n    g_ecdf, \n    rel_widths = c(1, 1), \n    ncol = 1,  \n    align = \"v\",  # 軸を合わせるのに必要 \n    axis = \"tblr\" # 余白を合わせるのに必要(特に凡例があったりなかったりするとき)\n)"
  },
  {
    "objectID": "contents/notes/ggplot2/working.html#関数曲線",
    "href": "contents/notes/ggplot2/working.html#関数曲線",
    "title": "ggplot2 Tips",
    "section": "2.3 関数曲線",
    "text": "2.3 関数曲線\n確率密度関数などを記述するときに使う.\n\n\nCode\ngenerate_dnorm &lt;- function (param) {\n    lift( partial )(\n        update_list(\n            param, .f = dnorm, .first = FALSE )\n        )\n}\n\nparam1 &lt;-\n    list( mean = 1.23 ) %&gt;%\n    update_list(\n        sd =  ~ .1\n    )\n#&gt; Warning: `update_list()` was deprecated in purrr 1.0.0.\nparam2 &lt;-\n    param1 %&gt;%\n    update_list(\n        mean = 1.48631\n    )\n\ndnorm1 &lt;- generate_dnorm( param1 )\n#&gt; Warning: `lift()` was deprecated in purrr 1.0.0.\n#&gt; Warning: The `.first` argument of `partial()` is deprecated as of purrr 0.3.0.\n#&gt; ℹ The deprecated feature was likely used in the purrr package.\n#&gt;   Please report the issue at &lt;https://github.com/tidyverse/purrr/issues&gt;.\ndnorm2 &lt;- generate_dnorm( param2 )\nfill_poly &lt;- data_frame(\n        x = seq(qnorm(.9, mean = param1$mean, sd = param1$sd), 2, length.out = 20)\n    ) %&gt;%\n    mutate(y = map_dbl(x, dnorm1))\n#&gt; Warning: `data_frame()` was deprecated in tibble 1.1.0.\n#&gt; ℹ Please use `tibble()` instead.\n\ngrh &lt;-\n    data_frame( x = seq(0, 2, .01) ) %&gt;%\n    ggplot() +\n    geom_abline(slope = 0, intercept = 0) +\n    geom_ribbon(data = fill_poly, aes(x = x, ymax = y, ymin = 0), fill = \"pink\", alpha = .5) +\n    stat_function(fun = dnorm1, colour = \"red\",  lwd = 1.2 ) +\n    stat_function(fun = dnorm2, colour = \"blue\", lwd = 1.2 ) +\n    ylim(c(0, 4)) +\n    scale_x_continuous(limits = c(0.9, 1.8), breaks = seq(0.9, 1.8, .1)) +\n    labs(x = \"\", y = \"\") +\n    theme_bw() +\n    theme(\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.text.y  = element_blank(),\n        axis.text.x  = element_text(size = 12)\n    )\ngrh"
  },
  {
    "objectID": "contents/notes/ggplot2/working.html#確率楕円",
    "href": "contents/notes/ggplot2/working.html#確率楕円",
    "title": "ggplot2 Tips",
    "section": "2.4 確率楕円",
    "text": "2.4 確率楕円\nデフォルトでは、2次元t分布の95%確率となる領域を記述してくれる。 つまり、異常値の発見に役立つ. geomパラメータを変更することで塗りつぶしを行うこともできるし、 t分布の変わりに正規分布を使うことも可能である. 単純に円を記述することも可能である.\n\n\nCode\ngp &lt;-\n    iris %&gt;% \n    ggplot(aes(Sepal.Length, Sepal.Width, color = Species)) + \n    theme_bw() + \n    labs(x = \"Sepal.Length\", y = \"Sepal.Width\") + \n    coord_equal() +\n    theme(\n        axis.ticks.length = unit(-2, \"mm\"), \n        axis.title.x = element_text(margin = margin(t = 1, unit = \"line\")),\n        axis.text.x  = element_text(margin = margin(t = 1, unit = \"line\")),\n        axis.title.y = element_text(margin = margin(r = 1, unit = \"line\")), \n        axis.text.y  = element_text(margin = margin(r = 1, unit = \"line\")),\n        plot.margin = margin(1, 0, 0, 0, \"line\")\n    ) + \n    scale_color_viridis_d()\n\ngp + \n    geom_point(size = 3, alpha = .5) + \n    stat_ellipse() + \n    stat_ellipse(type = \"norm\", lty = 2) + \n    stat_ellipse(type = \"euclid\", lty = 3)\n\n\n\n\n\n\n\n\n\n\n\nCode\ngp + \n    stat_ellipse(\n        aes(fill = Species), \n        type = \"norm\", \n        geom = \"polygon\", alpha = .2, color = \"transparent\") + \n    geom_point(size = 3, alpha = .5, position = \"jitter\") +\n    scale_fill_viridis_d()"
  },
  {
    "objectID": "contents/notes/ggplot2/working.html#annotate関数",
    "href": "contents/notes/ggplot2/working.html#annotate関数",
    "title": "ggplot2 Tips",
    "section": "2.5 annotate関数",
    "text": "2.5 annotate関数\n\n2.5.1 annotate\nannotate関数ではジオメトリを追加するが、 典型的なgeom functionとは方法がことなり、 ジオメトリの属性はデータフレームの変数ではなく ベクトルで与えらる。 テキストラベルなど小さなアノテーションを追加するとき、 あるいは、データフレームにしたくないデータを持っているときに有用である。\n\n\nCode\np &lt;- ggplot(mtcars, aes(x = wt, y = mpg)) + geom_point() + theme_bw()\nlift(plot_grid)(list(\n    p + annotate(\"text\", x = 4, y = 25, label = \"Some text\"), \n    p + annotate(\"text\", x = 2:5, y = 25, label = \"Some text\"), \n    p + annotate(\"rect\", xmin = 3, xmax = 4.2, ymin = 12, ymax = 21, alpha = .2),\n    p + annotate(\"segment\", x = 2.5, xend = 4, y = 15, yend = 25, colour = \"blue\"),\n    p + annotate(\"pointrange\", x = 3.5, y = 20, ymin = 12, ymax = 28, colour = \"red\", size = 1.5),\n    p + annotate(\"text\", x = 2:3, y = 20:21, label = c(\"my label\", \"label 2\")),\n    p + annotate(\"text\", x = 4, y = 25, label = \"italic(R) ^ 2 == 0.75\",   parse = TRUE),\n    p + annotate(\"text\", x = 4, y = 25, label = \"paste(italic(R) ^ 2, \\\" = .75\\\")\", parse = TRUE), \n    ncol = 2, \n    rel_heights = c(4, 4)\n))\n\n\n\n\n\n\n\n\n\nなんか頑張ったら、こんなのもかけた。。。 これがあれば特定の範囲のデータについて、分布を記述することが可能となる。 めっちゃこれが便利だというシーンは思い浮かばないけどキレイなグラフを 記述するという意味では良い経験になったと思う.\n\n\nCode\nd  &lt;- density(mtcars$mpg)\nd2 &lt;- density(mtcars$wt)\np + \n    annotate(\n        \"polygon\",\n        x = (5 - 4 * d$y), # シフトやスケールが必要\n        y = d$x,\n        color = \"red\", \n        fill = \"transparent\") +  \n    annotate(\n        \"polygon\", \n        x = d2$x, \n        y = d2$y * 6 + 5, \n        color = \"blue\", \n        fill = \"transparent\")"
  },
  {
    "objectID": "contents/notes/ggplot2/working.html#annotation",
    "href": "contents/notes/ggplot2/working.html#annotation",
    "title": "ggplot2 Tips",
    "section": "2.6 annotation",
    "text": "2.6 annotation\nすべてのパネルので同じ統計アノテーションとして使う特別なgeomである。 これらのアノテーションはscaleには影響を与えない.\n\n2.6.1 annotation_custom\n下記の例を見るとなんとなく使い方はわかる. あとは記述したい絵を考えたうえで、色々と工夫を重ねるのが一番良いと思う.\n適当なGrobを作成できれば後は勢いで作成できる?\n使い方の用途としては，全体を小さく書いておき メインは全体のうち拡大したい箇所，という方法にして置くのがわかりやすい気がする．\n\n\nCode\nbase &lt;- \n    iris %&gt;% \n    ggplot(aes(Sepal.Length, Sepal.Width, color = Species)) + \n    geom_point() + \n    lims(y = c(2, 5))\n\ng &lt;-\n  ggplotGrob(\n      ggplot(iris, aes(x = Sepal.Length, color = Species)) +\n      geom_line(stat = \"density\") + \n      guides(color = FALSE) + \n      theme(\n          panel.background = element_rect(fill = \"transparent\"), \n          plot.background  = element_rect(fill = \"transparent\"), \n          panel.grid   = element_blank(), \n          axis.title.y = element_blank(), \n          axis.line.y  = element_blank(), \n          axis.text.y  = element_blank(),\n          axis.ticks   = element_blank()\n      ))\n#&gt; Warning: The `&lt;scale&gt;` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\n#&gt; of ggplot2 3.3.4.\n \nbase + \n    annotation_custom(grob = g, xmin = 6, xmax = 8, ymin = 4, ymax = 5)\n\n\n\n\n\n\n\n\n\n\n\n2.6.2 annotation_logticks\nこれではないけどマイナーグリッドにチックを入れる方法として annotateにgeom = “segment”を使う方法が考えだされていたけど， 正直しんどい気がする．．．．\n\n\nCode\na &lt;- ggplot(msleep, aes(bodywt, brainwt)) +\n geom_point(na.rm = TRUE) +\n scale_x_log10(\n   breaks = scales::trans_breaks(\"log10\", function(x) 10^x),\n   labels = scales::trans_format(\"log10\", scales::math_format(10^.x))\n ) +\n scale_y_log10(\n   breaks = scales::trans_breaks(\"log10\", function(x) 10^x),\n   labels = scales::trans_format(\"log10\", scales::math_format(10^.x))\n ) +\n theme_bw()\n\nlift(plot_grid)(list(\n    a + annotation_logticks(),               # Default: log ticks on bottom and left\n    a + annotation_logticks(sides = \"lr\"),   # Log ticks for y, on left and right\n    a + annotation_logticks(sides = \"trbl\")  # All four sides\n))\n\n\n\n\n\n\n\n\n\n\n\n2.6.3 annotation_map\n\n\nCode\nif (require(\"maps\")) {\nusamap &lt;- map_data(\"state\")\n\nseal.sub &lt;- subset(seals, long &gt; -130 & lat &lt; 45 & lat &gt; 40)\nggplot(seal.sub, aes(x = long, y = lat)) +\n  annotation_map(usamap, fill = NA, colour = \"grey50\") +\n  geom_segment(aes(xend = long + delta_long, yend = lat + delta_lat))\n}\n\n\n\n\n\n\n\n\n\n\n\nCode\nif (require(\"maps\")) {\nseal2 &lt;- transform(seal.sub,\n  latr = cut(lat, 2),\n  longr = cut(long, 2))\n\nggplot(seal2,  aes(x = long, y = lat)) +\n  annotation_map(usamap, fill = NA, colour = \"grey50\") +\n  geom_segment(aes(xend = long + delta_long, yend = lat + delta_lat)) +\n  facet_grid(latr ~ longr, scales = \"free\", space = \"free\")\n}\n\n\n\n\n\n\n\n\n\n\n\n2.6.4 annotation_raster\n画像を読み込めば画像も行ける？ 16進数の色に変換しておけば良いのか?\n\n\nCode\n# Generate data\nrainbow &lt;- matrix(hcl(seq(0, 360, length.out = 50 * 50), 80, 70), nrow = 50)\nggplot(mtcars, aes(mpg, wt)) +\n  geom_point() +\n  annotation_raster(rainbow, 15, 20, 3, 4)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# To fill up whole plot\nggplot(mtcars, aes(mpg, wt)) +\n  annotation_raster(rainbow, -Inf, Inf, -Inf, Inf) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\nCode\nrainbow2 &lt;- matrix(hcl(seq(0, 360, length.out = 10), 80, 70), nrow = 1)\nggplot(mtcars, aes(mpg, wt)) +\n  annotation_raster(rainbow2, -Inf, Inf, -Inf, Inf) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(png)\nlibrary(grid)\nimg &lt;- readPNG(system.file(\"img\", \"Rlogo.png\", package = \"png\"))\ng   &lt;- rasterGrob(img, interpolate = TRUE)\nqplot(1:10, 1:10, geom = \"blank\") + \n    annotation_custom(g, xmin = 1, xmax = 5, ymin = 1, ymax = 2) + \n    geom_point()\n#&gt; Warning: `qplot()` was deprecated in ggplot2 3.4.0."
  },
  {
    "objectID": "contents/notes/ggplot2/working.html#凡例のハンドリング",
    "href": "contents/notes/ggplot2/working.html#凡例のハンドリング",
    "title": "ggplot2 Tips",
    "section": "2.7 凡例のハンドリング",
    "text": "2.7 凡例のハンドリング\n凡例の操作は難しい… とりあえず、次を操作できるようになりたい.\n\n凡例の出し入れ\n凡例の位置(panelの中か外か)\n凡例のタイトル\n凡例のキーの操作\n凡例の文字列\n\nまずは複数の凡例の順序と凡例自体の位置を制御する例. themeで見た目を整える事もできるけど, guides(guide_legend)でも 大概見た目を加工することができる. 以下の例では 標準的な出力に加えて、凡例を色々と操作してみた状態のプロット。\n\n\nCode\nbase &lt;- \n  ggplot(mpg, aes(displ, cty)) +\n  geom_point(aes(size = hwy, colour = cyl, shape = drv)) + \n  theme_bw()\n\nlift(plot_grid)(list(\n  base, \n  base + guides(\n   colour = guide_colourbar(order = 1, draw.llim = FALSE),\n   shape  = guide_legend(order = 2),\n   size   = guide_legend(\n     order = 3, \n     title = \"MyWay\", \n     keywidth = unit(2, \"cm\"),\n     reverse = 1, \n     title.position = \"top\", # or bottom, left, right\n     title.theme = element_text(color = \"red\", face = \"italic\"), \n     title.hjust = 1, \n     label.theme = element_text(size = 14),\n     direction = \"vertical\"\n    )\n ), \n ncol = 2\n))\n\n\n\n\n\n\n\n\n\nカラーバーなどでの操作を細かく行うための使い方。 guidesとかlegendとかではないけど、一応凡例が操作されているといいうことで. これってスゴい便利なのでは？ 例えば普通の連続値の場合にはscale_fill_continuousを使う.\n\n\nCode\ndf &lt;- expand.grid(X1 = 1:10, X2 = 1:10)\ndf$value &lt;- df$X1 * df$X2\n\np &lt;- ggplot(df, aes(X1, X2)) + geom_tile(aes(fill = value)) + theme_bw() + coord_equal()\n\n# Coloursteps guide is the default for binned colour scales\nlift(plot_grid)(list(\n  p , \n  p + \n    geom_hline(yintercept = 1:10, color = \"lightgrey\", lty = 2) + \n    geom_vline(xintercept = 1:10, color = \"lightgrey\", lty = 2),\n  p + scale_fill_binned(), \n  p + scale_fill_binned(breaks = c(10, 25, 50)), \n  p + scale_fill_binned(breaks = c(10, 25, 50), guide = guide_coloursteps(even.steps = FALSE)), \n  p + scale_fill_binned(show.limits = TRUE),\n  ncol = 2\n))\n\n\n\n\n\n\n\n\n\n凡例をpanelの中に記述する場合の書き方は次の通り.\n\n\nCode\ndf &lt;- tibble(x = 1:3, y = 1:3, z = c(\"a\", \"b\", \"c\"))\nbase &lt;- \n  df %&gt;%\n  ggplot(aes(x, y, color = z), size = 3) + \n  geom_point()\n\nlift(plot_grid)(list(\n  base, \n  base + theme(\n    legend.position = c(0, 1),       # アンカーの相対座標\n    legend.justification = c(0, 1)), # アンカーの相対座標と紐付ける凡例の相対座標\n  base + theme(\n    legend.position = c(.5, .5), \n    legend.justification = c(.5, .5)),\n  base + theme(\n    legend.position = c(.5, .5), \n    legend.justification = c(0, 1)), \n  base + theme(\n    legend.position = c(1, 0), \n    legend.justification = c(1, 0)\n  ), \n  ncol = 2\n))\n\n\n\n\n\n\n\n\n\nマニュアルで凡例を作成する. ここを参考にした. これはしっくりするやり方だと思う.\n\n\nCode\n\ncolors &lt;- c(\"Sepal Width\" = \"blue\", \"Petal Length\" = \"red\", \"Petal Width\" = \"orange\")\n\nggplot(iris, aes(x = Sepal.Length)) +\n    geom_line(aes(y = Sepal.Width, color = \"Sepal Width\"), size = 1.5) +\n    geom_line(aes(y = Petal.Length, color = \"Petal Length\"), size = 1.5) +\n    geom_line(aes(y = Petal.Width, color = \"Petal Width\"), size = 1.5) +\n    labs(x = \"Year\",\n         y = \"(%)\",\n         color = \"Legend\") +\n    scale_color_manual(values = colors)\n\n\n\n\n\n\n\n\n\n凡例を消したい場合の対処方法. ここを参考にしている.\n\n\nCode\n# レイヤー単位で指定\np &lt;- \n  ggplot(ToothGrowth, aes(x = dose, y = len))+ \n  geom_boxplot(aes(fill = dose), show.legend = FALSE) +\n  scale_fill_viridis_d()\np\n#&gt; Warning: Continuous x aesthetic\n#&gt; ℹ did you forget `aes(group = ...)`?\n#&gt; Warning: The following aesthetics were dropped during statistical transformation: fill\n#&gt; ℹ This can happen when ggplot fails to infer the correct grouping structure in\n#&gt;   the data.\n#&gt; ℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n#&gt;   variable into a factor?\n\n\n\n\n\n\n\n\n\n\n\nCode\n# グラフを作成してから指定\np + theme(legend.position = \"none\")\n#&gt; Warning: Continuous x aesthetic\n#&gt; ℹ did you forget `aes(group = ...)`?\n#&gt; Warning: The following aesthetics were dropped during statistical transformation: fill\n#&gt; ℹ This can happen when ggplot fails to infer the correct grouping structure in\n#&gt;   the data.\n#&gt; ℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n#&gt;   variable into a factor?\n\n\n\n\n\n\n\n\n\n\n\nCode\n# 特定の軸に対して処理をしたい場合の指定\nmtcars$cyl&lt;-as.factor(mtcars$cyl)\nmtcars$gear &lt;- as.factor(mtcars$gear)\n\n# Scatter plot\np2 &lt;- ggplot(data = mtcars, aes(x = mpg, y = wt))+\n    geom_point(aes(color = cyl, size = qsec, shape = gear)) +\n  scale_color_viridis_d()\np2\n\n\n\n\n\n\n\n\n\n\n\nCode\np2 + guides(color = \"none\", size = \"none\")\n\n\n\n\n\n\n\n\n\n\n2.7.1 文字や位置を微調整したい\nstackoverflowが参考になる.\n水平方向に調整する.\n\n\nCode\nlibrary(ggplot2)\n\nggplot(mtcars, aes(factor(cyl), fill = factor(cyl))) + \n  geom_bar() +\n  coord_flip() +\n  scale_fill_brewer(\"Cyl\", palette = \"Dark2\") +\n  theme_minimal(base_size = 14) +\n  theme(legend.position = 'top', \n        legend.spacing.x = unit(1.0, 'cm'))\n\n\n\n\n\n\n\n\n\n鉛直方向に調整する.\n\n\nCode\nlibrary(ggplot2)\n\nggplot(mtcars, aes(y = factor(cyl), fill = factor(cyl))) + \n  geom_bar() +\n  theme(legend.spacing.y = unit(1.0, 'cm'))  +\n  ## important additional element\n  guides(fill = guide_legend(byrow = TRUE))\n\n\n\n\n\n\n\n\n\nカラーバーなどは個別に微調整するみたい. バーの長さも自分で調整ができる見たい.\n\n\nCode\nggplot(mtcars, aes(mpg, wt)) +\n  geom_point(aes(fill = hp), pch = I(21), size = 5)+\n  scale_fill_viridis_c(guide = FALSE) +\n  theme_classic(base_size = 14) +\n  theme(legend.position = 'top', \n        legend.spacing.x = unit(0.5, 'cm'),\n        legend.text = element_text(margin = margin(t = 10))) +\n  guides(fill = guide_colorbar(title = \"HP\",\n                               label.position = \"bottom\",\n                               title.position = \"left\", title.vjust = 1,\n                               # draw border around the legend\n                               frame.colour = \"black\",\n                               barwidth = 25,\n                               barheight = 2)) \n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(mtcars) +\n  aes(x = cyl, fill = factor(cyl)) +\n  geom_bar() +\n  scale_fill_brewer(\"Cyl\", palette = \"Dark2\") +\n  theme_minimal(base_size = 14) +\n  theme(legend.key.size = unit(1, \"cm\"))\n\n\n\n\n\n\n\n\n\n\n\nCode\ndraw_key_polygon3 &lt;- function(data, params, size) {\n  lwd &lt;- min(data$size, min(size) / 4)\n  \n  grid::rectGrob(\n    width = grid::unit(0.6, \"npc\"),\n    height = grid::unit(0.6, \"npc\"),\n    gp = grid::gpar(\n      col = data$colour,\n      fill = alpha(data$fill, data$alpha),\n      lty = data$linetype,\n      lwd = lwd * .pt,\n      linejoin = \"mitre\"\n    ))\n}\n\n### this step is not needed anymore per tjebo's comment below\n### see also: https://ggplot2.tidyverse.org/reference/draw_key.html\n# register new key drawing function, \n# the effect is global & persistent throughout the R session\n# GeomBar$draw_key = draw_key_polygon3\n\nggplot(mtcars) +\n  aes(x = cyl, fill = factor(cyl)) +\n  geom_bar(key_glyph = \"polygon3\") +\n  scale_fill_brewer(\"Cyl\", palette = \"Dark2\") +\n  theme_minimal(base_size = 14) +\n  theme(legend.key = element_rect(color = NA, fill = NA),\n        legend.key.size = unit(1.5, \"cm\")) +\n  theme(legend.title.align = 0.5)"
  },
  {
    "objectID": "contents/notes/ggplot2/working.html#テキスト",
    "href": "contents/notes/ggplot2/working.html#テキスト",
    "title": "ggplot2 Tips",
    "section": "2.8 テキスト",
    "text": "2.8 テキスト\n\n2.8.1 hjust/vjusts\n凡例の位置設定と同じ考え方が，どうやらテキストも同様の考え方で対応でてきる気がする. これをみると、ラベルの左下が(0, 0)で、右上が(1, 1)となっている. ラベルの右端を点xに合わせたい場合には、hjust=1に調整するなど下のものを 参考としてもらいたい.\n\n\nCode\n\nd &lt;- tibble(\n  x = 1:3 %&gt;% rep(3), \n  y = 1:3 %&gt;% rep(each = 3), \n  hjust = c(0, .5, 1) %&gt;% rep(3), \n  vjust = c(0, .5, 1) %&gt;% rep(each = 3)\n) %&gt;%\n  mutate(\n    t = sprintf(\"h:%s\\nv:%s\", hjust, vjust)\n  )\n\ng &lt;- \n  d %&gt;% \n  ggplot(aes(x, y, label = t)) + \n  coord_equal() + \n  theme_bw()\n\nplot(\n  g +\n    geom_label(aes(hjust = hjust, vjust = vjust)) + \n    geom_point(color = \"gold\", size = 2)\n  )\n\n\n\n\n\n\n\n\n\n\n\n2.8.2 position\nposition系の関数を使うと気の利いた調整が行える.\n\n\nCode\ndf &lt;- data.frame(\n  x = factor(c(1, 1, 2, 2)),\n  y = c(1, 3, 2, 1),\n  grp = c(\"a\", \"b\", \"a\", \"b\")\n)\n\n\n\n\nCode\nggplot(data = df, aes(x, y, group = grp)) +\n  geom_col(aes(fill = grp), position = \"dodge\") +\n  # x軸の中心からそれぞれどれだけ離すか\n  geom_text(aes(label = y), position = position_dodge(0.9))\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Use you can't nudge and dodge text, so instead adjust the y position\nggplot(data = df, aes(x, y, group = grp)) +\n  geom_col(aes(fill = grp), position = \"dodge\") +\n  geom_text(\n    aes(label = y, y = y + 0.05),\n    position = position_dodge(0.9),\n    vjust = 0\n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\n# To place text in the middle of each bar in a stacked barplot, you\n# need to set the vjust parameter of position_stack()\nggplot(data = df, aes(x, y, group = grp)) +\n geom_col(aes(fill = grp)) +\n # スタックされているところは，つまり，境界のところ\n # この場合のvjustはスタックされているところで調整してくれている(文字の大きさでない)\n geom_text(aes(label = y), position = position_stack(vjust = 0.5))"
  },
  {
    "objectID": "contents/notes/ggplot2/working.html#facet_grid",
    "href": "contents/notes/ggplot2/working.html#facet_grid",
    "title": "ggplot2 Tips",
    "section": "2.9 facet_grid",
    "text": "2.9 facet_grid\n基本的な使い方はいいが，ここではストリップラベルをずらす例を紹介．\n\n\nCode\ndata &lt;- \n  tibble(\n    rows = sprintf(\"row_%d\", 1:2), \n    cols = sprintf(\"col_%d\", 1:2)\n  ) %&gt;%\n  tidyr::expand(rows, cols) %&gt;%\n  rowwise() %&gt;%\n  mutate(\n    data = list(tibble(x = rnorm(1000), y = rnorm(1000)))\n  ) %&gt;%\n  unnest(data)\n\n\n\n\nCode\ndata %&gt;%\n  ggplot() + \n  geom_point(aes(x, y), size = 1) + \n  coord_equal(xlim = c(-3, 3), ylim = c(-3, 3)) + \n  theme_cowplot() + \n  facet_grid(\n    rows = vars(rows), \n    cols = vars(cols), \n    switch = \"y\" # 行のラベルを左に置く\n  ) + \n  scale_y_continuous(position = \"right\") + \n  theme(\n    # RStudioの予測にも出てこないけど，\n    # leftにおいたyのstripにアングルを与えるには次を使うこと\n    strip.text.y.left = element_text(angle = 0, face = \"bold\")\n  )"
  },
  {
    "objectID": "contents/notes/ggplot2/working.html#summary_stat",
    "href": "contents/notes/ggplot2/working.html#summary_stat",
    "title": "ggplot2 Tips",
    "section": "2.10 summary_stat",
    "text": "2.10 summary_stat\ngeom関数とstat関数は一緒の関係であるが, stat_summaryにより関数を適用してプロットを行うことが可能となる. 正直使いにくいイメージがあるので，個人的には 事前に集計したレイヤーを重ねるという方法を常に選択しがちである．\n\n\nCode\np &lt;- \n  ggplot(\n    data = filter(penguins, complete.cases(penguins)), \n    mapping = aes(\n      x = species,\n      y = bill_length_mm\n    )\n  ) + \n  theme_minimal() + \n  theme(\n    panel.background = element_rect(color = \"black\")\n  )\n\np + \n  geom_point() + \n  stat_summary(fun = \"mean\", color = \"red\", size = 4)\n#&gt; Warning: Removed 3 rows containing missing values (`geom_segment()`)."
  },
  {
    "objectID": "contents/notes/ggplot2/working.html#マルチレベルのwrap",
    "href": "contents/notes/ggplot2/working.html#マルチレベルのwrap",
    "title": "ggplot2 Tips",
    "section": "2.11 マルチレベルのwrap",
    "text": "2.11 マルチレベルのwrap\n自然言語処理でドキュメントごとに単語頻度上位N件の 度数をバープロットで描画するときなど， ドキュメントでfacetしてその中でwordを並び変えてプロットしたいときがある．\nこのとき，何も考えずに行うと期待したプロットが作成できない． これに対処するには，並び換えを全体で行えるようにkeyを調整した上で， プロットする際にキーラベル名を調整するという処理が必要である.\n\n\nCode\ndata &lt;- \n  tibble(\n    key   = c(\"a\", \"a\", \"b\", \"b\"), \n    value = c(1, 2, 2, 1), \n    term  = c(\"w1\", \"w2\", \"w1\", \"w2\")\n  )\n\n# 並び変えてプロットしても\n# グラフは同じ順番になってしまう\n# これをfacetごとに降順に並び変えたい\ndata %&gt;% \n  group_by(key) %&gt;% \n  arrange(value) %&gt;% \n  ungroup() %&gt;% \n  ggplot(aes(reorder(term, value), value)) + \n  geom_col() + \n  facet_wrap(vars(key), scales = \"free\")\n\n\n\n\n\n\n\n\n\n一応このようにやれば対応が可能である.\n\n\nCode\ndata %&gt;%\n  mutate(new_key = factor(str_c(term, key, sep = \"___\"))) %&gt;%\n  arrange(value) %&gt;%\n  ggplot(aes(reorder(new_key, value), value)) + \n  geom_col() + \n  facet_wrap(vars(key), scales = \"free\") + \n  scale_x_discrete(label = function(x) sub(\"___.+$\", \"\", x), drop = TRUE)"
  },
  {
    "objectID": "contents/notes/ggplot2/working.html#trans",
    "href": "contents/notes/ggplot2/working.html#trans",
    "title": "ggplot2 Tips",
    "section": "2.12 trans",
    "text": "2.12 trans\ntrans系やscale系の関数を使うことで，データをggplot内で変換することが可能となるはず． たとえばscale_x_logなどがそれに該当する.\n\n\nCode\ntibble(\n  x = 1:10, \n  y = 1:10\n) %&gt;% \n  ggplot(aes(x, y)) + \n  geom_line() + \n  scale_y_log10()\n\n\n\n\n\n\n\n\n\n同じことを違う遣り方で実行してみる.\n\n\nCode\ntibble(\n  x = 1:10, \n  y = 1:10\n) %&gt;% \n  ggplot(aes(x, y)) + \n  geom_line() + \n  scale_y_continuous(trans = \"log10\")\n\n\n\n\n\n\n\n\n\nさらに別のやり方を試す.\n\n\nCode\ntibble(\n  x = 1:10, \n  y = 1:10\n) %&gt;% \n  ggplot(aes(x, y)) + \n  geom_line() + \n  scale_y_continuous(\n    trans = scales::trans_new(\"log10\", log10, function(x) 10 ** x), \n    minor_breaks = seq(1, 10, .5), \n    breaks = c(1, 6, 10)\n  ) + \n  theme(\n    axis.ticks.length = unit(-2, \"mm\")\n  )"
  },
  {
    "objectID": "contents/notes/ggplot2/working.html#グラフの順番に凡例の順番を合わす",
    "href": "contents/notes/ggplot2/working.html#グラフの順番に凡例の順番を合わす",
    "title": "ggplot2 Tips",
    "section": "2.13 グラフの順番に凡例の順番を合わす",
    "text": "2.13 グラフの順番に凡例の順番を合わす\n参考文献\n\n\nCode\nlibrary(tidyverse)  # 1.3.0\n\nusa_crop_yields &lt;- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-09-01/key_crop_yields.csv\") %&gt;%\n  rename_with(~ gsub(\" \\\\(tonnes per hectare\\\\)\", \"\", .)) %&gt;%\n  pivot_longer(Wheat:Bananas, names_to = \"crop\", values_to = \"yield\") %&gt;%\n  rename_with(tolower) %&gt;%\n  filter(entity == \"United States\", !is.na(yield)) %&gt;%\n  select(year, crop, yield)\n#&gt; Rows: 13075 Columns: 14\n#&gt; ── Column specification ────────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; chr  (2): Entity, Code\n#&gt; dbl (12): Year, Wheat (tonnes per hectare), Rice (tonnes per hectare), Maize...\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nusa_crop_yields\n#&gt; # A tibble: 522 × 3\n#&gt;     year crop     yield\n#&gt;    &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n#&gt;  1  1961 Wheat     1.61\n#&gt;  2  1961 Rice      3.82\n#&gt;  3  1961 Maize     3.92\n#&gt;  4  1961 Soybeans  1.69\n#&gt;  5  1961 Potatoes 22.2 \n#&gt;  6  1961 Beans     1.54\n#&gt;  7  1961 Peas      1.19\n#&gt;  8  1961 Barley    1.65\n#&gt;  9  1961 Bananas  10.5 \n#&gt; 10  1962 Wheat     1.68\n#&gt; # ℹ 512 more rows\n\n\n\n\nCode\nusa_crop_yields %&gt;%\n  mutate(crop = fct_reorder2(crop, year, yield)) %&gt;%\n  ggplot(aes(year, yield, color = crop)) +\n  geom_line() +\n  labs(x = NULL, y = NULL, color = NULL)"
  },
  {
    "objectID": "contents/notes/ggplot2/working.html#histgram",
    "href": "contents/notes/ggplot2/working.html#histgram",
    "title": "ggplot2 Tips",
    "section": "2.14 histgram",
    "text": "2.14 histgram\nヒストグラムをきれいに書きたい.\n\n\nCode\ndata &lt;- tibble(a = runif(100), b = sample(c(\"a\", \"b\"), 100, replace = TRUE))\ndata %&gt;%\n  ggplot(aes(x = a)) + \n  geom_histogram(aes(fill = b), center = 0, breaks = seq(0, 1., .1), color = \"lightgrey\", closed = \"left\") +\n  geom_text(\n    stat = \"bin\",\n    # count, dnesity, ncount, ndensity\n    aes(label = ..count.., y = ..count.., fill = b),\n    breaks = seq(0, 1., .1),\n    closed = \"left\",\n    vjust = -.5,\n    position = position_stack(vjust = .5)\n  ) + \n  geom_text(\n    stat = \"bin\", \n    aes(x = a, label = after_stat(count), y = after_stat(count)), \n    breaks = seq(0, 1., .1), \n    closed = \"left\", \n    vjust = -.5, \n    data = data\n  ) +\n  scale_x_continuous(breaks = seq(0, 1., .1))\n#&gt; Warning in geom_text(stat = \"bin\", aes(label = ..count.., y = ..count.., :\n#&gt; Ignoring unknown aesthetics: fill\n\n\n\n\n\n\n\n\n\n左に閉じたときにどのような挙動になるのかを確認したい. [0, .1), [.1, .2), …., [.9, 1.]となっていることがわかる.\n\n\nCode\ndata &lt;- tibble(a = sample(c(0, .1, .5,  1.), 100, TRUE), b = sample(c(\"a\", \"b\"), 100, replace = TRUE))\ndata %&gt;%\n  ggplot(aes(x = a)) + \n  geom_histogram(\n    aes(fill = b), \n    center = 0,\n    breaks = seq(0, 1., .1), \n    color = \"lightgrey\", \n    closed = \"left\"\n  ) +\n  geom_text(\n    stat = \"bin\",\n    aes(label = ..count.., y = ..count.., group = b),\n    breaks = seq(0, 1., .1),\n    closed = \"left\",\n    vjust = -.5,\n    position = position_stack(vjust = .5)\n  ) + \n  scale_x_continuous(breaks = seq(0, 1., .1))"
  },
  {
    "objectID": "contents/notes/ggplot2/working.html#geom_smooth",
    "href": "contents/notes/ggplot2/working.html#geom_smooth",
    "title": "ggplot2 Tips",
    "section": "2.15 geom_smooth",
    "text": "2.15 geom_smooth\n\n\nCode\ndf &lt;- tibble(\n    x = seq(1, 100, 1), \n    e = runif(n = 100)\n) |&gt; \n    mutate(y = x * .05 + e)\n\ndf |&gt; \n    ggplot(aes(x, y)) + \n    geom_point() + \n    geom_line(data = ~ . |&gt; filter(x &lt;= 50), col = \"red\") + \n    geom_smooth(data = ~ . |&gt; filter(x &gt; 50), col = \"blue\")\n#&gt; `geom_smooth()` using method = 'loess' and formula = 'y ~ x'"
  },
  {
    "objectID": "contents/notes/ggplot2/working.html#ggmosaic",
    "href": "contents/notes/ggplot2/working.html#ggmosaic",
    "title": "ggplot2 Tips",
    "section": "3.1 ggmosaic",
    "text": "3.1 ggmosaic\n\n\nCode\nlibrary(ggplot2)\nlibrary(ggmosaic)\nlibrary(dplyr)\n\ncc &lt;- count(diamonds, cut, clarity)\n\nggplot(cc) + \n    geom_mosaic(\n        aes(weight = n, x = product(cut), fill = clarity)\n    )\n#&gt; Warning: `unite_()` was deprecated in tidyr 1.2.0.\n#&gt; ℹ Please use `unite()` instead.\n#&gt; ℹ The deprecated feature was likely used in the ggmosaic package.\n#&gt;   Please report the issue at &lt;https://github.com/haleyjeppson/ggmosaic&gt;."
  },
  {
    "objectID": "contents/notes/ggplot2/working.html#ggokabeito",
    "href": "contents/notes/ggplot2/working.html#ggokabeito",
    "title": "ggplot2 Tips",
    "section": "3.2 ggokabeito",
    "text": "3.2 ggokabeito\nsafecolorらしい．\n\n\nCode\niris |&gt; \n    ggplot(aes(Sepal.Length, Sepal.Width, color = Species)) + \n    geom_point(size = 4) + \n    theme_bw() + \n    scale_color_okabe_ito()"
  },
  {
    "objectID": "contents/notes/ggplot2/working.html#ggprism",
    "href": "contents/notes/ggplot2/working.html#ggprism",
    "title": "ggplot2 Tips",
    "section": "3.3 ggprism",
    "text": "3.3 ggprism\nマイナーチック を打てるようです.\n他にも色々軸の加工が可能なためいろいろとチェックしてみるのがいい．\n\n3.3.1 Minor ticks\n\n\nCode\np &lt;- ggplot(\n  data = ToothGrowth, \n  mapping = aes(\n    x = factor(supp), \n    y = len\n  )\n) + \n  geom_boxplot(aes(fill = factor(supp))) + \n  theme_prism() + \n  theme(legend.position = \"none\")\np1 &lt;- p + scale_y_continuous(guide = guide_prism_minor())\np2 &lt;- p + guides(y = guide_prism_minor())\np2\n\n\n\n\n\n\n\n\n\n\n\nCode\np &lt;- \n  ggplot(\n    data = ToothGrowth, \n    mapping = aes(\n      x = factor(dose), \n      y = len\n    )\n  ) + \n  stat_summary(\n    mapping = aes(fill = factor(dose)), na.rm = TRUE, \n    geom = \"col\", fun = mean, colour = \"black\", size = .9\n  ) + \n  theme_classic() + \n  theme(legend.position = \"none\")\n\n\n# 書きたかったグラフはこれや！！！！！\n# これが土木学会のグラフや\np + \n  scale_y_continuous(\n    guide = \"prism_minor\", \n    limits = c(0, 30), \n    expand = c(0, 0), \n    minor_breaks = seq(0, 30)\n  ) + \n  theme(\n    axis.ticks.length.y = unit(10, \"pt\"), \n    prism.ticks.length.y = unit(5, \"pt\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n3.3.2 Brackets axis\n\n\nCode\np1 &lt;- ggplot(ToothGrowth, aes(x = factor(dose), y = len)) + \n  geom_jitter(aes(shape = factor(dose)), width = 0.2, size = 2) + \n  scale_shape_prism() + \n  theme_prism() + \n  theme(legend.position = \"none\") + \n  scale_y_continuous(limits = c(0, 40), guide = \"prism_offset\")\n\np2 &lt;- p1 + scale_x_discrete(guide = \"prism_bracket\")\n\np2\n\n\n\n\n\n\n\n\n\n\n\n3.3.3 Border with minor ticks\n\n\nCode\nbase &lt;- \n  ggplot(mpg, aes(x = displ, y = cty)) +\n  geom_point(aes(colour = class))\nbase\n\n\n\n\n\n\n\n\n\nannotation_ticksを使うをスゴく簡単にチックを打てる.\n\n\nCode\np &lt;- base + theme_prism(border = TRUE) +\n  theme(legend.position = c(0.8, 0.75)) +\n  coord_cartesian(clip = \"off\") + \n  guides(\n    x = \"prism_minor\", y = \"prism_minor\"\n  )\np_annot &lt;- \n  p + \n  annotation_ticks(\n    sides = \"tr\", \n    type = \"both\", \n    size = 1,\n    outside = TRUE,\n    tick.length = unit(14/2, \"pt\"),\n    minor.length = unit(14/4, \"pt\"))\np_annot\n\n\n\n\n\n\n\n\n\n離散値の場合にも出来るようでしたがあまりにも トリッキーにつき省略いたします."
  },
  {
    "objectID": "contents/notes/ggplot2/working.html#gghalves",
    "href": "contents/notes/ggplot2/working.html#gghalves",
    "title": "ggplot2 Tips",
    "section": "3.4 gghalves",
    "text": "3.4 gghalves\n\n(gghalves)[https://github.com/erocoar/gghalves]\n\nggplo2によるハーフ＆ハーフのプロットの合成を容易にする。\n\n\nCode\nlibrary(gghalves)\n\n\n\n\nCode\niris %&gt;%\n  ggplot(aes(Species, Sepal.Width, color = Species)) + \n  geom_half_point() + \n  geom_half_violin()"
  },
  {
    "objectID": "contents/notes/ggplot2/working.html#ggally",
    "href": "contents/notes/ggplot2/working.html#ggally",
    "title": "ggplot2 Tips",
    "section": "3.5 ggally",
    "text": "3.5 ggally\n\nggally\n\n\n\nCode\nlibrary(GGally)\n\n\n\n3.5.1 Types of Plots\n\ncontinuous: when both x and y variables are continuous\ncomboHorizontal: when x is continuous and y is discrete\ncomboVorizontal: when x is discrete and y is continuous\ndiscrete: when both x and y variables are discrete\nna: when all x data and all y data is NA\n\n\n\n3.5.2 ggpairs\nいろいろカスタマイズができるのはわかるが、 やりたいものがないとどのようなグラフを作成すべきであるのかがわからない。 こんため\n\n3.5.2.1 basic example\n\n\nCode\npm &lt;- \n  iris %&gt;%\n  ggpairs(\n    mapping = aes(color = Species), \n    columns = c(\"Sepal.Length\", \"Petal.Length\", \"Species\")\n  ) + \n  theme_bw()\npm\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\nCode\npm &lt;- \n  iris %&gt;%\n  ggpairs(\n    mapping = aes(color = Species), \n    columns = c(\"Sepal.Length\", \"Petal.Length\", \"Species\"), \n    lower   = list(\n      continuous = \"smooth\", \n      combo = \"facetdensity\", \n      mappping = aes(color = Species)\n    )\n  ) + \n  theme_bw()\npm\n\n\n\n\n\n\n\n\n\n\n\nCode\npm &lt;- \n  iris %&gt;%\n  ggpairs(\n    mapping = aes(color = Species), \n    columns = c(\"Sepal.Length\", \"Petal.Length\", \"Species\"), \n    upper = \"blank\", \n    diag  = NULL, \n    lower   = list(\n      continuous = \"smooth\", \n      combo = \"facetdensity\", \n      mappping = aes()\n    )\n  ) + \n  theme_bw()\npm\n\n\n\n\n\n\n\n\n\n\n\n3.5.2.2 custom functions\n\n\nCode\ndata(tips, package = \"reshape\")\nmy_bin &lt;- function(data, mapping, ..., low = \"#132B43\", high = \"#56B1F7\") {\n  ggplot(data = data, mapping = mapping) +\n    geom_bin2d(...) +\n    scale_fill_gradient(low = low, high = high) + \n    theme(\n      axis.text = element_text(color = \"red\")\n    )\n}\npm &lt;- ggpairs(\n  tips, \n  columns = c(\"total_bill\", \"time\", \"tip\"), \n  lower = list(\n    continuous = my_bin\n  )\n)\npm\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\nCode\npm &lt;- ggpairs(\n  tips, columns = c(\"total_bill\", \"time\", \"tip\"),\n  lower = list(\n    combo = wrap(\"facethist\", binwidth = 1),\n    continuous = wrap(my_bin, binwidth = c(5, 0.5), high = \"red\")\n  )\n)\npm\n\n\n\n\n\n\n\n\n\n\n\n3.5.2.3 plot matrix subsetting\n\n\nCode\npm &lt;- ggpairs(tips, columns = c(\"total_bill\", \"time\", \"tip\"))\np  &lt;- pm[3, 1]\np  &lt;- p + aes(color = time)\np\n\n\n\n\n\n\n\n\n\n\n\nCode\npm[3,1] &lt;- p\npm\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\nCode\ncustom_car &lt;- ggpairs(mtcars[, c(\"mpg\", \"wt\", \"cyl\")], \n                      upper = \"blank\", title = \"Custom Example\")\n# ggplot example taken from example(geom_text)\nplot &lt;- ggplot2::ggplot(mtcars, ggplot2::aes(x=wt, y=mpg, label=rownames(mtcars)))\nplot &lt;- plot +\n    ggplot2::geom_text(ggplot2::aes(colour=factor(cyl)), size = 3) +\n    ggplot2::scale_colour_discrete(l=40)\ncustom_car[1, 2] &lt;- plot\npersonal_plot &lt;- ggally_text(\n  \"ggpairs allows you\\nto put in your\\nown plot.\\nLike that one.\\n &lt;---\"\n)\ncustom_car[1, 3] &lt;- personal_plot\n(custom_car)\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\nCode\n## Remove binwidth warning from ggplot2\npm &lt;- ggpairs(tips, 2:3, lower = list(combo = wrap(\"facethist\", binwidth = 0.5)))\npm\n\n\n\n\n\n\n\n\n\n\n\nCode\n## Remove panel grid lines from correlation plots\npm &lt;- ggpairs(\n  flea, columns = 2:4,\n  upper = list(continuous = wrap(ggally_cor, display_grid = FALSE))\n)\npm + theme(\n  strip.background = element_rect(fill = \"black\"), \n  strip.text = element_text(color = \"white\"))\n\n\n\n\n\n\n\n\n\n\n\n\n3.5.3 ggnetworkmap\n\n\nCode\nsuppressMessages(library(ggplot2))\nsuppressMessages(library(maps))\nsuppressMessages(library(network))\nsuppressMessages(library(sna))\n\nairports &lt;- read.csv(\"http://datasets.flowingdata.com/tuts/maparcs/airports.csv\", header = TRUE)\nrownames(airports) &lt;- airports$iata\n\n# select some random flights\nset.seed(1234)\nflights &lt;- data.frame(\n  origin = sample(airports[200:400, ]$iata, 200, replace = TRUE),\n  destination = sample(airports[200:400, ]$iata, 200, replace = TRUE)\n)\n\n# convert to network\nflights &lt;- network(flights, directed = TRUE)\n\n# add geographic coordinates\nflights %v% \"lat\" &lt;- airports[ network.vertex.names(flights), \"lat\" ]\nflights %v% \"lon\" &lt;- airports[ network.vertex.names(flights), \"long\" ]\n\n# drop isolated airports\ndelete.vertices(flights, which(degree(flights) &lt; 2))\n\n# compute degree centrality\nflights %v% \"degree\" &lt;- degree(flights, gmode = \"digraph\")\n\n# add random groups\nflights %v% \"mygroup\" &lt;- sample(letters[1:4], network.size(flights), replace = TRUE)\n\n# create a map of the USA\nusa &lt;- ggplot(map_data(\"usa\"), aes(x = long, y = lat)) +\n  geom_polygon(aes(group = group), color = \"grey65\",\n               fill = \"#f9f9f9\", size = 0.2)\n\n# trim flights\ndelete.vertices(flights, which(flights %v% \"lon\" &lt; min(usa$data$long)))\ndelete.vertices(flights, which(flights %v% \"lon\" &gt; max(usa$data$long)))\ndelete.vertices(flights, which(flights %v% \"lat\" &lt; min(usa$data$lat)))\ndelete.vertices(flights, which(flights %v% \"lat\" &gt; max(usa$data$lat)))\n\n# overlay network data to map\nggnetworkmap(usa, flights, size = 4, great.circles = TRUE,\n             node.group = mygroup, segment.color = \"steelblue\",\n             ring.group = degree, weight = degree)"
  },
  {
    "objectID": "contents/notes/ggplot2/working.html#gganimate",
    "href": "contents/notes/ggplot2/working.html#gganimate",
    "title": "ggplot2 Tips",
    "section": "3.6 gganimate",
    "text": "3.6 gganimate\ngithub\n\n\nCode\nlibrary(gganimate)\n\nggplot(mtcars, aes(factor(cyl), mpg)) + \n  geom_boxplot() + \n  transition_states(\n    gear, \n    transition_length = 2, \n    state_length = 1\n  ) + \n  enter_fade() + \n  exit_shrink() + \n  ease_aes('sine-in-out')"
  },
  {
    "objectID": "contents/notes/ggplot2/working.html#waffle",
    "href": "contents/notes/ggplot2/working.html#waffle",
    "title": "ggplot2 Tips",
    "section": "3.7 waffle",
    "text": "3.7 waffle\n\n\nCode\nwaffle(c(30, 25, 20, 5), rows = 8)"
  },
  {
    "objectID": "contents/notes/ggplot2/working.html#ggupset",
    "href": "contents/notes/ggplot2/working.html#ggupset",
    "title": "ggplot2 Tips",
    "section": "3.8 ggupset",
    "text": "3.8 ggupset\n\n\nCode\nlibrary(ggplot2)\nlibrary(ggupset)\nggplot(tidy_movies[1:100, ], aes(x=Genres)) +\n  geom_bar() +\n  scale_x_upset(reverse = TRUE, sets=c(\"Drama\", \"Action\"))\n#&gt; Warning: Removed 33 rows containing non-finite values (`stat_count()`).\n\n\n\n\n\n\n\n\n\nCode\n\n ggplot(tidy_movies[1:100, ], aes(x=Genres)) +\n   geom_bar() +\n   scale_x_upset(n_intersections = 5, ytrans=\"sqrt\")\n#&gt; Warning: Removed 28 rows containing non-finite values (`stat_count()`).\n\n\n\n\n\n\n\n\n\nCode\n\n ggplot(tidy_movies[1:100, ], aes(x=Genres, y=year)) +\n   geom_boxplot() +\n   scale_x_upset(intersections = list(c(\"Drama\", \"Comedy\"), c(\"Short\"), c(\"Short\", \"Animation\")),\n                 sets = c(\"Drama\", \"Comedy\", \"Short\", \"Animation\", \"Horror\"))\n#&gt; Warning: Removed 90 rows containing missing values (`stat_boxplot()`)."
  },
  {
    "objectID": "contents/notes/ggplot2/working.html#heat-map-with-geom_tile",
    "href": "contents/notes/ggplot2/working.html#heat-map-with-geom_tile",
    "title": "ggplot2 Tips",
    "section": "3.9 Heat map with geom_tile",
    "text": "3.9 Heat map with geom_tile\n\n3.9.1 Sample Data\n\n\nCode\nlibrary(reshape)\n\n# Data \nset.seed(8)\nm &lt;- matrix(round(rnorm(200), 2), 10, 10)\n#&gt; Warning in matrix(round(rnorm(200), 2), 10, 10): data length differs from size\n#&gt; of matrix: [200 != 10 x 10]\ncolnames(m) &lt;- paste(\"Col\", 1:10)\nrownames(m) &lt;- paste(\"Row\", 1:10)\n\n# Transform the matrix in long format\ndf &lt;- melt(m)\n#&gt; Warning in type.convert.default(X[[i]], ...): 'as.is' should be specified by\n#&gt; the caller; using TRUE\n#&gt; Warning in type.convert.default(X[[i]], ...): 'as.is' should be specified by\n#&gt; the caller; using TRUE\ncolnames(df) &lt;- c(\"x\", \"y\", \"value\")\n\n\n\n\nCode\nggplot(df, aes(x = x, y = y, fill = value)) + \n  geom_tile()\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(df, aes(x = x, y = y, fill = value)) + \n  geom_tile() + \n  coord_fixed()\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(df, aes(x = x, y = y, fill = value)) + \n  geom_tile(\n    color = \"white\", \n    lwd = 1.5, \n    linetype = 1.\n  ) + \n  coord_fixed()\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(df, aes(x = x, y = y, fill = value)) + \n  geom_tile(color = \"black\") + \n  geom_text(aes(label = value), color = \"white\", size = 4) + \n  coord_fixed()\n\n\n\n\n\n\n\n\n\n\n\n3.9.2 Color Palette\n\n\nCode\nggplot(df, aes(x = x, y = y, fill = value)) + \n  geom_tile(color = \"black\") + \n  scale_fill_gradient(low = \"white\", high = \"red\")\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(df, aes(x = x, y = y, fill = value)) + \n  geom_tile(color = \"black\") + \n  scale_fill_gradient2(\n    low = \"#075AFF\", \n    mid = \"#FFFFCC\", \n    high = \"#FF0000\"\n  ) + \n  coord_fixed()\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(df, aes(x = x, y = y, fill = value)) + \n  geom_tile(color = \"black\") + \n  scale_fill_gradientn(colors = hcl.colors(20, \"RdYlGn\")) +\n  coord_fixed()\n\n\n\n\n\n\n\n\n\n\n\n3.9.3 Legend customization\n\n\nCode\nggplot(df, aes(x = x, y = y, fill = value)) + \n  geom_tile(color = \"black\") + \n  coord_fixed() + \n  guides(\n    fill = guide_colourbar(barwidth = .5, barheight = 20)\n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\n# install.packages(\"ggplot2\")\nlibrary(ggplot2)\n\nggplot(df, aes(x = x, y = y, fill = value)) +\n  geom_tile(color = \"black\") +\n  coord_fixed() +\n  guides(fill = guide_colourbar(title = \"Title\")) \n\n\n\n\n\n\n\n\n\n\n\nCode\n# install.packages(\"ggplot2\")\nlibrary(ggplot2)\n\nggplot(df, aes(x = x, y = y, fill = value)) +\n  geom_tile(color = \"black\") +\n  coord_fixed() +\n  guides(fill = guide_colourbar(label = FALSE,\n                                ticks = FALSE)) \n\n\n\n\n\n\n\n\n\n\n\nCode\n# install.packages(\"ggplot2\")\nlibrary(ggplot2)\n\nggplot(df, aes(x = x, y = y, fill = value)) +\n  geom_tile(color = \"black\") +\n  coord_fixed() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "contents/notes/ggplot2/working.html#alluvial-plot",
    "href": "contents/notes/ggplot2/working.html#alluvial-plot",
    "title": "ggplot2 Tips",
    "section": "3.10 Alluvial plot",
    "text": "3.10 Alluvial plot\n\n3.10.1 sample dataset\n\n\nCode\ndata(\"vaccinations\")\nvaccinations\n#&gt;        survey freq subject  response start_date   end_date\n#&gt; 1   ms153_NSA   48       1    Always 2010-09-22 2010-10-25\n#&gt; 2   ms153_NSA    9       2    Always 2010-09-22 2010-10-25\n#&gt; 3   ms153_NSA   66       3    Always 2010-09-22 2010-10-25\n#&gt; 4   ms153_NSA    1       4    Always 2010-09-22 2010-10-25\n#&gt; 5   ms153_NSA   11       5    Always 2010-09-22 2010-10-25\n#&gt; 6   ms153_NSA    1       6    Always 2010-09-22 2010-10-25\n#&gt; 7   ms153_NSA    5       7    Always 2010-09-22 2010-10-25\n#&gt; 8   ms153_NSA    4       8    Always 2010-09-22 2010-10-25\n#&gt; 9   ms153_NSA   24       9   Missing 2010-09-22 2010-10-25\n#&gt; 10  ms153_NSA    4      10   Missing 2010-09-22 2010-10-25\n#&gt; 11  ms153_NSA   29      11   Missing 2010-09-22 2010-10-25\n#&gt; 12  ms153_NSA    1      12   Missing 2010-09-22 2010-10-25\n#&gt; 13  ms153_NSA    1      13   Missing 2010-09-22 2010-10-25\n#&gt; 14  ms153_NSA    9      14   Missing 2010-09-22 2010-10-25\n#&gt; 15  ms153_NSA   10      15   Missing 2010-09-22 2010-10-25\n#&gt; 16  ms153_NSA   14      16   Missing 2010-09-22 2010-10-25\n#&gt; 17  ms153_NSA    3      17     Never 2010-09-22 2010-10-25\n#&gt; 18  ms153_NSA    7      18     Never 2010-09-22 2010-10-25\n#&gt; 19  ms153_NSA   42      19     Never 2010-09-22 2010-10-25\n#&gt; 20  ms153_NSA   20      20     Never 2010-09-22 2010-10-25\n#&gt; 21  ms153_NSA    2      21     Never 2010-09-22 2010-10-25\n#&gt; 22  ms153_NSA   36      22     Never 2010-09-22 2010-10-25\n#&gt; 23  ms153_NSA    7      23     Never 2010-09-22 2010-10-25\n#&gt; 24  ms153_NSA    2      24     Never 2010-09-22 2010-10-25\n#&gt; 25  ms153_NSA    4      25     Never 2010-09-22 2010-10-25\n#&gt; 26  ms153_NSA    9      26     Never 2010-09-22 2010-10-25\n#&gt; 27  ms153_NSA   48      27 Sometimes 2010-09-22 2010-10-25\n#&gt; 28  ms153_NSA   11      28 Sometimes 2010-09-22 2010-10-25\n#&gt; 29  ms153_NSA   99      29 Sometimes 2010-09-22 2010-10-25\n#&gt; 30  ms153_NSA    3      30 Sometimes 2010-09-22 2010-10-25\n#&gt; 31  ms153_NSA   41      31 Sometimes 2010-09-22 2010-10-25\n#&gt; 32  ms153_NSA  168      32 Sometimes 2010-09-22 2010-10-25\n#&gt; 33  ms153_NSA    2      33 Sometimes 2010-09-22 2010-10-25\n#&gt; 34  ms153_NSA   23      34 Sometimes 2010-09-22 2010-10-25\n#&gt; 35  ms153_NSA   22      35 Sometimes 2010-09-22 2010-10-25\n#&gt; 36  ms153_NSA   38      36 Sometimes 2010-09-22 2010-10-25\n#&gt; 37  ms153_NSA    1      37 Sometimes 2010-09-22 2010-10-25\n#&gt; 38  ms153_NSA   15      38 Sometimes 2010-09-22 2010-10-25\n#&gt; 39  ms153_NSA  113      39 Sometimes 2010-09-22 2010-10-25\n#&gt; 40  ms432_NSA   48       1    Always 2015-06-04 2015-10-05\n#&gt; 41  ms432_NSA    9       2    Always 2015-06-04 2015-10-05\n#&gt; 42  ms432_NSA   66       3   Missing 2015-06-04 2015-10-05\n#&gt; 43  ms432_NSA    1       4   Missing 2015-06-04 2015-10-05\n#&gt; 44  ms432_NSA   11       5   Missing 2015-06-04 2015-10-05\n#&gt; 45  ms432_NSA    1       6     Never 2015-06-04 2015-10-05\n#&gt; 46  ms432_NSA    5       7 Sometimes 2015-06-04 2015-10-05\n#&gt; 47  ms432_NSA    4       8 Sometimes 2015-06-04 2015-10-05\n#&gt; 48  ms432_NSA   24       9    Always 2015-06-04 2015-10-05\n#&gt; 49  ms432_NSA    4      10    Always 2015-06-04 2015-10-05\n#&gt; 50  ms432_NSA   29      11   Missing 2015-06-04 2015-10-05\n#&gt; 51  ms432_NSA    1      12   Missing 2015-06-04 2015-10-05\n#&gt; 52  ms432_NSA    1      13   Missing 2015-06-04 2015-10-05\n#&gt; 53  ms432_NSA    9      14   Missing 2015-06-04 2015-10-05\n#&gt; 54  ms432_NSA   10      15 Sometimes 2015-06-04 2015-10-05\n#&gt; 55  ms432_NSA   14      16 Sometimes 2015-06-04 2015-10-05\n#&gt; 56  ms432_NSA    3      17    Always 2015-06-04 2015-10-05\n#&gt; 57  ms432_NSA    7      18   Missing 2015-06-04 2015-10-05\n#&gt; 58  ms432_NSA   42      19   Missing 2015-06-04 2015-10-05\n#&gt; 59  ms432_NSA   20      20   Missing 2015-06-04 2015-10-05\n#&gt; 60  ms432_NSA    2      21     Never 2015-06-04 2015-10-05\n#&gt; 61  ms432_NSA   36      22     Never 2015-06-04 2015-10-05\n#&gt; 62  ms432_NSA    7      23     Never 2015-06-04 2015-10-05\n#&gt; 63  ms432_NSA    2      24 Sometimes 2015-06-04 2015-10-05\n#&gt; 64  ms432_NSA    4      25 Sometimes 2015-06-04 2015-10-05\n#&gt; 65  ms432_NSA    9      26 Sometimes 2015-06-04 2015-10-05\n#&gt; 66  ms432_NSA   48      27    Always 2015-06-04 2015-10-05\n#&gt; 67  ms432_NSA   11      28    Always 2015-06-04 2015-10-05\n#&gt; 68  ms432_NSA   99      29   Missing 2015-06-04 2015-10-05\n#&gt; 69  ms432_NSA    3      30   Missing 2015-06-04 2015-10-05\n#&gt; 70  ms432_NSA   41      31   Missing 2015-06-04 2015-10-05\n#&gt; 71  ms432_NSA  168      32   Missing 2015-06-04 2015-10-05\n#&gt; 72  ms432_NSA    2      33     Never 2015-06-04 2015-10-05\n#&gt; 73  ms432_NSA   23      34     Never 2015-06-04 2015-10-05\n#&gt; 74  ms432_NSA   22      35     Never 2015-06-04 2015-10-05\n#&gt; 75  ms432_NSA   38      36 Sometimes 2015-06-04 2015-10-05\n#&gt; 76  ms432_NSA    1      37 Sometimes 2015-06-04 2015-10-05\n#&gt; 77  ms432_NSA   15      38 Sometimes 2015-06-04 2015-10-05\n#&gt; 78  ms432_NSA  113      39 Sometimes 2015-06-04 2015-10-05\n#&gt; 79  ms460_NSA   48       1    Always 2016-09-27 2016-10-25\n#&gt; 80  ms460_NSA    9       2 Sometimes 2016-09-27 2016-10-25\n#&gt; 81  ms460_NSA   66       3    Always 2016-09-27 2016-10-25\n#&gt; 82  ms460_NSA    1       4     Never 2016-09-27 2016-10-25\n#&gt; 83  ms460_NSA   11       5 Sometimes 2016-09-27 2016-10-25\n#&gt; 84  ms460_NSA    1       6    Always 2016-09-27 2016-10-25\n#&gt; 85  ms460_NSA    5       7    Always 2016-09-27 2016-10-25\n#&gt; 86  ms460_NSA    4       8 Sometimes 2016-09-27 2016-10-25\n#&gt; 87  ms460_NSA   24       9    Always 2016-09-27 2016-10-25\n#&gt; 88  ms460_NSA    4      10 Sometimes 2016-09-27 2016-10-25\n#&gt; 89  ms460_NSA   29      11    Always 2016-09-27 2016-10-25\n#&gt; 90  ms460_NSA    1      12   Missing 2016-09-27 2016-10-25\n#&gt; 91  ms460_NSA    1      13     Never 2016-09-27 2016-10-25\n#&gt; 92  ms460_NSA    9      14 Sometimes 2016-09-27 2016-10-25\n#&gt; 93  ms460_NSA   10      15    Always 2016-09-27 2016-10-25\n#&gt; 94  ms460_NSA   14      16 Sometimes 2016-09-27 2016-10-25\n#&gt; 95  ms460_NSA    3      17    Always 2016-09-27 2016-10-25\n#&gt; 96  ms460_NSA    7      18    Always 2016-09-27 2016-10-25\n#&gt; 97  ms460_NSA   42      19     Never 2016-09-27 2016-10-25\n#&gt; 98  ms460_NSA   20      20 Sometimes 2016-09-27 2016-10-25\n#&gt; 99  ms460_NSA    2      21   Missing 2016-09-27 2016-10-25\n#&gt; 100 ms460_NSA   36      22     Never 2016-09-27 2016-10-25\n#&gt; 101 ms460_NSA    7      23 Sometimes 2016-09-27 2016-10-25\n#&gt; 102 ms460_NSA    2      24    Always 2016-09-27 2016-10-25\n#&gt; 103 ms460_NSA    4      25     Never 2016-09-27 2016-10-25\n#&gt; 104 ms460_NSA    9      26 Sometimes 2016-09-27 2016-10-25\n#&gt; 105 ms460_NSA   48      27    Always 2016-09-27 2016-10-25\n#&gt; 106 ms460_NSA   11      28 Sometimes 2016-09-27 2016-10-25\n#&gt; 107 ms460_NSA   99      29    Always 2016-09-27 2016-10-25\n#&gt; 108 ms460_NSA    3      30   Missing 2016-09-27 2016-10-25\n#&gt; 109 ms460_NSA   41      31     Never 2016-09-27 2016-10-25\n#&gt; 110 ms460_NSA  168      32 Sometimes 2016-09-27 2016-10-25\n#&gt; 111 ms460_NSA    2      33    Always 2016-09-27 2016-10-25\n#&gt; 112 ms460_NSA   23      34     Never 2016-09-27 2016-10-25\n#&gt; 113 ms460_NSA   22      35 Sometimes 2016-09-27 2016-10-25\n#&gt; 114 ms460_NSA   38      36    Always 2016-09-27 2016-10-25\n#&gt; 115 ms460_NSA    1      37   Missing 2016-09-27 2016-10-25\n#&gt; 116 ms460_NSA   15      38     Never 2016-09-27 2016-10-25\n#&gt; 117 ms460_NSA  113      39 Sometimes 2016-09-27 2016-10-25\n\n\n\n\n3.10.2 plot\n次の２つを使うことができるようになるのでコレを使うこと. 曲線の形は色々と選択することが可能である.\n\ngeom_alluvium\ngeom_stratum\n\n\n\nCode\n\nggplot(\n  data = vaccinations, \n  aes(\n    axis1 = survey, \n    axis2 = response, \n    y = freq\n  )) + \n  geom_alluvium(aes(fill = response), curve_type = \"sine\") + \n  geom_stratum() + \n  geom_text(\n    stat = \"stratum\", \n    aes(label = after_stat(stratum))\n  ) + \n  scale_x_discrete(limits = c(\"Survey\", \"Response\"), expand = c(.15, .05)) +\n  theme_void()\n\n\n\n\n\n\n\n\n\nもちろん色のカスタマイズも可能である.\n\n\nCode\ncolors &lt;- hcl.colors(4, \"Red-Blue\")\n\n\nggplot(\n  data = vaccinations, \n  aes(\n    axis1 = survey, \n    axis2 = response, \n    y = freq\n  ) \n) + \n  geom_alluvium(aes(fill = response)) + \n  geom_stratum() + \n  geom_text(\n    stat = \"stratum\", \n    aes(label = after_stat(stratum))\n  ) + \n  scale_x_discrete(limits = c(\"Survey\", \"Response\"), expand = c(.15, .05)) + \n  scale_fill_manual(values = colors) + \n  theme_void()\n\n\n\n\n\n\n\n\n\n\n\nCode\nhcl.colors(4, \"Red-Blue\")\n#&gt; [1] \"#A93154\" \"#BC569E\" \"#B788CD\" \"#AEB6E5\""
  },
  {
    "objectID": "contents/notes/ggplot2/working.html#ggbumps",
    "href": "contents/notes/ggplot2/working.html#ggbumps",
    "title": "ggplot2 Tips",
    "section": "3.11 ggbumps",
    "text": "3.11 ggbumps\n\n\nCode\nlibrary(ggplot2)\nlibrary(ggbump)\nlibrary(tidyverse)\n\n\ngithub\n\n\nCode\n\ndf &lt;- tibble(country = c(\"India\", \"India\", \"India\", \"Sweden\", \"Sweden\", \"Sweden\", \"Germany\", \"Germany\", \"Germany\", \"Finland\", \"Finland\", \"Finland\"),\n             year = c(2011, 2012, 2013, 2011, 2012, 2013, 2011, 2012, 2013, 2011, 2012, 2013),\n             value = c(492, 246, 246, 369, 123, 492, 246, 369, 123, 123, 492, 369))\n\ndf &lt;- df %&gt;% \n  group_by(year) %&gt;% \n  mutate(rank = rank(value, ties.method = \"random\")) %&gt;% \n  ungroup()\n\nknitr::kable(head(df))\n\n\n\n\n\ncountry\nyear\nvalue\nrank\n\n\n\n\nIndia\n2011\n492\n4\n\n\nIndia\n2012\n246\n2\n\n\nIndia\n2013\n246\n2\n\n\nSweden\n2011\n369\n3\n\n\nSweden\n2012\n123\n1\n\n\nSweden\n2013\n492\n4\n\n\n\n\n\n\n\nCode\nggplot(df, aes(year, rank, color = country)) +\n    geom_bump()\n\n\n\n\n\n\n\n\n\n\n\nCode\npacman::p_load(tidyverse, cowplot, wesanderson)\nggplot(df, aes(year, rank, color = country)) +\n  geom_point(size = 7) +\n  geom_text(data = df %&gt;% filter(year == min(year)),\n            aes(x = year - .1, label = country), size = 5, hjust = 1) +\n  geom_text(data = df %&gt;% filter(year == max(year)),\n            aes(x = year + .1, label = country), size = 5, hjust = 0) +\n  geom_bump(size = 2, smooth = 8) +\n  scale_x_continuous(limits = c(2010.6, 2013.4),\n                     breaks = seq(2011, 2013, 1)) +\n  theme_minimal_grid(font_size = 14, line_size = 0) +\n  theme(legend.position = \"none\",\n        panel.grid.major = element_blank()) +\n  labs(y = \"RANK\",\n       x = NULL) +\n  scale_y_reverse() +\n  scale_color_manual(values = wes_palette(n = 4, name = \"GrandBudapest1\"))\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Original df\ndf &lt;- tibble(season = c(\"Spring\", \"Pre-season\", \"Summer\", \"Season finale\", \"Autumn\", \"Winter\", \n                        \"Spring\", \"Pre-season\", \"Summer\", \"Season finale\", \"Autumn\", \"Winter\", \n                        \"Spring\", \"Pre-season\", \"Summer\", \"Season finale\", \"Autumn\", \"Winter\",\n                        \"Spring\", \"Pre-season\", \"Summer\", \"Season finale\", \"Autumn\", \"Winter\"),\n             rank = c(1, 3, 4, 2, 1, 4,\n                      2, 4, 1, 3, 2, 3,\n                      4, 1, 2, 4, 4, 1,\n                      3, 2, 3, 1, 3, 2),\n             player = c(rep(\"David\", 6),\n                        rep(\"Anna\", 6),\n                        rep(\"Franz\", 6),\n                        rep(\"Ika\", 6)))\n\n# Create factors and order factor\n# チュートリアルでは文字列などでも描画出来ていたけどここではうまくいかなった\n# x軸を数値に変更すると上手く描画できる\ndf &lt;- df %&gt;% \n  mutate(season = factor(season, levels = unique(season), ordered = TRUE)) \n\n# Add manual axis labels to plot\nggplot(df, aes(season, rank, color = player)) +\n  geom_bump(size = 2, smooth = 20, show.legend = F) +\n  geom_point(size = 5, aes(shape = player)) +\n  theme_minimal_grid(font_size = 10, line_size = 0) +\n  theme(panel.grid.major = element_blank(),\n        axis.ticks = element_blank()) +\n  scale_color_manual(values = wes_palette(n = 4, name = \"IsleofDogs1\"))\n#&gt; Warning in compute_group(...): 'StatBump' needs at least two observations per\n#&gt; group\n\n#&gt; Warning in compute_group(...): 'StatBump' needs at least two observations per\n#&gt; group\n\n#&gt; Warning in compute_group(...): 'StatBump' needs at least two observations per\n#&gt; group\n\n#&gt; Warning in compute_group(...): 'StatBump' needs at least two observations per\n#&gt; group\n\n#&gt; Warning in compute_group(...): 'StatBump' needs at least two observations per\n#&gt; group\n\n#&gt; Warning in compute_group(...): 'StatBump' needs at least two observations per\n#&gt; group\n\n#&gt; Warning in compute_group(...): 'StatBump' needs at least two observations per\n#&gt; group\n\n#&gt; Warning in compute_group(...): 'StatBump' needs at least two observations per\n#&gt; group\n\n#&gt; Warning in compute_group(...): 'StatBump' needs at least two observations per\n#&gt; group\n\n#&gt; Warning in compute_group(...): 'StatBump' needs at least two observations per\n#&gt; group\n\n#&gt; Warning in compute_group(...): 'StatBump' needs at least two observations per\n#&gt; group\n\n#&gt; Warning in compute_group(...): 'StatBump' needs at least two observations per\n#&gt; group\n\n#&gt; Warning in compute_group(...): 'StatBump' needs at least two observations per\n#&gt; group\n\n#&gt; Warning in compute_group(...): 'StatBump' needs at least two observations per\n#&gt; group\n\n#&gt; Warning in compute_group(...): 'StatBump' needs at least two observations per\n#&gt; group\n\n#&gt; Warning in compute_group(...): 'StatBump' needs at least two observations per\n#&gt; group\n\n#&gt; Warning in compute_group(...): 'StatBump' needs at least two observations per\n#&gt; group\n\n#&gt; Warning in compute_group(...): 'StatBump' needs at least two observations per\n#&gt; group\n\n#&gt; Warning in compute_group(...): 'StatBump' needs at least two observations per\n#&gt; group\n\n#&gt; Warning in compute_group(...): 'StatBump' needs at least two observations per\n#&gt; group\n\n#&gt; Warning in compute_group(...): 'StatBump' needs at least two observations per\n#&gt; group\n\n#&gt; Warning in compute_group(...): 'StatBump' needs at least two observations per\n#&gt; group\n\n#&gt; Warning in compute_group(...): 'StatBump' needs at least two observations per\n#&gt; group\n\n#&gt; Warning in compute_group(...): 'StatBump' needs at least two observations per\n#&gt; group"
  },
  {
    "objectID": "contents/notes/ggplot2/working.html#ggridges",
    "href": "contents/notes/ggplot2/working.html#ggridges",
    "title": "ggplot2 Tips",
    "section": "3.12 ggridges",
    "text": "3.12 ggridges\n公式ページをみるのが１番．どのようなグラフが描けるのかは，サンプルを見て欲しい．グラフの幅が拡がること間違いなし．\n\n\nCode\ndata &lt;- data.frame(x = 1:5, y = rep(1, 5), height = c(0, 1, 3, 4, 2))\nggplot(data, aes(x, y, height = height)) + geom_ridgeline()\n\n\n\n\n\n\n\n\n\n\n\nCode\n\ndata &lt;- data.frame(x = 1:5, y = rep(1, 5), height = c(0, 1, -1, 3, 2))\nplot_base &lt;- ggplot(data, aes(x, y, height = height))\n\nplot_base + geom_ridgeline() | plot_base + geom_ridgeline(min_height = -2)\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(iris, aes(x=Sepal.Length, y=Species, fill = factor(stat(quantile)))) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\", calc_ecdf = TRUE,\n    quantiles = 4, quantile_lines = TRUE\n  ) +\n  scale_fill_viridis_d(name = \"Quartiles\")\n#&gt; Warning: `stat(quantile)` was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `after_stat(quantile)` instead.\n#&gt; Picking joint bandwidth of 0.181\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(iris, aes(x = Sepal.Length, y = Species, fill = factor(stat(quantile)))) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE,\n    quantiles = c(0.025, 0.975)\n  ) +\n  scale_fill_manual(\n    name = \"Probability\", values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  )\n#&gt; Picking joint bandwidth of 0.181\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(iris, aes(x = Sepal.Length, y = Species)) +\n  geom_density_ridges(\n    jittered_points = TRUE, quantile_lines = TRUE, scale = 0.9, alpha = 0.7,\n    vline_size = 1, vline_color = \"red\",\n    point_size = 0.4, point_alpha = 1,\n    position = position_raincloud(adjust_vlines = TRUE)\n  )\n#&gt; Picking joint bandwidth of 0.181\n#&gt; Warning: Use of the `vline_size` or `size` aesthetic are deprecated, please use\n#&gt; `linewidth` instead of `size` and `vline_width` instead of `vline_size`.\n#&gt; Warning: Use of the `vline_size` aesthetics is deprecated, please use\n#&gt; `vline_width` instead of `vline_size`.\n\n#&gt; Warning: Use of the `vline_size` aesthetics is deprecated, please use\n#&gt; `vline_width` instead of `vline_size`.\n\n#&gt; Warning: Use of the `vline_size` aesthetics is deprecated, please use\n#&gt; `vline_width` instead of `vline_size`.\n\n\n\n\n\n\n\n\n\nスケールは縦スケールである．重なりを避けたい場合には小さくすればいいし，重なりがあっても強調したい場合には大きい値を設定すればよい.\n\n\nCode\nggplot(lincoln_weather, aes(x = `Mean Temperature [F]`, y = Month, fill = stat(x))) +\n  geom_density_ridges_gradient(scale = 3, rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\", option = \"C\") +\n  labs(title = 'Temperatures in Lincoln NE in 2016')\n#&gt; Picking joint bandwidth of 3.37"
  },
  {
    "objectID": "contents/notes/ggplot2/working.html#ggblend",
    "href": "contents/notes/ggplot2/working.html#ggblend",
    "title": "ggplot2 Tips",
    "section": "3.13 ggblend",
    "text": "3.13 ggblend\nlink\n透過色でグラフを記述すると，レンダリングの順番でグラフの見え方が変わる. pngにしているとブレンドが機能しないとのことである. RStudioのレンダリングをcario pngにするとRStudio上でレンダリングすることが可能であった.\n\n\nCode\nlibrary(ggplot2)\nlibrary(ggblend)\ntheme_set(ggdist::theme_ggdist() + theme(\n  plot.title = element_text(size = rel(1), lineheight = 1.1, face = \"bold\"),\n  plot.subtitle = element_text(face = \"italic\"),\n  panel.border = element_rect(color = \"gray75\", fill = NA)\n))\n\nset.seed(1234)\ndf_a = data.frame(x = rnorm(500, 0), y = rnorm(500, 1), set = \"a\")\ndf_b = data.frame(x = rnorm(500, 1), y = rnorm(500, 2), set = \"b\")\n\ndf_ab = rbind(df_a, df_b) |&gt;\n  transform(order = \"draw a then b\")\n\ndf_ba = rbind(df_b, df_a) |&gt;\n  transform(order = \"draw b then a\")\n\ndf = rbind(df_ab, df_ba)\n\n\n\n\nCode\ndf |&gt;\n  ggplot(aes(x, y, color = set)) +\n  geom_point(size = 3, alpha = 0.5) +\n  scale_color_brewer(palette = \"Set1\") +\n  facet_grid(~ order) +\n  labs(title = \"geom_point() without blending\", subtitle = \"Draw order matters.\")\n\n\n\n\n\n\n\n\n\n\n\nCode\noptions(ggblend.check_blend = FALSE)\ndf |&gt;\n  ggplot(aes(x, y, color = set)) +\n  geom_point(size = 3, alpha = 0.5) |&gt; blend(\"multiply\") +\n  scale_color_brewer(palette = \"Set1\") +\n  facet_grid(~ order) +\n  labs(\n    title = \"geom_point(alpha = 0.5) |&gt; blend('multiply')\",\n    subtitle = \"Draw order does not matter, but color is too dark.\"\n  )\n#&gt; Warning in drawDetails.GridGroup(x, recording = FALSE): Group definition failed\n\n#&gt; Warning in drawDetails.GridGroup(x, recording = FALSE): Group definition failed"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/119_欠測データ処理の基礎.html",
    "href": "contents/books/05_統計的因果推論の理論と実際/119_欠測データ処理の基礎.html",
    "title": "欠損データ処理",
    "section": "",
    "text": "MCAR(完全にランダム)\nMAR(条件付けたときにランダム)\nNMAR(ランダムとは言えない情況)\n\nMCARは欠測値を削除して良い． NMARのときには何もできない． MARのときは条件を探す必要がある.\nMARは次式で表される．つまり変数\\(X\\)の欠損を表す\\(K\\)は変数\\(Y\\)で条件づけたときに， 変数\\(X\\)の値によらない． たとえば性別で条件づけることで体重に関する回答の欠損の有無は 体重によらないと考えられる．\n\\[\nX \\perp K_i|Y\n\\]\nまあ色々あるけど多重代入法から傾向スコアマッチングによる効果推定がデフォルトでよい."
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/119_欠測データ処理の基礎.html#欠測のメカニズム",
    "href": "contents/books/05_統計的因果推論の理論と実際/119_欠測データ処理の基礎.html#欠測のメカニズム",
    "title": "欠損データ処理",
    "section": "",
    "text": "MCAR(完全にランダム)\nMAR(条件付けたときにランダム)\nNMAR(ランダムとは言えない情況)\n\nMCARは欠測値を削除して良い． NMARのときには何もできない． MARのときは条件を探す必要がある.\nMARは次式で表される．つまり変数\\(X\\)の欠損を表す\\(K\\)は変数\\(Y\\)で条件づけたときに， 変数\\(X\\)の値によらない． たとえば性別で条件づけることで体重に関する回答の欠損の有無は 体重によらないと考えられる．\n\\[\nX \\perp K_i|Y\n\\]\nまあ色々あるけど多重代入法から傾向スコアマッチングによる効果推定がデフォルトでよい."
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/114_操作変数法による非遵守への対処.html",
    "href": "contents/books/05_統計的因果推論の理論と実際/114_操作変数法による非遵守への対処.html",
    "title": "操作変数の非遵守への対処",
    "section": "",
    "text": "操作変数法による応用として，実験兼研究における無作為割り付けが守られない場合の対処法を考える．\n\n\n小学生の学力にテレビの視聴が与える影響を計りたいとする． 理論的には，無作為にサンプリングした小学生に，無作為にテレビの視聴時間を割り当てることで， 計測することができる．\nしかし，このような実験は必ずしも対象者が条件を守るとは限らない． 実験者が監視することは出来ないので，たとえば「視聴時間０」と割り付けられた対象者が， 本当にテレビを見ていないのかを管理することが出来ない． このような状況を非遵守という．\n\n\n処置の割り付け変数\\(T_i\\)とは別に，新たに\\(D_i\\)を個体\\(i\\)が 実際に処置を受けたかどうか表す変数として定義する． たとえば\\(D_i(T_i=0)=1\\)とは処理が割り付けられていないが実際には処置を受けたということを 表す．\\(T_i\\)と\\(D_i\\)の組合せで各個人がどのような振る舞いをするのかが分類できる.\n\n\n\n\n\n\nCode\ndata14 &lt;- read_csv(\"./causality/data14.csv\", show_col_types = FALSE)\ndata14 |&gt; head()\n#&gt; # A tibble: 6 × 7\n#&gt;      y3    t1    d1   y0t   y1t   d0t   d1t\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1    70     0     0    70    79     0     1\n#&gt; 2    74     0     0    74    82     0     1\n#&gt; 3    69     0     0    69    78     0     1\n#&gt; 4    81     0     0    81    89     0     1\n#&gt; 5    75     0     0    75    75     0     0\n#&gt; 6    69     0     0    69    69     0     0\n\n\n\n\n\n単調性は次式で表される．これは一言でいうと，処置が割り付けられたときにおこなわず， 割り付けられていないときにおこなう，という天邪鬼が存在していない，という仮定である.\n\\[\nD_i(T_i=1)\\ge D_i(T_i=0)\n\\]\n天邪鬼は実際には少ないため，上記の仮定は妥当なものと考えられる． これ以外の常に処置を受ける人，常に処置を受けない人は，処置効果を求められないので， 効果を計測することが出来ない． このため結局は，遵守者のみを対象にした推定をおこなうことになる.\n\\[\nCACE = E[Y_i(1)-Y_i(0)|C]\n\\]\n\n\nCode\n# d1tは処置が割り付けられたときに実際に取る行動\n# d0tは処理が割り付けられなかったときに実際に取る行動\n# d1t==1 & d0t ==0 は遵守者を抽出していることになる\nwith(subset(data14, d1t==1 & d0t==0), {\n    print(\n        mean(y1t) - mean(y0t)\n    )\n})\n#&gt; [1] 7.875\n\n\nとは言え遵守者を抽出出来ないので意味はない気もする．\n\n\n\n小学生のTVの話に戻ると，実際に制御することは出来ないが， TVを見ること，見ないことの奨励をすることは出来，奨励するのかどうかは 無作為化することが出来る．\n基本的に過小推定することしか出来ない． しかし，過小であることがわかっているので，それはそれで意味がある値となる．"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/114_操作変数法による非遵守への対処.html#非遵守",
    "href": "contents/books/05_統計的因果推論の理論と実際/114_操作変数法による非遵守への対処.html#非遵守",
    "title": "操作変数の非遵守への対処",
    "section": "",
    "text": "小学生の学力にテレビの視聴が与える影響を計りたいとする． 理論的には，無作為にサンプリングした小学生に，無作為にテレビの視聴時間を割り当てることで， 計測することができる．\nしかし，このような実験は必ずしも対象者が条件を守るとは限らない． 実験者が監視することは出来ないので，たとえば「視聴時間０」と割り付けられた対象者が， 本当にテレビを見ていないのかを管理することが出来ない． このような状況を非遵守という．\n\n\n処置の割り付け変数\\(T_i\\)とは別に，新たに\\(D_i\\)を個体\\(i\\)が 実際に処置を受けたかどうか表す変数として定義する． たとえば\\(D_i(T_i=0)=1\\)とは処理が割り付けられていないが実際には処置を受けたということを 表す．\\(T_i\\)と\\(D_i\\)の組合せで各個人がどのような振る舞いをするのかが分類できる."
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/114_操作変数法による非遵守への対処.html#使用するデータ",
    "href": "contents/books/05_統計的因果推論の理論と実際/114_操作変数法による非遵守への対処.html#使用するデータ",
    "title": "操作変数の非遵守への対処",
    "section": "",
    "text": "Code\ndata14 &lt;- read_csv(\"./causality/data14.csv\", show_col_types = FALSE)\ndata14 |&gt; head()\n#&gt; # A tibble: 6 × 7\n#&gt;      y3    t1    d1   y0t   y1t   d0t   d1t\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1    70     0     0    70    79     0     1\n#&gt; 2    74     0     0    74    82     0     1\n#&gt; 3    69     0     0    69    78     0     1\n#&gt; 4    81     0     0    81    89     0     1\n#&gt; 5    75     0     0    75    75     0     0\n#&gt; 6    69     0     0    69    69     0     0"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/114_操作変数法による非遵守への対処.html#単調性の仮定と推定対象者",
    "href": "contents/books/05_統計的因果推論の理論と実際/114_操作変数法による非遵守への対処.html#単調性の仮定と推定対象者",
    "title": "操作変数の非遵守への対処",
    "section": "",
    "text": "単調性は次式で表される．これは一言でいうと，処置が割り付けられたときにおこなわず， 割り付けられていないときにおこなう，という天邪鬼が存在していない，という仮定である.\n\\[\nD_i(T_i=1)\\ge D_i(T_i=0)\n\\]\n天邪鬼は実際には少ないため，上記の仮定は妥当なものと考えられる． これ以外の常に処置を受ける人，常に処置を受けない人は，処置効果を求められないので， 効果を計測することが出来ない． このため結局は，遵守者のみを対象にした推定をおこなうことになる.\n\\[\nCACE = E[Y_i(1)-Y_i(0)|C]\n\\]\n\n\nCode\n# d1tは処置が割り付けられたときに実際に取る行動\n# d0tは処理が割り付けられなかったときに実際に取る行動\n# d1t==1 & d0t ==0 は遵守者を抽出していることになる\nwith(subset(data14, d1t==1 & d0t==0), {\n    print(\n        mean(y1t) - mean(y0t)\n    )\n})\n#&gt; [1] 7.875\n\n\nとは言え遵守者を抽出出来ないので意味はない気もする．"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/114_操作変数法による非遵守への対処.html#無作為化奨励デザインと４つの推定量",
    "href": "contents/books/05_統計的因果推論の理論と実際/114_操作変数法による非遵守への対処.html#無作為化奨励デザインと４つの推定量",
    "title": "操作変数の非遵守への対処",
    "section": "",
    "text": "小学生のTVの話に戻ると，実際に制御することは出来ないが， TVを見ること，見ないことの奨励をすることは出来，奨励するのかどうかは 無作為化することが出来る．\n基本的に過小推定することしか出来ない． しかし，過小であることがわかっているので，それはそれで意味がある値となる．"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/112_傾向スコアによる層化解析法および重み付き法.html",
    "href": "contents/books/05_統計的因果推論の理論と実際/112_傾向スコアによる層化解析法および重み付き法.html",
    "title": "傾向スコアによる層化解析法および重み付き法",
    "section": "",
    "text": "ここまでに傾向スコアマッチングによりATTを推定できること， 仮定が満たされているならば共分散分析によりATEが推定できることも確認した． しかし，ATEを推定するための共分散分析の仮定を満たすことは現実的には難しい.\nそこで登場するのが傾向スコアを用いた層化解析手法である.\n\n\nまず層化抽出とは，母集団をいくつかのグループに分けて， それぞれのグループで無作為抽出する方法である． このときのグループは調べる共変量が似通った値になるように調整する． たとえば「県民性」を調べたいときには 日本全国からサンプリングするよりも４７都道府県別でサンプリングする方がよいのは 直感的に理解できる． 層別は「意味がある」特性が行うことが重要である．\n層別サンプリングは交絡因子を使って層にわけることで， 交絡因子の影響を受けるするという考えであり， フィッシャーの三原則の「局所管理」にあたる作法である．\n層ごとの推定値の情報をまとめたものを全体の推定値とする． \\(K\\)層に分けた場合のATEは次式で求められる.\n\\[\n\\begin{align}\n\\hat{\\tau}_{\\text{ATE}}&=\\sum_{k=1}^{K}\\frac{n_k}{N}[\\overline{Y_k}(1)-\\overline{Y_k}(0)]\\\\\n\\text{var}(\\hat{\\tau}_{\\text{ATE}})&=\\sum_{k=1}^{K}\\left(\\frac{n_k}{N}\\right)^2[\\overline{Y_k}(1)-\\overline{Y_k}(0)]\n\\end{align}\n\\]\n交絡変数をなくそうとして多変量で層別にすると， パターンは膨大になるので，傾向スコアで層別するのがやはり基本となる．\n\n\n\n\nCode\ndata11 &lt;- read_csv(\"./causality/data11.csv\", show_col_types = FALSE)\nwith(data11, {\n    print(\n        mean(y1t) - mean(y0t)\n    )\n})\n#&gt; [1] 3.755947\n\n\n\n\nCode\ndata11 |&gt; head()\n#&gt; # A tibble: 6 × 10\n#&gt;      y0t   y1t     y3    t1     x1     x2      x3      x4    x5     x6\n#&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1 12.7   23.2  12.7       0  2.75   3.08   1.74   1.04    0.708 -0.411\n#&gt; 2 61.6   64.7  64.7       1  0.640 -1.20  -0.0539 1.67    2.11   2.47 \n#&gt; 3 -0.275 -1.97 -0.275     0 -0.473  0.747  0.961  0.956   0.223 -1.06 \n#&gt; 4 25.8   38.4  25.8       0  1.27  -0.828 -0.962  0.00882 0.668  1.81 \n#&gt; 5 24.8   21.0  24.8       0  0.640 -0.492  0.630  0.114   0.936  0.886\n#&gt; 6 46.8   48.3  48.3       1  0.846 -0.855  0.159  1.05    1.29   2.05\n\n\n上記がATEのバイアスのない推定値である． この値が算出できるのかを傾向モデルを使った層別サンプリングで試す．\n\n\nCode\nlibrary(MatchIt)\n#&gt; Warning: package 'MatchIt' was built under R version 4.3.2\n\nsub    &lt;- 5\nm.out2 &lt;- matchit(\n    t1 ~ x1 + x2 + x3 + x4 + x5 + x6, \n    data      = data11, \n    method    = \"subclass\", \n    subclass  = sub, \n    estimand  = \"ATE\", \n    min.n     = 2\n)\nm.data2 &lt;- match.data(m.out2)\nm.data2\n#&gt; # A tibble: 1,000 × 13\n#&gt;        y0t   y1t      y3    t1     x1     x2      x3       x4       x5     x6\n#&gt;      &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n#&gt;  1  12.7   23.2   12.7       0  2.75   3.08   1.74    1.04     0.708   -0.411\n#&gt;  2  61.6   64.7   64.7       1  0.640 -1.20  -0.0539  1.67     2.11     2.47 \n#&gt;  3  -0.275 -1.97  -0.275     0 -0.473  0.747  0.961   0.956    0.223   -1.06 \n#&gt;  4  25.8   38.4   25.8       0  1.27  -0.828 -0.962   0.00882  0.668    1.81 \n#&gt;  5  24.8   21.0   24.8       0  0.640 -0.492  0.630   0.114    0.936    0.886\n#&gt;  6  46.8   48.3   48.3       1  0.846 -0.855  0.159   1.05     1.29     2.05 \n#&gt;  7  31.0   34.6   34.6       1  0.680 -0.106  0.304   0.362    1.66     0.992\n#&gt;  8  53.3   54.3   54.3       1  1.70   2.02   2.23    2.88     1.58     1.22 \n#&gt;  9  23.6   20.6   23.6       0 -0.752 -0.567  0.440   1.56     0.686    0.263\n#&gt; 10 -17.8   11.4  -17.8       0  1.05   0.397 -2.04   -0.851   -0.00748 -0.232\n#&gt; # ℹ 990 more rows\n#&gt; # ℹ 3 more variables: distance &lt;dbl&gt;, weights &lt;dbl&gt;, subclass &lt;fct&gt;\n\n\n上記で層を割り当てることが出来たので， 層ごとに解析して，その結果を集約すれば終わりである.\n\n\nCode\nlibrary(lmtest); library(sandwich);\n#&gt; Warning: package 'lmtest' was built under R version 4.3.2\n#&gt; Loading required package: zoo\n#&gt; \n#&gt; Attaching package: 'zoo'\n#&gt; The following objects are masked from 'package:base':\n#&gt; \n#&gt;     as.Date, as.Date.numeric\nfits &lt;- \n    m.data2 |&gt; \n    group_by(subclass) |&gt; \n    summarise(\n        fit = list(lm(y3 ~ t1 + x1 + x2 + x3 + x4 + x5 + x6, data = cur_data()))\n    )\n#&gt; Warning: There was 1 warning in `summarise()`.\n#&gt; ℹ In argument: `fit = list(lm(y3 ~ t1 + x1 + x2 + x3 + x4 + x5 + x6, data =\n#&gt;   cur_data()))`.\n#&gt; ℹ In group 1: `subclass = 1`.\n#&gt; Caused by warning:\n#&gt; ! `cur_data()` was deprecated in dplyr 1.1.0.\n#&gt; ℹ Please use `pick()` instead.\nclass_size &lt;- \n    m.data2 |&gt; \n    count(subclass, name = \"N\")\nfit_stats &lt;- \n    fits |&gt; \n    mutate(coef = map(fit, ~ tidy(.x))) |&gt; \n    select(!fit) |&gt; \n    unnest(coef) |&gt; \n    filter(term == \"t1\") \nate &lt;- \n    fit_stats|&gt; \n    left_join(class_size, by = \"subclass\") |&gt; \n    mutate( \n        psvar = std.error ^ 2\n    ) |&gt; \n    select(\n        subclass, \n        psp = estimate, \n        psvar, \n        nps = N, \n        p.value\n    )\n    \nate\n#&gt; # A tibble: 5 × 5\n#&gt;   subclass   psp psvar   nps  p.value\n#&gt;   &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt;\n#&gt; 1 1        8.21  0.401   200 5.16e-28\n#&gt; 2 2        4.48  0.567   200 1.26e- 8\n#&gt; 3 3        3.82  0.488   200 1.44e- 7\n#&gt; 4 4        2.12  0.493   200 2.86e- 3\n#&gt; 5 5        0.114 0.411   200 8.58e- 1\n\n\n上記の結果を集約する.\n\n\nCode\nestimated &lt;- \n    ate |&gt; \n    summarise(\n        tauhat = sum(nps/sum(nps) * psp), \n        vartau = sum((nps/sum(nps)) ^ 2 * psvar), \n        settau = sqrt(vartau)\n    )\n\nestimated\n#&gt; # A tibble: 1 × 3\n#&gt;   tauhat vartau settau\n#&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1   3.75 0.0944  0.307\n\n\n\n\n\n\nStd.Mean Diffの値が0に近く, Var.Ratioの値が1に近ければ， バランシングが取れていることを意味する. ここでは出力結果を省略する.\n\n\nCode\nsummary(m.out2)\n#&gt; \n#&gt; Call:\n#&gt; matchit(formula = t1 ~ x1 + x2 + x3 + x4 + x5 + x6, data = data11, \n#&gt;     method = \"subclass\", estimand = \"ATE\", subclass = sub, min.n = 2)\n#&gt; \n#&gt; Summary of Balance for All Data:\n#&gt;          Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance        0.4371        0.3584          0.6007     0.9897    0.1755\n#&gt; x1              0.9655        0.9919         -0.0280     0.7966    0.0210\n#&gt; x2              0.9596        0.9810         -0.0211     0.8841    0.0200\n#&gt; x3              1.1451        0.9162          0.2213     1.0303    0.0616\n#&gt; x4              1.2246        0.8986          0.3371     0.9352    0.1017\n#&gt; x5              1.2874        0.7913          0.4971     1.0065    0.1461\n#&gt; x6              1.2896        0.8382          0.4753     0.9166    0.1376\n#&gt;          eCDF Max\n#&gt; distance   0.3232\n#&gt; x1         0.0540\n#&gt; x2         0.0524\n#&gt; x3         0.1002\n#&gt; x4         0.1797\n#&gt; x5         0.2387\n#&gt; x6         0.2212\n#&gt; \n#&gt; Summary of Balance Across Subclasses\n#&gt;          Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance        0.3902        0.3882          0.0148     1.0303    0.0095\n#&gt; x1              0.9917        0.9727          0.0202     0.7583    0.0190\n#&gt; x2              0.9844        0.9713          0.0129     0.9283    0.0213\n#&gt; x3              1.0157        1.0030          0.0123     1.0600    0.0107\n#&gt; x4              1.0413        1.0228          0.0191     0.9487    0.0205\n#&gt; x5              0.9994        0.9760          0.0235     1.0893    0.0100\n#&gt; x6              1.0112        1.0121         -0.0009     0.9771    0.0083\n#&gt;          eCDF Max\n#&gt; distance   0.0339\n#&gt; x1         0.0536\n#&gt; x2         0.0474\n#&gt; x3         0.0408\n#&gt; x4         0.0553\n#&gt; x5         0.0324\n#&gt; x6         0.0328\n#&gt; \n#&gt; Sample Sizes:\n#&gt;               Control Treated\n#&gt; All            611.       389\n#&gt; Matched (ESS)  570.38     325\n#&gt; Matched        611.       389\n#&gt; Unmatched        0.         0\n#&gt; Discarded        0.         0\n\n\n\n\nCode\ndiffa &lt;- abs(summary(m.out2)$sum.all[,3])\ndiffb &lt;- abs(summary(m.out2)$sum.acros[,3])\ndiff1 &lt;- rev(diffa)\ndiff2 &lt;- rev(diffb)\n\nmaxx    &lt;- max(diff1, diff2)\nlabels0 &lt;- rownames(summary(m.out2)$sum.all)\nlabels1 &lt;- rev(labels0)\n\ndotchart(diff1, xlim = c(0, maxx), labels = c(labels1))\nabline(v = .0, col = 8)\nabline(v = .1, col = 8)\nabline(v = .05, lty = 2, col = 8)\n\npar(new = TRUE)\ndotchart(diff2, xlim = c(0, maxx), labels = c(labels1), \n         pch = 16, xlab = \"Absolute Standardized Mean Difference\")\n\n\n\n\n\n\n\n\n\n\n\n\n調査標本における重み付けと似ている． 調査標本ではある個体がサンプリングされる確率が等確率にならない， つまり，ランダムサンプリングが実現できない現象である．\n例えば男子6000人，女子4000人の学校で1000人を対象にしたアンケートを行うとき， 女子ロッカーに関することのため女子の人数を多くしたアンケートをしたいと考える． このとき，男子120人，女子880人をサンプリングすると， 男子は120/6000なので0.02, 女子は880/4000なので0.22の確率でサンプリングされる．\nそこでサンプリングされた個人の意見はサンプリング確率の逆数， この場合だと男子は50人, 女子は4.8人分の価値があると解釈する． これが，重み付け法である．\n\n\n標本調査では抽出確率の逆数を使っていた． 傾向スコアは共変量\\(X\\)があたてられたとき，処置に割り付けられる確率という意味であることから， その逆数を重みとして使うことは自然である． これを逆重み付け法(IPW)とおいう.\n無作為化実験から得られるであろう解析結果に一致するように， 処置群の個体に対して「傾向スコアの逆数」を乗じて， 統制群の個体に対して「１－傾向スコア」の逆数を乗じることで，データの重み付けを算出する． つまり出にくい方の値が出たときにはその価値を重視するというものとなる．\n\\[\nw_i = \\frac{T_i}{\\hat{e_i}}+\\frac{1-T_i}{1-\\hat{e_i}}\n\\]\n上記の計算は傾向スコアを算出したのちに，そのスコアを重みとした 回帰分析を行うことで算出が可能である.\n\n\nCode\nmodel1  &lt;- glm(t1 ~ x1 + x2 + x3 + x4 + x5 + x6, data = data11, family = binomial(link = \"logit\"))\nps1     &lt;- model1$fitted.values\nweights &lt;- data11$t1 / ps1 + (1 - data11$t1) / (1 - ps1)\n\n\n\n\nCode\nmodel2 &lt;- lm(y3 ~ t1, data = data11, weights = weights)\nmodel3 &lt;- lm(y3 ~ t1 + x1 + x2 + x3 + x4 + x5 + x6, data = data11, weights = weights)\n\n\n\n\nCode\ntidy(model2)\n#&gt; # A tibble: 2 × 5\n#&gt;   term        estimate std.error statistic   p.value\n#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 (Intercept)    31.9       1.06     29.9  4.09e-141\n#&gt; 2 t1              3.20      1.51      2.13 3.38e-  2\n\n\n\n\nCode\ntidy(model3)\n#&gt; # A tibble: 8 × 5\n#&gt;   term        estimate std.error statistic   p.value\n#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 (Intercept)    1.36      0.341      3.98 7.44e-  5\n#&gt; 2 t1             3.82      0.311     12.3  2.66e- 32\n#&gt; 3 x1             1.54      0.191      8.05 2.29e- 15\n#&gt; 4 x2             0.454     0.198      2.30 2.19e-  2\n#&gt; 5 x3            -0.765     0.198     -3.87 1.15e-  4\n#&gt; 6 x4             7.64      0.208     36.7  2.87e-187\n#&gt; 7 x5             9.68      0.195     49.6  9.98e-271\n#&gt; 8 x6            11.3       0.187     60.2  0"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/112_傾向スコアによる層化解析法および重み付き法.html#傾向スコアによる層化解析法",
    "href": "contents/books/05_統計的因果推論の理論と実際/112_傾向スコアによる層化解析法および重み付き法.html#傾向スコアによる層化解析法",
    "title": "傾向スコアによる層化解析法および重み付き法",
    "section": "",
    "text": "まず層化抽出とは，母集団をいくつかのグループに分けて， それぞれのグループで無作為抽出する方法である． このときのグループは調べる共変量が似通った値になるように調整する． たとえば「県民性」を調べたいときには 日本全国からサンプリングするよりも４７都道府県別でサンプリングする方がよいのは 直感的に理解できる． 層別は「意味がある」特性が行うことが重要である．\n層別サンプリングは交絡因子を使って層にわけることで， 交絡因子の影響を受けるするという考えであり， フィッシャーの三原則の「局所管理」にあたる作法である．\n層ごとの推定値の情報をまとめたものを全体の推定値とする． \\(K\\)層に分けた場合のATEは次式で求められる.\n\\[\n\\begin{align}\n\\hat{\\tau}_{\\text{ATE}}&=\\sum_{k=1}^{K}\\frac{n_k}{N}[\\overline{Y_k}(1)-\\overline{Y_k}(0)]\\\\\n\\text{var}(\\hat{\\tau}_{\\text{ATE}})&=\\sum_{k=1}^{K}\\left(\\frac{n_k}{N}\\right)^2[\\overline{Y_k}(1)-\\overline{Y_k}(0)]\n\\end{align}\n\\]\n交絡変数をなくそうとして多変量で層別にすると， パターンは膨大になるので，傾向スコアで層別するのがやはり基本となる．\n\n\n\n\nCode\ndata11 &lt;- read_csv(\"./causality/data11.csv\", show_col_types = FALSE)\nwith(data11, {\n    print(\n        mean(y1t) - mean(y0t)\n    )\n})\n#&gt; [1] 3.755947\n\n\n\n\nCode\ndata11 |&gt; head()\n#&gt; # A tibble: 6 × 10\n#&gt;      y0t   y1t     y3    t1     x1     x2      x3      x4    x5     x6\n#&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1 12.7   23.2  12.7       0  2.75   3.08   1.74   1.04    0.708 -0.411\n#&gt; 2 61.6   64.7  64.7       1  0.640 -1.20  -0.0539 1.67    2.11   2.47 \n#&gt; 3 -0.275 -1.97 -0.275     0 -0.473  0.747  0.961  0.956   0.223 -1.06 \n#&gt; 4 25.8   38.4  25.8       0  1.27  -0.828 -0.962  0.00882 0.668  1.81 \n#&gt; 5 24.8   21.0  24.8       0  0.640 -0.492  0.630  0.114   0.936  0.886\n#&gt; 6 46.8   48.3  48.3       1  0.846 -0.855  0.159  1.05    1.29   2.05\n\n\n上記がATEのバイアスのない推定値である． この値が算出できるのかを傾向モデルを使った層別サンプリングで試す．\n\n\nCode\nlibrary(MatchIt)\n#&gt; Warning: package 'MatchIt' was built under R version 4.3.2\n\nsub    &lt;- 5\nm.out2 &lt;- matchit(\n    t1 ~ x1 + x2 + x3 + x4 + x5 + x6, \n    data      = data11, \n    method    = \"subclass\", \n    subclass  = sub, \n    estimand  = \"ATE\", \n    min.n     = 2\n)\nm.data2 &lt;- match.data(m.out2)\nm.data2\n#&gt; # A tibble: 1,000 × 13\n#&gt;        y0t   y1t      y3    t1     x1     x2      x3       x4       x5     x6\n#&gt;      &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n#&gt;  1  12.7   23.2   12.7       0  2.75   3.08   1.74    1.04     0.708   -0.411\n#&gt;  2  61.6   64.7   64.7       1  0.640 -1.20  -0.0539  1.67     2.11     2.47 \n#&gt;  3  -0.275 -1.97  -0.275     0 -0.473  0.747  0.961   0.956    0.223   -1.06 \n#&gt;  4  25.8   38.4   25.8       0  1.27  -0.828 -0.962   0.00882  0.668    1.81 \n#&gt;  5  24.8   21.0   24.8       0  0.640 -0.492  0.630   0.114    0.936    0.886\n#&gt;  6  46.8   48.3   48.3       1  0.846 -0.855  0.159   1.05     1.29     2.05 \n#&gt;  7  31.0   34.6   34.6       1  0.680 -0.106  0.304   0.362    1.66     0.992\n#&gt;  8  53.3   54.3   54.3       1  1.70   2.02   2.23    2.88     1.58     1.22 \n#&gt;  9  23.6   20.6   23.6       0 -0.752 -0.567  0.440   1.56     0.686    0.263\n#&gt; 10 -17.8   11.4  -17.8       0  1.05   0.397 -2.04   -0.851   -0.00748 -0.232\n#&gt; # ℹ 990 more rows\n#&gt; # ℹ 3 more variables: distance &lt;dbl&gt;, weights &lt;dbl&gt;, subclass &lt;fct&gt;\n\n\n上記で層を割り当てることが出来たので， 層ごとに解析して，その結果を集約すれば終わりである.\n\n\nCode\nlibrary(lmtest); library(sandwich);\n#&gt; Warning: package 'lmtest' was built under R version 4.3.2\n#&gt; Loading required package: zoo\n#&gt; \n#&gt; Attaching package: 'zoo'\n#&gt; The following objects are masked from 'package:base':\n#&gt; \n#&gt;     as.Date, as.Date.numeric\nfits &lt;- \n    m.data2 |&gt; \n    group_by(subclass) |&gt; \n    summarise(\n        fit = list(lm(y3 ~ t1 + x1 + x2 + x3 + x4 + x5 + x6, data = cur_data()))\n    )\n#&gt; Warning: There was 1 warning in `summarise()`.\n#&gt; ℹ In argument: `fit = list(lm(y3 ~ t1 + x1 + x2 + x3 + x4 + x5 + x6, data =\n#&gt;   cur_data()))`.\n#&gt; ℹ In group 1: `subclass = 1`.\n#&gt; Caused by warning:\n#&gt; ! `cur_data()` was deprecated in dplyr 1.1.0.\n#&gt; ℹ Please use `pick()` instead.\nclass_size &lt;- \n    m.data2 |&gt; \n    count(subclass, name = \"N\")\nfit_stats &lt;- \n    fits |&gt; \n    mutate(coef = map(fit, ~ tidy(.x))) |&gt; \n    select(!fit) |&gt; \n    unnest(coef) |&gt; \n    filter(term == \"t1\") \nate &lt;- \n    fit_stats|&gt; \n    left_join(class_size, by = \"subclass\") |&gt; \n    mutate( \n        psvar = std.error ^ 2\n    ) |&gt; \n    select(\n        subclass, \n        psp = estimate, \n        psvar, \n        nps = N, \n        p.value\n    )\n    \nate\n#&gt; # A tibble: 5 × 5\n#&gt;   subclass   psp psvar   nps  p.value\n#&gt;   &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt;\n#&gt; 1 1        8.21  0.401   200 5.16e-28\n#&gt; 2 2        4.48  0.567   200 1.26e- 8\n#&gt; 3 3        3.82  0.488   200 1.44e- 7\n#&gt; 4 4        2.12  0.493   200 2.86e- 3\n#&gt; 5 5        0.114 0.411   200 8.58e- 1\n\n\n上記の結果を集約する.\n\n\nCode\nestimated &lt;- \n    ate |&gt; \n    summarise(\n        tauhat = sum(nps/sum(nps) * psp), \n        vartau = sum((nps/sum(nps)) ^ 2 * psvar), \n        settau = sqrt(vartau)\n    )\n\nestimated\n#&gt; # A tibble: 1 × 3\n#&gt;   tauhat vartau settau\n#&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1   3.75 0.0944  0.307"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/112_傾向スコアによる層化解析法および重み付き法.html#傾向スコアによるバランシングの評価",
    "href": "contents/books/05_統計的因果推論の理論と実際/112_傾向スコアによる層化解析法および重み付き法.html#傾向スコアによるバランシングの評価",
    "title": "傾向スコアによる層化解析法および重み付き法",
    "section": "",
    "text": "Std.Mean Diffの値が0に近く, Var.Ratioの値が1に近ければ， バランシングが取れていることを意味する. ここでは出力結果を省略する.\n\n\nCode\nsummary(m.out2)\n#&gt; \n#&gt; Call:\n#&gt; matchit(formula = t1 ~ x1 + x2 + x3 + x4 + x5 + x6, data = data11, \n#&gt;     method = \"subclass\", estimand = \"ATE\", subclass = sub, min.n = 2)\n#&gt; \n#&gt; Summary of Balance for All Data:\n#&gt;          Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance        0.4371        0.3584          0.6007     0.9897    0.1755\n#&gt; x1              0.9655        0.9919         -0.0280     0.7966    0.0210\n#&gt; x2              0.9596        0.9810         -0.0211     0.8841    0.0200\n#&gt; x3              1.1451        0.9162          0.2213     1.0303    0.0616\n#&gt; x4              1.2246        0.8986          0.3371     0.9352    0.1017\n#&gt; x5              1.2874        0.7913          0.4971     1.0065    0.1461\n#&gt; x6              1.2896        0.8382          0.4753     0.9166    0.1376\n#&gt;          eCDF Max\n#&gt; distance   0.3232\n#&gt; x1         0.0540\n#&gt; x2         0.0524\n#&gt; x3         0.1002\n#&gt; x4         0.1797\n#&gt; x5         0.2387\n#&gt; x6         0.2212\n#&gt; \n#&gt; Summary of Balance Across Subclasses\n#&gt;          Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance        0.3902        0.3882          0.0148     1.0303    0.0095\n#&gt; x1              0.9917        0.9727          0.0202     0.7583    0.0190\n#&gt; x2              0.9844        0.9713          0.0129     0.9283    0.0213\n#&gt; x3              1.0157        1.0030          0.0123     1.0600    0.0107\n#&gt; x4              1.0413        1.0228          0.0191     0.9487    0.0205\n#&gt; x5              0.9994        0.9760          0.0235     1.0893    0.0100\n#&gt; x6              1.0112        1.0121         -0.0009     0.9771    0.0083\n#&gt;          eCDF Max\n#&gt; distance   0.0339\n#&gt; x1         0.0536\n#&gt; x2         0.0474\n#&gt; x3         0.0408\n#&gt; x4         0.0553\n#&gt; x5         0.0324\n#&gt; x6         0.0328\n#&gt; \n#&gt; Sample Sizes:\n#&gt;               Control Treated\n#&gt; All            611.       389\n#&gt; Matched (ESS)  570.38     325\n#&gt; Matched        611.       389\n#&gt; Unmatched        0.         0\n#&gt; Discarded        0.         0\n\n\n\n\nCode\ndiffa &lt;- abs(summary(m.out2)$sum.all[,3])\ndiffb &lt;- abs(summary(m.out2)$sum.acros[,3])\ndiff1 &lt;- rev(diffa)\ndiff2 &lt;- rev(diffb)\n\nmaxx    &lt;- max(diff1, diff2)\nlabels0 &lt;- rownames(summary(m.out2)$sum.all)\nlabels1 &lt;- rev(labels0)\n\ndotchart(diff1, xlim = c(0, maxx), labels = c(labels1))\nabline(v = .0, col = 8)\nabline(v = .1, col = 8)\nabline(v = .05, lty = 2, col = 8)\n\npar(new = TRUE)\ndotchart(diff2, xlim = c(0, maxx), labels = c(labels1), \n         pch = 16, xlab = \"Absolute Standardized Mean Difference\")"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/112_傾向スコアによる層化解析法および重み付き法.html#傾向スコアによる重み付け法",
    "href": "contents/books/05_統計的因果推論の理論と実際/112_傾向スコアによる層化解析法および重み付き法.html#傾向スコアによる重み付け法",
    "title": "傾向スコアによる層化解析法および重み付き法",
    "section": "",
    "text": "調査標本における重み付けと似ている． 調査標本ではある個体がサンプリングされる確率が等確率にならない， つまり，ランダムサンプリングが実現できない現象である．\n例えば男子6000人，女子4000人の学校で1000人を対象にしたアンケートを行うとき， 女子ロッカーに関することのため女子の人数を多くしたアンケートをしたいと考える． このとき，男子120人，女子880人をサンプリングすると， 男子は120/6000なので0.02, 女子は880/4000なので0.22の確率でサンプリングされる．\nそこでサンプリングされた個人の意見はサンプリング確率の逆数， この場合だと男子は50人, 女子は4.8人分の価値があると解釈する． これが，重み付け法である．\n\n\n標本調査では抽出確率の逆数を使っていた． 傾向スコアは共変量\\(X\\)があたてられたとき，処置に割り付けられる確率という意味であることから， その逆数を重みとして使うことは自然である． これを逆重み付け法(IPW)とおいう.\n無作為化実験から得られるであろう解析結果に一致するように， 処置群の個体に対して「傾向スコアの逆数」を乗じて， 統制群の個体に対して「１－傾向スコア」の逆数を乗じることで，データの重み付けを算出する． つまり出にくい方の値が出たときにはその価値を重視するというものとなる．\n\\[\nw_i = \\frac{T_i}{\\hat{e_i}}+\\frac{1-T_i}{1-\\hat{e_i}}\n\\]\n上記の計算は傾向スコアを算出したのちに，そのスコアを重みとした 回帰分析を行うことで算出が可能である.\n\n\nCode\nmodel1  &lt;- glm(t1 ~ x1 + x2 + x3 + x4 + x5 + x6, data = data11, family = binomial(link = \"logit\"))\nps1     &lt;- model1$fitted.values\nweights &lt;- data11$t1 / ps1 + (1 - data11$t1) / (1 - ps1)\n\n\n\n\nCode\nmodel2 &lt;- lm(y3 ~ t1, data = data11, weights = weights)\nmodel3 &lt;- lm(y3 ~ t1 + x1 + x2 + x3 + x4 + x5 + x6, data = data11, weights = weights)\n\n\n\n\nCode\ntidy(model2)\n#&gt; # A tibble: 2 × 5\n#&gt;   term        estimate std.error statistic   p.value\n#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 (Intercept)    31.9       1.06     29.9  4.09e-141\n#&gt; 2 t1              3.20      1.51      2.13 3.38e-  2\n\n\n\n\nCode\ntidy(model3)\n#&gt; # A tibble: 8 × 5\n#&gt;   term        estimate std.error statistic   p.value\n#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 (Intercept)    1.36      0.341      3.98 7.44e-  5\n#&gt; 2 t1             3.82      0.311     12.3  2.66e- 32\n#&gt; 3 x1             1.54      0.191      8.05 2.29e- 15\n#&gt; 4 x2             0.454     0.198      2.30 2.19e-  2\n#&gt; 5 x3            -0.765     0.198     -3.87 1.15e-  4\n#&gt; 6 x4             7.64      0.208     36.7  2.87e-187\n#&gt; 7 x5             9.68      0.195     49.6  9.98e-271\n#&gt; 8 x6            11.3       0.187     60.2  0"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/110_傾向スコア.html",
    "href": "contents/books/05_統計的因果推論の理論と実際/110_傾向スコア.html",
    "title": "傾向スコア",
    "section": "",
    "text": "実験研究がよいのは，処置の有無を無作為に割り付けられることで， 共変量の分布が確率的に同じになることにより， 交絡が発生しないことである．\n観察研究における因果推論が難しいのは，処置群と統制群が傾向的に異なっている可能性のためである．\n傾向スコアによる分析は「準実験」と呼ばれる． 処置の無作為な割り付けが出来ない場合でも， 割り付けや比較対象の集団について研究者が何らかの統制を行うことで 無作為化をマネすデザインのことをいう．\n傾向スコアマッチングとは傾向スコアが同じペアを同一だと見なし， 処置群の処置効果を測るための手法とするものである. 共変量で調整されていれば，結果の違いは，共変量以外の要因からなり， それは主として処置効果からくるものと考えられる． この考え方の妥当性は，これまでと同じように条件付き独立性が満たされるという考え方になる.\n\\[\n\\{Y(1), Y(0)\\} \\perp T |X\n\\] 上記のマッチングがうまく出来れば, 本来観測不可能である「処置群の処置効果(ATT)」を推定することが可能となる．傾向スコアによりATEを推定するには，スコアごとの層別解析をなんらかの方法で平均すればよい.\n\\[\n\\tau_{ATT}=E[Y_i(1)-Y_i(0)|T_i=1]=E[Y_i(1)|T_i=1]-E[T_i(0)|T_i=1]\n\\] なお，これまで調べていたのは「処置の平均効果(ATE)」である．これは，処置と結果変数を独立となるようにすることで，推定が行える.\n\\[\n\\tau_{ATE}=E[Y_i(1)-Y_i(0)|T_i]=E[Y_i(1)|T_i]-E[T_i(0)|T_i]=E[Y_i(1)]-E[T_i(0)]\n\\]\nとはいえ，まずはATTとATEは異なるということをまずは知っておく必要がある．\n\n\n共変量が単変量の場合には共分散分析により解析することが出来た． しかし，通常共変量は多変量である．これに対して傾向スコアが開発された． 傾向スコアとはバランシングスコアの１つであり， 観測される共変量\\(X\\)の関数\\(b(X)\\)が与えられたときの\\(X\\)の条件つき分布が， 処置群と統制群において同じとなる関数である.\nとにかくバランシングスコアを見るようにして，バランシングスコアが悪いときに，マッチングを使ったATT推定を行ってはならない. マッチしたからといってどの程度マッチに意味があるかは，別であるよね，という話だと理解した．\n\n\nCode\ndata10a &lt;- read_csv(\"./causality/data10a.csv\", show_col_types = FALSE)\n\n# 平均処置効果\nwith(data10a, {\n    print(mean(y1t) - mean(y0t))\n})\n#&gt; [1] 9.95\n\n# 処置群の平均処置効果\nwith(data10a, {\n    print(mean(y1t[t1==1])-mean(y0t[t1==1]))   \n})\n#&gt; [1] 9.090909\n\n# ナイーブな平均処置効果\nwith(data10a, {\n    print(mean(y1t[t1==1])-mean(y0t[t1==0]))   \n})\n#&gt; [1] 17.39394\n\n\nナイーブな平均処置結果が使えないことがよくわかる.\nこのような結果が起こるのは共変量の分布が異なることによる. 処置群と統制群で平均値や分散が同じになることを指して「バランスが取れている」ということになる．\n\n\nCode\ndata10a |&gt; \n    group_by(t1) |&gt;\n    summarise(quantile = list(stack(quantile(x1)))) |&gt; \n    unnest(quantile) |&gt; \n    pivot_wider(id_cols = t1, names_from = \"ind\", values_from = \"values\")\n#&gt; # A tibble: 2 × 6\n#&gt;      t1  `0%` `25%` `50%` `75%` `100%`\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1     0    66  70      74    78     88\n#&gt; 2     1    73  77.5    83    89     92\n\n\n\n\n\n共変量が多変量である場合を考える. 多変量である場合には上記のように 共変量の分布が同一であるのかを確認することは容易ではない．\n\n\nCode\ndata10b &lt;- read_csv(\"./causality/data10b.csv\", show_col_types = FALSE)\nprint(data10b |&gt; head())\n#&gt; # A tibble: 6 × 8\n#&gt;     y0t   y1t    t1     y    x1    x2    x3   ps1\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1    63    74     0    63    66    76    75  0.12\n#&gt; 2    55    70     0    55    70    75    55  0.05\n#&gt; 3    59    69     0    59    70    60    73  0.19\n#&gt; 4    71    77     1    77    73    76    82  0.43\n#&gt; 5    73    78     0    73    73    79    78  0.35\n#&gt; 6    66    77     0    66    74    72    79  0.41\n\n\nそこで傾向スコアを考える．傾向スコアとは，共変量\\(X\\)が与えられたとき， 処置に割り付けらあれる確率と定義される．\n\\[\ne(X) = \\text{Pr}(T_i=1|X)\n\\]\n傾向スコアは最も粗いバランシングスコアである． ここで粗いとは，共変量の情報を一つの値に集約しているという意味である． 最も細かいバランシングスコアは共変量が取り得る値の組合せになる.\n傾向スコアが同程度で異なる処置がされたデータの組合せを選び， 処置群の処置群の平均処置効果を求めることになる\n\n\n\n\n定理１（バランシング）：処置の割り付け\\(T\\)を観測された共変量\\(X\\)は，傾向スコア\\(e(X)\\)が和えられたとき条件付き独立である．すなわち傾向スコアが\\(e(X)\\)が同じであれば処置群と統制群で共変量の分布は同じである.\n\n\\[\nX \\perp T|e(X)\n\\]\n\n定理２（条件付き独立）：傾向スコア\\(e(X)\\)が与えられれば潜在的結果変数\\({Y(1), Y(2)}\\)と割り付け変数\\(T\\)は条件付き独立である．すなわり傾向スコアが同じ個体であれば，処置への割り付けえは無作為と見なせる\n\n\\[\n\\{Y(0), Y(1)\\} \\perp T|e(X)\n\\]\n上記の定理はこれまでに使っていた条件付き独立性（無交絡性）と条件付き正直性である．\n\\[\n\\{Y(1), Y(0)\\} \\perp T|X\\\\\n0 &lt; \\text{Pr}(T_i=1|X) &lt; 1\n\\]\n条件付き独立性が述べているのは観測された共変量のみが処置の割り付けに影響を与えている ということであり，潜在的結果変数とは独立ということである. 二つ目の式で述べていることは実用的には傾向スコアが０になっても１になってもいけない ということである．処置群と統制群のどちらにも観測値があるということを意味している．\n何がいいたいのかというと観測されない共変量\\(\\mathcal{U}\\)がないという想定だし， それが合った場合にどのような結果となるのかは何もいえない. それを調べる場合には別のモデルを使う必要がある.\n\n\n\n省略\n\n\n\n\n\nCode\ndata03 &lt;- read_csv(\"./causality/data03.csv\", show_col_types = FALSE)\nsummary(data03)\n#&gt;        x1              y3              t1           y0t             y1t       \n#&gt;  Min.   :70.00   Min.   :63.00   Min.   :0.0   Min.   :62.00   Min.   :71.00  \n#&gt;  1st Qu.:73.75   1st Qu.:73.75   1st Qu.:0.0   1st Qu.:66.50   1st Qu.:75.50  \n#&gt;  Median :80.00   Median :77.00   Median :0.5   Median :71.00   Median :81.50  \n#&gt;  Mean   :80.00   Mean   :77.25   Mean   :0.5   Mean   :72.20   Mean   :82.00  \n#&gt;  3rd Qu.:86.25   3rd Qu.:82.00   3rd Qu.:1.0   3rd Qu.:78.75   3rd Qu.:88.75  \n#&gt;  Max.   :90.00   Max.   :91.00   Max.   :1.0   Max.   :82.00   Max.   :92.00\n\n\n\n\nCode\n# 傾向スコア\npsmodel &lt;- glm(t1 ~ x1, family = binomial(link = \"logit\"), data = data03)\nps3 &lt;- round(psmodel$fitted.values, 4)\nps4 &lt;- c(rep(.8, 5), rep(.6, 5), rep(.4, 5), rep(.2, 5))\n\nn1 &lt;- 1000\nx1 &lt;- runif(n1, -10, 10)\ne1 &lt;- rlogis(n1, location = 0, scale = 1)\ntstar &lt;- .5 + 1.1 * x1 + e1\nt1 &lt;- NULL\nt1[tstar &gt;  0] &lt;- 1\nt1[tstar &lt;= 0] &lt;- 0\n\n\ndf2 &lt;- with(data03, data.frame(x1, y3, t1, ps3, ps4))\nprint(df2)\n#&gt;    x1 y3 t1    ps3 ps4\n#&gt; 1  70 74  1 0.7751 0.8\n#&gt; 2  70 63  0 0.7751 0.8\n#&gt; 3  70 73  1 0.7751 0.8\n#&gt; 4  70 71  1 0.7751 0.8\n#&gt; 5  70 74  1 0.7751 0.8\n#&gt; 6  75 67  0 0.6499 0.6\n#&gt; 7  75 77  1 0.6499 0.6\n#&gt; 8  75 68  0 0.6499 0.6\n#&gt; 9  75 77  1 0.6499 0.6\n#&gt; 10 75 78  1 0.6499 0.6\n#&gt; 11 85 88  1 0.3501 0.4\n#&gt; 12 85 77  0 0.3501 0.4\n#&gt; 13 85 76  0 0.3501 0.4\n#&gt; 14 85 86  1 0.3501 0.4\n#&gt; 15 85 78  0 0.3501 0.4\n#&gt; 16 90 81  0 0.2249 0.2\n#&gt; 17 90 91  1 0.2249 0.2\n#&gt; 18 90 82  0 0.2249 0.2\n#&gt; 19 90 82  0 0.2249 0.2\n#&gt; 20 90 82  0 0.2249 0.2\n\n\n\n\n\n傾向スコアとは，共変量\\(X\\)が与えられたときに処置に割り付けられる確率であり， ロジスティック回帰モデルによる確率の予測値である。 実務ではもろもろ処理をパッケージで済ます．\n\n\nCode\nlibrary(MatchIt)\n#&gt; Warning: package 'MatchIt' was built under R version 4.3.2\n\nm.out &lt;- matchit(t1 ~ x1, data = data03)\nps5 &lt;- m.out$model$fitted.values\nsummary(ps3)\n#&gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#&gt;  0.2249  0.3188  0.5000  0.5000  0.6812  0.7751\nsummary(ps5)\n#&gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#&gt;  0.2249  0.3188  0.5000  0.5000  0.6812  0.7751\ncor(ps3, ps5)\n#&gt; [1] 1\n\n\nパッケージで算出した傾向スコアとロジスティックス回帰モデルで算出した傾向スコアが 一致していることがわかる."
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/110_傾向スコア.html#バランシングスコア",
    "href": "contents/books/05_統計的因果推論の理論と実際/110_傾向スコア.html#バランシングスコア",
    "title": "傾向スコア",
    "section": "",
    "text": "共変量が単変量の場合には共分散分析により解析することが出来た． しかし，通常共変量は多変量である．これに対して傾向スコアが開発された． 傾向スコアとはバランシングスコアの１つであり， 観測される共変量\\(X\\)の関数\\(b(X)\\)が与えられたときの\\(X\\)の条件つき分布が， 処置群と統制群において同じとなる関数である.\nとにかくバランシングスコアを見るようにして，バランシングスコアが悪いときに，マッチングを使ったATT推定を行ってはならない. マッチしたからといってどの程度マッチに意味があるかは，別であるよね，という話だと理解した．\n\n\nCode\ndata10a &lt;- read_csv(\"./causality/data10a.csv\", show_col_types = FALSE)\n\n# 平均処置効果\nwith(data10a, {\n    print(mean(y1t) - mean(y0t))\n})\n#&gt; [1] 9.95\n\n# 処置群の平均処置効果\nwith(data10a, {\n    print(mean(y1t[t1==1])-mean(y0t[t1==1]))   \n})\n#&gt; [1] 9.090909\n\n# ナイーブな平均処置効果\nwith(data10a, {\n    print(mean(y1t[t1==1])-mean(y0t[t1==0]))   \n})\n#&gt; [1] 17.39394\n\n\nナイーブな平均処置結果が使えないことがよくわかる.\nこのような結果が起こるのは共変量の分布が異なることによる. 処置群と統制群で平均値や分散が同じになることを指して「バランスが取れている」ということになる．\n\n\nCode\ndata10a |&gt; \n    group_by(t1) |&gt;\n    summarise(quantile = list(stack(quantile(x1)))) |&gt; \n    unnest(quantile) |&gt; \n    pivot_wider(id_cols = t1, names_from = \"ind\", values_from = \"values\")\n#&gt; # A tibble: 2 × 6\n#&gt;      t1  `0%` `25%` `50%` `75%` `100%`\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1     0    66  70      74    78     88\n#&gt; 2     1    73  77.5    83    89     92"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/110_傾向スコア.html#傾向スコア-1",
    "href": "contents/books/05_統計的因果推論の理論と実際/110_傾向スコア.html#傾向スコア-1",
    "title": "傾向スコア",
    "section": "",
    "text": "共変量が多変量である場合を考える. 多変量である場合には上記のように 共変量の分布が同一であるのかを確認することは容易ではない．\n\n\nCode\ndata10b &lt;- read_csv(\"./causality/data10b.csv\", show_col_types = FALSE)\nprint(data10b |&gt; head())\n#&gt; # A tibble: 6 × 8\n#&gt;     y0t   y1t    t1     y    x1    x2    x3   ps1\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1    63    74     0    63    66    76    75  0.12\n#&gt; 2    55    70     0    55    70    75    55  0.05\n#&gt; 3    59    69     0    59    70    60    73  0.19\n#&gt; 4    71    77     1    77    73    76    82  0.43\n#&gt; 5    73    78     0    73    73    79    78  0.35\n#&gt; 6    66    77     0    66    74    72    79  0.41\n\n\nそこで傾向スコアを考える．傾向スコアとは，共変量\\(X\\)が与えられたとき， 処置に割り付けらあれる確率と定義される．\n\\[\ne(X) = \\text{Pr}(T_i=1|X)\n\\]\n傾向スコアは最も粗いバランシングスコアである． ここで粗いとは，共変量の情報を一つの値に集約しているという意味である． 最も細かいバランシングスコアは共変量が取り得る値の組合せになる.\n傾向スコアが同程度で異なる処置がされたデータの組合せを選び， 処置群の処置群の平均処置効果を求めることになる"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/110_傾向スコア.html#傾向スコア定理",
    "href": "contents/books/05_統計的因果推論の理論と実際/110_傾向スコア.html#傾向スコア定理",
    "title": "傾向スコア",
    "section": "",
    "text": "定理１（バランシング）：処置の割り付け\\(T\\)を観測された共変量\\(X\\)は，傾向スコア\\(e(X)\\)が和えられたとき条件付き独立である．すなわち傾向スコアが\\(e(X)\\)が同じであれば処置群と統制群で共変量の分布は同じである.\n\n\\[\nX \\perp T|e(X)\n\\]\n\n定理２（条件付き独立）：傾向スコア\\(e(X)\\)が与えられれば潜在的結果変数\\({Y(1), Y(2)}\\)と割り付け変数\\(T\\)は条件付き独立である．すなわり傾向スコアが同じ個体であれば，処置への割り付けえは無作為と見なせる\n\n\\[\n\\{Y(0), Y(1)\\} \\perp T|e(X)\n\\]\n上記の定理はこれまでに使っていた条件付き独立性（無交絡性）と条件付き正直性である．\n\\[\n\\{Y(1), Y(0)\\} \\perp T|X\\\\\n0 &lt; \\text{Pr}(T_i=1|X) &lt; 1\n\\]\n条件付き独立性が述べているのは観測された共変量のみが処置の割り付けに影響を与えている ということであり，潜在的結果変数とは独立ということである. 二つ目の式で述べていることは実用的には傾向スコアが０になっても１になってもいけない ということである．処置群と統制群のどちらにも観測値があるということを意味している．\n何がいいたいのかというと観測されない共変量\\(\\mathcal{U}\\)がないという想定だし， それが合った場合にどのような結果となるのかは何もいえない. それを調べる場合には別のモデルを使う必要がある."
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/110_傾向スコア.html#傾向スコアのモデル化",
    "href": "contents/books/05_統計的因果推論の理論と実際/110_傾向スコア.html#傾向スコアのモデル化",
    "title": "傾向スコア",
    "section": "",
    "text": "省略"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/110_傾向スコア.html#傾向スコアの算出例",
    "href": "contents/books/05_統計的因果推論の理論と実際/110_傾向スコア.html#傾向スコアの算出例",
    "title": "傾向スコア",
    "section": "",
    "text": "Code\ndata03 &lt;- read_csv(\"./causality/data03.csv\", show_col_types = FALSE)\nsummary(data03)\n#&gt;        x1              y3              t1           y0t             y1t       \n#&gt;  Min.   :70.00   Min.   :63.00   Min.   :0.0   Min.   :62.00   Min.   :71.00  \n#&gt;  1st Qu.:73.75   1st Qu.:73.75   1st Qu.:0.0   1st Qu.:66.50   1st Qu.:75.50  \n#&gt;  Median :80.00   Median :77.00   Median :0.5   Median :71.00   Median :81.50  \n#&gt;  Mean   :80.00   Mean   :77.25   Mean   :0.5   Mean   :72.20   Mean   :82.00  \n#&gt;  3rd Qu.:86.25   3rd Qu.:82.00   3rd Qu.:1.0   3rd Qu.:78.75   3rd Qu.:88.75  \n#&gt;  Max.   :90.00   Max.   :91.00   Max.   :1.0   Max.   :82.00   Max.   :92.00\n\n\n\n\nCode\n# 傾向スコア\npsmodel &lt;- glm(t1 ~ x1, family = binomial(link = \"logit\"), data = data03)\nps3 &lt;- round(psmodel$fitted.values, 4)\nps4 &lt;- c(rep(.8, 5), rep(.6, 5), rep(.4, 5), rep(.2, 5))\n\nn1 &lt;- 1000\nx1 &lt;- runif(n1, -10, 10)\ne1 &lt;- rlogis(n1, location = 0, scale = 1)\ntstar &lt;- .5 + 1.1 * x1 + e1\nt1 &lt;- NULL\nt1[tstar &gt;  0] &lt;- 1\nt1[tstar &lt;= 0] &lt;- 0\n\n\ndf2 &lt;- with(data03, data.frame(x1, y3, t1, ps3, ps4))\nprint(df2)\n#&gt;    x1 y3 t1    ps3 ps4\n#&gt; 1  70 74  1 0.7751 0.8\n#&gt; 2  70 63  0 0.7751 0.8\n#&gt; 3  70 73  1 0.7751 0.8\n#&gt; 4  70 71  1 0.7751 0.8\n#&gt; 5  70 74  1 0.7751 0.8\n#&gt; 6  75 67  0 0.6499 0.6\n#&gt; 7  75 77  1 0.6499 0.6\n#&gt; 8  75 68  0 0.6499 0.6\n#&gt; 9  75 77  1 0.6499 0.6\n#&gt; 10 75 78  1 0.6499 0.6\n#&gt; 11 85 88  1 0.3501 0.4\n#&gt; 12 85 77  0 0.3501 0.4\n#&gt; 13 85 76  0 0.3501 0.4\n#&gt; 14 85 86  1 0.3501 0.4\n#&gt; 15 85 78  0 0.3501 0.4\n#&gt; 16 90 81  0 0.2249 0.2\n#&gt; 17 90 91  1 0.2249 0.2\n#&gt; 18 90 82  0 0.2249 0.2\n#&gt; 19 90 82  0 0.2249 0.2\n#&gt; 20 90 82  0 0.2249 0.2"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/110_傾向スコア.html#rパッケージによる傾向スコアのモデル化",
    "href": "contents/books/05_統計的因果推論の理論と実際/110_傾向スコア.html#rパッケージによる傾向スコアのモデル化",
    "title": "傾向スコア",
    "section": "",
    "text": "傾向スコアとは，共変量\\(X\\)が与えられたときに処置に割り付けられる確率であり， ロジスティック回帰モデルによる確率の予測値である。 実務ではもろもろ処理をパッケージで済ます．\n\n\nCode\nlibrary(MatchIt)\n#&gt; Warning: package 'MatchIt' was built under R version 4.3.2\n\nm.out &lt;- matchit(t1 ~ x1, data = data03)\nps5 &lt;- m.out$model$fitted.values\nsummary(ps3)\n#&gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#&gt;  0.2249  0.3188  0.5000  0.5000  0.6812  0.7751\nsummary(ps5)\n#&gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#&gt;  0.2249  0.3188  0.5000  0.5000  0.6812  0.7751\ncor(ps3, ps5)\n#&gt; [1] 1\n\n\nパッケージで算出した傾向スコアとロジスティックス回帰モデルで算出した傾向スコアが 一致していることがわかる."
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/108_最小二乗法による重回帰モデルの仮定と診断2.html",
    "href": "contents/books/05_統計的因果推論の理論と実際/108_最小二乗法による重回帰モデルの仮定と診断2.html",
    "title": "最小二乗法の仮定と診断2",
    "section": "",
    "text": "ここで紹介する家庭は次の三つである.\n\n完全な多重共線性が存在しない\n誤差項の分散均一の仮定\n誤差項の世紀性の仮定\n\n\n\n変数X1とX2との相関が強くなることで，パラメータの不偏性には影響ないが， 相関が強くなるにつれて標準誤差が大きくなることになる． 結果的に検定が棄却されにくくなる．\n\n\nVIFによる診断がある.\n\\[\n\\text{VIF}=\\frac{1}{1-R_j^2}\n\\]\nここで\\(R_j^2\\)は説明変数\\(j\\)を除いた他の説明変数で，説明変数\\(j\\)を重回帰分析したときの， 決定係数である．決定係数が大きいとき，つまり残りの変数で説明できるときには，VIFが大きくなる． VIFが大きいことは多重共線性の存在を疑うことになる.\n交絡因子として取り込んだ共変量同士で多重共線性があっても， 着目した変数との多重共線性がなければ，偏回帰係数の推定には影響がない． ただし共変量の回帰係数は解釈可能ではないということに注意する.\n\n\n\n\nたとえば，年収と食費の関係を調べたとする． 年収が少ない場合には食費に使える予算はほぼ一定であること対して， 年収が増えると食費に使う予算のばらつきが大きくなったとする． これは年収が増えることで食費に対する贅沢が可能となり， 質素派と贅沢派という個人の属性が影響し分散が大きくなり， 年収で食費を回帰した場合には分散不均一の仮定を満たさなくなる．\n不均一分散はそれ自体が発見であるし，様々なモデルが既に開発されている．\n\n\n分散が不均一であっても推定量の不偏性には影響しない．一方で標準誤差が大きくなる. これにより最小二乗推定量が最良線形不偏推定量を満たさないことになる.\n\n\n\nブルーシュ・ペイガン検定を行うことでよい. Rではlmtest::bptestを使うことで出来る.\n\n\n\n説明変数が分散に与える影響がわかっている場合，加重最小二乗法を使うことで， 不均一分散に対処することが可能である.\n関数系の推定は作法があるのでそれに従うこと.\n\n\nCode\ndata08b &lt;- read_csv(\"./causality/data08b.csv\", show_col_types = FALSE)\nsummary(data08b)\n#&gt;        y1                y2                 x1           \n#&gt;  Min.   :-2.4949   Min.   :-8.17685   Min.   :-0.997053  \n#&gt;  1st Qu.:-0.5390   1st Qu.:-0.52864   1st Qu.:-0.477269  \n#&gt;  Median : 0.1584   Median :-0.02624   Median :-0.008905  \n#&gt;  Mean   : 0.1779   Mean   : 0.18978   Mean   : 0.012520  \n#&gt;  3rd Qu.: 0.8890   3rd Qu.: 0.79394   3rd Qu.: 0.525134  \n#&gt;  Max.   : 3.3866   Max.   :10.32879   Max.   : 0.997758\n\n\n\n\nCode\n# 加重最小二乗法\nmodel5 &lt;- lm(y2 ~ x1, weights = 1/ exp(1.5 * x1), data = data08b)\nmodel5\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y2 ~ x1, data = data08b, weights = 1/exp(1.5 * x1))\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           x1  \n#&gt;      0.1689       0.4748\n\n\nなお関数系は一般に知ることが出来ないので， 通常は下記の実行可能一般化最小二乗法における関数系の推定手順を用いた分析が行われている。\n\n\nCode\nmodel4    &lt;- lm(y2 ~ x1, data = data08b)\nlog_resid &lt;- log(residuals(model4) ** 2)\nmodel6 &lt;- lm(log_resid ~ x1, data = data08b)\nhhat1  &lt;- predict(model6)\nhhat2  &lt;- exp(hhat1)\nmodel7 &lt;- lm(y2 ~ x1, weights = 1/ hhat2, data = data08b)\nsummary(model7)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y2 ~ x1, data = data08b, weights = 1/hhat2)\n#&gt; \n#&gt; Weighted Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -4.9655 -1.2527 -0.0158  1.2804  5.8643 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  0.11808    0.04006   2.947  0.00328 ** \n#&gt; x1           0.38348    0.05509   6.961  6.1e-12 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 1.883 on 998 degrees of freedom\n#&gt; Multiple R-squared:  0.04631,    Adjusted R-squared:  0.04535 \n#&gt; F-statistic: 48.46 on 1 and 998 DF,  p-value: 6.102e-12\n\n\n\n\n\n\nここまでの５つの仮定が満たされていればこれは通常問題にならない． 一般に誤差項の正規性は問題になるが， 誤差項に正規性があるのかどうかは， 最小二乗推定量が最良線形不偏推定量であるのかどうかには影響がない．\n本来正規性について気にすべき問題は， 誤差項でなくパラメータの推定量の正規性である． パラメータの推定値は標本平均であるため中心極限定理からデータサイズに依存して， 正規分布となる．一般にはデータサイズが３０以上で正規分布として扱うことができるとされている．\n一方で誤差項の正規性はそれなりに意味を持つ． つまり，すべての共変量をモデルに取り込むことは現実的ではなく， 多くの場合には誤差項として表現することになる． 誤差項で様々な共変量をまとめて表現することにあるため， 誤差項が正規性を持つことは適切なモデリングが行えているのかの重要な指標となる.\n次の例では，データがベータ分布に従っている場合，データが正規分布に従っている場合の ２つの例で回帰分析を行い，その際の誤差項の分布を比べてみる. また誤差項をジャック・ベラの正規性検定をおこなう. (ライブラリが入らずできななかった)\nベータ分布に従うものは偏りが大きいことがグラフから見て取れる.\n\n\nCode\ndata08c &lt;- read_csv(\"./causality/data08c.csv\", show_col_types = FALSE)\nmodel1  &lt;- lm(y1 ~ x1, data = data08c)\nresid1  &lt;- residuals(model1)\nmodel2  &lt;- lm(y2 ~ x1, data = data08c)\nresid2  &lt;- residuals(model2)\n\n\n\n\nCode\nhist(resid1)\n\n\n\n\n\n\n\n\n\n\n\nCode\nhist(resid2)"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/108_最小二乗法による重回帰モデルの仮定と診断2.html#完全な多重共線性が存在しない",
    "href": "contents/books/05_統計的因果推論の理論と実際/108_最小二乗法による重回帰モデルの仮定と診断2.html#完全な多重共線性が存在しない",
    "title": "最小二乗法の仮定と診断2",
    "section": "",
    "text": "変数X1とX2との相関が強くなることで，パラメータの不偏性には影響ないが， 相関が強くなるにつれて標準誤差が大きくなることになる． 結果的に検定が棄却されにくくなる．\n\n\nVIFによる診断がある.\n\\[\n\\text{VIF}=\\frac{1}{1-R_j^2}\n\\]\nここで\\(R_j^2\\)は説明変数\\(j\\)を除いた他の説明変数で，説明変数\\(j\\)を重回帰分析したときの， 決定係数である．決定係数が大きいとき，つまり残りの変数で説明できるときには，VIFが大きくなる． VIFが大きいことは多重共線性の存在を疑うことになる.\n交絡因子として取り込んだ共変量同士で多重共線性があっても， 着目した変数との多重共線性がなければ，偏回帰係数の推定には影響がない． ただし共変量の回帰係数は解釈可能ではないということに注意する."
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/108_最小二乗法による重回帰モデルの仮定と診断2.html#誤差項の分散均一性",
    "href": "contents/books/05_統計的因果推論の理論と実際/108_最小二乗法による重回帰モデルの仮定と診断2.html#誤差項の分散均一性",
    "title": "最小二乗法の仮定と診断2",
    "section": "",
    "text": "たとえば，年収と食費の関係を調べたとする． 年収が少ない場合には食費に使える予算はほぼ一定であること対して， 年収が増えると食費に使う予算のばらつきが大きくなったとする． これは年収が増えることで食費に対する贅沢が可能となり， 質素派と贅沢派という個人の属性が影響し分散が大きくなり， 年収で食費を回帰した場合には分散不均一の仮定を満たさなくなる．\n不均一分散はそれ自体が発見であるし，様々なモデルが既に開発されている．\n\n\n分散が不均一であっても推定量の不偏性には影響しない．一方で標準誤差が大きくなる. これにより最小二乗推定量が最良線形不偏推定量を満たさないことになる.\n\n\n\nブルーシュ・ペイガン検定を行うことでよい. Rではlmtest::bptestを使うことで出来る.\n\n\n\n説明変数が分散に与える影響がわかっている場合，加重最小二乗法を使うことで， 不均一分散に対処することが可能である.\n関数系の推定は作法があるのでそれに従うこと.\n\n\nCode\ndata08b &lt;- read_csv(\"./causality/data08b.csv\", show_col_types = FALSE)\nsummary(data08b)\n#&gt;        y1                y2                 x1           \n#&gt;  Min.   :-2.4949   Min.   :-8.17685   Min.   :-0.997053  \n#&gt;  1st Qu.:-0.5390   1st Qu.:-0.52864   1st Qu.:-0.477269  \n#&gt;  Median : 0.1584   Median :-0.02624   Median :-0.008905  \n#&gt;  Mean   : 0.1779   Mean   : 0.18978   Mean   : 0.012520  \n#&gt;  3rd Qu.: 0.8890   3rd Qu.: 0.79394   3rd Qu.: 0.525134  \n#&gt;  Max.   : 3.3866   Max.   :10.32879   Max.   : 0.997758\n\n\n\n\nCode\n# 加重最小二乗法\nmodel5 &lt;- lm(y2 ~ x1, weights = 1/ exp(1.5 * x1), data = data08b)\nmodel5\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y2 ~ x1, data = data08b, weights = 1/exp(1.5 * x1))\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           x1  \n#&gt;      0.1689       0.4748\n\n\nなお関数系は一般に知ることが出来ないので， 通常は下記の実行可能一般化最小二乗法における関数系の推定手順を用いた分析が行われている。\n\n\nCode\nmodel4    &lt;- lm(y2 ~ x1, data = data08b)\nlog_resid &lt;- log(residuals(model4) ** 2)\nmodel6 &lt;- lm(log_resid ~ x1, data = data08b)\nhhat1  &lt;- predict(model6)\nhhat2  &lt;- exp(hhat1)\nmodel7 &lt;- lm(y2 ~ x1, weights = 1/ hhat2, data = data08b)\nsummary(model7)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y2 ~ x1, data = data08b, weights = 1/hhat2)\n#&gt; \n#&gt; Weighted Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -4.9655 -1.2527 -0.0158  1.2804  5.8643 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  0.11808    0.04006   2.947  0.00328 ** \n#&gt; x1           0.38348    0.05509   6.961  6.1e-12 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 1.883 on 998 degrees of freedom\n#&gt; Multiple R-squared:  0.04631,    Adjusted R-squared:  0.04535 \n#&gt; F-statistic: 48.46 on 1 and 998 DF,  p-value: 6.102e-12"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/108_最小二乗法による重回帰モデルの仮定と診断2.html#誤差項の正規性",
    "href": "contents/books/05_統計的因果推論の理論と実際/108_最小二乗法による重回帰モデルの仮定と診断2.html#誤差項の正規性",
    "title": "最小二乗法の仮定と診断2",
    "section": "",
    "text": "ここまでの５つの仮定が満たされていればこれは通常問題にならない． 一般に誤差項の正規性は問題になるが， 誤差項に正規性があるのかどうかは， 最小二乗推定量が最良線形不偏推定量であるのかどうかには影響がない．\n本来正規性について気にすべき問題は， 誤差項でなくパラメータの推定量の正規性である． パラメータの推定値は標本平均であるため中心極限定理からデータサイズに依存して， 正規分布となる．一般にはデータサイズが３０以上で正規分布として扱うことができるとされている．\n一方で誤差項の正規性はそれなりに意味を持つ． つまり，すべての共変量をモデルに取り込むことは現実的ではなく， 多くの場合には誤差項として表現することになる． 誤差項で様々な共変量をまとめて表現することにあるため， 誤差項が正規性を持つことは適切なモデリングが行えているのかの重要な指標となる.\n次の例では，データがベータ分布に従っている場合，データが正規分布に従っている場合の ２つの例で回帰分析を行い，その際の誤差項の分布を比べてみる. また誤差項をジャック・ベラの正規性検定をおこなう. (ライブラリが入らずできななかった)\nベータ分布に従うものは偏りが大きいことがグラフから見て取れる.\n\n\nCode\ndata08c &lt;- read_csv(\"./causality/data08c.csv\", show_col_types = FALSE)\nmodel1  &lt;- lm(y1 ~ x1, data = data08c)\nresid1  &lt;- residuals(model1)\nmodel2  &lt;- lm(y2 ~ x1, data = data08c)\nresid2  &lt;- residuals(model2)\n\n\n\n\nCode\nhist(resid1)\n\n\n\n\n\n\n\n\n\n\n\nCode\nhist(resid2)"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/106_図で理解する重回帰モデルの基礎.html",
    "href": "contents/books/05_統計的因果推論の理論と実際/106_図で理解する重回帰モデルの基礎.html",
    "title": "重回帰分析の基礎",
    "section": "",
    "text": "チョコレートの消費量とノーベル章受賞者の数が回帰分析により有意な関係があると 算出されたとき，因果推論を考えるにはまず交絡因子の探索が必要となる． つまり，チョコレートの消費量とノーベル章受賞者のどちらにも影響を与えると考えられる 変数を探すことになる．\nそのような変数が明示できなければ，なんらかの因果関係があると解釈を進めていくことが出来る.\n交絡因子についての検討はデータ分析担当者の責任のもと行うべきであるとともに， 後に検証可能な形で分析結果を共有してくことが必須である.\n重回帰モデルを考えたときある説明変数Aと別の説明変数Bに相関があるときには， AとBが交絡していることとなり， AとBの相関を除いた上で回帰分析することが望ましい． 共分散分析ではそのような場合の因果推論に役に立つ．\n重回帰分析における回帰係数とは当該変数以外で説明できる当該変数の分散を除いた， 当該変数の分散によるものである． 他の変数から受ける影響を統計的に除外， つまり交絡を取り除いて推定してると考えることが出来る.\n\n\nCode\n# 共分散分析\n# 重回帰分析は残差に対して単回帰を繰り返すことと同じ\n\ndata03 &lt;- read_csv(\"./causality/data03.csv\", locale = locale(encoding = \"UTF-8\"))\n#&gt; Rows: 20 Columns: 5\n#&gt; ── Column specification ────────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; dbl (5): x1, y3, t1, y0t, y1t\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nmodel1 &lt;- lm(t1 ~ x1, data = data03)\net1    &lt;- resid(model1)\nmodel2 &lt;- lm(y3 ~ et1, data = data03)\nsummary(model2)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y3 ~ et1, data = data03)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt; -8.409 -4.328 -0.250  4.828  6.910 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)   77.250      1.236  62.475  &lt; 2e-16 ***\n#&gt; et1            9.816      2.758   3.559  0.00224 ** \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 5.53 on 18 degrees of freedom\n#&gt; Multiple R-squared:  0.413,  Adjusted R-squared:  0.3804 \n#&gt; F-statistic: 12.67 on 1 and 18 DF,  p-value: 0.002242\n\n\n\n\n処置の割り付けが無作為化されてていても， 実際にはたまたま共変量がうまくバランスしていないことがある． そのような時にも共変量を考慮した モデル化を行い共分散分析を行うことで，バランシングできることがある．\nまた処置の無作為割り付け自体は成功しており，交絡因子を気にする必要がない場合でも， 結果辺陬の変動を説明することに寄与する変数があれば，共分散分析のモデルに取り入れることが望ましい. 不偏性をもったまま決定係数を減らすことが出来る."
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/106_図で理解する重回帰モデルの基礎.html#実験研究における共分散分析の活用",
    "href": "contents/books/05_統計的因果推論の理論と実際/106_図で理解する重回帰モデルの基礎.html#実験研究における共分散分析の活用",
    "title": "重回帰分析の基礎",
    "section": "",
    "text": "処置の割り付けが無作為化されてていても， 実際にはたまたま共変量がうまくバランスしていないことがある． そのような時にも共変量を考慮した モデル化を行い共分散分析を行うことで，バランシングできることがある．\nまた処置の無作為割り付け自体は成功しており，交絡因子を気にする必要がない場合でも， 結果辺陬の変動を説明することに寄与する変数があれば，共分散分析のモデルに取り入れることが望ましい. 不偏性をもったまま決定係数を減らすことが出来る."
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/104_推測統計の基礎：標準誤差と信頼区間.html",
    "href": "contents/books/05_統計的因果推論の理論と実際/104_推測統計の基礎：標準誤差と信頼区間.html",
    "title": "標準誤差と信頼区間",
    "section": "",
    "text": "本章では標準誤差とは何か，信頼区間とはなにか，具体的に検討したのち２標本t検定の メカニズムについて解説する.\n無作為に割り付けされている場合には，線形回帰分析で定量化しt.testで検定が行える．\n\n\n標本平均が従う分布の標準偏差である. いつも思うけどこれくらいの計算も出来なくなるのではないか，という一末の不安がある． これは何度も計算すれば解消さるのだろうか・・・\n\n\n\n信頼区間について納得できる説明がされている．t.testのやり方について説明されている. そういえば，\\(t\\)検定の場合，自由度は\\(n-1\\)とするけど，標本平均と標本分散を使っているので自由度\\(n-2\\)のような気がするのだけど，どうなのだろうか？"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/104_推測統計の基礎：標準誤差と信頼区間.html#標準誤差",
    "href": "contents/books/05_統計的因果推論の理論と実際/104_推測統計の基礎：標準誤差と信頼区間.html#標準誤差",
    "title": "標準誤差と信頼区間",
    "section": "",
    "text": "標本平均が従う分布の標準偏差である. いつも思うけどこれくらいの計算も出来なくなるのではないか，という一末の不安がある． これは何度も計算すれば解消さるのだろうか・・・"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/104_推測統計の基礎：標準誤差と信頼区間.html#信頼区間",
    "href": "contents/books/05_統計的因果推論の理論と実際/104_推測統計の基礎：標準誤差と信頼区間.html#信頼区間",
    "title": "標準誤差と信頼区間",
    "section": "",
    "text": "信頼区間について納得できる説明がされている．t.testのやり方について説明されている. そういえば，\\(t\\)検定の場合，自由度は\\(n-1\\)とするけど，標本平均と標本分散を使っているので自由度\\(n-2\\)のような気がするのだけど，どうなのだろうか？"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/102_潜在的結果変数の枠組み.html",
    "href": "contents/books/05_統計的因果推論の理論と実際/102_潜在的結果変数の枠組み.html",
    "title": "潜在的結果変数の枠組み",
    "section": "",
    "text": "この枠組みでは因果推論を「欠測データの問題」として扱う．\n\n\n20人の学生を対象にした数学の試験結果を考える． 10人は補習講義を受けており，試験結果から補習講義の効果を知りたいとする． しかし，補習講義を受けた人は受けていない場合の結果はなく，その逆もまた然りである． つまり，補習講義の有無による個々人の試験結果の違いの分布を得ることは出来ない．\n補習講義の有無がランダムに割り付けられている場合には評価が出来るものの， 補習講義を受けるの者はそれまでの成績が悪い場合である．\n仮にすべての生徒に対して補修講義の有無が観測されているならば 単に平均値を比較することでよい．．\n\n\n\n補習講義を受けたどうかを「補修講義を受ける確率」として考えるとことで 補習講義の有無をまとめて表現することが可能となる． 具体的には\\(Y_i(0)\\)を補習講義を受けていない場合の潜在的結果， \\(Y_i(1)\\)を補習講義を受けた場合の潜在的結果といして，次の式でモデル化する.\n\\[\n\\begin{align}\nY_i &= (1-T_i)Y_i(0) + T_iY_i(1) \\\\\nT_i &\\in {0, 1}\n\\end{align}\n\\]\n\n\nCode\npath   &lt;- \"./causality/data02.csv\"\ndata02 &lt;- read_csv(path, locale = locale(encoding = \"UTF-8\"), show_col_types = FALSE)\ndata02 |&gt; summary()\n#&gt;        x1              y3             t1            y0              y1       \n#&gt;  Min.   :58.00   Min.   :61.0   Min.   :0.0   Min.   :72.00   Min.   :61.00  \n#&gt;  1st Qu.:76.25   1st Qu.:75.0   1st Qu.:0.0   1st Qu.:75.00   1st Qu.:74.25  \n#&gt;  Median :83.50   Median :76.5   Median :0.0   Median :77.00   Median :75.50  \n#&gt;  Mean   :81.95   Mean   :76.6   Mean   :0.3   Mean   :77.79   Mean   :73.83  \n#&gt;  3rd Qu.:87.25   3rd Qu.:80.0   3rd Qu.:1.0   3rd Qu.:80.00   3rd Qu.:76.75  \n#&gt;  Max.   :96.00   Max.   :87.0   Max.   :1.0   Max.   :87.00   Max.   :80.00  \n#&gt;                                               NA's   :6       NA's   :14     \n#&gt;       y0t            y1t       \n#&gt;  Min.   :52.0   Min.   :61.00  \n#&gt;  1st Qu.:69.5   1st Qu.:79.25  \n#&gt;  Median :75.0   Median :84.50  \n#&gt;  Mean   :73.8   Mean   :83.85  \n#&gt;  3rd Qu.:78.5   3rd Qu.:89.00  \n#&gt;  Max.   :87.0   Max.   :97.00  \n#&gt; \n\n\ny0, y1が条件付きの値，つまり実際の結果であり，y0t, y1tがもしどちらも観測可能である場合の結果である． y0t, y1tが観測できるときにはt検定などで比較が可能である.\n\n\n\n個体因果結果とは\\(\\tau_i = Y_i(1) - Y_i(0)\\)であり，つまりは個体差である. 通常はどちらか一方しか観測できないのでこの値を算出することは出来ない. また推測も出来ない.\n\n\nCode\nwith(data02, {\n    # 個体ごとの因果効果(理想的)\n    print(y1t - y0t)\n})\n#&gt;  [1]  8  9 10 13  9  9 11 12 10 10  9 10 10  9 12 12 10  9 10  9\n\n\n\n\n\n個体因果効果は観測も推測も出来ないので， 個体の母集団に対する平均的な因果効果を考えることになる． つまり正しく推定が行えていないことがわかる.\n\n\nCode\nwith(data02, {\n    # 母集団への平均的な効果の推定\n    print(mean(y1t, na.rm = TRUE) - mean(y0t, na.rm = TRUE))\n    # しかし，この値をこのまま実際の結果に当てはめると結果が大きく異なる\n    print(mean(y1, na.rm = TRUE) - mean(y0, na.rm = TRUE))\n})\n#&gt; [1] 10.05\n#&gt; [1] -3.952381\n\n\n\n\n\nある処置が取られた対象に対してどれくらい影響があったのかについて知る． これは処置群の平均処置効果と呼ばれるものである. 次の式で定義される. これは処置を受けた人の処置を受けていなかったときの結果\\(E[Y_i(0)|T_i=1\\)が含まれている． このような値を推定することも出来るのが統計的因果推論の面白さになる.\n\\[\n\\tau_{\\text{ATT}}=E[Y_i(1)-Y_i(0)|T_i=1]=E[Y_i(1)|T_i=1]-E[Y_i(0)|T_i=1]\n\\]\nこれを計算してみるとかなりよい値を推定する.\n\n\nCode\nwith(subset(data02, t1==1), {\n    print(mean(y1t)-mean(y0t))\n})\n#&gt; [1] 9.333333\n\n\n\n\n\n処置効果２におけるナイーブな推定は大きく外れていた． このような場合交絡因子を疑うことが重要な点である． 今回の場合には，補習講義を受けたかどうかは入学時の成績が考慮されており， この部分が交絡している．\n処置と結果変数のどちらにも影響する変数が交絡因子である． たとえば，補習授業の効果を知りたいとき，補習講義を受けるかどうかがテストの点で決まり， 効果を測るときにもテストの点を使うとすると，学力が交絡しており，補習講義の効果を適切に推定することが困難になる.\n平均処置効果を適切似推定するには２つの比較可能な集団を作る必要がある． 比較可能な集団とは共変量の分布は異なるが，原因変数と結果変数だけ異なる である．\n\n\n\n観測されない交絡を統制するにはどうすればよいのか． 理想はランダムサンプリングでの割り付けである. 一般に無作為割り付けがされている実験を実験研究といい，無作為割り付けされていない実験を観察研究という．\n\n\n\n内的妥当性とはある限られた条件での因果である．外的妥当性とは条件が変更された場合における妥当性である."
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/102_潜在的結果変数の枠組み.html#具体例",
    "href": "contents/books/05_統計的因果推論の理論と実際/102_潜在的結果変数の枠組み.html#具体例",
    "title": "潜在的結果変数の枠組み",
    "section": "",
    "text": "20人の学生を対象にした数学の試験結果を考える． 10人は補習講義を受けており，試験結果から補習講義の効果を知りたいとする． しかし，補習講義を受けた人は受けていない場合の結果はなく，その逆もまた然りである． つまり，補習講義の有無による個々人の試験結果の違いの分布を得ることは出来ない．\n補習講義の有無がランダムに割り付けられている場合には評価が出来るものの， 補習講義を受けるの者はそれまでの成績が悪い場合である．\n仮にすべての生徒に対して補修講義の有無が観測されているならば 単に平均値を比較することでよい．．"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/102_潜在的結果変数の枠組み.html#理論",
    "href": "contents/books/05_統計的因果推論の理論と実際/102_潜在的結果変数の枠組み.html#理論",
    "title": "潜在的結果変数の枠組み",
    "section": "",
    "text": "補習講義を受けたどうかを「補修講義を受ける確率」として考えるとことで 補習講義の有無をまとめて表現することが可能となる． 具体的には\\(Y_i(0)\\)を補習講義を受けていない場合の潜在的結果， \\(Y_i(1)\\)を補習講義を受けた場合の潜在的結果といして，次の式でモデル化する.\n\\[\n\\begin{align}\nY_i &= (1-T_i)Y_i(0) + T_iY_i(1) \\\\\nT_i &\\in {0, 1}\n\\end{align}\n\\]\n\n\nCode\npath   &lt;- \"./causality/data02.csv\"\ndata02 &lt;- read_csv(path, locale = locale(encoding = \"UTF-8\"), show_col_types = FALSE)\ndata02 |&gt; summary()\n#&gt;        x1              y3             t1            y0              y1       \n#&gt;  Min.   :58.00   Min.   :61.0   Min.   :0.0   Min.   :72.00   Min.   :61.00  \n#&gt;  1st Qu.:76.25   1st Qu.:75.0   1st Qu.:0.0   1st Qu.:75.00   1st Qu.:74.25  \n#&gt;  Median :83.50   Median :76.5   Median :0.0   Median :77.00   Median :75.50  \n#&gt;  Mean   :81.95   Mean   :76.6   Mean   :0.3   Mean   :77.79   Mean   :73.83  \n#&gt;  3rd Qu.:87.25   3rd Qu.:80.0   3rd Qu.:1.0   3rd Qu.:80.00   3rd Qu.:76.75  \n#&gt;  Max.   :96.00   Max.   :87.0   Max.   :1.0   Max.   :87.00   Max.   :80.00  \n#&gt;                                               NA's   :6       NA's   :14     \n#&gt;       y0t            y1t       \n#&gt;  Min.   :52.0   Min.   :61.00  \n#&gt;  1st Qu.:69.5   1st Qu.:79.25  \n#&gt;  Median :75.0   Median :84.50  \n#&gt;  Mean   :73.8   Mean   :83.85  \n#&gt;  3rd Qu.:78.5   3rd Qu.:89.00  \n#&gt;  Max.   :87.0   Max.   :97.00  \n#&gt; \n\n\ny0, y1が条件付きの値，つまり実際の結果であり，y0t, y1tがもしどちらも観測可能である場合の結果である． y0t, y1tが観測できるときにはt検定などで比較が可能である."
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/102_潜在的結果変数の枠組み.html#処置効果1個体因果結果",
    "href": "contents/books/05_統計的因果推論の理論と実際/102_潜在的結果変数の枠組み.html#処置効果1個体因果結果",
    "title": "潜在的結果変数の枠組み",
    "section": "",
    "text": "個体因果結果とは\\(\\tau_i = Y_i(1) - Y_i(0)\\)であり，つまりは個体差である. 通常はどちらか一方しか観測できないのでこの値を算出することは出来ない. また推測も出来ない.\n\n\nCode\nwith(data02, {\n    # 個体ごとの因果効果(理想的)\n    print(y1t - y0t)\n})\n#&gt;  [1]  8  9 10 13  9  9 11 12 10 10  9 10 10  9 12 12 10  9 10  9"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/102_潜在的結果変数の枠組み.html#処置効果2平均処置効果",
    "href": "contents/books/05_統計的因果推論の理論と実際/102_潜在的結果変数の枠組み.html#処置効果2平均処置効果",
    "title": "潜在的結果変数の枠組み",
    "section": "",
    "text": "個体因果効果は観測も推測も出来ないので， 個体の母集団に対する平均的な因果効果を考えることになる． つまり正しく推定が行えていないことがわかる.\n\n\nCode\nwith(data02, {\n    # 母集団への平均的な効果の推定\n    print(mean(y1t, na.rm = TRUE) - mean(y0t, na.rm = TRUE))\n    # しかし，この値をこのまま実際の結果に当てはめると結果が大きく異なる\n    print(mean(y1, na.rm = TRUE) - mean(y0, na.rm = TRUE))\n})\n#&gt; [1] 10.05\n#&gt; [1] -3.952381"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/102_潜在的結果変数の枠組み.html#処置効果3処置群の平均処置効果",
    "href": "contents/books/05_統計的因果推論の理論と実際/102_潜在的結果変数の枠組み.html#処置効果3処置群の平均処置効果",
    "title": "潜在的結果変数の枠組み",
    "section": "",
    "text": "ある処置が取られた対象に対してどれくらい影響があったのかについて知る． これは処置群の平均処置効果と呼ばれるものである. 次の式で定義される. これは処置を受けた人の処置を受けていなかったときの結果\\(E[Y_i(0)|T_i=1\\)が含まれている． このような値を推定することも出来るのが統計的因果推論の面白さになる.\n\\[\n\\tau_{\\text{ATT}}=E[Y_i(1)-Y_i(0)|T_i=1]=E[Y_i(1)|T_i=1]-E[Y_i(0)|T_i=1]\n\\]\nこれを計算してみるとかなりよい値を推定する.\n\n\nCode\nwith(subset(data02, t1==1), {\n    print(mean(y1t)-mean(y0t))\n})\n#&gt; [1] 9.333333"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/102_潜在的結果変数の枠組み.html#交絡因子",
    "href": "contents/books/05_統計的因果推論の理論と実際/102_潜在的結果変数の枠組み.html#交絡因子",
    "title": "潜在的結果変数の枠組み",
    "section": "",
    "text": "処置効果２におけるナイーブな推定は大きく外れていた． このような場合交絡因子を疑うことが重要な点である． 今回の場合には，補習講義を受けたかどうかは入学時の成績が考慮されており， この部分が交絡している．\n処置と結果変数のどちらにも影響する変数が交絡因子である． たとえば，補習授業の効果を知りたいとき，補習講義を受けるかどうかがテストの点で決まり， 効果を測るときにもテストの点を使うとすると，学力が交絡しており，補習講義の効果を適切に推定することが困難になる.\n平均処置効果を適切似推定するには２つの比較可能な集団を作る必要がある． 比較可能な集団とは共変量の分布は異なるが，原因変数と結果変数だけ異なる である．"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/102_潜在的結果変数の枠組み.html#無作為抽出と無作為割り付け",
    "href": "contents/books/05_統計的因果推論の理論と実際/102_潜在的結果変数の枠組み.html#無作為抽出と無作為割り付け",
    "title": "潜在的結果変数の枠組み",
    "section": "",
    "text": "観測されない交絡を統制するにはどうすればよいのか． 理想はランダムサンプリングでの割り付けである. 一般に無作為割り付けがされている実験を実験研究といい，無作為割り付けされていない実験を観察研究という．"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/102_潜在的結果変数の枠組み.html#内的妥当性と外的妥当性",
    "href": "contents/books/05_統計的因果推論の理論と実際/102_潜在的結果変数の枠組み.html#内的妥当性と外的妥当性",
    "title": "潜在的結果変数の枠組み",
    "section": "",
    "text": "内的妥当性とはある限られた条件での因果である．外的妥当性とは条件が変更された場合における妥当性である."
  },
  {
    "objectID": "contents/books/03_数値シミュレーションで身につける統計の仕組み/index.html",
    "href": "contents/books/03_数値シミュレーションで身につける統計の仕組み/index.html",
    "title": "数値シミュレーションで身につける統計の仕組み",
    "section": "",
    "text": "1 はじめに\n\n『統計シミュレーションで身につける統計の仕組み』の読書ノートです\n誤植が多い図書なので次のサポートページをよくみること\nサポートページ\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/books/03_数値シミュレーションで身につける統計の仕組み/ch06_適切な検定のためのサンプルサイズ設計.html",
    "href": "contents/books/03_数値シミュレーションで身につける統計の仕組み/ch06_適切な検定のためのサンプルサイズ設計.html",
    "title": "ch06 サンプルサイズ",
    "section": "",
    "text": "統計的検定において、エラー確率を管理するには、 次のことを検定する前に決めておく必要がある。\n\n確率モデルと検定する母数\nその母数についての帰無仮説\n\\(\\alpha\\)と\\(\\beta\\)\n計算する検定統計量\nサンプルサイズ"
  },
  {
    "objectID": "contents/books/03_数値シミュレーションで身につける統計の仕組み/ch06_適切な検定のためのサンプルサイズ設計.html#標本のt検定のサンプルサイズ",
    "href": "contents/books/03_数値シミュレーションで身につける統計の仕組み/ch06_適切な検定のためのサンプルサイズ設計.html#標本のt検定のサンプルサイズ",
    "title": "ch06 サンプルサイズ",
    "section": "2.1 1標本のt検定のサンプルサイズ",
    "text": "2.1 1標本のt検定のサンプルサイズ\n\n小さめのサンプルサイズnを適当に決める\n見積もった効果量\\(\\delta_0\\)と\\(n\\)から非心度\\(\\lambda\\)を計算する\n帰無頒布の自由度を求めて\\(\\alpha\\)の臨界値を計算する\n臨界値と非心度からタイプ２エラーを求める\nタイプ２が\\(\\beta\\)を下回っていればそこで終了しそうでないなあ\\(n\\)を増やす\n\n\n\nCode\nt2e_ttest &lt;- function(alpah, delta, n) {\n  df &lt;- n - 1\n  lambda &lt;- delta * sqrt(n)\n  cv &lt;- qt(p = 1 - alpha / 2, df = df)\n  type2error &lt;- pt(q = cv, df = df, ncp = lambda)\n  return(type2error)\n}\n\n# 設定と準備\nalpha &lt;- .05\nbeta &lt;- .2\ndelta &lt;- .5\n\niter &lt;- 1000\n\nfor (n in 5:iter) {\n  type2error &lt;- t2e_ttest(alpha, delta, n)\n  if (type2error &lt; beta) {\n    break\n  }\n}\n\nprint(n)\n#&gt; [1] 34\n\nprint(type2error)\n#&gt; [1] 0.1922233"
  },
  {
    "objectID": "contents/books/03_数値シミュレーションで身につける統計の仕組み/ch04_母数の推定のシミュレーション.html",
    "href": "contents/books/03_数値シミュレーションで身につける統計の仕組み/ch04_母数の推定のシミュレーション.html",
    "title": "ch04 母数の推定",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "contents/books/03_数値シミュレーションで身につける統計の仕組み/ch02_プログラミングの基礎.html",
    "href": "contents/books/03_数値シミュレーションで身につける統計の仕組み/ch02_プログラミングの基礎.html",
    "title": "ch02 プログラミングの基礎",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "contents/books/02_因果推論ミックステープ/index.html",
    "href": "contents/books/02_因果推論ミックステープ/index.html",
    "title": "因果推論ミックステープ",
    "section": "",
    "text": "1 はじめに\n\n『因果推論ミックステープ』の読書ノートです\n因果推論の初中級レベルとのことです\n本書をきっかけとして計量経済学についても学習してもらいたいとのことです\n本書はサイバーエージェントのゼミが誕生したとのこと\n\n非常にすごいことだと思います\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/books/02_因果推論ミックステープ/ch10_合成コントロール法.html",
    "href": "contents/books/02_因果推論ミックステープ/ch10_合成コントロール法.html",
    "title": "ch10 合成コントロール",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "contents/books/02_因果推論ミックステープ/ch08_パネルデータ.html",
    "href": "contents/books/02_因果推論ミックステープ/ch08_パネルデータ.html",
    "title": "ch08 パネルデータ",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "contents/books/02_因果推論ミックステープ/ch06_回帰不連続デザイン.html",
    "href": "contents/books/02_因果推論ミックステープ/ch06_回帰不連続デザイン.html",
    "title": "ch06 回帰不連続デザイン",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "contents/books/02_因果推論ミックステープ/ch04_潜在アウトカム因果モデル.html",
    "href": "contents/books/02_因果推論ミックステープ/ch04_潜在アウトカム因果モデル.html",
    "title": "ch04 潜在アウトカム因果モデル",
    "section": "",
    "text": "潜在アウトカムとは、次のスイッチング方程式により決定される。\n\\[\nY_i = D_i Y_i^1 + (1-D_i)Y_i^0\n\\]\nここで\\(D_i\\)はそのユニットが処置を受けたときには\\(1\\), 受けなかった場合は\\(0\\)となる。 \\(D_i=1\\)のときには\\(Y_i=Y_i^1\\)となり、\\(D_i=0\\)のときには\\(Y_i=Y_i^0\\)となる。\nこの表記を用いて、ユニット固有の処置効果を２つの状態の差として定義する。\n\\[\n\\delta_i = Y_i^1 - Y_i^0\n\\]\nこの式が意味するところはあるユニットに対する処置効果を知るには、 処置が施された場合の結果、施されていない場合の結果のどちらも必要であり、 現実には知り得ない情報っであるということである.\n\n\n個体ごとの効果を知ることは出来ないので、 平均的な処置効果\\(ATE(Average treatment effect)\\)を調べることにする。\n\\[\n\\begin{align}\nATE &= E[\\delta_i]\\\\\n&=E[Y_i^1 - Y_i^0] \\\\\n&=E[Y_i^1] - E[Y_i^0]\n\\end{align}\n\\]\nATEを考えることで処置効果を推定することができる。 ただし、いずれにせよあるユニットにはどちらかしか観測できないのに注意する。\n次に関心があるのは処置群の平均処置効果である\\(ATT(average treatment effect for the treated group)\\)である。処置群においても、処置効果はユニットごとに異なるので、平均的にどの程度の効果があるのかを知りたいということになる。\n\\[\n\\begin{align}\nATT &= E[\\delta_i\\mid D_i = 1]\\\\\n&=E[Y_i^1 - Y_i^0\\mid D_i = 1] \\\\\n&=E[Y_i^1\\mid D_i = 1] - E[Y_i^0\\mid D_i = 1]\n\\end{align}\n\\]\n最期に関心があるのは、コントロール群、または未処理群に対する平均処置効果\\(ATU(average treatement effect for the untreated)\\)である。\n\\[\n\\begin{align}\nATU &= E[\\delta_i\\mid D_i = 0]\\\\\n&=E[Y_i^1 - Y_i^0\\mid D_i = 0] \\\\\n&=E[Y_i^1\\mid D_i = 0] - E[Y_i^0\\mid D_i = 0]\n\\end{align}\n\\]\n研究ではこれらの効果を 観測できる情報からどのように推定するのかが重要となる。\nところで, \\(ATE\\)の推定値として２つの処置群の単純差(Simple difference in mean outcomes: SDO)を考える。この値はデータから推定できる値である。\n\\[\nATE =　E[Y_i^1\\mid D=1] - E[Y_i^0\\mid D=0]\n\\]\nこの統計処理自体は正しいものの、誤解を招きかねないことには注意が必要である。 処置の割り当てがランダムでないときには、処置群とコントロール群に根本的な差が生じ津ことが知られている。\n\\[\n\\begin{align}\nE[Y_i^1\\mid D_i = 0] - E[Y_i^0\\mid D_i = 0] &= ATE + E[Y^0\\mid D=1]-E[Y^0\\mid D=0]+(1-\\pi)(ATT - ATU)\n\\end{align}\n\\]\n上記の結果は下の数式を整理したものである。\n\\[\n\\begin{align}\nATE&=\\pi ATT + (1-\\pi)ATU\\\\\n&=\\pi E[Y^1\\mid D=1]-\\pi E[Y^0\\mid D = 1] + (1-\\pi)E[Y^1\\mid D=0]-(1-\\pi)E[Y^0\\mid D = 0]\\\\\n&=\\{\\pi E[Y^1\\mid D=1]+(1-\\pi)E[Y^1\\mid D=0]\\}-{\\pi E[Y^0\\mid D = 1]+(1-\\pi)E[Y^0\\mid D = 0]}\n\\end{align}\n\\]\n\\(\\pi\\)は処置を受けた人の割合である。第一式は\\(ATT\\)の定義から、 処置を受けた人、受けていない人の処置効果に分会しているということになる。\nこれを見ると、単純な差にはATEだけでなく２つの項がある。 まずは次の式は選択バイアスと呼ばれるものである。 処置を受けていない場合の平均的なアウトカムが、 処置を受けているかどうかで変わるのでこのように呼ばれる。\n\\[\nE[Y^0\\mid D=1]-E[Y^0\\mid D=0]\n\\]\n次の式は異質性のある処置効果にともなうバイアスである。\n\\[\n(1-\\pi)(ATT - ATU)\n\\]\n上記２つの項は反実仮想を含んでいるため計算することが出来ない。 いずれにせよバイアスを含んでいることはわかる。\n\n\n\nSDOを使ってATEを推定するにあたり最も信頼できるのは、 処置を受けるのかどうかとアウトカムが独立であるときである。\n\\[\n(Y^1, Y^0) \\mathop{\\perp\\!\\!\\!\\!\\perp} D\n\\]\nランダム化によって実現したいのは、次の状態である。\n\\[\n\\begin{align}\nE[Y^1\\mid D=1]-E[Y^1\\mid D=0]&=0\\\\\nE[Y^0\\mid D=1]-E[Y^0\\mid D=0]&=0\n\\end{align}\n\\] ランダム化により明らかに選択バイアスを除くことができる。\nまた異質性のある処置効果についても取り除くことができる。\n\\[\nATT-ATU=E[Y^1\\mid D=1]-E[Y^0\\mid  D=1]-E[Y^1\\mid D=0]+E[Y^0\\mid D=0]\n\\]\n\n\n\nRubinはこの種の計算をいつくかの仮定が伴うとして、その仮定をSUTVAとまとめています。具体的には次の３つです。\n\n処置の均質性\n処置の外部性がないこと\n\nユニット間で影響しあわないこと\n\n一般均衡効果がないこと"
  },
  {
    "objectID": "contents/books/02_因果推論ミックステープ/ch04_潜在アウトカム因果モデル.html#平均処置効果",
    "href": "contents/books/02_因果推論ミックステープ/ch04_潜在アウトカム因果モデル.html#平均処置効果",
    "title": "ch04 潜在アウトカム因果モデル",
    "section": "",
    "text": "個体ごとの効果を知ることは出来ないので、 平均的な処置効果\\(ATE(Average treatment effect)\\)を調べることにする。\n\\[\n\\begin{align}\nATE &= E[\\delta_i]\\\\\n&=E[Y_i^1 - Y_i^0] \\\\\n&=E[Y_i^1] - E[Y_i^0]\n\\end{align}\n\\]\nATEを考えることで処置効果を推定することができる。 ただし、いずれにせよあるユニットにはどちらかしか観測できないのに注意する。\n次に関心があるのは処置群の平均処置効果である\\(ATT(average treatment effect for the treated group)\\)である。処置群においても、処置効果はユニットごとに異なるので、平均的にどの程度の効果があるのかを知りたいということになる。\n\\[\n\\begin{align}\nATT &= E[\\delta_i\\mid D_i = 1]\\\\\n&=E[Y_i^1 - Y_i^0\\mid D_i = 1] \\\\\n&=E[Y_i^1\\mid D_i = 1] - E[Y_i^0\\mid D_i = 1]\n\\end{align}\n\\]\n最期に関心があるのは、コントロール群、または未処理群に対する平均処置効果\\(ATU(average treatement effect for the untreated)\\)である。\n\\[\n\\begin{align}\nATU &= E[\\delta_i\\mid D_i = 0]\\\\\n&=E[Y_i^1 - Y_i^0\\mid D_i = 0] \\\\\n&=E[Y_i^1\\mid D_i = 0] - E[Y_i^0\\mid D_i = 0]\n\\end{align}\n\\]\n研究ではこれらの効果を 観測できる情報からどのように推定するのかが重要となる。\nところで, \\(ATE\\)の推定値として２つの処置群の単純差(Simple difference in mean outcomes: SDO)を考える。この値はデータから推定できる値である。\n\\[\nATE =　E[Y_i^1\\mid D=1] - E[Y_i^0\\mid D=0]\n\\]\nこの統計処理自体は正しいものの、誤解を招きかねないことには注意が必要である。 処置の割り当てがランダムでないときには、処置群とコントロール群に根本的な差が生じ津ことが知られている。\n\\[\n\\begin{align}\nE[Y_i^1\\mid D_i = 0] - E[Y_i^0\\mid D_i = 0] &= ATE + E[Y^0\\mid D=1]-E[Y^0\\mid D=0]+(1-\\pi)(ATT - ATU)\n\\end{align}\n\\]\n上記の結果は下の数式を整理したものである。\n\\[\n\\begin{align}\nATE&=\\pi ATT + (1-\\pi)ATU\\\\\n&=\\pi E[Y^1\\mid D=1]-\\pi E[Y^0\\mid D = 1] + (1-\\pi)E[Y^1\\mid D=0]-(1-\\pi)E[Y^0\\mid D = 0]\\\\\n&=\\{\\pi E[Y^1\\mid D=1]+(1-\\pi)E[Y^1\\mid D=0]\\}-{\\pi E[Y^0\\mid D = 1]+(1-\\pi)E[Y^0\\mid D = 0]}\n\\end{align}\n\\]\n\\(\\pi\\)は処置を受けた人の割合である。第一式は\\(ATT\\)の定義から、 処置を受けた人、受けていない人の処置効果に分会しているということになる。\nこれを見ると、単純な差にはATEだけでなく２つの項がある。 まずは次の式は選択バイアスと呼ばれるものである。 処置を受けていない場合の平均的なアウトカムが、 処置を受けているかどうかで変わるのでこのように呼ばれる。\n\\[\nE[Y^0\\mid D=1]-E[Y^0\\mid D=0]\n\\]\n次の式は異質性のある処置効果にともなうバイアスである。\n\\[\n(1-\\pi)(ATT - ATU)\n\\]\n上記２つの項は反実仮想を含んでいるため計算することが出来ない。 いずれにせよバイアスを含んでいることはわかる。"
  },
  {
    "objectID": "contents/books/02_因果推論ミックステープ/ch04_潜在アウトカム因果モデル.html#独立性の仮定",
    "href": "contents/books/02_因果推論ミックステープ/ch04_潜在アウトカム因果モデル.html#独立性の仮定",
    "title": "ch04 潜在アウトカム因果モデル",
    "section": "",
    "text": "SDOを使ってATEを推定するにあたり最も信頼できるのは、 処置を受けるのかどうかとアウトカムが独立であるときである。\n\\[\n(Y^1, Y^0) \\mathop{\\perp\\!\\!\\!\\!\\perp} D\n\\]\nランダム化によって実現したいのは、次の状態である。\n\\[\n\\begin{align}\nE[Y^1\\mid D=1]-E[Y^1\\mid D=0]&=0\\\\\nE[Y^0\\mid D=1]-E[Y^0\\mid D=0]&=0\n\\end{align}\n\\] ランダム化により明らかに選択バイアスを除くことができる。\nまた異質性のある処置効果についても取り除くことができる。\n\\[\nATT-ATU=E[Y^1\\mid D=1]-E[Y^0\\mid  D=1]-E[Y^1\\mid D=0]+E[Y^0\\mid D=0]\n\\]"
  },
  {
    "objectID": "contents/books/02_因果推論ミックステープ/ch04_潜在アウトカム因果モデル.html#sutva",
    "href": "contents/books/02_因果推論ミックステープ/ch04_潜在アウトカム因果モデル.html#sutva",
    "title": "ch04 潜在アウトカム因果モデル",
    "section": "",
    "text": "Rubinはこの種の計算をいつくかの仮定が伴うとして、その仮定をSUTVAとまとめています。具体的には次の３つです。\n\n処置の均質性\n処置の外部性がないこと\n\nユニット間で影響しあわないこと\n\n一般均衡効果がないこと"
  },
  {
    "objectID": "contents/books/02_因果推論ミックステープ/ch02_確率と回帰の概要.html",
    "href": "contents/books/02_因果推論ミックステープ/ch02_確率と回帰の概要.html",
    "title": "ch02 確率と回帰の概要",
    "section": "",
    "text": "Note\n\n\n\nランダム過程とは、何度も繰り返し可能であり、そのたびに異なるアウトカムが得られる過程である。 標本空間とはランダム過程における起こり得るアウトカムの集合である。\n\n\n\n\n\\(x\\)の値ごとに分割した母集団の誤差項の期待値に関する、次のような仮定がある。\n$$\n(u x) = (u)\n$$ さらに、回帰分析における自明な仮定として次がある。\n\\[\n\\textrm{E}(u) = 0\n\\]\nよって、回帰分析の文脈でいえば説明変数で条件付けることで、誤差項の期待値はすべて０となる、という解釈になる。\n\n\n\n\n\n\nNote\n\n\n\n残差と誤差項は異なる。残差とは、標本値と推定値の差であり、誤差項とはアウトカムに影響を与える要因のうちモデルが補足できない全て要因を含んだ値である。実態としては残差は計算することが出来るが、誤差項は含めることができない。\n\n\n\n\nCode\nset.seed(1)\ntb &lt;- tibble(\nx = rnorm(10000),\nu = rnorm(10000),\ny = 5.5*x + 12*u\n)\n\nreg_tb &lt;- tb %&gt;%\nlm(y ~ x, .) %&gt;%\nprint()\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y ~ x, data = .)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)            x  \n#&gt;    -0.04991      5.55690\nreg_tb$coefficients\n#&gt; (Intercept)           x \n#&gt; -0.04990882  5.55690164\ntb &lt;- tb %&gt;%\nmutate(\nyhat1 = predict(lm(y ~ x, .)),\nyhat2 = 0.0732608 + 5.685033*x,\nuhat1 = residuals(lm(y ~ x, .)),\nuhat2 = y - yhat2\n)\nsummary(tb[-1:-3])\n#&gt;      yhat1               yhat2              uhat1              uhat2         \n#&gt;  Min.   :-20.45096   Min.   :-20.7982   Min.   :-51.5275   Min.   :-51.5247  \n#&gt;  1st Qu.: -3.79189   1st Qu.: -3.7550   1st Qu.: -8.1520   1st Qu.: -8.2751  \n#&gt;  Median : -0.13842   Median : -0.0173   Median : -0.1727   Median : -0.3147  \n#&gt;  Mean   : -0.08624   Mean   :  0.0361   Mean   :  0.0000   Mean   : -0.1223  \n#&gt;  3rd Qu.:  3.71578   3rd Qu.:  3.9258   3rd Qu.:  7.9778   3rd Qu.:  7.8506  \n#&gt;  Max.   : 21.12342   Max.   : 21.7348   Max.   : 44.7176   Max.   : 44.4416\ntb %&gt;%\nlm(y ~ x, .) %&gt;%\nggplot(aes(x=x, y=y)) +\nggtitle(\"OLS Regression Line\") +\ngeom_point(size = 0.05, color = \"black\", alpha = 0.5) +\ngeom_smooth(method = lm, color = \"black\") +\nannotate(\"text\", x = -1.5, y = 30, color = \"red\",\nlabel = paste(\"Intercept = \", -0.0732608)) +\nannotate(\"text\", x = 1.5, y = -30, color = \"blue\",\nlabel = paste(\"Slope =\", 5.685033))\n#&gt; `geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "contents/books/02_因果推論ミックステープ/ch02_確率と回帰の概要.html#平均独立",
    "href": "contents/books/02_因果推論ミックステープ/ch02_確率と回帰の概要.html#平均独立",
    "title": "ch02 確率と回帰の概要",
    "section": "",
    "text": "\\(x\\)の値ごとに分割した母集団の誤差項の期待値に関する、次のような仮定がある。\n$$\n(u x) = (u)\n$$ さらに、回帰分析における自明な仮定として次がある。\n\\[\n\\textrm{E}(u) = 0\n\\]\nよって、回帰分析の文脈でいえば説明変数で条件付けることで、誤差項の期待値はすべて０となる、という解釈になる。\n\n\n\n\n\n\nNote\n\n\n\n残差と誤差項は異なる。残差とは、標本値と推定値の差であり、誤差項とはアウトカムに影響を与える要因のうちモデルが補足できない全て要因を含んだ値である。実態としては残差は計算することが出来るが、誤差項は含めることができない。\n\n\n\n\nCode\nset.seed(1)\ntb &lt;- tibble(\nx = rnorm(10000),\nu = rnorm(10000),\ny = 5.5*x + 12*u\n)\n\nreg_tb &lt;- tb %&gt;%\nlm(y ~ x, .) %&gt;%\nprint()\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y ~ x, data = .)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)            x  \n#&gt;    -0.04991      5.55690\nreg_tb$coefficients\n#&gt; (Intercept)           x \n#&gt; -0.04990882  5.55690164\ntb &lt;- tb %&gt;%\nmutate(\nyhat1 = predict(lm(y ~ x, .)),\nyhat2 = 0.0732608 + 5.685033*x,\nuhat1 = residuals(lm(y ~ x, .)),\nuhat2 = y - yhat2\n)\nsummary(tb[-1:-3])\n#&gt;      yhat1               yhat2              uhat1              uhat2         \n#&gt;  Min.   :-20.45096   Min.   :-20.7982   Min.   :-51.5275   Min.   :-51.5247  \n#&gt;  1st Qu.: -3.79189   1st Qu.: -3.7550   1st Qu.: -8.1520   1st Qu.: -8.2751  \n#&gt;  Median : -0.13842   Median : -0.0173   Median : -0.1727   Median : -0.3147  \n#&gt;  Mean   : -0.08624   Mean   :  0.0361   Mean   :  0.0000   Mean   : -0.1223  \n#&gt;  3rd Qu.:  3.71578   3rd Qu.:  3.9258   3rd Qu.:  7.9778   3rd Qu.:  7.8506  \n#&gt;  Max.   : 21.12342   Max.   : 21.7348   Max.   : 44.7176   Max.   : 44.4416\ntb %&gt;%\nlm(y ~ x, .) %&gt;%\nggplot(aes(x=x, y=y)) +\nggtitle(\"OLS Regression Line\") +\ngeom_point(size = 0.05, color = \"black\", alpha = 0.5) +\ngeom_smooth(method = lm, color = \"black\") +\nannotate(\"text\", x = -1.5, y = 30, color = \"red\",\nlabel = paste(\"Intercept = \", -0.0732608)) +\nannotate(\"text\", x = 1.5, y = -30, color = \"blue\",\nlabel = paste(\"Slope =\", 5.685033))\n#&gt; `geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "contents/books/01_Rによる実証分析_2e/index.html",
    "href": "contents/books/01_Rによる実証分析_2e/index.html",
    "title": "Rによる実証分析 2nd",
    "section": "",
    "text": "1 はじめに\n\nRによる実証分析 2eの読書ノートです\n計量経済学をバックグラウンドとして回帰分析の基礎から解説しています\n応用として因果推論についても解説しています\n出版社HP\n著者サポートページ\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/books/01_Rによる実証分析_2e/ch11_操作変数法.html",
    "href": "contents/books/01_Rによる実証分析_2e/ch11_操作変数法.html",
    "title": "ch11 操作変数法",
    "section": "",
    "text": "1 Setup\n\n\n2 はじめに\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/books/01_Rによる実証分析_2e/ch09_マッチング法.html",
    "href": "contents/books/01_Rによる実証分析_2e/ch09_マッチング法.html",
    "title": "ch09 マッチング法",
    "section": "",
    "text": "1 Setup\n\n\n2 計算練習\nRを使って実際にマッチング法から因果分析を行っていく。\n\n\nCode\npath &lt;- here(cur_dir, \"data/R_EmpiricalAnalysis_csv/chap09/wage_training.csv\")\nwagedata &lt;- read_csv(path, show_col_types = FALSE)\nwagedata |&gt; \n    head() |&gt; \n    paged_table()\n\n\n\n\n  \n\n\n\n\nwagea：研修期間後の賃金\nD：研修参加の有無\nyears：経験年数\nwageb：研修以前の賃金\n\n\n\nCode\nwagedata |&gt; \n    summarise(\n        mean_treated = mean(wagea[D == 1]), \n        mean_controlled = mean(wagea[D == 0]), \n        mean_diff = mean_treated - mean_controlled\n    )\n#&gt; # A tibble: 1 × 3\n#&gt;   mean_treated mean_controlled mean_diff\n#&gt;          &lt;dbl&gt;           &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1         25.7            26.8     -1.13\n\n\n上記の結果をみると、研修をおこなった人の方が賃金が低いという結果が出ている。 これは、他の要因がコントロールされている状況下では、その通りであるが実際には、 次でみるように研修参加が経験年数などと相関していることがわかる。 経験年数などは賃金と相関することが高いと考えられるため、 この値を制御した上で比較する必要がある。\n\n\nCode\nlibrary(correlation)\nwagedata |&gt; \n    select(-wagea) |&gt; \n    correlation() |&gt; \n    paged_table()\n\n\n\n\n  \n\n\n\nそこでマッチングを行うことにする。\n\n\nCode\nm.out &lt;- matchit(D ~ years + wageb,\n                 data     = wagedata,\n                 method   = \"nearest\",\n                 distance = \"scaled_euclidean\",\n                 replace  = TRUE)\nm.out\n#&gt; A matchit object\n#&gt;  - method: 1:1 nearest neighbor matching with replacement\n#&gt;  - distance: Scaled Euclidean\n#&gt;  - number of obs.: 800 (original), 362 (matched)\n#&gt;  - target estimand: ATT\n#&gt;  - covariates: years, wageb\n\n\nバランスさせる前と後で統計量が変わっていることがわかる。 バランスさせると統計量が非常に近くなっていることがわかる。 注意点としてはUnmatchedなデータが多数発生してることは忘れないことにする。\nStd. Mean DiffというのはMean TreatedとMeaan Controlの差を、 treatedの標準偏差で割った値である。\n\n\nCode\nm.out |&gt; \n    summary()\n#&gt; \n#&gt; Call:\n#&gt; matchit(formula = D ~ years + wageb, data = wagedata, method = \"nearest\", \n#&gt;     distance = \"scaled_euclidean\", replace = TRUE)\n#&gt; \n#&gt; Summary of Balance for All Data:\n#&gt;       Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean eCDF Max\n#&gt; years        8.2311       10.9377         -0.4970     0.6556    0.1044   0.1722\n#&gt; wageb       24.4874       26.6637         -0.4734     0.6734    0.0989   0.2094\n#&gt; \n#&gt; Summary of Balance for Matched Data:\n#&gt;       Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean eCDF Max\n#&gt; years        8.2311        8.2101          0.0039     1.0147    0.0044   0.0210\n#&gt; wageb       24.4874       24.4958         -0.0018     0.9905    0.0008   0.0042\n#&gt;       Std. Pair Dist.\n#&gt; years          0.0239\n#&gt; wageb          0.0037\n#&gt; \n#&gt; Sample Sizes:\n#&gt;               Control Treated\n#&gt; All            562.       238\n#&gt; Matched (ESS)   88.78     238\n#&gt; Matched        124.       238\n#&gt; Unmatched      438.         0\n#&gt; Discarded        0.         0\n\n\n\n\nCode\nwagedata |&gt; group_by(D) |&gt; summarise(across(c(years), .fns = list(mean = mean, sd = sd)))\n#&gt; # A tibble: 2 × 3\n#&gt;       D years_mean years_sd\n#&gt;   &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1     0      10.9      6.73\n#&gt; 2     1       8.23     5.45\n\n\nStd. Mean Diffの絶対値をプロットしたものをラブプロットという。 ラブプロットでマッチングがうまくいっているのかどうかを判定することができる。\n\n\nCode\nm.out |&gt; \n    summary() |&gt; \n    plot(xlim = c(0, 1.5))\n\n\n\n\n\n\n\n\n\nマッチングに使われたデータは次である。重複については重みで管理されているみたいです。 このあたりは詳しい使い方を調べる必要がある。\n\n\nCode\nmatch.data(m.out) \n#&gt; # A tibble: 362 × 7\n#&gt;    wagea     D years wageb  educ female weights\n#&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n#&gt;  1    19     1     4    18    17      1   1    \n#&gt;  2    20     1     2    18    15      1   1    \n#&gt;  3    36     1    14    34    14      1   1    \n#&gt;  4    18     0     4    18    11      1   2.61 \n#&gt;  5    29     0    19    29    15      0   0.521\n#&gt;  6    21     1     3    20    18      1   1    \n#&gt;  7    31     0    13    31    15      1   1.04 \n#&gt;  8    26     0    13    26    14      0   2.61 \n#&gt;  9    35     0    19    34    15      1   0.521\n#&gt; 10    33     0    13    33    15      1   0.521\n#&gt; # ℹ 352 more rows\n\n\n\n\nCode\nmatch.data(m.out) |&gt; \n    group_by(D) |&gt; \n    skim() |&gt; \n    as_tibble() |&gt; \n    paged_table()\n\n\n\n\n  \n\n\n\nこの状態であれば通常の回帰分析を使うことで対象を推定することができる。\n\n\nCode\nmatch.data(m.out) |&gt; \n    lm(wagea ~ D + years + wageb, educ, female, data = _, weigths = weights) |&gt; \n    tidy()\n#&gt; Warning: In lm.wfit(x, y, w, offset = offset, singular.ok = singular.ok, \n#&gt;     ...) :\n#&gt;  extra argument 'weigths' will be disregarded\n#&gt; # A tibble: 4 × 5\n#&gt;   term        estimate std.error statistic   p.value\n#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 (Intercept)    1.48    0.209        7.10 7.67e- 12\n#&gt; 2 D             -0.386   0.0961      -4.01 7.40e-  5\n#&gt; 3 years          0.142   0.00948     14.9  8.02e- 39\n#&gt; 4 wageb          0.916   0.0102      89.8  1.48e-232\n\n\nまた、傾向スコアによるマッチングも行える。\n\n\nCode\nm.out &lt;- matchit(D ~ years + wageb,\n                 data     = wagedata,\n                 method   = \"nearest\",\n                 distance = \"glm\",\n                 replace  = TRUE)\n\nm.out %&gt;% \n  match.data() %&gt;% \n  lm(wagea ~ D,\n       data = .,\n     weights = weights) %&gt;% \n  tidy()\n#&gt; # A tibble: 2 × 5\n#&gt;   term        estimate std.error statistic   p.value\n#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 (Intercept)   25.1       0.369     68.0  3.92e-221\n#&gt; 2 D              0.613     0.479      1.28 2.01e-  1\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/books/01_Rによる実証分析_2e/ch07_外生変数と内生変数.html#欠落変数",
    "href": "contents/books/01_Rによる実証分析_2e/ch07_外生変数と内生変数.html#欠落変数",
    "title": "ch07 内生変数と外生変数",
    "section": "2.1 欠落変数",
    "text": "2.1 欠落変数\nもとのモデルは内生変数がない次の状態を考える。この状態であれば通常の回帰分析で推定することができる。\n$$\nY_i = _0 + 1X{1i} + 2X{2i} + _i\n$$\nここで\\(X_2\\)が観測できない状態を考える。\n$$ \\[\\begin{align}\n\nY_i &= \\alpha_0 + \\beta_1X_{1i} + \\eta_i \\\\\n\\alpha_0 &= \\beta_0 + \\beta_2\\textrm{E}[X_{2i}] \\\\\n\\eta_i &= \\beta_2(X_{2i}-\\textrm{E}[X_{2i}])+\\epsilon_i\n\n\n\\end{align}\\] $$\n単回帰モデルで正しく\\(\\beta\\)を推定するためには、\\(X_{i}\\)が誤差項と外生的変数であることが求められる。 下記の結果をみると\\(X_{1i}\\)は外生的であるため欠落したままでは回帰分析は適していない\n\\[\n\\begin{align}\n\\textrm{E}(X_{1i}) &= \\textrm{E}\\{X_{1i}[\\beta_2(X_{2i}-\\textrm{E}[X_{2i}])+\\epsilon_i]\\} \\\\\n&=\\beta_2\\textrm{E}{X_{1i}(X_{2i}-\\textrm{E}[X_{2i}])} + E[X_{1i}\\epsilon_i]\\\\\n&=\\beta_2\\textrm{Cov}(X_{1i}., X_{2i})\n\\end{align}\n\\]"
  },
  {
    "objectID": "contents/books/01_Rによる実証分析_2e/ch07_外生変数と内生変数.html#測定誤差",
    "href": "contents/books/01_Rによる実証分析_2e/ch07_外生変数と内生変数.html#測定誤差",
    "title": "ch07 内生変数と外生変数",
    "section": "2.2 測定誤差",
    "text": "2.2 測定誤差\n測定誤差があると、過小バイアスがかかる。ただし符号は変化しない。\n\n\nCode\nn &lt;- 200\ne &lt;- rnorm(n)\nX &lt;- rnorm(n)\nu &lt;- runif(n, -1, 1)\nW &lt;- X + u \nb0 &lt;- 1\nb1 &lt;- 2\nY &lt;- b0 + X * b1 + e\n\nlm(\n    Y ~ W\n)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = Y ~ W)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)            W  \n#&gt;       1.040        1.463"
  },
  {
    "objectID": "contents/books/01_Rによる実証分析_2e/ch07_外生変数と内生変数.html#同時性",
    "href": "contents/books/01_Rによる実証分析_2e/ch07_外生変数と内生変数.html#同時性",
    "title": "ch07 内生変数と外生変数",
    "section": "2.3 同時性",
    "text": "2.3 同時性\nこれも通常の回帰分析では正しく推定することは出来ない。"
  },
  {
    "objectID": "contents/books/01_Rによる実証分析_2e/ch05_推測統計の基礎.html",
    "href": "contents/books/01_Rによる実証分析_2e/ch05_推測統計の基礎.html",
    "title": "ch05 推測統計の基礎",
    "section": "",
    "text": "1 Setup\n\n\n2 平均値の検定\n\n\nCode\ndata_path &lt;- here(cur_dir, \"data/R_EmpiricalAnalysis_csv/chap05/distributions.csv\")\nsimdata &lt;- read_csv(data_path, show_col_types = FALSE)\nsimdata\n#&gt; # A tibble: 100 × 2\n#&gt;    distA  distB\n#&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n#&gt;  1  2.83  0.816\n#&gt;  2  2.66  0.755\n#&gt;  3  2.64 -0.971\n#&gt;  4  1.31 -0.572\n#&gt;  5  2.29  0.450\n#&gt;  6  1.44  0.848\n#&gt;  7  2.56  0.130\n#&gt;  8  1.30 -0.640\n#&gt;  9  1.39  0.196\n#&gt; 10  1.27  0.817\n#&gt; # ℹ 90 more rows\n\n\n\n\nCode\nsimdata |&gt; \n    summarise(mean_A = mean(distA), var_A = var(distA)) |&gt; \n    mutate(t.value = sqrt(100) / sqrt(var_A) * mean_A)\n#&gt; # A tibble: 1 × 3\n#&gt;   mean_A var_A t.value\n#&gt;    &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1   2.04 0.373    33.4\n\n\n\n\n3 回帰係数の検定\n線形モデルでシミュレーションして回帰係数の値をみてみる。 次の結果からモデル通りの値が出ていることがわかる。\n\n\nCode\nX &lt;- rnorm(1000, 0, 1)\nY &lt;- 1 + 5 * X + rnorm(1000, 0, 1)\nbeta1 &lt;- lm(Y ~ X)$coefficients[2]\nbeta1\n#&gt;        X \n#&gt; 4.998162\n\n\n上記の推定の流れをモンテカルロシミュレーションする。だいたい5に近い値が出ていることがわかる。\n\n\nCode\nn_simulations &lt;- 1000\nbetas &lt;- replicate(n_simulations, {\n    X &lt;- rnorm(1000, 0, 1)\n    Y &lt;- 1 + 5 * X + rnorm(1000, 0, 1)\n    lm(Y ~ X)$coefficients[2]\n})\n\nhist(betas)\n\n\n\n\n\n\n\n\n\n分析例としてwageデータを使う.\n\n\nCode\nwagedata &lt;- read_csv(here(cur_dir, \"data/R_EmpiricalAnalysis_csv/chap03/wage.csv\"), show_col_types = FALSE)\nfit &lt;- \n    wagedata |&gt; \n    lm(log(wage) ~ educ + exper, data = _) \n\nfit |&gt; summary()\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = log(wage) ~ educ + exper, data = wagedata)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -1.93442 -0.26396  0.02404  0.27287  1.42863 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) 4.666034   0.063790   73.15   &lt;2e-16 ***\n#&gt; educ        0.093168   0.003612   25.80   &lt;2e-16 ***\n#&gt; exper       0.040657   0.002334   17.42   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.4017 on 3007 degrees of freedom\n#&gt; Multiple R-squared:  0.1813, Adjusted R-squared:  0.1808 \n#&gt; F-statistic:   333 on 2 and 3007 DF,  p-value: &lt; 2.2e-16\n\n\n\n\nCode\nconfint(fit) \n#&gt;                  2.5 %     97.5 %\n#&gt; (Intercept) 4.54095799 4.79111090\n#&gt; educ        0.08608627 0.10024978\n#&gt; exper       0.03608017 0.04523456\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/books/01_Rによる実証分析_2e/ch03_確率論の基礎.html#独立性と相関係数",
    "href": "contents/books/01_Rによる実証分析_2e/ch03_確率論の基礎.html#独立性と相関係数",
    "title": "ch03 確率論の基礎",
    "section": "2.1 独立性と相関係数",
    "text": "2.1 独立性と相関係数\n無相関であるとういことは、独立を意味しないことの例を示す。\n\n\nCode\nx &lt;- rnorm(100000, 50, 10)\nz &lt;- - ((x - 50) ** 2) / 10\ncor(x, z)\n#&gt; [1] 0.00199626\n\n\n\n\nCode\nplot(x, z)"
  },
  {
    "objectID": "contents/books/01_Rによる実証分析_2e/ch03_確率論の基礎.html#確率密度",
    "href": "contents/books/01_Rによる実証分析_2e/ch03_確率論の基礎.html#確率密度",
    "title": "ch03 確率論の基礎",
    "section": "2.2 確率密度",
    "text": "2.2 確率密度\n確率変数\\(X\\)がある値を取る確率はゼロになってしまう。そこで、ある値に収束するように、確率関数を微分した確率密度関数を使う。"
  },
  {
    "objectID": "contents/books/01_Rによる実証分析_2e/ch03_確率論の基礎.html#データによる条件付き期待値の推定",
    "href": "contents/books/01_Rによる実証分析_2e/ch03_確率論の基礎.html#データによる条件付き期待値の推定",
    "title": "ch03 確率論の基礎",
    "section": "2.3 データによる条件付き期待値の推定",
    "text": "2.3 データによる条件付き期待値の推定\n1976年にアメリカ合衆国の男性労働者を対象に実施された賃金調査結果データの1部分を扱う。educが教育年数であり、experは職業経験根数、wageは1時間あたり賃金です。\n\n\nCode\npath &lt;- here(cur_dir, \"data/R_EmpiricalAnalysis_csv/chap03/wage.csv\")\nwage &lt;- read_csv(path, show_col_types = FALSE)\n\nwage |&gt; \n    head() |&gt; \n    paged_table()\n\n\n\n\n  \n\n\n\n\n\nCode\nsummary(wage)\n#&gt;       educ           exper             wage       \n#&gt;  Min.   : 1.00   Min.   : 0.000   Min.   : 100.0  \n#&gt;  1st Qu.:12.00   1st Qu.: 6.000   1st Qu.: 394.2  \n#&gt;  Median :13.00   Median : 8.000   Median : 537.5  \n#&gt;  Mean   :13.26   Mean   : 8.856   Mean   : 577.3  \n#&gt;  3rd Qu.:16.00   3rd Qu.:11.000   3rd Qu.: 708.8  \n#&gt;  Max.   :18.00   Max.   :23.000   Max.   :2404.0\n\n\n\n\nCode\nplot(wage)\n\n\n\n\n\n\n\n\n\nこのデータに対して、educ = 12の個人だけを対象にサマリーする。とおもったけど面倒であるので、ここではすべてを対象にする。 これを見るだけでも、どうやら教育年数により収入の平均値が変化していそうなことがわかる。\n\n\nCode\nwage_summary &lt;- \n    wage |&gt; \n    group_by(educ) |&gt; \n    skim() |&gt; \n    as_tibble() |&gt; \n    filter(skim_variable == \"wage\")\n\nwage_summary |&gt; paged_table()\n\n\n\n\n  \n\n\n\n\n\nCode\nwage_summary |&gt; \n    ggplot(aes(x = educ, y = numeric.mean)) +\n    geom_linerange(aes(ymin = numeric.p25, ymax = numeric.p75), lwd = 2) + \n    geom_point(color = \"red\", size = 5)"
  },
  {
    "objectID": "contents/books/01_Rによる実証分析_2e/ch01_回帰分析の目的.html#身長と体重",
    "href": "contents/books/01_Rによる実証分析_2e/ch01_回帰分析の目的.html#身長と体重",
    "title": "ch01 回帰分析の目的",
    "section": "2.1 身長と体重",
    "text": "2.1 身長と体重\nある年代の人の身長と体重をプロットとすると「正の相関」が見られる。 一方で、この相関からは「体重を増やせば身長が伸びる」という因果関係を得ることはできない。 よく使われる例であるが、これを別の言い方に変えると、相関はマクロな指標のため入力も出力も統計的であるが、 因果は個別の人についても適用される。\n\n\n\n\n\n\nNote\n\n\n\nある集団の平均的な体重が増えるとも身長も増えるのが相関であり、ある人のことについて言及できるのが因果である"
  },
  {
    "objectID": "contents/books/01_Rによる実証分析_2e/ch01_回帰分析の目的.html#疑似相関",
    "href": "contents/books/01_Rによる実証分析_2e/ch01_回帰分析の目的.html#疑似相関",
    "title": "ch01 回帰分析の目的",
    "section": "2.2 疑似相関",
    "text": "2.2 疑似相関\n次のグラフは、一見因果関係がありそうな２つの支出であるが、これは経済自体が成長している時期であるため、 どのような指標とも医療への支出額が相関関係をもつ。 統計的には「所得」という因子が交絡しているということになる。\n\ndata(\"USPersonalExpenditure\")\nUSPersonalExpenditure &lt;-\n    USPersonalExpenditure |&gt;\n    t() |&gt; \n    as.data.frame() \n\nUSPersonalExpenditure |&gt; \n    ggplot(aes(x = `Food and Tobacco`, y = `Medical and Health`)) +\n    geom_path() + \n    geom_point(size = 10) + \n    labs(\n        x = \"食料品およびタバコへの支出総額(Food and tobacco)\", \n        y = \"医療および健康への支出総額\"\n    ) \n\n\n\n\n\n\n\n\nその他のカラムとの関係をみてみる。\n\n\nCode\npairs  &lt;- combn(syms(names(USPersonalExpenditure)), 2, simplify = FALSE)\ngraphs &lt;- \n    pairs |&gt; \n    map(\\(x) {\n        ggplot(USPersonalExpenditure, aes(!!x[[1]], !!x[[2]])) + \n            geom_path() + \n            geom_point(size = 5)\n    }) |&gt; \n    list_modify(ncol = 2)\n\ndo.call(grid.arrange, graphs)\n\n\n\n\n\n\n\n\n\nこのように一般にはデータからだけでは因果関係に言及することは困難である。 データ分析のまえに事前にフィールドワークや文献調査をおこない信頼できる因果関係を仮説立てた上で、その仮説をモデルにより検証する。\nただし近年では古典的なビッグデータを使った因果特定の研究もある。"
  },
  {
    "objectID": "contents/libs/sf/working.html",
    "href": "contents/libs/sf/working.html",
    "title": "sf",
    "section": "",
    "text": "Code\ncur_dir     &lt;- here::here(\"contents/libs/sf\")\ndataset_dir &lt;- here::here(cur_dir, \"dataset\")\noutput_dir  &lt;- here::here(cur_dir, \"output\")"
  },
  {
    "objectID": "contents/libs/sf/working.html#idw",
    "href": "contents/libs/sf/working.html#idw",
    "title": "sf",
    "section": "2.1 IDW",
    "text": "2.1 IDW\nデータを作成する。\n\n\nCode\nlocations &lt;- \n  tibble(\n    longitude = c(10, 10.5, 11),\n    latitude = c(10, 14.5, 18),\n    measurement = c(100, 150, 120)\n  ) |&gt;\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326)\n\nregion &lt;- st_as_sf(data.frame(\n  x = c(10, 10, 20, 20),\n  y = c(10, 20, 20, 10)\n), coords = c(\"x\", \"y\"), crs = 4326)\n\n\n逆距離補間をおこなう。\n\n\nCode\ngrid &lt;- st_make_grid(region, what = \"centers\")\nidw_result &lt;- idw(formula = measurement ~ 1, locations, grid)\n#&gt; [inverse distance weighted interpolation]\nidw_result\n#&gt; Simple feature collection with 100 features and 2 fields\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: 10.5 ymin: 10.5 xmax: 19.5 ymax: 19.5\n#&gt; Geodetic CRS:  WGS 84\n#&gt; First 10 features:\n#&gt;    var1.pred var1.var          geometry\n#&gt; 1   101.6566       NA POINT (10.5 10.5)\n#&gt; 2   106.8246       NA POINT (11.5 10.5)\n#&gt; 3   112.7551       NA POINT (12.5 10.5)\n#&gt; 4   116.9918       NA POINT (13.5 10.5)\n#&gt; 5   119.5808       NA POINT (14.5 10.5)\n#&gt; 6   121.1055       NA POINT (15.5 10.5)\n#&gt; 7   122.0098       NA POINT (16.5 10.5)\n#&gt; 8   122.5585       NA POINT (17.5 10.5)\n#&gt; 9   122.9007       NA POINT (18.5 10.5)\n#&gt; 10  123.1201       NA POINT (19.5 10.5)\n\n\n\n\nCode\nplot(\n  st_make_grid(\n    region, \n    cellsize = 1,\n    what = \"polygons\")\n)\nplot(select(idw_result, var1.pred), add = TRUE)\nplot(locations, add = TRUE, col = \"red\", cex = 3, pch = 19)\n\n\n\n\n\n\n\n\n\nラスタ化する.\n\n\nCode\nplot(\n  rasterize(\n    idw_result, \n    rast(\n      extent = st_bbox(region), \n      resolution = 1\n    ),\n    field = \"var1.pred\"\n  )\n)\n\n\n\n\n\n\n\n\n\n距離の次数を変更してみる。\n\n\nCode\n# IDW補間の実行、距離のべき乗を3に設定\nidw_result_power3 &lt;- idw(formula = measurement ~ 1, locations, grid, idp = 3)\n#&gt; [inverse distance weighted interpolation]\nidw_result_power3\n#&gt; Simple feature collection with 100 features and 2 fields\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: 10.5 ymin: 10.5 xmax: 19.5 ymax: 19.5\n#&gt; Geodetic CRS:  WGS 84\n#&gt; First 10 features:\n#&gt;    var1.pred var1.var          geometry\n#&gt; 1   100.2868       NA POINT (10.5 10.5)\n#&gt; 2   102.7593       NA POINT (11.5 10.5)\n#&gt; 3   108.0653       NA POINT (12.5 10.5)\n#&gt; 4   113.3959       NA POINT (13.5 10.5)\n#&gt; 5   117.2178       NA POINT (14.5 10.5)\n#&gt; 6   119.6376       NA POINT (15.5 10.5)\n#&gt; 7   121.1204       NA POINT (16.5 10.5)\n#&gt; 8   122.0318       NA POINT (17.5 10.5)\n#&gt; 9   122.6014       NA POINT (18.5 10.5)\n#&gt; 10  122.9651       NA POINT (19.5 10.5)"
  },
  {
    "objectID": "contents/libs/sf/working.html#st_rasterize",
    "href": "contents/libs/sf/working.html#st_rasterize",
    "title": "sf",
    "section": "3.1 st_rasterize",
    "text": "3.1 st_rasterize\nstarsオブジェクトなどをラスターのテンプレートとして、空間データをラスター化する関数です。 leafletでみると少しズレているように見えるけど、QGISでみるとズレていない。\n\n\nCode\npath_to_polygon &lt;- here(dataset_dir, \"meshes_bursa2320.geojson\")\npolygon &lt;- st_read(path_to_polygon)\n#&gt; Reading layer `meshes_bursa2320' from data source \n#&gt;   `C:\\Users\\suzuk\\Dropbox\\R\\Workspace\\RTipsSite\\contents\\libs\\sf\\dataset\\meshes_bursa2320.geojson' \n#&gt;   using driver `GeoJSON'\n#&gt; Simple feature collection with 174928 features and 0 fields\n#&gt; Geometry type: POLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: 337290.5 ymin: 4383603 xmax: 493290.5 ymax: 4497853\n#&gt; Projected CRS: ED50 / TM30\nst_write(st_centroid(polygon), here(output_dir, \"centroid.geojson\"), delete_dsn = TRUE)\n#&gt; Deleting source `C:/Users/suzuk/Dropbox/R/Workspace/RTipsSite/contents/libs/sf/output/centroid.geojson' using driver `GeoJSON'\n#&gt; Writing layer `centroid' to data source \n#&gt;   `C:/Users/suzuk/Dropbox/R/Workspace/RTipsSite/contents/libs/sf/output/centroid.geojson' using driver `GeoJSON'\n#&gt; Writing 174928 features with 0 fields and geometry type Point.\nraster_template &lt;- st_as_stars(\n  st_bbox(polygon), \n  dx = set_units(250, \"m\"), \n  dy = set_units(250, \"m\"))\nrasterized &lt;- st_rasterize(polygon, raster_template)\nrasterized |&gt; write_stars(here(output_dir, \"rasterized.tif\"))\nrasterized\n#&gt; stars object with 2 dimensions and 1 attribute\n#&gt; attribute(s):\n#&gt;     Min. 1st Qu.  Median     Mean  3rd Qu.   Max.\n#&gt; ID     0       0 32344.5 53652.55 103636.2 174928\n#&gt; dimension(s):\n#&gt;   from  to  offset delta      refsys point x/y\n#&gt; x    1 624  337291   250 ED50 / TM30 FALSE [x]\n#&gt; y    1 457 4497853  -250 ED50 / TM30 FALSE [y]\n\n\n\n\nCode\nxx  &lt;- st_transform(st_centroid(head(polygon, 1000)), 4326)\nlng &lt;- st_coordinates(xx)[1:1000, 1]\nlat &lt;- st_coordinates(xx)[1:1000, 2]\nleaflet(\n    # options = leafletOptions(crs = leafletCRS(crsClass = \"L.CRS.EPSG3857\"))\n  ) |&gt; \n  addTiles() |&gt;\n  addCircleMarkers(lng = lng, lat = lat, radius = .1, color = \"blue\") |&gt; \n  addPolygons(data = st_transform(head(polygon, 1000), 4326), color = \"red\") |&gt;  \n  addStarsImage(rasterized, colors = \"RdPu\", opacity = 0.9, project = TRUE)"
  },
  {
    "objectID": "contents/libs/sf/working.html#st_make_grid",
    "href": "contents/libs/sf/working.html#st_make_grid",
    "title": "sf",
    "section": "3.2 st_make_grid",
    "text": "3.2 st_make_grid\n\n空間データをグリッドに変換する関数です。\n以下のように、グリッドのセルの大きさを指定することができます。\n\n\n\nCode\n# 例として、ある地域のポリゴンを定義\nregion &lt;- st_as_sf(data.frame(\n  x = c(10, 10, 20, 20),\n  y = c(10, 20, 20, 10)\n), coords = c(\"x\", \"y\"), crs = 4326)\n\n\n\n\nCode\ngrid &lt;- st_make_grid(region, cellsize = 1, what = \"polygons\")\ngrid\n#&gt; Geometry set for 100 features \n#&gt; Geometry type: POLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: 10 ymin: 10 xmax: 20 ymax: 20\n#&gt; Geodetic CRS:  WGS 84\n#&gt; First 5 geometries:\n#&gt; POLYGON ((10 10, 11 10, 11 11, 10 11, 10 10))\n#&gt; POLYGON ((11 10, 12 10, 12 11, 11 11, 11 10))\n#&gt; POLYGON ((12 10, 13 10, 13 11, 12 11, 12 10))\n#&gt; POLYGON ((13 10, 14 10, 14 11, 13 11, 13 10))\n#&gt; POLYGON ((14 10, 15 10, 15 11, 14 11, 14 10))\n\n\n\n\nCode\nplot(grid)\nplot(region, add = TRUE)\n# ポイントデータを作成することもできる\nplot(\n  st_make_grid(region, cellsize = 1, what = \"centers\"),\n  col = \"red\", \n  add = TRUE\n)\nplot(\n  st_make_grid(region, cellsize = 1, what = \"corners\"),\n  col = \"blue\", \n  add = TRUE\n)\n\n\n\n\n\n\n\n\n\nセルサイズはXYで変更することもできる。\n\n\nCode\nplot(grid)\nplot(\n  st_make_grid(region, cellsize = c(1, 2), what = \"centers\"),\n  col = \"red\", \n  add = TRUE\n)"
  },
  {
    "objectID": "contents/libs/igraph/r_interface.html",
    "href": "contents/libs/igraph/r_interface.html",
    "title": "R インターフェイス",
    "section": "",
    "text": "Code\nrenv::activate(here::here())\ncur_dir &lt;- here::here(\"contents/libs/igraph\")\nCode\nbox::use(\n  igraph[..., V, E],\n  ggplot2[...],\n  cowplot[...], \n  showtext[showtext_auto], \n  sysfonts[font_add_google],\n)\nshowtext_auto()\nfont_add_google(\"Noto Sans\")"
  },
  {
    "objectID": "contents/libs/igraph/r_interface.html#selecting-vertices",
    "href": "contents/libs/igraph/r_interface.html#selecting-vertices",
    "title": "R インターフェイス",
    "section": "7.1 Selecting vertices",
    "text": "7.1 Selecting vertices\n\n\nCode\n# 最も辺が多い頂点\nwhich.max(degree(g))\n#&gt; Claire \n#&gt;      3\n\n\n1を除いた奇数個のエッジを持つ頂点を探す.\n\n\nCode\ngraph &lt;- graph.full(10)\nonly_odd_vertices &lt;- which(V(graph) %% 2 == 1)\nlength(only_odd_vertices)\n#&gt; [1] 5\n\n\n属性を使いフィルターすることも可能である。\n\n\nCode\nV(g)[age &lt; 30]\n#&gt; + 4/7 vertices, named, from 220d792:\n#&gt; [1] Alice  Claire Frank  Esther"
  },
  {
    "objectID": "contents/libs/igraph/r_interface.html#selecting-edges",
    "href": "contents/libs/igraph/r_interface.html#selecting-edges",
    "title": "R インターフェイス",
    "section": "7.2 Selecting edges",
    "text": "7.2 Selecting edges\n.toや.fromを使うことで、エッジのフィルターが可能となる。\n\n\nCode\nE(g)[.from(\"Alice\")]\n#&gt; + 3/9 edges from 220d792 (vertex names):\n#&gt; [1] Alice--Bob    Alice--Claire Alice--Frank\n\n\n\n\nCode\nE(g)[.from(3)]\n#&gt; + 4/9 edges from 220d792 (vertex names):\n#&gt; [1] Alice --Claire Claire--Frank  Claire--Dennis Claire--Esther\n\n\n%--%オペレータを使うことでエッジを頂点グループで指定することができる。 頂点グループの指定方法はcでもいいし、色々と使うことができる。\n\n\nCode\nE(g)[c(1, 2) %--% V(g)]\n#&gt; + 3/9 edges from 220d792 (vertex names):\n#&gt; [1] Alice--Bob    Alice--Claire Alice--Frank\n\n\n%--%はname属性でも動かすことができる.\n\n\nCode\nV(g)$gender &lt;-  c(\"f\", \"m\", \"f\", \"m\", \"m\", \"f\", \"m\")\nmen &lt;- V(g)[gender == \"m\"]$name\nwomen &lt;- V(g)[gender == \"f\"]$name\nE(g)[men %--% women]\n#&gt; + 5/9 edges from 220d792 (vertex names):\n#&gt; [1] Alice --Bob    Alice --Frank  Claire--Frank  Claire--Dennis Dennis--Esther"
  },
  {
    "objectID": "contents/libs/igraph/r_interface.html#write_graphread_graph",
    "href": "contents/libs/igraph/r_interface.html#write_graphread_graph",
    "title": "R インターフェイス",
    "section": "10.1 write_graph/read_graph",
    "text": "10.1 write_graph/read_graph\n\n\nCode\ng &lt;- make_ring(10)\nfile &lt;- tempfile(fileext = \".txt\")\nwrite_graph(g, file, \"edgelist\")\n\n\nplot(g)\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot(read_graph(file, \"edgelist\", directed = FALSE))"
  },
  {
    "objectID": "contents/libs/ggtext/working.html",
    "href": "contents/libs/ggtext/working.html",
    "title": "ggtext",
    "section": "",
    "text": "Code\nrenv::activate(here::here())\ncur_dir &lt;- here::here(\"contents/libs/ggtext\")\nCode\npackages &lt;- c(\n  \"tidyverse\", \n  \"magick\",\n  \"ggplot2\", \n  \"readr\", \n  \"tibble\", \n  \"tidyr\", \n  \"forcats\", \n  \"stringr\",\n  \"lubridate\", \n  \"here\", \n  \"systemfonts\", \n  \"magick\", \n  \"scales\", \n  \"grid\",\n  \"grDevices\", \n  \"colorspace\", \n  \"viridis\", \n  \"RColorBrewer\", \n  \"rcartocolor\",\n  \"scico\", \n  \"ggsci\", \n  \"ggthemes\", \n  \"nord\", \n  \"MetBrewer\", \n  \"ggrepel\",\n  \"ggforce\",\n  \"ggtext\", \n  \"ggdist\", \n  \"ggbeeswarm\", \n  \"gghalves\", \n  \"patchwork\", \n  \"palmerpenguins\", \n  \"rnaturalearth\", \n  \"sf\", \n  \"rmapshaper\", \n  \"devtools\", \n  \"extrafont\"\n) |&gt; lapply(\\(x) library(x, character.only = TRUE))\nlibrary(cowplot)\nlibrary(colorblindr)\n\n\nlibrary(showtext)\nshowtext_auto()\nfont_add_google(\"Noto Sans\")"
  },
  {
    "objectID": "contents/libs/ggtext/working.html#markdown-in-theme-elements",
    "href": "contents/libs/ggtext/working.html#markdown-in-theme-elements",
    "title": "ggtext",
    "section": "2.1 Markdown in theme elements",
    "text": "2.1 Markdown in theme elements\nthemeでelementを指定することで、html要素を使うことが可能となる。 たとえば&lt;br&gt;で改行したり、iタグでCSSを当てたりすることができる.\n\n\nCode\nlibrary(tidyverse)\nlibrary(ggtext)\nlibrary(glue)\n\ndata &lt;- tibble(\n  bactname = c(\"Staphylococcaceae\", \"Moraxella\", \"Streptococcus\", \"Acinetobacter\"),\n  OTUname = c(\"OTU 1\", \"OTU 2\", \"OTU 3\", \"OTU 4\"),\n  value = c(-0.5, 0.5, 2, 3)\n)\n\ndata %&gt;% mutate(\n  color = c(\"#009E73\", \"#D55E00\", \"#0072B2\", \"#000000\"),\n  name = glue(\"&lt;i style='color:{color}'&gt;{bactname}&lt;/i&gt; ({OTUname})\"),\n  name = fct_reorder(name, value)\n)  %&gt;%\n  ggplot(aes(value, name, fill = color)) + \n  geom_col(alpha = 0.5) + \n  scale_fill_identity() +\n  labs(caption = \"Example posted on **stackoverflow.com**&lt;br&gt;(using made-up data)\") +\n  theme(\n    axis.text.y = element_markdown(),\n    plot.caption = element_markdown(lineheight = 1.2)\n  )\n\n\n\n\n\n\n\n\n\nimgタグを使うことも可能である。\n\n\nCode\nlabels &lt;- c(\n  setosa = \"&lt;img src='unnamed-chunk-6-1.png'\n    width='100' /&gt;&lt;br&gt;*I. setosa*\",\n  virginica = \"&lt;img src='unnamed-chunk-4-1.png'\n    width='100' /&gt;&lt;br&gt;*I. virginica*\",\n  versicolor = \"&lt;img src='unnamed-chunk-5-1.png'\n    width='100' /&gt;&lt;br&gt;*I. versicolor*\"\n)\n\nggplot(iris, aes(Species, Sepal.Width)) +\n  geom_boxplot() +\n  scale_x_discrete(\n    name = NULL,\n    labels = labels\n  ) +\n  theme(\n    axis.text.x = element_markdown(color = \"black\", size = 11)\n  )\n\n\n\n\n\n\n\n\n\ngeom_textbox_simpleなどでは、直接マークダウン要素を使うことが可能である。\n\n\nCode\nggplot(mtcars, aes(disp, mpg)) + \n  geom_point() +\n  labs(\n    title = \"&lt;b&gt;Fuel economy vs. engine displacement&lt;/b&gt;&lt;br&gt;\n    &lt;span style = 'font-size:10pt'&gt;Lorem ipsum *dolor sit amet,*\n    consectetur adipiscing elit, **sed do eiusmod tempor incididunt** ut\n    labore et dolore magna aliqua. &lt;span style = 'color:red;'&gt;Ut enim\n    ad minim veniam,&lt;/span&gt; quis nostrud exercitation ullamco laboris nisi\n    ut aliquip ex ea commodo consequat.&lt;/span&gt;\",\n    x = \"displacement (in&lt;sup&gt;3&lt;/sup&gt;)\",\n    y = \"Miles per gallon (mpg)&lt;br&gt;&lt;span style = 'font-size:8pt'&gt;A measure of\n    the car's fuel efficiency.&lt;/span&gt;\"\n  ) +\n  theme(\n    plot.title.position = \"plot\",\n    plot.title = element_textbox_simple(\n      size = 13,\n      lineheight = 1,\n      padding = margin(5.5, 5.5, 5.5, 5.5),\n      margin = margin(0, 0, 5.5, 0),\n      fill = \"cornsilk\"\n    ),\n    axis.title.x = element_textbox_simple(\n      width = NULL,\n      padding = margin(4, 4, 4, 4),\n      margin = margin(4, 0, 0, 0),\n      linetype = 1,\n      r = grid::unit(8, \"pt\"),\n      fill = \"azure1\"\n    ),\n    axis.title.y = element_textbox_simple(\n      hjust = 0,\n      orientation = \"left-rotated\",\n      minwidth = unit(1, \"in\"),\n      maxwidth = unit(2, \"in\"),\n      padding = margin(4, 4, 2, 4),\n      margin = margin(0, 0, 2, 0),\n      fill = \"lightsteelblue1\"\n    )\n  )\n\n\n\n\n\n\n\n\n\nfacetのラベルにも使うことが可能である。\n\n\nCode\n\nlibrary(cowplot)\n\nggplot(mpg, aes(cty, hwy)) + \n  geom_point() +\n  facet_wrap(~class) +\n  theme_half_open(12) +\n  background_grid() +\n  theme(\n    strip.background = element_blank(),\n    strip.text = element_textbox(\n      size = 12,\n      color = \"white\", fill = \"#5D729D\", box.color = \"#4A618C\",\n      halign = 0.5, linetype = 1, r = unit(5, \"pt\"), width = unit(1, \"npc\"),\n      padding = margin(2, 0, 1, 0), margin = margin(3, 3, 3, 3)\n    )\n  )\n\n\n\n\n\n\n\n\n\nCode\n#&gt; Warning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\n#&gt; Please use the `linewidth` argument instead.\n#&gt; Warning: The `size` argument of `element_rect()` is deprecated as of ggplot2 3.4.0.\n#&gt; Please use the `linewidth` argument instead."
  },
  {
    "objectID": "contents/libs/ggtext/working.html#geoms",
    "href": "contents/libs/ggtext/working.html#geoms",
    "title": "ggtext",
    "section": "2.2 Geoms",
    "text": "2.2 Geoms\ngeom_richtextを使うとテキストボックスの加工が色々と可能となる。\n\n\nCode\ndf &lt;- tibble(\n  label = c(\n    \"Some text **in bold.**\",\n    \"Linebreaks&lt;br&gt;Linebreaks&lt;br&gt;Linebreaks\",\n    \"*x*&lt;sup&gt;2&lt;/sup&gt; + 5*x* + *C*&lt;sub&gt;*i*&lt;/sub&gt;\",\n    \"Some &lt;span style='color:blue'&gt;blue text **in bold.**&lt;/span&gt;&lt;br&gt;And *italics text.*&lt;br&gt;\n    And some &lt;span style='font-size:18pt; color:black'&gt;large&lt;/span&gt; text.\"\n  ),\n  x = c(.2, .1, .5, .9),\n  y = c(.8, .4, .1, .5),\n  hjust = c(0.5, 0, 0, 1),\n  vjust = c(0.5, 1, 0, 0.5),\n  angle = c(0, 0, 45, -45),\n  color = c(\"black\", \"blue\", \"black\", \"red\"),\n  fill = c(\"cornsilk\", \"white\", \"lightblue1\", \"white\")\n)\n\n\nggplot(df) +\n  aes(\n    x, y, label = label, angle = angle, color = color, fill = fill,\n    hjust = hjust, vjust = vjust\n  ) +\n  geom_richtext() +\n  geom_point(color = \"black\", size = 2) +\n  scale_color_identity() +\n  scale_fill_identity() +\n  xlim(0, 1) + ylim(0, 1)\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(df) +\n  aes(\n    x, y, label = label, angle = angle, color = color,\n    hjust = hjust, vjust = vjust\n  ) +\n  geom_richtext(\n    fill = NA, label.color = NA, # remove background and outline\n    label.padding = grid::unit(rep(0, 4), \"pt\") # remove padding\n  ) +\n  geom_point(color = \"black\", size = 2) +\n  scale_color_identity() +\n  xlim(0, 1) + ylim(0, 1)\n\n\n\n\n\n\n\n\n\ngeom_textboxは、word wrapさせることも可能である。ただし、回転角度についてはサポートされれていない。\n\n\nCode\n\ndf &lt;- tibble(\n  label = rep(\"Lorem ipsum dolor **sit amet,** consectetur adipiscing elit,\n    sed do *eiusmod tempor incididunt* ut labore et dolore magna\n    aliqua.\", 2),\n  x = c(0, .6),\n  y = c(1, .6),\n  hjust = c(0, 0),\n  vjust = c(1, 0),\n  orientation = c(\"upright\", \"right-rotated\"),\n  color = c(\"black\", \"blue\"),\n  fill = c(\"cornsilk\", \"white\")\n)\n\nggplot(df) +\n  aes(\n    x, y, label = label, color = color, fill = fill,\n    hjust = hjust, vjust = vjust,\n    orientation = orientation\n  ) +\n  geom_textbox(width = unit(0.4, \"npc\")) +\n  geom_point(color = \"black\", size = 2) +\n  scale_discrete_identity(aesthetics = c(\"color\", \"fill\", \"orientation\")) +\n  xlim(0, 1) + ylim(0, 1)"
  },
  {
    "objectID": "contents/libs/ggmosaic/working.html",
    "href": "contents/libs/ggmosaic/working.html",
    "title": "ggmosaic",
    "section": "",
    "text": "Code\nrenv::activate(here::here())\ncur_dir &lt;- here::here(\"contents/libs/ggmosaic\")\n\n\n\n\nCode\nlibrary(ggmosaic)\nlibrary(showtext)\nlibrary(dplyr)\nshowtext_auto()\nfont_add_google(\"Noto Sans\")\n\n\n\n1 はじめに\nggmosaicで美しいモザイクプロットを作成することができる。\nHPが再発サイトである。\n\n\n2 Example\n\n\nCode\nhappy %&gt;% \n  mutate(finrela = forcats::fct_recode(finrela,\n    \"far below     \" = \"far below average\",\n    \"    below\" = \"below average\",\n    \"average\" = \"average\",\n    \"above    \" = \"above average\", \n    \"l\\n   far above\" = \"far above average\")) %&gt;% \n  ggplot() +\n  geom_mosaic(aes(x = product(finrela), fill=health), show.legend = FALSE) +\n  theme_mosaic() +\n  scale_fill_manual(values = c(\"#4575B4\", \"#ABD9E9\", \"#FEE090\", \"#F46D43\"))\n#&gt; Warning: `unite_()` was deprecated in tidyr 1.2.0.\n#&gt; ℹ Please use `unite()` instead.\n#&gt; ℹ The deprecated feature was likely used in the ggmosaic package.\n#&gt;   Please report the issue at &lt;https://github.com/haleyjeppson/ggmosaic&gt;.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/libs/gganimate/working.html",
    "href": "contents/libs/gganimate/working.html",
    "title": "gganimate",
    "section": "",
    "text": "Code\nrenv::activate(here::here())\ncur_dir &lt;- here::here(\"contents/libs/gganimate\")\n\n\n\n1 はじめに\n\nGithub\n\n\n\n2 An Example\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/libs/corrr/working.html",
    "href": "contents/libs/corrr/working.html",
    "title": "corrr",
    "section": "",
    "text": "Code\nrenv::activate(here::here())\ncur_dir &lt;- here::here(\"contents/libs/corr\")\n\n\n\n\nCode\nlibrary(corrr)\nlibrary(tidyverse)\nlibrary(showtext)\nshowtext_auto()\nfont_add_google(\"Noto Sans\")\n\n\n\n1 はじめに\ncorrrは相関係数をデータフレームでハンドリングできるパッケージである。\ncorrrが公式サイトである。\ncorrelateで相関係数を計算して、データフレームとしての相関係数行列を各種APIでハンドリングするのが主な流れである。\nNAが含まれる場合は、correlateの引数にuse = \"pairwise.complete.obs\"を指定する。 デフォルトでは指定されている。\n\n\nCode\ncor_df &lt;- \n  iris |&gt; \n  select(where(is.numeric)) |&gt; \n  correlate() \n#&gt; Correlation computed with\n#&gt; • Method: 'pearson'\n#&gt; • Missing treated using: 'pairwise.complete.obs'\n\n\ncor_df\n#&gt; # A tibble: 4 × 5\n#&gt;   term         Sepal.Length Sepal.Width Petal.Length Petal.Width\n#&gt;   &lt;chr&gt;               &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;\n#&gt; 1 Sepal.Length       NA          -0.118        0.872       0.818\n#&gt; 2 Sepal.Width        -0.118      NA           -0.428      -0.366\n#&gt; 3 Petal.Length        0.872      -0.428       NA           0.963\n#&gt; 4 Petal.Width         0.818      -0.366        0.963      NA\n\n\n\n\nCode\ncor_df |&gt; \n  # 下△成分だけを取り出す\n  shave() |&gt; \n  # ロングフォーマットに変換する\n  stretch()# |&gt; \n#&gt; # A tibble: 16 × 3\n#&gt;    x            y                 r\n#&gt;    &lt;chr&gt;        &lt;chr&gt;         &lt;dbl&gt;\n#&gt;  1 Sepal.Length Sepal.Length NA    \n#&gt;  2 Sepal.Length Sepal.Width  -0.118\n#&gt;  3 Sepal.Length Petal.Length  0.872\n#&gt;  4 Sepal.Length Petal.Width   0.818\n#&gt;  5 Sepal.Width  Sepal.Length NA    \n#&gt;  6 Sepal.Width  Sepal.Width  NA    \n#&gt;  7 Sepal.Width  Petal.Length -0.428\n#&gt;  8 Sepal.Width  Petal.Width  -0.366\n#&gt;  9 Petal.Length Sepal.Length NA    \n#&gt; 10 Petal.Length Sepal.Width  NA    \n#&gt; 11 Petal.Length Petal.Length NA    \n#&gt; 12 Petal.Length Petal.Width   0.963\n#&gt; 13 Petal.Width  Sepal.Length NA    \n#&gt; 14 Petal.Width  Sepal.Width  NA    \n#&gt; 15 Petal.Width  Petal.Length NA    \n#&gt; 16 Petal.Width  Petal.Width  NA\n  # ggplot(aes(x = x, y = y, fill = r)) +\n  # geom_tile() +\n  # geom_text(aes(label = round(r, 2))) +\n  # scale_fill_viridis_c() +\n  # theme_minimal() +\n  # theme(\n  #   axis.text.x = element_text(angle = 45, hjust = 1)\n  # )\n\n\n\n\nCode\ncor_df |&gt; \n  # 特定の変数に着目する\n  focus(Sepal.Length)\n#&gt; # A tibble: 3 × 2\n#&gt;   term         Sepal.Length\n#&gt;   &lt;chr&gt;               &lt;dbl&gt;\n#&gt; 1 Sepal.Width        -0.118\n#&gt; 2 Petal.Length        0.872\n#&gt; 3 Petal.Width         0.818\n\n\n\n\nCode\nx &lt;- \n  mtcars |&gt;\n  correlate() |&gt; \n  # 強い順に並び変える\n  rearrange()\n#&gt; Correlation computed with\n#&gt; • Method: 'pearson'\n#&gt; • Missing treated using: 'pairwise.complete.obs'\nx |&gt; \n  # 綺麗な見た目にして表示\n  fashion()\n#&gt;    term  mpg   vs drat   am gear qsec carb   hp   wt disp  cyl\n#&gt; 1   mpg       .66  .68  .60  .48  .42 -.55 -.78 -.87 -.85 -.85\n#&gt; 2    vs  .66       .44  .17  .21  .74 -.57 -.72 -.55 -.71 -.81\n#&gt; 3  drat  .68  .44       .71  .70  .09 -.09 -.45 -.71 -.71 -.70\n#&gt; 4    am  .60  .17  .71       .79 -.23  .06 -.24 -.69 -.59 -.52\n#&gt; 5  gear  .48  .21  .70  .79      -.21  .27 -.13 -.58 -.56 -.49\n#&gt; 6  qsec  .42  .74  .09 -.23 -.21      -.66 -.71 -.17 -.43 -.59\n#&gt; 7  carb -.55 -.57 -.09  .06  .27 -.66       .75  .43  .39  .53\n#&gt; 8    hp -.78 -.72 -.45 -.24 -.13 -.71  .75       .66  .79  .83\n#&gt; 9    wt -.87 -.55 -.71 -.69 -.58 -.17  .43  .66       .89  .78\n#&gt; 10 disp -.85 -.71 -.71 -.59 -.56 -.43  .39  .79  .89       .90\n#&gt; 11  cyl -.85 -.81 -.70 -.52 -.49 -.59  .53  .83  .78  .90\n\n\n\n\nCode\nx |&gt; \n  shave() |&gt; \n  rplot()\n\n\n\n\n\n\n\n\n\n\n\nCode\ndatasets::airquality %&gt;% \n  correlate() %&gt;% \n  network_plot(min_cor = .2)\n#&gt; Correlation computed with\n#&gt; • Method: 'pearson'\n#&gt; • Missing treated using: 'pairwise.complete.obs'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/libs/GGally/working.html",
    "href": "contents/libs/GGally/working.html",
    "title": "GGally",
    "section": "",
    "text": "Code\nrenv::activate(here::here())\ncur_dir &lt;- here::here(\"contents/libs/GGally\")\nCode\n library(ComplexHeatmap)\nlibrary(ggplot2)\nlibrary(tidyverse)\nlibrary(showtext)\nshowtext_auto()\nfont_add_google(\"Noto Sans\")"
  },
  {
    "objectID": "contents/libs/GGally/working.html#ggparcoord",
    "href": "contents/libs/GGally/working.html#ggparcoord",
    "title": "GGally",
    "section": "2.1 ggparcoord",
    "text": "2.1 ggparcoord\n\n\nCode\nggparcoord(data = iris,\n           columns = 1:4,\n           groupColumn = \"Species\",\n           showPoints = TRUE) +\n           scale_color_brewer(palette = \"Set2\") \n\n\n\n\n\n\n\n\n\n\n\nCode\nggparcoord(data = iris,\n           columns = 1:4,\n           groupColumn = \"Species\",\n           splineFactor = TRUE) +\n           scale_color_brewer(palette = \"Set2\")\n\n\n\n\n\n\n\n\n\nスケールを色々と変更することが可能である。\n\n\nCode\nggparcoord(data = iris,\n           columns = 1:4,\n           groupColumn = \"Species\",\n           scale = \"robust\") +\n           scale_color_brewer(palette = \"Set2\")\n\n\n\n\n\n\n\n\n\n\n\nCode\nggparcoord(data = iris,\n           columns = 1:4,\n           groupColumn = \"Species\",\n           scale = \"uniminmax\") +\n           scale_color_brewer(palette = \"Set2\")\n\n\n\n\n\n\n\n\n\n\n\nCode\nggparcoord(data = iris,\n           columns = 1:4,\n           groupColumn = \"Species\",\n           scale = \"globalminmax\") +\n           scale_color_brewer(palette = \"Set2\")\n\n\n\n\n\n\n\n\n\n\n\nCode\nggparcoord(data = iris,\n           columns = 1:4,\n           groupColumn = \"Species\",\n           scale = \"center\") +\n           scale_color_brewer(palette = \"Set2\")\n\n\n\n\n\n\n\n\n\n\n\nCode\nggparcoord(data = iris,\n           columns = 1:4,\n           groupColumn = \"Species\",\n           scale = \"centerObs\") +\n           scale_color_brewer(palette = \"Set2\")"
  },
  {
    "objectID": "contents/libs/ComplexHeatmap/working.html",
    "href": "contents/libs/ComplexHeatmap/working.html",
    "title": "ComplexHeatmap",
    "section": "",
    "text": "Code\nrenv::activate(here::here())\ncur_dir &lt;- here::here(\"contents/libs/ComplexHeatmap\")\n\n\n\n\nCode\nlibrary(ComplexHeatmap)\nlibrary(showtext)\nlibrary(dplyr)\nlibrary(ggplot2)\nshowtext_auto()\nfont_add_google(\"Noto Sans\")\n\n\n\n1 はじめに\nComplexHeatmapで美しいモザイクプロットを作成することができる。\n\n\n2 Example\n\n\nCode\nif (!requireNamespace(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\nBiocManager::install(\"ComplexHeatmap\")\nlibrary(ComplexHeatmap)\n\n\n\n\nCode\n# サンプルデータの生成\nset.seed(123)\ndata &lt;- matrix(rnorm(100), nrow=10, ncol=10)\n\n# ヒートマップの作成\nHeatmap(data, \n        name = \"my_heatmap\", \n        cluster_rows = TRUE, \n        cluster_columns = TRUE,\n        show_row_dend = TRUE, \n        show_column_dend = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/website/graphic_design_with_ggplot2/ch07_working_with_layouts_and_composition.html",
    "href": "contents/website/graphic_design_with_ggplot2/ch07_working_with_layouts_and_composition.html",
    "title": "Working with Layouts and Composition",
    "section": "",
    "text": "Code\nrenv::activate(here::here())\ncur_dir &lt;- here::here(\"contents/website/graphic_design_with_ggplot2\")\nCode\npackages &lt;- c(\n  \"tidyverse\", \n  \"magick\",\n  \"ggplot2\", \n  \"readr\", \n  \"tibble\", \n  \"tidyr\", \n  \"forcats\", \n  \"stringr\",\n  \"lubridate\", \n  \"here\", \n  \"systemfonts\", \n  \"magick\", \n  \"scales\", \n  \"grid\",\n  \"grDevices\", \n  \"colorspace\", \n  \"viridis\", \n  \"RColorBrewer\", \n  \"rcartocolor\",\n  \"scico\", \n  \"ggsci\", \n  \"ggthemes\", \n  \"nord\", \n  \"MetBrewer\", \n  \"ggrepel\",\n  \"ggforce\",\n  \"ggtext\", \n  \"ggfittext\",\n  \"ggdist\", \n  \"ggbeeswarm\", \n  \"gghalves\", \n  \"patchwork\", \n  \"palmerpenguins\", \n  \"rnaturalearth\", \n  \"sf\", \n  \"rmapshaper\", \n  \"devtools\", \n  \"extrafont\"\n) |&gt; lapply(\\(x) library(x, character.only = TRUE))\nlibrary(cowplot)\nlibrary(colorblindr)\n\n\nlibrary(showtext)\nshowtext_auto()\nfont_add_google(\"Noto Sans\")"
  },
  {
    "objectID": "contents/website/graphic_design_with_ggplot2/ch07_working_with_layouts_and_composition.html#discrete",
    "href": "contents/website/graphic_design_with_ggplot2/ch07_working_with_layouts_and_composition.html#discrete",
    "title": "Working with Layouts and Composition",
    "section": "2.1 discrete",
    "text": "2.1 discrete\n\n\nCode\npal &lt;- c(\"#3c89d9\", \"#1ec99b\", \"#F7B01B\", \"#a26e7c\")\n\nggplot(\n    bikes,\n    aes(x = temp_feel, y = count,\n        color = season)\n  ) +\n  geom_point() +\n  scale_color_manual(values = pal)"
  },
  {
    "objectID": "contents/website/graphic_design_with_ggplot2/ch07_working_with_layouts_and_composition.html#continuous",
    "href": "contents/website/graphic_design_with_ggplot2/ch07_working_with_layouts_and_composition.html#continuous",
    "title": "Working with Layouts and Composition",
    "section": "2.2 Continuous",
    "text": "2.2 Continuous\n\n\nCode\nggplot(\n    bikes,\n    aes(x = temp_feel, y = count,\n        color = humidity)\n  ) +\n  geom_point() +\n  scale_color_viridis_c() + \n  theme(\n      legend.position = \"bottom\", \n      legend.justification = \"right\"\n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(\n    bikes,\n    aes(x = temp_feel, y = count,\n        color = humidity)\n  ) +\n  geom_point() +\n  scale_color_viridis_c(\n      guide = \"colorbar\"\n  ) + \n  theme(\n      legend.position = c(.25, .85), \n      legend.direction = \"horizontal\"\n  )\n\n\n\n\n\n\n\n\n\n次は凡例を離散的に表現しているが、 プロットの色自体は色分けされていないことに注意する。\n\n\nCode\nggplot(\n    bikes,\n    aes(x = temp_feel, y = count,\n        color = humidity)\n  ) +\n  geom_point() +\n  scale_color_viridis_c(\n      guide = \"colorsteps\",\n  ) + \n  theme(\n      legend.position = c(.25, .85), \n      legend.direction = \"horizontal\"\n  )\n\n\n\n\n\n\n\n\n\n次はプロットの色自体も離散的にしている。つまり、viridis_bを使っている。\n\n\nCode\nbikes |&gt; \n    ggplot(\n        aes(x = temp_feel, y = count, color = humidity)\n    ) + \n    geom_point() + \n    scale_color_viridis_b(\n        guide = \"colorsteps\"\n    ) + \n    theme(\n        legend.position = c(.25, .85), \n        legend.direction = \"horizontal\"\n    )\n\n\n\n\n\n\n\n\n\n細かく凡例を調整したいときには次のようにguide_colorstepsを使う。\n\n\nCode\nggplot(\n    bikes,\n    aes(x = temp_feel, y = count,\n        color = humidity)\n  ) +\n  geom_point() +\n  scale_color_viridis_b(\n    breaks = seq(30, 90, 10),\n    limits = c(30, 100),\n    guide = guide_colorsteps(\n      title.position = \"top\",\n      title.hjust = .5,\n      show.limits = TRUE,\n      frame.colour = \"black\",\n      frame.linewidth = 3,\n      barwidth = unit(8, \"lines\"), \n      ticks.linewidth = 1\n    )\n  ) +\n  theme(\n    legend.position = c(.25, .85),\n    legend.direction = \"horizontal\"\n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(\n    bikes,\n    aes(x = temp_feel, y = count,\n        color = humidity)\n  ) +\n  geom_point() +\n  scale_color_viridis_c(\n    breaks = 3:10*10,\n    limits = c(30, 100),\n    guide = guide_colorbar(\n      title.position = \"top\",\n      title.hjust = .5,\n      ticks = FALSE,\n      barwidth = unit(20, \"lines\"),\n      barheight = unit(.6, \"lines\")\n    )\n  ) +\n  theme(\n    legend.position = \"top\"\n  )"
  },
  {
    "objectID": "contents/website/graphic_design_with_ggplot2/ch07_working_with_layouts_and_composition.html#key-glyphs",
    "href": "contents/website/graphic_design_with_ggplot2/ch07_working_with_layouts_and_composition.html#key-glyphs",
    "title": "Working with Layouts and Composition",
    "section": "2.3 Key Glyphs",
    "text": "2.3 Key Glyphs\n\n\nCode\nggplot(\n    bikes,\n    aes(x = lubridate::week(date),\n        y = count,\n        color = day_night)\n  ) +\n  stat_summary(\n    geom = \"line\",\n    fun = sum,\n    size = 1\n  ) +\n  scale_color_manual(\n    values = c(\"#28A87D\", \"#663399\"),\n    name = NULL\n  ) +\n  theme(\n    legend.text = element_text(size = 16)\n  )\n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(\n    bikes,\n    aes(x = lubridate::week(date),\n        y = count,\n        color = day_night)\n  ) +\n  stat_summary(\n    geom = \"line\",\n    fun = sum,\n    key_glyph = \"timeseries\",\n    size = 1\n  ) +\n  scale_color_manual(\n    values = c(\"#28A87D\", \"#663399\"),\n    name = NULL\n  ) +\n  theme(\n    legend.text = element_text(size = 16)\n  )"
  },
  {
    "objectID": "contents/website/graphic_design_with_ggplot2/ch07_working_with_layouts_and_composition.html#patchwork",
    "href": "contents/website/graphic_design_with_ggplot2/ch07_working_with_layouts_and_composition.html#patchwork",
    "title": "Working with Layouts and Composition",
    "section": "3.1 patchwork",
    "text": "3.1 patchwork\n\n\nCode\ntheme_std &lt;- theme_set(theme_minimal(base_size = 18, base_family = \"Noto Sans\"))\ntheme_update(\n  panel.grid = element_blank(),\n  axis.text = element_text(color = \"grey50\", size = 12),\n  axis.title = element_text(color = \"grey40\", face = \"bold\"),\n  axis.title.x = element_text(margin = margin(t = 12)),\n  axis.title.y = element_text(margin = margin(r = 12)),\n  axis.line = element_line(color = \"grey80\", size = .4),\n  legend.text = element_text(color = \"grey50\", size = 12),\n  plot.tag = element_text(size = 40, margin = margin(b = 15)),\n  plot.background = element_rect(fill = \"white\", color = \"white\")\n)\n#&gt; Warning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\n#&gt; ℹ Please use the `linewidth` argument instead.\n\nbikes_sorted &lt;-\n  bikes %&gt;%\n  filter(!is.na(weather_type)) %&gt;%\n  group_by(weather_type) %&gt;%\n  mutate(sum = sum(count)) %&gt;%\n  ungroup() %&gt;%\n  mutate(\n    weather_type = forcats::fct_reorder(\n      str_to_title(str_wrap(weather_type, 5)), sum\n    )\n  )\n\np1 &lt;- ggplot(\n    bikes_sorted,\n    aes(x = weather_type, y = count, color = weather_type)\n  ) +\n  geom_hline(yintercept = 0, color = \"grey80\", size = .4) +\n  stat_summary(\n    geom = \"point\", fun = \"sum\", size = 12\n  ) +\n  stat_summary(\n    geom = \"linerange\", ymin = 0, fun.max = function(y) sum(y),\n    size = 2, show.legend = FALSE\n  ) +\n  coord_flip(ylim = c(0, NA), clip = \"off\") +\n  scale_y_continuous(\n    expand = c(0, 0), limits = c(0, 8500000),\n    labels = scales::comma_format(scale = .0001, suffix = \"K\")\n  ) +\n  scale_color_viridis_d(\n    option = \"magma\", direction = -1, begin = .1, end = .9, name = NULL,\n    guide = guide_legend(override.aes = list(size = 7))\n  ) +\n  labs(\n    x = NULL, y = \"Sum of reported bike shares\", tag = \"P1\",\n  ) +\n  theme(\n    axis.line.y = element_blank(),\n    axis.text.y = element_text(color = \"grey50\", face = \"bold\",\n                               margin = margin(r = 15), lineheight = .9)\n  )\n\n\np2 &lt;- bikes_sorted %&gt;%\n  filter(season == \"winter\", is_weekend == TRUE, day_night == \"night\") %&gt;%\n  group_by(weather_type, .drop = FALSE) %&gt;%\n  mutate(id = row_number()) %&gt;%\n  ggplot(\n      aes(x = weather_type, y = id, color = weather_type)\n    ) +\n    geom_point(size = 4.5) +\n    scale_color_viridis_d(\n      option = \"magma\", direction = -1, begin = .1, end = .9, name = NULL,\n      guide = guide_legend(override.aes = list(size = 7))\n    ) +\n    labs(\n      x = NULL, y = \"Reported bike shares on\\nweekend winter nights\", tag = \"P2\",\n    ) +\n    coord_cartesian(ylim = c(.5, NA), clip = \"off\")\n\n\nmy_colors &lt;- c(\"#cc0000\", \"#000080\")\n\np3 &lt;- bikes %&gt;%\n  group_by(week = lubridate::week(date), day_night, year) %&gt;%\n  summarize(count = sum(count)) %&gt;%\n  group_by(week, day_night) %&gt;%\n  mutate(avg = mean(count)) %&gt;%\n  ggplot(aes(x = week, y = count, group = interaction(day_night, year))) +\n    geom_line(color = \"grey65\", size = 1) +\n    geom_line(aes(y = avg, color = day_night), stat = \"unique\", size = 1.7) +\n    annotate(\n      geom = \"text\", label = c(\"Day\", \"Night\"), color = my_colors,\n      x = c(5, 18), y = c(125000, 29000), size = 8, fontface = \"bold\"\n    ) +\n    scale_x_continuous(breaks = c(1, 1:10*5)) +\n    scale_y_continuous(labels = scales::comma_format()) +\n    scale_color_manual(values = my_colors, guide = \"none\") +\n    labs(\n      x = \"Week of the Year\", y = \"Reported bike shares\\n(cumulative # per week)\", tag = \"P3\",\n    )\n#&gt; `summarise()` has grouped output by 'week', 'day_night'. You can override using\n#&gt; the `.groups` argument.\n\n\n# install.packages(\"patchwork\")\nlibrary(patchwork)\n(p1 + p2) / p3\n\n\n\n\n\n\n\n\n\n\n\nCode\n(p1 + p2) / p3 + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\n\n\n\nCode\n((p1 + p2) / p3 & theme(legend.justification = \"top\")) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\n\n\n\nCode\n(p1 + p2) / p3 & theme(legend.position = \"none\", plot.background = element_rect(color = \"black\", size = 3))\n#&gt; Warning: The `size` argument of `element_rect()` is deprecated as of ggplot2 3.4.0.\n#&gt; ℹ Please use the `linewidth` argument instead.\n\n\n\n\n\n\n\n\n\n\n\nCode\n\n((p1 + p2) / p3 & theme(legend.position = \"none\")) +\n  plot_layout(heights = c(.2, .1), widths = c(2, 1))\n\n\n\n\n\n\n\n\n\n\n\nCode\npicasso &lt;- \"\nAAAAAA#BBBB\nCCCCCCCCC##\nCCCCCCCCC##\"\n(p1 + p2 + p3 & theme(legend.position = \"none\")) + plot_layout(design = picasso)\n\n\n\n\n\n\n\n\n\n\n\nCode\ntheme_std &lt;- theme_set(theme_minimal(base_size = 18, base_family = \"Noto Sans\"))\ntheme_update(\n  panel.grid = element_blank(),\n  axis.text = element_text(color = \"grey50\", size = 12),\n  axis.title = element_text(color = \"grey40\", face = \"bold\"),\n  axis.title.x = element_text(margin = margin(t = 12)),\n  axis.title.y = element_text(margin = margin(r = 12)),\n  axis.line = element_line(color = \"grey80\", size = .4),\n  legend.text = element_text(color = \"grey50\", size = 12),\n  plot.tag = element_text(size = 40, margin = margin(b = 15)),\n  plot.background = element_rect(fill = \"white\", color = \"white\")\n)\n\nbikes_sorted &lt;-\n  bikes %&gt;%\n  filter(!is.na(weather_type)) %&gt;%\n  group_by(weather_type) %&gt;%\n  mutate(sum = sum(count)) %&gt;%\n  ungroup() %&gt;%\n  mutate(\n    weather_type = forcats::fct_reorder(\n      str_to_title(str_wrap(weather_type, 5)), sum\n    )\n  )\n\np1 &lt;- ggplot(\n    bikes_sorted,\n    aes(x = weather_type, y = count, color = weather_type)\n  ) +\n  geom_hline(yintercept = 0, color = \"grey80\", size = .4) +\n  stat_summary(\n    geom = \"point\", fun = \"sum\", size = 12\n  ) +\n  stat_summary(\n    geom = \"linerange\", ymin = 0, fun.max = function(y) sum(y),\n    size = 2, show.legend = FALSE\n  ) +\n  coord_flip(ylim = c(0, NA), clip = \"off\") +\n  scale_y_continuous(\n    expand = c(0, 0), limits = c(0, 8500000),\n    labels = scales::comma_format(scale = .0001, suffix = \"K\")\n  ) +\n  scale_color_viridis_d(\n    option = \"magma\", direction = -1, begin = .1, end = .9, name = NULL,\n    guide = guide_legend(override.aes = list(size = 7))\n  ) +\n  labs(\n    x = NULL, y = \"Sum of reported bike shares\", tag = \"P1\",\n  ) +\n  theme(\n    axis.line.y = element_blank(),\n    axis.text.y = element_text(color = \"grey50\", face = \"bold\",\n                               margin = margin(r = 15), lineheight = .9)\n  )\n\n\np2 &lt;- bikes_sorted %&gt;%\n  filter(season == \"winter\", is_weekend == TRUE, day_night == \"night\") %&gt;%\n  group_by(weather_type, .drop = FALSE) %&gt;%\n  mutate(id = row_number()) %&gt;%\n  ggplot(\n      aes(x = weather_type, y = id, color = weather_type)\n    ) +\n    geom_point(size = 4.5) +\n    scale_color_viridis_d(\n      option = \"magma\", direction = -1, begin = .1, end = .9, name = NULL,\n      guide = guide_legend(override.aes = list(size = 7))\n    ) +\n    labs(\n      x = NULL, y = \"Reported bike shares on\\nweekend winter nights\", tag = \"P2\",\n    ) +\n    coord_cartesian(ylim = c(.5, NA), clip = \"off\")\n\n\nmy_colors &lt;- c(\"#cc0000\", \"#000080\")\n\np3 &lt;- bikes %&gt;%\n  group_by(week = lubridate::week(date), day_night, year) %&gt;%\n  summarize(count = sum(count)) %&gt;%\n  group_by(week, day_night) %&gt;%\n  mutate(avg = mean(count)) %&gt;%\n  ggplot(aes(x = week, y = count, group = interaction(day_night, year))) +\n    geom_line(color = \"grey65\", size = 1) +\n    geom_line(aes(y = avg, color = day_night), stat = \"unique\", size = 1.7) +\n    annotate(\n      geom = \"text\", label = c(\"Day\", \"Night\"), color = my_colors,\n      x = c(5, 18), y = c(125000, 29000), size = 8, fontface = \"bold\"\n    ) +\n    scale_x_continuous(breaks = c(1, 1:10*5)) +\n    scale_y_continuous(labels = scales::comma_format()) +\n    scale_color_manual(values = my_colors, guide = \"none\") +\n    labs(\n      x = \"Week of the Year\", y = \"Reported bike shares\\n(cumulative # per week)\", tag = \"P3\",\n    )\n#&gt; `summarise()` has grouped output by 'week', 'day_night'. You can override using\n#&gt; the `.groups` argument.\n\n\n# install.packages(\"patchwork\")\nlibrary(patchwork)\n(p1 + p2) / p3\n\n\n\n\n\n\n\n\n\n\n\nCode\n(p1 + p2) / p3 + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\n\n\n\nCode\n((p1 + p2) / p3 & theme(legend.justification = \"top\")) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\n\n\n\nCode\n(p1 + p2) / p3 & theme(legend.position = \"none\", plot.background = element_rect(color = \"black\", size = 3))\n\n\n\n\n\n\n\n\n\n\n\nCode\n\n((p1 + p2) / p3 & theme(legend.position = \"none\")) +\n  plot_layout(heights = c(.2, .1), widths = c(2, 1))\n\n\n\n\n\n\n\n\n\n\n\nCode\npicasso &lt;- \"\nAAAAAA#BBBB\nCCCCCCCCC##\nCCCCCCCCC##\"\n(p1 + p2 + p3 & theme(legend.position = \"none\")) + plot_layout(design = picasso)\n\n\n\n\n\n\n\n\n\n\n\nCode\n\ntext &lt;- tibble(\n  x = 0, y = 0, label = \"Lorem ipsum dolor sit amet, **consectetur adipiscing elit**, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation &lt;b style='color:#000080;'&gt;ullamco laboris nisi&lt;/b&gt; ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat &lt;b style='color:#cc0000;'&gt;cupidatat non proident&lt;/b&gt;, sunt in culpa qui officia deserunt mollit anim id est laborum.\"\n)\n\npt &lt;- ggplot(text, aes(x = x, y = y)) +\n  ggtext::geom_textbox(\n    aes(label = label),\n    box.color = NA, width = unit(23, \"lines\"),\n    color = \"grey40\", size = 6.5, lineheight = 1.4\n  ) +\n  coord_cartesian(expand = FALSE, clip = \"off\") +\n  theme_void()\n\npt\n\n\n\n\n\n\n\n\n\n\n\nCode\n(p1 + pt) / p3\n\n\n\n\n\n\n\n\n\n\n\nCode\np1 + inset_element(p2, l = .6, b = .1, r = 1, t = .6)\n\n\n\n\n\n\n\n\n\n\n\nCode\n(p1 + inset_element(p2, l = .6, b = .1, r = 1, t = .6) + pt) / p3"
  },
  {
    "objectID": "contents/website/graphic_design_with_ggplot2/ch04_working_with_labels_and_annotations.html",
    "href": "contents/website/graphic_design_with_ggplot2/ch04_working_with_labels_and_annotations.html",
    "title": "Working with Labels and Annotations",
    "section": "",
    "text": "Code\nrenv::activate(here::here())\ncur_dir &lt;- here::here(\"contents/website/graphic_design_with_ggplot2\")\n\n\n\n\nCode\npackages &lt;- c(\n  \"tidyverse\", \n  \"magick\",\n  \"ggplot2\", \n  \"readr\", \n  \"tibble\", \n  \"tidyr\", \n  \"forcats\", \n  \"stringr\",\n  \"lubridate\", \n  \"here\", \n  \"systemfonts\", \n  \"magick\", \n  \"scales\", \n  \"grid\",\n  \"grDevices\", \n  \"colorspace\", \n  \"viridis\", \n  \"RColorBrewer\", \n  \"rcartocolor\",\n  \"scico\", \n  \"ggsci\", \n  \"ggthemes\", \n  \"nord\", \n  \"MetBrewer\", \n  \"ggrepel\",\n  \"ggforce\",\n  \"ggtext\", \n  \"ggdist\", \n  \"ggbeeswarm\", \n  \"gghalves\", \n  \"patchwork\", \n  \"palmerpenguins\", \n  \"rnaturalearth\", \n  \"sf\", \n  \"rmapshaper\", \n  \"devtools\", \n  \"extrafont\"\n) |&gt; lapply(\\(x) library(x, character.only = TRUE))\nlibrary(cowplot)\nlibrary(colorblindr)\n\n\nlibrary(showtext)\nshowtext_auto()\nfont_add_google(\"Noto Sans\")\n\n\n\n1 Setup\n\n\nCode\nbikes &lt;- read_csv(\n    here(cur_dir, \"ggplot2-course-data/london-bikes-custom.csv\"), \n    col_types = \"Dcfffilllddddc\"\n)\n\nbikes$season &lt;- forcats::fct_inorder(bikes$season)\n\ntheme_set(\n    theme_light(\n        base_size = 14, \n        base_family = \"Noto Sans\"\n    )\n)\n\nglimpse(bikes)\n#&gt; Rows: 1,454\n#&gt; Columns: 14\n#&gt; $ date         &lt;date&gt; 2015-01-04, 2015-01-04, 2015-01-05, 2015-01-05, 2015-01-…\n#&gt; $ day_night    &lt;chr&gt; \"day\", \"night\", \"day\", \"night\", \"day\", \"night\", \"day\", \"n…\n#&gt; $ year         &lt;fct&gt; 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 201…\n#&gt; $ month        &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n#&gt; $ season       &lt;fct&gt; winter, winter, winter, winter, winter, winter, winter, w…\n#&gt; $ count        &lt;int&gt; 6830, 2404, 14763, 5609, 14501, 6112, 16358, 4706, 9971, …\n#&gt; $ is_workday   &lt;lgl&gt; FALSE, FALSE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, T…\n#&gt; $ is_weekend   &lt;lgl&gt; TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL…\n#&gt; $ is_holiday   &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, F…\n#&gt; $ temp         &lt;dbl&gt; 2.166667, 2.791667, 8.958333, 7.125000, 9.000000, 6.70833…\n#&gt; $ temp_feel    &lt;dbl&gt; -0.750000, 2.041667, 7.708333, 5.708333, 6.458333, 4.2083…\n#&gt; $ humidity     &lt;dbl&gt; 95.16667, 93.37500, 81.08333, 79.54167, 80.20833, 77.5833…\n#&gt; $ wind_speed   &lt;dbl&gt; 10.416667, 4.583333, 8.666667, 9.041667, 19.208333, 12.79…\n#&gt; $ weather_type &lt;chr&gt; \"broken clouds\", \"clear\", \"broken clouds\", \"cloudy\", \"bro…\n\n\n\n\n2 Labels + theme\n\n\nCode\n\ng &lt;- ggplot(\n    bikes, \n    aes(x = temp_feel, y = count, color = season)\n) +\n    geom_point(\n        alpha = .5\n    ) + \n    labs(\n        x = \"Feels Like temperature (℉)\", \n        y = \"Reported bike shares\", \n        title = \"TfL bike shareing trends\", \n        subtitle = \"Reporeted bike rents versus Feels Like temperature in London\", \n        caption= \"Data: TfL\", \n        color = \"Season: \", \n        tag = \"1.\"\n    )\n\nplot(g)\n\n\n\n\n\n\n\n\n\n上記のグラフをカスタマイズする.\n\n\nCode\ng + \n    theme(\n        plot.title = element_text(face = \"bold\"), \n        plot.title.position = \"plot\", \n        axis.text = element_text(\n            color = \"#28a87d\", \n            family = \"Noto Sans\", \n            face = \"italic\", \n            hjust = 1, \n            vjust = 0, \n            angle = 45, \n            lineheight = 1.3, \n            margin = margin(10, 0, 20, 0), \n            debug = TRUE\n        ), \n        axis.text.x = element_text(\n            margin = margin(0, 12, -8, 0)\n        ), \n        plot.tag = element_text(\n            margin = margin(0, 12, -8, 0), \n            debug = TRUE\n        )\n    )\n\n\n\n\n\n\n\n\n\n\n\n3 Labels + scale\n\n\nCode\ng &lt;- \n    g + \n    labs(\n        tag = NULL, \n        title = NULL, \n        subtitle = NULL\n    )\n\ng + \n    scale_y_continuous(\n        breaks = 0:4 * 15000, \n        labels = scales::comma_format(\n            suffix = \"\\n bikes shared\"\n        ), \n        name = NULL\n    ) + \n    theme(\n        axis.text.y = element_text(\n            hjust = .5\n        )\n    )\n\n\n\n\n\n\n\n\n\n\n\nCode\ng +\n  scale_y_continuous(\n    breaks = 0:4*15000,\n    labels = function(y) y / 1000,\n    name = \"Reported bike shares in thousands\",\n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(\n    bikes,\n    aes(x = season, y = count)\n  ) +\n  geom_boxplot() +\n  scale_x_discrete(\n    name = NULL,\n    labels = stringr::str_to_title\n  )\n\n\n\n\n\n\n\n\n\n\n\n4 Labels + element_markdown\nggtextパッケージを使うことで対応することができる.\n\n\nCode\n# install.packages(\"ggtext\")\n\ng +\n  ggtitle(\"**TfL bike sharing trends by _season_**\") +\n  theme(\n    plot.title = ggtext::element_markdown()\n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\n# install.packages(\"ggtext\")\n\ng +\n  ggtitle(\"&lt;b style='font-size:25pt'&gt;TfL&lt;/b&gt; bike sharing trends by &lt;i style='color:#28a87d;'&gt;season&lt;/i&gt;\") +\n  theme(\n    plot.title = ggtext::element_markdown()\n  )\n\n\n\n\n\n\n\n\n\n\n\n5 Labels + facet\n\n\nCode\ncodes &lt;- c(\n  `TRUE` = \"Workday\",\n  `FALSE` = \"Weekend or Holiday\"\n)\n\ng +\n  facet_grid(\n    day_night ~ is_workday,\n    scales = \"free\",\n    space = \"free\",\n    labeller = labeller(\n      day_night = stringr::str_to_title,\n      is_workday = codes\n    )\n  )\n\n\n\n\n\n\n\n\n\n\n\n6 Handling Long Labels\n\n\nCode\nggplot(\n    bikes,\n    aes(x = stringr::str_wrap(weather_type, 6),\n        y = count)\n  ) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\nタイトルを調整することも可能です.\n\n\nCode\ng +\n  ggtitle(\"TfL bike sharing trends in 2015 and 2016 by season for day and night periods\") +\n  theme(\n    plot.title =\n      ggtext::element_textbox_simple(\n          margin = margin(t = 12, b = 12), \n          lineheight = .9, \n          fill = \"grey90\", \n          padding = margin(rep(12, 4)), \n          r = unit(9, \"pt\"),\n          box.color = \"grey40\",  \n          halign = .5, \n          size = 20),\n    plot.title.position = \"plot\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n7 Annotations with annotate\n\n\nCode\nggplot(bikes, aes(humidity, temp)) +\n  geom_point(size = 2, color = \"grey\") +\n  annotate(\n    geom = \"text\",\n    x = c(90, 50),\n    y = c(27.5, 3.5),\n    label = c(\"Text A\", \"Text B\"),\n    color = c(\"black\", \"firebrick\"),\n    size = c(5, 10),\n    fontface = c(\"plain\", \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\n\nggplot(bikes, aes(humidity, temp)) +\n  annotate(\n    geom = \"rect\",\n    xmin = -Inf,\n    xmax = 60,\n    ymin = 20,\n    ymax = Inf,\n    fill = \"#663399\"\n  ) +\n  geom_point(size = 2, color = \"grey\")\n\n\n\n\n\n\n\n\n\n\n\nCode\n\nggplot(bikes, aes(humidity, temp)) +\n  geom_point(size = 2, color = \"grey\") +\n  annotate(\n    geom = \"text\",\n    x = 90,\n    y = 27.5,\n    label = \"Some\\nadditional\\ntext\",\n    size = 6,\n    lineheight = .9\n  ) +\n  annotate(\n    geom = \"curve\",\n    x = 90, xend = 82,\n    y = 25, yend = 18.5, \n    curvature = -.5, \n    lwd = 5, \n    arrow = arrow(\n        length = unit(20, \"pt\"), \n        type = \"closed\", \n        ends = \"both\", \n        \n    )\n  )\n\n\n\n\n\n\n\n\n\n\n\n8 Annotations with geom\n\n\nCode\nggplot(\n    filter(bikes, temp &gt;= 27),\n    aes(x = humidity, y = temp)\n  ) +\n  geom_point(\n    data = bikes,\n    color = \"grey65\", alpha = .3\n  ) +\n  geom_point(size = 2.5) +\n  geom_text(\n    aes(label = season),\n    nudge_x = .3,\n    hjust = 0\n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\n\nggplot(\n    filter(bikes, temp &gt;= 27),\n    aes(x = humidity, y = temp,\n        color = season == \"summer\")\n  ) +\n  geom_point(\n    data = bikes,\n    color = \"grey65\", alpha = .3\n  ) +\n  geom_point(size = 2.5) +\n  ggrepel::geom_text_repel(\n    aes(label = str_to_title(season))\n  ) +\n  scale_color_manual(\n    values = c(\"firebrick\", \"black\"),\n    guide = \"none\"\n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(\n    filter(bikes, temp &gt;= 27),\n    aes(\n        x = humidity, \n        y = temp,\n        color = season == \"summer\")\n  ) +\n  geom_point(\n    data  = bikes,\n    color = \"grey65\", \n    alpha = .3\n  ) +\n  geom_point(size = 2.5) +\n  ggrepel::geom_text_repel(\n    aes(label = str_to_title(season)),\n    ## force to the right\n    xlim = c(NA, 35), \n    hjust = 1\n  ) +\n  scale_color_manual(\n    values = c(\"firebrick\", \"black\"),\n    guide  = \"none\"\n  ) +\n  xlim(25, NA)\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(\n    filter(bikes, temp &gt; 20 & season != \"summer\"),\n    aes(x = humidity, y = temp,\n        color = season)\n  ) +\n  geom_point(\n    data = bikes,\n    color = \"grey65\", alpha = .3\n  ) +\n  geom_point() +\n  ggforce::geom_mark_rect(\n    aes(label = str_to_title(season))\n  ) +\n  scale_color_brewer(\n    palette = \"Dark2\",\n    guide = \"none\"\n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(\n    filter(bikes, temp &gt; 20 & season != \"summer\"),\n    aes(x = humidity, y = temp,\n        color = season)\n  ) +\n  geom_point(\n    data = bikes,\n    color = \"grey65\", alpha = .3\n  ) +\n  geom_point() +\n  ggforce::geom_mark_rect(\n    aes(label = str_to_title(season)),\n    expand = unit(5, \"pt\"),\n    radius = unit(0, \"pt\"),\n    con.cap = unit(0, \"pt\"),\n    label.buffer = unit(15, \"pt\"),\n    con.type = \"straight\",\n    label.fill = \"transparent\"\n  ) +\n  scale_color_brewer(\n    palette = \"Dark2\",\n    guide = \"none\"\n  ) +\n  ylim(NA, 35)\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(\n    bikes,\n    aes(x = humidity, y = temp,\n        color = season == \"summer\")\n  ) +\n  geom_point(alpha = .4) +\n  ggforce::geom_mark_hull(\n    aes(label = str_to_title(season),\n        filter = season == \"summer\",\n        description = \"June to August\"),\n    expand = unit(10, \"pt\")\n  ) +\n  scale_color_manual(\n    values = c(\"grey65\", \"firebrick\"),\n    guide = \"none\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n9 Adding Images\n\n\nCode\nurl &lt;- \"https://d33wubrfki0l68.cloudfront.net/dbb07b06a7b3fe056db386fef0b158cc2fd33cb9/8b491/assets/img/2022conf/logo-rstudio-conf.png\"\nimg &lt;- magick::image_read(url)\nimg &lt;- magick::image_negate(img)\n\nimg\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(bikes, aes(date, temp_feel)) +\n  annotation_custom(\n    grid::rasterGrob(\n      image = img,\n      x = .47,\n      y = 1.15,\n      width = .9\n    )\n  ) +\n  geom_point(color = \"#71a5d4\") +\n  coord_cartesian(clip = \"off\") +\n  theme(\n    plot.margin = margin(90, 10, 10, 10)\n  )\n\n\n\n\n\n\n\n\n\n\n\n10 Exercise 1\nggtextを調べろ\n\n\n11 Exercise 2\n\n\nCode\n\ng &lt;- \n    palmerpenguins::penguins |&gt; \n    filter(complete.cases(pick(everything()))) |&gt; \n    # mutate(body_mass_kg_fct = body_mass_g |&gt; \n    #            set_units(\"g\") |&gt; \n    #            set_units(\"kg\") |&gt; \n    #            round(0) |&gt; \n    #            as.character() |&gt; \n    #            fct_inseq(ordered = TRUE)) |&gt; \n    ggplot() + \n    geom_point(\n        aes(\n            x = bill_length_mm, \n            y = bill_depth_mm, \n            color = species, \n            size = body_mass_g / 1000\n        ), \n        alpha = .1\n    ) + \n    labs(\n        title = \"Bill dimensions fo brush-tailed penguins Pygoscelis spec\", \n        x = \"Bill length(&lt;i&gt;mm&lt;/i&gt;)\", \n        y = \"Bill depth(&lt;i&gt;mm&lt;/i&gt;)\", \n        caption = \"Horst AM, Hill AP, Gorman KB(2020). palmerpenguins R package version 0.1.0\", \n        size = \"Body mass\"\n    ) + \n    scale_y_continuous(\n        breaks = seq(12.5, 22.5, 2.5), \n        labels = \\(x) format(x, digits = 3), \n        limits = c(12.5, 22.5), \n        expand = expansion(0, 0),\n    ) + \n    scale_x_continuous(\n        breaks = seq(30, 60, 5), \n        limits = c(30, 60), \n        expand = expansion(0, 0),\n    ) +\n    scale_color_manual(\n        values =  c(\"Adelie\" = \"red\", \"Chinstrap\" = \"blue\", \"Gentoo\" = \"green\"), \n        guide = \"none\"\n    ) + \n    scale_size_continuous(\n        breaks = 3:6,\n        labels = \\(x) paste(x, \"kg\")\n    ) + \n    theme(\n        panel.grid.minor = element_blank(), \n        plot.title.position = \"plot\", \n        plot.title = element_text(size = rel(1.3), margin = margin(b = 1, unit = \"line\")), \n        plot.caption = element_text(hjust = 1, color = \"grey80\"), \n        plot.caption.position = \"plot\", \n        axis.title.y = element_markdown(\n            size = rel(1.1), margin = margin(10, 10, 10, 10, \"pt\")), \n        axis.title.x = element_markdown(\n            size = rel(1.1), margin = margin(10, 10, 10, 10, \"pt\")),\n        axis.ticks = element_blank()\n    ) + \n    guides(\n        size = guide_legend(\n            override.aes = list(color = \"grey80\")\n        )\n    )\n\n\ng\n\n\n\n\n\n\n\n\n\n上記に、テキストボックスを追加する。と思ったけどどうすればいいのかがよくわからない・・・・\n\n\nCode\ncodes &lt;- c(\n    \"Adelie\" = \"&lt;span style='font-size:20px'&gt;&lt;b&gt;P.adelie&lt;/b&gt;&lt;/span&gt;&lt;br&gt;(Adelie penguin)\", \n    \"Chinstrap\" = \"&lt;span style='font-size:20px'&gt;&lt;b&gt;P.antarctica&lt;/b&gt;&lt;/span&gt;&lt;br&gt;(Chinstrap pengui)\", \n    \"Gentoo\" = \"&lt;span style='font-size:20px'&gt;&lt;b&gt;P.papua&lt;/b&gt;&lt;/span&gt;&lt;br&gt;(Gentoo pengui)\"\n)\n\nd &lt;- \n    palmerpenguins::penguins |&gt; \n    filter(complete.cases(pick(everything()))) |&gt; \n    group_by(species) |&gt; \n    summarise(across(c(bill_length_mm, bill_depth_mm), mean)) |&gt; \n    ungroup() |&gt; \n    mutate(label = codes[species]) \n\ng + \n    geom_richtext(\n        data = d, \n        aes(x = bill_length_mm, y = bill_depth_mm, label = label), \n        fill = \"white\", \n        color = \"transparent\", \n        alpha = .1, \n        label.padding = unit(.7, units = \"lines\"), \n        label.r = unit(10, \"pt\"), \n    ) +\n    geom_richtext(\n        data = d, \n        aes(x = bill_length_mm, y = bill_depth_mm, label = label), \n        fill = \"transparent\", \n        color = c(\"red\", \"blue\", \"green\"),\n        label.padding = unit(.7, units = \"lines\"), \n        label.r = unit(10, \"pt\"), \n    )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/website/graphic_design_with_ggplot2/ch02_concepts_of_the_ggplot2_part2.html",
    "href": "contents/website/graphic_design_with_ggplot2/ch02_concepts_of_the_ggplot2_part2.html",
    "title": "Concepts of the ggplot2 Packages pt 2",
    "section": "",
    "text": "Code\nrenv::activate(here::here())\ncur_dir &lt;- here::here(\"contents/website/graphic_design_with_ggplot2\")\n\n\n\n\nCode\npackages &lt;- c(\n  \"tidyverse\", \n  \"ggplot2\", \"readr\", \"tibble\", \"tidyr\", \"forcats\", \n  \"stringr\",\n  \"lubridate\", \"here\", \"systemfonts\", \"magick\", \n  \"scales\", \"grid\",\n  \"grDevices\", \"colorspace\", \"viridis\", \n  \"RColorBrewer\", \"rcartocolor\",\n  \"scico\", \"ggsci\", \"ggthemes\", \"nord\", \n  \"MetBrewer\", \"ggrepel\",\n  \"ggforce\", \"ggtext\", \"ggdist\", \"ggbeeswarm\", \n  \"gghalves\", \"patchwork\", \n  \"palmerpenguins\", \"rnaturalearth\", \"sf\", \"rmapshaper\", \"devtools\", \n  \"extrafont\"\n) |&gt; lapply(\\(x) library(x, character.only = TRUE))\nlibrary(cowplot)\nlibrary(colorblindr)\n\n\nlibrary(showtext)\nshowtext_auto()\nfont_add_google(\"Noto Sans\")\n\n\n\n1 Setup\n\n\nCode\nlibrary(tidyverse)\n\nbikes &lt;- readr::read_csv(\n  here::here(cur_dir, \"ggplot2-course-data\", \"london-bikes-custom.csv\"),\n  col_types = \"Dcfffilllddddc\"\n)\n\nbikes$season &lt;- forcats::fct_inorder(bikes$season)\n\ntheme_set(theme_light(base_size = 14, base_family = \"Noto Sans\"))\n\ntheme_update(\n  panel.grid.minor = element_blank(),\n  plot.title = element_text(face = \"bold\"),\n  legend.position = \"top\",\n  plot.title.position = \"plot\"\n)\n\ninvisible(Sys.setlocale(\"LC_TIME\", \"C\"))\n\n\n\n\nCode\ng &lt;-\n  ggplot(\n    bikes,\n    aes(x = temp_feel, y = count,\n        color = season,\n        group = day_night)\n  ) +\n  geom_point(\n    alpha = .5\n  ) +\n  geom_smooth(\n    method = \"lm\",\n    color = \"black\"\n  )\n\n\n\n\n2 Facets\n\n\nCode\ng +\n  facet_wrap(\n    ~ is_workday + day_night\n  )\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nCode\ng +\n  facet_wrap(\n    ~ day_night,\n    ncol = 1,\n    strip.position = \"bottom\"\n  )\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nCode\ng +\n  facet_grid(\n    day_night ~ is_workday,\n    scales = \"free\",\n    switch = \"y\"\n  ) + \n  scale_y_continuous(position = \"right\")\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nCode\ng +\n  facet_grid(\n    rows = vars(day_night),\n    cols = vars(is_workday)\n  )\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nCode\ng +\n  facet_grid(\n    day_night ~ is_workday, \n    scales = c(\"free_y\"), \n    space = c(\"free_y\")\n  )\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(\n    diamonds,\n    aes(x = carat, y = price)\n  ) +\n  geom_point(\n    alpha = .3,\n    color = \"white\"\n  ) +\n  geom_smooth(\n    method = \"lm\",\n    se = FALSE,\n    color = \"dodgerblue\"\n  ) +\n  facet_grid(\n    cut ~ clarity,\n    space = \"free_x\",\n    scales = \"free_x\"\n  ) + \n  theme_dark()\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n3 Scales\n\n\nCode\nggplot(\n    bikes,\n    aes(x = date, y = count,\n        color = season)\n  ) +\n  geom_point() +\n  scale_x_date(\n        name = NULL,\n        date_breaks = \"6 months\",\n        date_labels = \"%b '%y\"\n  ) +\n  scale_y_continuous(\n      trans = \"log10\", \n      name = \"Reported bike shares\", \n      breaks = seq(0, 60000, by = 15000), \n      labels = \\(x) paste0(x, \" bikes\"), \n      limits = c(NA, 60000), \n      expand = expansion(0, 0), # add, mult\n      # guide = \"none\"\n  ) +\n  scale_color_discrete()\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(\n    bikes,\n    aes(x = season, y = count)\n  ) +\n  geom_boxplot() +\n  scale_x_discrete(\n    name = \"Period\",\n    labels = c(\"Dec-Feb\", \"Mar-May\", \"Jun-Aug\", \"Sep-Nov\")\n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(\n    bikes,\n    aes(x = date, y = count,\n        color = season)\n  ) +\n  geom_point() +\n  scale_color_discrete(\n    name = \"Season:\",\n    type = c(\"#69b0d4\", \"#00CB79\", \"#F7B01B\", \"#a78f5f\")\n  )\n\n\n\n\n\n\n\n\n\n色についてもscale_colorの中でマニュアルで指定することが可能である.\n\n\nCode\nmy_colors &lt;- c(\n  `winter` = \"#3c89d9\",\n  `spring` = \"#1ec99b\",\n  `summer` = \"#F7B01B\",\n  `autumn` = \"#a26e7c\"\n)\n\nggplot(\n    bikes,\n    aes(x = date, y = count,\n        color = season)\n  ) +\n  geom_point() +\n  scale_color_discrete(\n    name = \"Season:\",\n    type = my_colors\n  )\n\n\n\n\n\n\n\n\n\nNAは別の値で決めることができる. パステルカラーにブラックはよくわかるので良さそうである.\n\n\nCode\nggplot(\n    bikes,\n    aes(x = date, y = count,\n        color = weather_type)\n  ) +\n  geom_point() +\n  scale_color_manual(\n    name = \"Season:\",\n    values = brewer.pal(n = 6, name = \"Pastel1\"),\n    na.value = \"black\"\n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(\n    bikes,\n    aes(x = date, y = count,\n        color = weather_type)\n  ) +\n  geom_point() +\n  rcartocolor::scale_color_carto_d(\n    name = \"Season:\",\n    palette = \"Pastel\",\n    na.value = \"black\"\n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\nfacet &lt;-\n  ggplot(\n    diamonds,\n    aes(x = carat, y = price)\n  ) +\n  geom_point(\n    alpha = .3\n  ) +\n  geom_smooth(\n    aes(color = cut),\n    method = \"lm\",\n    se = FALSE\n  ) +\n  facet_grid(\n    cut ~ clarity,\n    space = \"free_x\",\n    scales = \"free_x\"\n  )\n\nfacet + \n    scale_x_continuous(breaks = 0:5) + \n    scale_y_continuous(\n        limits = c(0, 30000), \n        breaks = 0:3 * 10000, \n        labels = \\(x) paste0(\"$\", format(x, big.mark = \",\", trim = TRUE))\n    ) + \n    scale_color_brewer(palette = \"Set2\") + \n    theme(legend.position = \"none\")\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n#&gt; Warning: Removed 131 rows containing missing values (`geom_smooth()`).\n\n\n\n\n\n\n\n\n\n\n\n4 Coordinates Systems\n線形の座標系は次である.\n\ncoord_cartesian()\ncoord_fixed()\ncoord_flip()\n\n非線形の座標系として次がある.\n\ncoord_polar()\ncoord_map()\ncoord_sf()\ncoord_trans()\n\n\n\n\n\nCode\nggplot(\n    bikes,\n    aes(x = season, y = count)\n  ) +\n  geom_boxplot() +\n  coord_cartesian(\n      ylim = c(NA, 15000)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(\n    bikes,\n    aes(x = season, y = count)\n  ) +\n  geom_boxplot() +\n  scale_y_continuous(\n      limits = c(NA, 15000)\n  )\n#&gt; Warning: Removed 575 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n\n\nclip = \"off\"を使うとpanel領域をはみ出してグラフを記述することが出来る.\n\n\nCode\nggplot(\n    bikes,\n    aes(x = season, y = count)\n  ) +\n  geom_boxplot() +\n  coord_cartesian(\n    ylim = c(NA, 15000),\n    clip = \"off\"\n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(\n    filter(bikes, is_holiday == TRUE),\n    aes(x = temp_feel, y = count)\n  ) +\n  geom_point() +\n  geom_text(\n    aes(label = season),\n    nudge_x = .3,\n    hjust = 0, \n    vjust = -1\n  ) +\n  coord_cartesian(\n    clip = \"off\"\n  )\n\n\n\n\n\n\n\n\n\nパディングをすべて消すことも可能である.\n\n\nCode\nggplot(\n    bikes,\n    aes(x = temp_feel, y = count)\n  ) +\n  geom_point() +\n  coord_cartesian(\n    expand = FALSE,\n    clip = \"off\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(\n    bikes,\n    aes(x = temp_feel, y = temp)\n  ) +\n  geom_point() +\n  coord_fixed()\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(\n    bikes,\n    aes(x = temp_feel, y = temp)\n  ) +\n  geom_point() +\n  coord_fixed(ratio = 4) # y / x\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(\n    bikes,\n    aes(y = weather_type)\n  ) +\n  geom_bar() +\n  coord_cartesian()\n\n\n\n\n\n\n\n\n\nreorderすることも出来る.\n\n\nCode\nggplot(\n    filter(bikes, !is.na(weather_type)),\n    aes(y = fct_rev(fct_infreq(weather_type)))\n  ) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(\n    filter(bikes, !is.na(weather_type)),\n    aes(x = weather_type,\n        fill = weather_type)\n  ) +\n  geom_bar() +\n  coord_polar(theta = \"y\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(\n    filter(bikes, !is.na(weather_type)),\n    aes(x = fct_infreq(weather_type),\n        fill = weather_type)\n  ) +\n  geom_bar(width = 1) +\n  coord_polar()\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(\n    filter(bikes, !is.na(weather_type)),\n    aes(x = fct_infreq(weather_type),\n        fill = weather_type)\n  ) +\n  geom_bar(width = 1) +\n  coord_cartesian()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(\n    filter(bikes, !is.na(weather_type)),\n    aes(x = 1, fill = weather_type)\n  ) +\n  geom_bar(position = \"stack\") +\n  coord_polar(theta = \"y\") \n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(\n    filter(bikes, !is.na(weather_type)),\n    aes(x = 1, fill = weather_type)\n  ) +\n  geom_bar(position = \"stack\") +\n  coord_cartesian() \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(\n    bikes,\n    aes(x = temp, y = count,\n        group = day_night)\n  ) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  coord_trans(y = \"log10\")\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(\n    bikes,\n    aes(x = temp, y = count,\n        group = day_night)\n  ) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  scale_y_log10()\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\n\n5 Spaital Coordiate\n\n\nCode\ncountries &lt;- rnaturalearth::ne_countries(\n  returnclass = \"sf\"\n)\n\n\n\nggplot() +\n  geom_sf(\n    data = countries,\n    color = \"#79dfbd\",\n    fill = \"#28a87d\",\n    size = .3\n  ) +\n  coord_sf(\n    crs = \"+proj=moll\"\n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\noceans &lt;- rnaturalearth::ne_download(\n  category = \"physical\", type = \"ocean\", returnclass = \"sf\"\n)\nggplot() +\n  geom_sf(\n    data = oceans,\n    fill = \"#d8f1f6\",\n    color = \"white\"\n  ) +\n  geom_sf(\n    data = countries,\n    aes(fill = economy),\n    color = \"white\",\n    size = .3\n  ) +\n  coord_sf(\n    crs = \"+proj=bonne +lat_1=10\"\n  ) +\n  scale_fill_viridis_d(option = \"magma\") +\n  theme_void() +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/website/analizeUSCensus/index.html",
    "href": "contents/website/analizeUSCensus/index.html",
    "title": "Analyzing US Census Data",
    "section": "",
    "text": "1 はじめに\n\nアメリカのセンサスデータのデータ分析\n空間データ分析のトレーニングとして有用\nリンクス\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/website/analizeUSCensus/ch06_mapping_census_data_with_r.html",
    "href": "contents/website/analizeUSCensus/ch06_mapping_census_data_with_r.html",
    "title": "Mapping Census data with R",
    "section": "",
    "text": "Code\nrenv::activate(here::here())\n\n\n\n\nCode\nlibrary(sf)\nlibrary(here)\nlibrary(tidyverse)\nlibrary(tidycensus)\nlibrary(tigris)\nlibrary(spdep)\n\ncur_dir &lt;- here()\noptions(tigris_use_cache = TRUE)\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/website/leaflet4r/chapters/ch12_choropleths.html",
    "href": "contents/website/leaflet4r/chapters/ch12_choropleths.html",
    "title": "Choropleths",
    "section": "",
    "text": "Code\nlibrary(here)\nlibrary(shiny)\nlibrary(leaflet)\nlibrary(leafem)\nlibrary(htmltools)\nlibrary(htmlwidgets)\nlibrary(rjson)\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(stars)\nlibrary(terra)\nlibrary(glue)\nlibrary(knitr)\n\ndata_dir &lt;- here(\"contents/website/leaflet4r/data\")"
  },
  {
    "objectID": "contents/website/leaflet4r/chapters/ch12_choropleths.html#basic-stats-map",
    "href": "contents/website/leaflet4r/chapters/ch12_choropleths.html#basic-stats-map",
    "title": "Choropleths",
    "section": "1.1 Basic stats map",
    "text": "1.1 Basic stats map\n\n\nCode\nm &lt;- leaflet(states) %&gt;%\n  setView(-96, 37.8, 4) %&gt;%\n  addProviderTiles(\"MapBox\", options = providerTileOptions(\n    id = \"mapbox.light\",\n    accessToken = Sys.getenv('MAPBOX_ACCESS_TOKEN')))\n\nm\n\n\n\n\n\n\n\n\nCode\nm %&gt;% addPolygons()"
  },
  {
    "objectID": "contents/website/leaflet4r/chapters/ch10_Legends.html",
    "href": "contents/website/leaflet4r/chapters/ch10_Legends.html",
    "title": "Legends",
    "section": "",
    "text": "Code\nlibrary(here)\nlibrary(shiny)\nlibrary(leaflet)\nlibrary(leafem)\nlibrary(htmltools)\nlibrary(htmlwidgets)\nlibrary(rjson)\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(stars)\nlibrary(terra)\nlibrary(glue)\nlibrary(knitr)\n\ndata_dir &lt;- here(\"contents/website/leaflet4r/data\")\n\n\n\n1 Lgends\n\n\nCode\ncountries &lt;- sf::st_read(\"https://rstudio.github.io/leaflet/json/countries.geojson\")\n#&gt; Reading layer `countries' from data source \n#&gt;   `https://rstudio.github.io/leaflet/json/countries.geojson' \n#&gt;   using driver `GeoJSON'\n#&gt; Simple feature collection with 177 features and 2 fields\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -180 ymin: -90 xmax: 180 ymax: 83.64513\n#&gt; Geodetic CRS:  WGS 84\n\n\n\n\nCode\nmap &lt;- leaflet(countries) %&gt;% addTiles()\n\n\naddLegend関数を使うことで凡例を追加することができる.\n\n\nCode\npal &lt;- colorNumeric(\n  palette = \"YlGnBu\",\n  domain = countries$gdp_md_est\n)\nmap %&gt;%\n  addPolygons(stroke = FALSE, smoothFactor = 0.2, fillOpacity = 1,\n    color = ~pal(gdp_md_est)\n  ) %&gt;%\n  addLegend(\n      \"bottomright\", \n      pal = pal, \n      values = ~gdp_md_est,\n      title = \"Est. GDP (2010)\",\n      labFormat = labelFormat(prefix = \"$\"),\n      opacity = 1\n  )\n\n\n\n\n\n\n異なる凡例を使うのも簡単である.\n\n\nCode\nqpal &lt;- colorQuantile(\"RdYlBu\", countries$gdp_md_est, n = 5)\nmap %&gt;%\n  addPolygons(stroke = FALSE, smoothFactor = 0.2, fillOpacity = 1,\n    color = ~qpal(gdp_md_est)\n  ) %&gt;%\n  addLegend(pal = qpal, values = ~gdp_md_est, opacity = 1)\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/website/leaflet4r/chapters/ch08_shiny_integration.html",
    "href": "contents/website/leaflet4r/chapters/ch08_shiny_integration.html",
    "title": "Shiny Integration",
    "section": "",
    "text": "Quartoのプロジェクトの中に置いていると shinyを動かすことができないんだけど、 基本的にはleafletでもshinyで使えますという話し.\nまた, Proxyとしてマウスの位置やクリック位置などを検出することができるので, それを使えばリッチなWebアプリが作成できますという主旨のことが書いてある。\n作るときに忘れず参照することが大事である.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/website/leaflet4r/chapters/ch06_geojson.html",
    "href": "contents/website/leaflet4r/chapters/ch06_geojson.html",
    "title": "Working with GeoJSON and TopoJSON",
    "section": "",
    "text": "Code\nlibrary(here)\nlibrary(shiny)\nlibrary(leaflet)\nlibrary(leafem)\nlibrary(htmltools)\nlibrary(htmlwidgets)\nlibrary(rjson)\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(stars)\nlibrary(glue)\nlibrary(knitr)\n\ndata_dir &lt;- here(\"contents/website/leaflet4r/data\")"
  },
  {
    "objectID": "contents/website/leaflet4r/chapters/ch06_geojson.html#styling-raw-geojson-topojson",
    "href": "contents/website/leaflet4r/chapters/ch06_geojson.html#styling-raw-geojson-topojson",
    "title": "Working with GeoJSON and TopoJSON",
    "section": "1.1 Styling raw GeoJSON / TopoJSON",
    "text": "1.1 Styling raw GeoJSON / TopoJSON\nGeoJSONなどはいくつかの方法でスタイルを直接変更することができる.\n\n\nCode\nlibrary(jsonlite)\n#&gt; \n#&gt; Attaching package: 'jsonlite'\n#&gt; The following object is masked from 'package:purrr':\n#&gt; \n#&gt;     flatten\n#&gt; The following objects are masked from 'package:rjson':\n#&gt; \n#&gt;     fromJSON, toJSON\n#&gt; The following object is masked from 'package:shiny':\n#&gt; \n#&gt;     validate\n\n# From http://data.okfn.org/data/datasets/geo-boundaries-world-110m\ngeojson &lt;- \n    readLines(\n        \"https://rstudio.github.io/leaflet/json/countries.geojson\", \n        warn = FALSE) %&gt;%\n  paste(collapse = \"\\n\") %&gt;%\n  fromJSON(simplifyVector = FALSE)\n\n# Default styles for all features\ngeojson$style = list(\n  weight = 1,\n  color = \"#555555\",\n  opacity = 1,\n  fillOpacity = 0.8\n)\n\n# Gather GDP estimate from all countries\ngdp_md_est &lt;- sapply(geojson$features, function(feat) {\n  feat$properties$gdp_md_est\n})\n# Gather population estimate from all countries\npop_est &lt;- sapply(geojson$features, function(feat) {\n  max(1, feat$properties$pop_est)\n})\n\n# Color by per-capita GDP using quantiles\npal &lt;- colorQuantile(\"Greens\", gdp_md_est / pop_est)\n# Add a properties$style list to each feature\ngeojson$features &lt;- lapply(geojson$features, function(feat) {\n  feat$properties$style &lt;- list(\n    fillColor = pal(\n      feat$properties$gdp_md_est / max(1, feat$properties$pop_est)\n    )\n  )\n  feat\n})\n\n# Add the now-styled GeoJSON object to the map\nleaflet() %&gt;% addGeoJSON(geojson)"
  },
  {
    "objectID": "contents/website/leaflet4r/chapters/ch04_popups_and_shapes.html",
    "href": "contents/website/leaflet4r/chapters/ch04_popups_and_shapes.html",
    "title": "Popups and Shapes",
    "section": "",
    "text": "Code\nlibrary(here)\nlibrary(shiny)\nlibrary(leaflet)\nlibrary(leafem)\nlibrary(htmltools)\nlibrary(htmlwidgets)\nlibrary(rjson)\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(stars)\nlibrary(glue)\nlibrary(knitr)"
  },
  {
    "objectID": "contents/website/leaflet4r/chapters/ch04_popups_and_shapes.html#customizing-marker-labels",
    "href": "contents/website/leaflet4r/chapters/ch04_popups_and_shapes.html#customizing-marker-labels",
    "title": "Popups and Shapes",
    "section": "2.1 Customizing Marker Labels",
    "text": "2.1 Customizing Marker Labels\n\n\nCode\n# Change Text Size and text Only and also a custom CSS\nleaflet() %&gt;% addTiles() %&gt;% setView(-118.456554, 34.09, 13) %&gt;%\n  addMarkers(\n    lng = -118.456554, lat = 34.105,\n    label = \"Default Label\",\n    labelOptions = labelOptions(noHide = T)) %&gt;%\n  addMarkers(\n    lng = -118.456554, lat = 34.095,\n    label = \"Label w/o surrounding box\",\n    labelOptions = labelOptions(noHide = T, textOnly = TRUE)) %&gt;%\n  addMarkers(\n    lng = -118.456554, lat = 34.085,\n    label = \"label w/ textsize 15px\",\n    labelOptions = labelOptions(noHide = T, textsize = \"15px\")) %&gt;%\n  addMarkers(\n    lng = -118.456554, lat = 34.075,\n    label = \"Label w/ custom CSS style\",\n    labelOptions = labelOptions(noHide = T, direction = \"bottom\",\n      style = list(\n        \"color\" = \"red\",\n        \"font-family\" = \"serif\",\n        \"font-style\" = \"italic\",\n        \"box-shadow\" = \"3px 3px rgba(0,0,0,0.25)\",\n        \"font-size\" = \"12px\",\n        \"border-color\" = \"rgba(0,0,0,0.5)\"\n      )))"
  },
  {
    "objectID": "contents/website/leaflet4r/chapters/ch04_popups_and_shapes.html#labels-without-markers",
    "href": "contents/website/leaflet4r/chapters/ch04_popups_and_shapes.html#labels-without-markers",
    "title": "Popups and Shapes",
    "section": "2.2 Labels without markers",
    "text": "2.2 Labels without markers\n\n\nCode\nleaflet() %&gt;%\n  addTiles() %&gt;%\n  addLabelOnlyMarkers(\n    data = breweries91,\n    label = as.character(breweries91$brewery),\n    group = \"brew\",\n    labelOptions = leaflet::labelOptions(\n      noHide = TRUE,\n      direction = \"bottom\",\n      textOnly = TRUE,\n      offset = c(0, -10),\n      opacity = 1\n    )\n  )"
  },
  {
    "objectID": "contents/website/leaflet4r/chapters/ch02_basemaps.html",
    "href": "contents/website/leaflet4r/chapters/ch02_basemaps.html",
    "title": "Basemap",
    "section": "",
    "text": "Code\nlibrary(here)\nlibrary(shiny)\nlibrary(leaflet)\nlibrary(leafem)\nlibrary(htmltools)\nlibrary(htmlwidgets)\nlibrary(rjson)\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(stars)\nlibrary(glue)\nlibrary(knitr)\n\n\n\n1 Default\n\nOpenstreet Mapが使われる.\n\n\n\nCode\nm &lt;- leaflet() %&gt;% setView(lng = -71.0589, lat = 42.3601, zoom = 12)\nm %&gt;% addTiles()\n\n\n\n\n\n\n\n\n2 Third-Party Tiles\n\n\nCode\nm %&gt;% addProviderTiles(providers$CartoDB.Positron)\n\n\n\n\n\n\n\n\n3 Custom Tile URL Template\n\n\nCode\nleaflet() %&gt;% addTiles() %&gt;% setView(-93.65, 42.0285, zoom = 4) %&gt;%\n  addWMSTiles(\n    \"http://mesonet.agron.iastate.edu/cgi-bin/wms/nexrad/n0r.cgi\",\n    layers = \"nexrad-n0r-900913\",\n    options = WMSTileOptions(format = \"image/png\", transparent = TRUE),\n    attribution = \"Weather data © 2012 IEM Nexrad\"\n  )\n\n\n\n\n\n\n\n\n4 Combining Tile Layers\nbasemapは重ねることが可能である. ちなみにvector tileをどのように重ねたらよいのかはまだわかっていない。\n\n\nCode\nm |&gt; \n  addProviderTiles(providers$MtbMap) |&gt;\n  addProviderTiles(providers$Stamen.TonerLines,\n    options = providerTileOptions(opacity = 0.35)) |&gt;\n  addProviderTiles(providers$Stamen.TonerLabels)\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/website/leaflet4r/index.html",
    "href": "contents/website/leaflet4r/index.html",
    "title": "Leaflet for R",
    "section": "",
    "text": "Leaflet for Rの学習ノートです\nAPI reference\nすべてではなく気になった部分だけを記録しています\nalbersusaパッケージはここインストールしています"
  },
  {
    "objectID": "contents/website/leaflet4r/index.html#文字列へのリンク",
    "href": "contents/website/leaflet4r/index.html#文字列へのリンク",
    "title": "Leaflet for R",
    "section": "3.1 文字列へのリンク",
    "text": "3.1 文字列へのリンク\nleaflet map"
  },
  {
    "objectID": "contents/website/leaflet4r/index.html#画像へのリンク",
    "href": "contents/website/leaflet4r/index.html#画像へのリンク",
    "title": "Leaflet for R",
    "section": "3.2 画像へのリンク",
    "text": "3.2 画像へのリンク\nlightboxの効果はないのに注意すること.\n\n\n\n画像へのリンク作成"
  },
  {
    "objectID": "contents/website/leaflet4r/index.html#geojson",
    "href": "contents/website/leaflet4r/index.html#geojson",
    "title": "Leaflet for R",
    "section": "3.3 GeoJSON",
    "text": "3.3 GeoJSON\n\n\nCode\ngeojson &lt;- \"https://www.geospatial.jp/ckan/dataset/669fc4ff-317b-48cf-a43d-9340ff04ff18/resource/ccff82d4-2353-49e6-9845-371ee6d622de/download/biomasspowerstation42.geojson\"\ngeojson &lt;- \"https://www.geospatial.jp/ckan/dataset/a4f2f167-1433-47ea-b7be-ce88660a30a2/resource/72f6ed4e-a68c-4082-a90f-dd7e5423d87a/download/p35_18_03.geojson\"\nx &lt;- fromJSON(file = geojson)\ny &lt;- read_sf(geojson)\nytext &lt;- \n    y %&gt;%\n    \"st_geometry&lt;-\"(NULL) %&gt;%\n    transpose() %&gt;%\n    map( ~ glue(\"{names(.x)} = {.x}\")) %&gt;%\n    map_chr(~ str_c(.x, collapse = \"&lt;br/&gt;\"))\nas_longstyle_htmltable &lt;- function(data) {\n    data %&gt;%\n        mutate(across(everything(), as.character)) %&gt;%\n        rowwise() %&gt;%\n        summarise(htmltbl = list(tibble(`属性` = names(cur_data()), `値` = flatten_chr(cur_data())))) %&gt;%\n        mutate(htmltbl = map(htmltbl, ~ kable(.x, format = \"html\"))) %&gt;%\n        mutate(htmltbl = map(htmltbl, ~ str_replace(.x, \"&lt;table&gt;\", \"&lt;table style='border: solid 1px #f8f8f8;border-collapse:collapse;height:auto;max-height:35vh;overflow-y:scroll'&gt;\"))) %&gt;%\n        mutate(htmltbl = map(htmltbl, ~ str_replace_all(.x, \"&lt;th style=\\\"text-align:left;\\\"&gt;\", \"&lt;th style=\\\"text-align:center;background-color:black;color:white\\\"&gt;\"))) %&gt;%\n        mutate(htmltbl = map(htmltbl, ~ str_replace_all(.x, \"&lt;tr&gt;\", \"&lt;tr style='border: solid 1px #f8f8f8;'&gt;\"))) %&gt;%\n        mutate(htmltbl = map(htmltbl, ~ str_replace_all(.x, \"&lt;td style=\\\"text-align:left;\\\"&gt;\", \"&lt;td style=\\\"text-align:left;padding:0.5em\\\"&gt;\")))\n}\n\nyattr      &lt;- \"st_geometry&lt;-\"(y, NULL)\nytabletext &lt;- as_longstyle_htmltable(yattr)\n#&gt; Warning: There was 1 warning in `summarise()`.\n#&gt; ℹ In argument: `htmltbl = list(tibble(属性 = names(cur_data()), 値 =\n#&gt;   flatten_chr(cur_data())))`.\n#&gt; ℹ In row 1.\n#&gt; Caused by warning:\n#&gt; ! `cur_data()` was deprecated in dplyr 1.1.0.\n#&gt; ℹ Please use `pick()` instead.\n\n\nrm(m)\nm &lt;- \n    leaflet(\n        width = \"100%\",\n        height = \"800\"\n    ) %&gt;%\n    addTiles(urlTemplate = \"https://cyberjapandata.gsi.go.jp/xyz/seamlessphoto/{z}/{x}/{y}.jpg\", group = \"空中写真\", layerId = \"photo\") %&gt;%\n    addTiles(urlTemplate = \"http://cyberjapandata.gsi.go.jp/xyz/std/{z}/{x}/{y}.png\", group = \"標準地図\", layerId = \"gsi\") %&gt;%\n    addTiles(urlTemplate = \"https://tile.geospatial.jp/ks-shinsuisoutei/A31-19_83_SHP_tile/{z}/{x}/{y}.png\", group = \"MLIT\") %&gt;%\n    addFeatures(data = st_geometry(y), popup = ytabletext$htmltbl, group = \"new\") %&gt;%\n    addLayersControl(\n        baseGroup     = c(\"標準地図\", \"空中写真\"), \n        overlayGroups = c(\"new\", \"MLIT\")\n    )\n    \n\nm %&gt;%\n    addFeatures(data = st_geometry(y), popup = ytabletext$htmltbl, group = \"new2\") %&gt;%\n    addLayersControl(\n        baseGroup     = c(\"標準地図\", \"空中写真\"), \n        overlayGroups = c(\"new\", \"new2\")\n    )"
  },
  {
    "objectID": "contents/website/leaflet4r/index.html#geotiff",
    "href": "contents/website/leaflet4r/index.html#geotiff",
    "title": "Leaflet for R",
    "section": "3.4 GeoTiff",
    "text": "3.4 GeoTiff\n\n\nCode\nlibrary(stars)\nlibrary(leafem)\n\nr &lt;- read_stars(here(cur_dir, \"data/DCWD_map.tif\"))\nleaflet() %&gt;%\n    addTiles(group = \"OpenStreetMap\") %&gt;% \n    addStarsRGB(r)"
  },
  {
    "objectID": "contents/website/leaflet4r/index.html#gps",
    "href": "contents/website/leaflet4r/index.html#gps",
    "title": "Leaflet for R",
    "section": "3.5 GPS",
    "text": "3.5 GPS\n\n\nCode\nlibrary(leaflet)\nlibrary(leaflet.extras)\n\nmap &lt;- leaflet() %&gt;% addTiles()\n\nmap &lt;- addControlGPS(\n    map, \n    options = gpsOptions(\n        position = \"topleft\", \n        activate = TRUE, \n        autoCenter = TRUE, \n        maxZoom = 10, \n        setView = TRUE\n    )\n)\n\nactivateGPS(map)"
  },
  {
    "objectID": "contents/website/leaflet4r/index.html#vector-tile",
    "href": "contents/website/leaflet4r/index.html#vector-tile",
    "title": "Leaflet for R",
    "section": "3.6 Vector tile",
    "text": "3.6 Vector tile\n\n\nCode\nlibrary(leaflet)\nlibrary(htmltools)\n\nm &lt;- leaflet() %&gt;%\n  addTiles() %&gt;%\n  setView(lng = 174.768, lat = -36.852, zoom = 10)\n\nm_html &lt;- as.character(m)\n\nvector_tile_js &lt;- \"\nL.vectorGrid.protobuf('https://cyberjapandata.gsi.go.jp/xyz/experimental_bvmap/{z}/{x}/{y}.pbf').addTo(map);\n\"\n\nbrowsable(\n  tagList(\n    tags$head(tags$script(src = \"https://unpkg.com/leaflet.vectorgrid/dist/Leaflet.VectorGrid.js\")),\n    HTML(m_html),\n    tags$script(HTML(vector_tile_js))\n  )\n)"
  },
  {
    "objectID": "contents/website/r4ds2e/index.html",
    "href": "contents/website/r4ds2e/index.html",
    "title": "R for Data Science 2e",
    "section": "",
    "text": "1 はじめに\n\nR for Data Science 2eの学習ノートです\nすべてではなく気になった部分だけを記録しています\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R Tips Site",
    "section": "",
    "text": "1 はじめに\n\nRに関するTips, 勉強ノートです\nサイト、図書、勉強会などの情報を一箇所にまとめるのが目的です\nRは常に進化しており、知らないことは損をします\nデータサイエンスを極めましょう\n\n\n\n2 構成\ncontents/{web/book/adhoc/library}/source_name/section/chapter.qmdを基本的な構成とします.\n\n\n3 開発環境\n\nR 4.3.1を使います\nhereパッケージを使います\nrenvパッケージを使いマス\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/website/r4ds2e/Import/ch23_arrow.html",
    "href": "contents/website/r4ds2e/Import/ch23_arrow.html",
    "title": "23 Arrow",
    "section": "",
    "text": "Code\nrenv::activate(here::here())\ncur_dir &lt;- here::here(\"contents/website/r4ds2e/Import/\")\nCode\nlibrary(tidyverse)\nlibrary(arrow)\nlibrary(dbplyr)\nlibrary(duckdb)\nlibrary(here)\nlibrary(showtext)\nshowtext_auto()\nfont_add_google(\"Noto Sans\")"
  },
  {
    "objectID": "contents/website/r4ds2e/Import/ch23_arrow.html#advantages",
    "href": "contents/website/r4ds2e/Import/ch23_arrow.html#advantages",
    "title": "23 Arrow",
    "section": "4.1 Advantages",
    "text": "4.1 Advantages\n\nParquetは効率的なエンコードでファイルサイズを小さくする\nCSVに持たせることが出来ない情報を持たせることができる\nカラム指向である\nチャンク化されていても,異なるチャンクを同時扱うことが出来る"
  },
  {
    "objectID": "contents/website/r4ds2e/Import/ch23_arrow.html#partitioning",
    "href": "contents/website/r4ds2e/Import/ch23_arrow.html#partitioning",
    "title": "23 Arrow",
    "section": "4.2 Partitioning",
    "text": "4.2 Partitioning\n\nデータが巨大になるほど1つのファイルで管理するのが困難となる\nチャンク化は20MB以下になることと2GB以上になることを避ける\nChekoutYearを軸にチャンク化をおこなう\nISBNがint64やnullだと出力が出来ないのでここでは文字列として出力する\n\n\n\nCode\npq_path &lt;- here(cur_dir, \"data/seattle-library-checkouts\")\nseattle_csv |&gt; \n    group_by(CheckoutYear) |&gt; \n    write_dataset(path = pq_path, format = \"parquet\")\n\n\n生成したデータを確認する.\n\n\nCode\ntibble(\n    files = list.files(pq_path, recursive = TRUE), \n    size_MB = file.size(here(pq_path, files)) / 1024^2\n)\n#&gt; # A tibble: 18 × 2\n#&gt;    files                            size_MB\n#&gt;    &lt;chr&gt;                              &lt;dbl&gt;\n#&gt;  1 CheckoutYear=2005/part-0.parquet    109.\n#&gt;  2 CheckoutYear=2006/part-0.parquet    164.\n#&gt;  3 CheckoutYear=2007/part-0.parquet    178.\n#&gt;  4 CheckoutYear=2008/part-0.parquet    195.\n#&gt;  5 CheckoutYear=2009/part-0.parquet    214.\n#&gt;  6 CheckoutYear=2010/part-0.parquet    222.\n#&gt;  7 CheckoutYear=2011/part-0.parquet    239.\n#&gt;  8 CheckoutYear=2012/part-0.parquet    249.\n#&gt;  9 CheckoutYear=2013/part-0.parquet    269.\n#&gt; 10 CheckoutYear=2014/part-0.parquet    282.\n#&gt; 11 CheckoutYear=2015/part-0.parquet    294.\n#&gt; 12 CheckoutYear=2016/part-0.parquet    300.\n#&gt; 13 CheckoutYear=2017/part-0.parquet    304.\n#&gt; 14 CheckoutYear=2018/part-0.parquet    292.\n#&gt; 15 CheckoutYear=2019/part-0.parquet    288.\n#&gt; 16 CheckoutYear=2020/part-0.parquet    151.\n#&gt; 17 CheckoutYear=2021/part-0.parquet    229.\n#&gt; 18 CheckoutYear=2022/part-0.parquet    241."
  },
  {
    "objectID": "contents/website/r4ds2e/Import/ch23_arrow.html#using-dplyr-with-arrow",
    "href": "contents/website/r4ds2e/Import/ch23_arrow.html#using-dplyr-with-arrow",
    "title": "23 Arrow",
    "section": "4.3 Using dplyr with arrow",
    "text": "4.3 Using dplyr with arrow\n\n\nCode\nseattle_pq &lt;- open_dataset(pq_path)\nseattle_pq\n#&gt; FileSystemDataset with 18 Parquet files\n#&gt; UsageClass: string\n#&gt; CheckoutType: string\n#&gt; MaterialType: string\n#&gt; CheckoutMonth: int64\n#&gt; Checkouts: int64\n#&gt; Title: string\n#&gt; ISBN: string\n#&gt; Creator: string\n#&gt; Subjects: string\n#&gt; Publisher: string\n#&gt; PublicationYear: string\n#&gt; CheckoutYear: int32\n\n\ndplyrの構文がそのまま使える. collectを実行したときに, コードが実行される.\n\n\nCode\nquery &lt;- \n    seattle_pq |&gt; \n    filter(CheckoutYear &gt;= 2008, MaterialType == \"BOOK\") |&gt; \n    group_by(CheckoutYear, CheckoutMonth) |&gt; \n    summarise(TotalCheckouts = sum(Checkouts)) |&gt; \n    arrange(CheckoutYear, CheckoutMonth)\nquery\n#&gt; FileSystemDataset (query)\n#&gt; CheckoutYear: int32\n#&gt; CheckoutMonth: int64\n#&gt; TotalCheckouts: int64\n#&gt; \n#&gt; * Grouped by CheckoutYear\n#&gt; * Sorted by CheckoutYear [asc], CheckoutMonth [asc]\n#&gt; See $.data for the source Arrow object\n\n\n前述したように, collectで評価される.\n\n\nCode\nquery |&gt; collect()\n#&gt; # A tibble: 178 × 3\n#&gt; # Groups:   CheckoutYear [15]\n#&gt;    CheckoutYear CheckoutMonth TotalCheckouts\n#&gt;           &lt;int&gt;         &lt;int&gt;          &lt;int&gt;\n#&gt;  1         2008             1         343384\n#&gt;  2         2008             2         315806\n#&gt;  3         2008             3         291710\n#&gt;  4         2008             4         341452\n#&gt;  5         2008             5         328072\n#&gt;  6         2008             6         356621\n#&gt;  7         2008             7         388959\n#&gt;  8         2008             8         363506\n#&gt;  9         2008             9         353561\n#&gt; 10         2008            10         354779\n#&gt; # ℹ 168 more rows"
  },
  {
    "objectID": "contents/website/r4ds2e/Import/ch23_arrow.html#performance",
    "href": "contents/website/r4ds2e/Import/ch23_arrow.html#performance",
    "title": "23 Arrow",
    "section": "4.4 Performance",
    "text": "4.4 Performance\nデータが絞られるほどCSVよりも高速に動作する.\n\n\nCode\nbench::mark(\n    {\n        seattle_csv |&gt; \n        filter(CheckoutYear &gt;= 2008, MaterialType == \"BOOK\") |&gt; \n        group_by(CheckoutYear, CheckoutMonth) |&gt; \n        summarise(TotalCheckouts = sum(Checkouts)) |&gt; \n        arrange(CheckoutYear, CheckoutMonth) |&gt; \n        collect()\n    }, \n    {\n        seattle_pq |&gt; \n        filter(CheckoutYear &gt;= 2008, MaterialType == \"BOOK\") |&gt; \n        group_by(CheckoutYear, CheckoutMonth) |&gt; \n        summarise(TotalCheckouts = sum(Checkouts)) |&gt; \n        arrange(CheckoutYear, CheckoutMonth) |&gt; \n        collect()\n    }, \n    check = FALSE, \n    max_iterations = 1\n)\n#&gt; Warning: Some expressions had a GC in every iteration; so filtering is\n#&gt; disabled.\n#&gt; # A tibble: 2 × 6\n#&gt;   expression                             min median `itr/sec` mem_alloc `gc/sec`\n#&gt;   &lt;bch:expr&gt;                           &lt;bch&gt; &lt;bch:&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt;\n#&gt; 1 { collect(arrange(summarise(group_b… 18.3s  18.3s    0.0547     218KB    0    \n#&gt; 2 { collect(arrange(summarise(group_b…  2.1s   2.1s    0.475      218KB    0.475"
  },
  {
    "objectID": "contents/website/r4ds2e/Import/ch23_arrow.html#advance",
    "href": "contents/website/r4ds2e/Import/ch23_arrow.html#advance",
    "title": "23 Arrow",
    "section": "4.5 Advance",
    "text": "4.5 Advance\nparquetはカラム指向なので同じカラム指向のリレーショナルデータベースであるDuckDBと非常に相性がよい. DuckDBはカラム指向でデータの高速処理を指向して開発されたデータベースである. サーバーレスで動作する.\n\n\nCode\nseattle_pq |&gt; \n  to_duckdb() |&gt;\n  filter(CheckoutYear &gt;= 2008, MaterialType == \"BOOK\") |&gt;\n  group_by(CheckoutYear) |&gt;\n  summarize(TotalCheckouts = sum(Checkouts)) |&gt;\n  arrange(desc(CheckoutYear)) |&gt;\n  collect() |&gt; \n  system.time()\n#&gt; Warning: Missing values are always removed in SQL aggregation functions.\n#&gt; Use `na.rm = TRUE` to silence this warning\n#&gt; This warning is displayed once every 8 hours.\n#&gt;    user  system elapsed \n#&gt;    1.44    0.21    2.69"
  },
  {
    "objectID": "contents/website/leaflet4r/chapters/ch01_map_object.html",
    "href": "contents/website/leaflet4r/chapters/ch01_map_object.html",
    "title": "The Map Widget",
    "section": "",
    "text": "Code\nlibrary(here)\nlibrary(shiny)\nlibrary(leaflet)\nlibrary(leafem)\nlibrary(htmltools)\nlibrary(htmlwidgets)\nlibrary(rjson)\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(stars)\nlibrary(glue)\nlibrary(knitr)\n\n\n\n1 ランダムメモ\n\n基本的にはleafletのAPIドックと同じものが動こう\n\n\n\n2 プリミティブな図形\n\ndata frame作成してしまうのが１番簡単である\n\n\n\nCode\n# add some circles to a map\ndf = data.frame(Lat = 1:10, Long = rnorm(10))\nleaflet(df) |&gt; addCircles()\n\n\n\n\n\n\n\n\nCode\nlibrary(maps)\n#&gt; \n#&gt; Attaching package: 'maps'\n#&gt; The following object is masked from 'package:purrr':\n#&gt; \n#&gt;     map\nmapStates = map(\"state\", fill = TRUE, plot = FALSE)\nleaflet(data = mapStates) %&gt;% addTiles() %&gt;%\n  addPolygons(fillColor = topo.colors(10, alpha = NULL), stroke = FALSE)\n\n\n\n\n\n\n上記の場合にはデータはリスト形になっている. NAがあるとペンが外れるGISではよくあるプリミティブな形状で、 記述することができる。\n\n\nCode\nmapStates |&gt; str(1)\n#&gt; List of 4\n#&gt;  $ x    : num [1:15599] -87.5 -87.5 -87.5 -87.5 -87.6 ...\n#&gt;  $ y    : num [1:15599] 30.4 30.4 30.4 30.3 30.3 ...\n#&gt;  $ range: num [1:4] -124.7 -67 25.1 49.4\n#&gt;  $ names: chr [1:63] \"alabama\" \"arizona\" \"arkansas\" \"california\" ...\n#&gt;  - attr(*, \"class\")= chr \"map\"\n\n\n\n\n3 Formula interface\nRらしい記述を使うことが可能である.\n\n\nCode\nm = leaflet() %&gt;% addTiles()\ndf = data.frame(\n  lat = rnorm(100),\n  lng = rnorm(100),\n  size = runif(100, 5, 20),\n  color = sample(colors(), 100)\n)\nm = leaflet(df) %&gt;% addTiles()\nm %&gt;% addCircleMarkers(radius = ~size, color = ~color, fill = FALSE)\n#&gt; Assuming \"lng\" and \"lat\" are longitude and latitude, respectively\n\n\n\n\n\n\n\n\nCode\nm %&gt;% addCircleMarkers(radius = runif(100, 4, 10), color = c('red'))\n#&gt; Assuming \"lng\" and \"lat\" are longitude and latitude, respectively\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/website/leaflet4r/chapters/ch03_markers.html",
    "href": "contents/website/leaflet4r/chapters/ch03_markers.html",
    "title": "Markers",
    "section": "",
    "text": "Code\nlibrary(here)\nlibrary(shiny)\nlibrary(leaflet)\nlibrary(leafem)\nlibrary(htmltools)\nlibrary(htmlwidgets)\nlibrary(rjson)\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(stars)\nlibrary(glue)\nlibrary(knitr)"
  },
  {
    "objectID": "contents/website/leaflet4r/chapters/ch03_markers.html#customizing-marker-icons",
    "href": "contents/website/leaflet4r/chapters/ch03_markers.html#customizing-marker-icons",
    "title": "Markers",
    "section": "1.1 Customizing Marker Icons",
    "text": "1.1 Customizing Marker Icons\n\n\nCode\ngreenLeafIcon &lt;- makeIcon(\n  iconUrl = \"https://leafletjs.com/examples/custom-icons/leaf-green.png\",\n  iconWidth = 38, iconHeight = 95,\n  iconAnchorX = 22, iconAnchorY = 94,\n  shadowUrl = \"https://leafletjs.com/examples/custom-icons/leaf-shadow.png\",\n  shadowWidth = 50, shadowHeight = 64,\n  shadowAnchorX = 4, shadowAnchorY = 62\n)\n\nleaflet(data = quakes[1:4,]) %&gt;% addTiles() %&gt;%\n  addMarkers(~long, ~lat, icon = greenLeafIcon)\n\n\n\n\n\n\n\n\nCode\noceanIcons &lt;- iconList(\n  ship = makeIcon(\"ferry-18.png\", \"ferry-18@2x.png\", 18, 18),\n  pirate = makeIcon(\"danger-24.png\", \"danger-24@2x.png\", 24, 24)\n)\n\n# Some fake data\ndf &lt;- sp::SpatialPointsDataFrame(\n  cbind(\n    (runif(20) - .5) * 10 - 90.620130,  # lng\n    (runif(20) - .5) * 3.8 + 25.638077  # lat\n  ),\n  data.frame(type = factor(\n    ifelse(runif(20) &gt; 0.75, \"pirate\", \"ship\"),\n    c(\"ship\", \"pirate\")\n  ))\n)\n\nleaflet (df) |&gt; \n    addTiles() |&gt; \n    addMarkers(icon = ~ oceanIcons[type])"
  },
  {
    "objectID": "contents/website/leaflet4r/chapters/ch03_markers.html#marker-clusters",
    "href": "contents/website/leaflet4r/chapters/ch03_markers.html#marker-clusters",
    "title": "Markers",
    "section": "1.2 Marker Clusters",
    "text": "1.2 Marker Clusters\n\n\nCode\nleaflet(quakes) %&gt;% addTiles() %&gt;% addMarkers(\n  clusterOptions = markerClusterOptions()\n)\n#&gt; Assuming \"long\" and \"lat\" are longitude and latitude, respectively"
  },
  {
    "objectID": "contents/website/leaflet4r/chapters/ch05_lines_and_shapes.html",
    "href": "contents/website/leaflet4r/chapters/ch05_lines_and_shapes.html",
    "title": "Lines and Shapes",
    "section": "",
    "text": "Code\nlibrary(here)\nlibrary(shiny)\nlibrary(leaflet)\nlibrary(leafem)\nlibrary(htmltools)\nlibrary(htmlwidgets)\nlibrary(rjson)\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(stars)\nlibrary(glue)\nlibrary(knitr)\n\ndata_dir &lt;- here(\"contents/website/leaflet4r/data\")"
  },
  {
    "objectID": "contents/website/leaflet4r/chapters/ch05_lines_and_shapes.html#simplifying-complex-polygons",
    "href": "contents/website/leaflet4r/chapters/ch05_lines_and_shapes.html#simplifying-complex-polygons",
    "title": "Lines and Shapes",
    "section": "1.1 Simplifying complex polygons",
    "text": "1.1 Simplifying complex polygons\nデータが複雑が重たいときにはシンプリファイする必要がある.\nsimplified &lt;- rmapshaper::ms_simplify(fullsize)\nobject.size(simplified)"
  },
  {
    "objectID": "contents/website/leaflet4r/chapters/ch07_raster_images.html",
    "href": "contents/website/leaflet4r/chapters/ch07_raster_images.html",
    "title": "Raster Images",
    "section": "",
    "text": "Code\nlibrary(here)\nlibrary(shiny)\nlibrary(leaflet)\nlibrary(leafem)\nlibrary(htmltools)\nlibrary(htmlwidgets)\nlibrary(rjson)\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(stars)\nlibrary(terra)\nlibrary(glue)\nlibrary(knitr)\n\ndata_dir &lt;- here(\"contents/website/leaflet4r/data\")\n\n\n2次元のSpatRasterオブジェクトについては,addRasterImageにより表示することが可能である. 読み込んだラスターデータは,EPSGは3857に変換されるとともに, 各セルの値はRGBAに変換される.\n\n1 Large Raster\nterra::resampleを使って解像度を調整すること.\n\n\n2 Projection Performance\n大量のデータがある場合にはleaflet::projectRasterFroLeaflet を使って事前にデータを変換しておくのがよい.\nその上でaddRasterImageでproject=FALSEにしておく.\n\n\n3 Coloring\n色々できるという感じです.\n\n\n4 Example\n\n\nCode\nr &lt;- rast(here(data_dir, \"FG-GML-5339-05-DEM5A.tif\")) \n\npal &lt;- \n    colorNumeric(\n        c(\"#0C2C84\", \"#41B6C4\", \"#FFFFCC\"), \n        values(r),\n        na.color = \"transparent\")\n\nleaflet() |&gt; \n    addTiles() |&gt;\n    addRasterImage(r, colors = pal, opacity = .5) |&gt; \n    addLegend(\n        pal = pal, \n        values = values(r), \n        title = \"Surface terrain\"\n    )\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/website/leaflet4r/chapters/ch09_Colors.html",
    "href": "contents/website/leaflet4r/chapters/ch09_Colors.html",
    "title": "Colors",
    "section": "",
    "text": "Code\nlibrary(here)\nlibrary(shiny)\nlibrary(leaflet)\nlibrary(leafem)\nlibrary(htmltools)\nlibrary(htmlwidgets)\nlibrary(rjson)\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(stars)\nlibrary(terra)\nlibrary(glue)\nlibrary(knitr)\n\ndata_dir &lt;- here(\"contents/website/leaflet4r/data\")"
  },
  {
    "objectID": "contents/website/leaflet4r/chapters/ch09_Colors.html#coloring-continuous-data",
    "href": "contents/website/leaflet4r/chapters/ch09_Colors.html#coloring-continuous-data",
    "title": "Colors",
    "section": "2.1 Coloring continuous data",
    "text": "2.1 Coloring continuous data\n\n\nCode\ncountries &lt;- sf::st_read(\"https://rstudio.github.io/leaflet/json/countries.geojson\")\n#&gt; Reading layer `countries' from data source \n#&gt;   `https://rstudio.github.io/leaflet/json/countries.geojson' \n#&gt;   using driver `GeoJSON'\n#&gt; Simple feature collection with 177 features and 2 fields\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -180 ymin: -90 xmax: 180 ymax: 83.64513\n#&gt; Geodetic CRS:  WGS 84\nmap &lt;- leaflet(countries)\n\n\n\n\nCode\npar(mar = c(5,5,0,0), cex = 0.8)\nhist(countries$gdp_md_est, breaks = 20, main = \"\")\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Create a continuous palette function\npal &lt;- colorNumeric(\n  palette = \"Blues\",\n  domain = countries$gdp_md_est)\n\n# Apply the function to provide RGB colors to addPolygons\nmap %&gt;%\n  addPolygons(stroke = FALSE, smoothFactor = 0.2, fillOpacity = 1,\n    color = ~pal(gdp_md_est))\n\n\n\n\n\n\n\n\nCode\nbinpal &lt;- colorBin(\"Blues\", countries$gdp_md_est, 6, pretty = FALSE)\n\nmap %&gt;%\n  addPolygons(stroke = FALSE, smoothFactor = 0.2, fillOpacity = 1,\n    color = ~binpal(gdp_md_est))\n\n\n\n\n\n\n\n\nCode\nqpal &lt;- colorQuantile(\"Blues\", countries$gdp_md_est, n = 7)\nmap %&gt;%\n  addPolygons(stroke = FALSE, smoothFactor = 0.2, fillOpacity = 1,\n    color = ~qpal(gdp_md_est))"
  },
  {
    "objectID": "contents/website/leaflet4r/chapters/ch09_Colors.html#coloring-categorical-data",
    "href": "contents/website/leaflet4r/chapters/ch09_Colors.html#coloring-categorical-data",
    "title": "Colors",
    "section": "2.2 Coloring categorical data",
    "text": "2.2 Coloring categorical data\n\n\nCode\n# Make up some random levels. (TODO: Better example)\ncountries$category &lt;- factor(sample.int(5L, nrow(countries), TRUE))\n\nfactpal &lt;- colorFactor(topo.colors(5), countries$category)\n\nleaflet(countries) %&gt;%\n  addPolygons(stroke = FALSE, smoothFactor = 0.2, fillOpacity = 1,\n    color = ~factpal(category))"
  },
  {
    "objectID": "contents/website/leaflet4r/chapters/ch11_show_hide_layers.html",
    "href": "contents/website/leaflet4r/chapters/ch11_show_hide_layers.html",
    "title": "Show/Hide Layers",
    "section": "",
    "text": "Code\nlibrary(here)\nlibrary(shiny)\nlibrary(leaflet)\nlibrary(leafem)\nlibrary(htmltools)\nlibrary(htmlwidgets)\nlibrary(rjson)\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(stars)\nlibrary(terra)\nlibrary(glue)\nlibrary(knitr)\n\ndata_dir &lt;- here(\"contents/website/leaflet4r/data\")"
  },
  {
    "objectID": "contents/website/leaflet4r/chapters/ch11_show_hide_layers.html#interactive-layer-display",
    "href": "contents/website/leaflet4r/chapters/ch11_show_hide_layers.html#interactive-layer-display",
    "title": "Show/Hide Layers",
    "section": "1.1 Interactive Layer Display",
    "text": "1.1 Interactive Layer Display\n\n\nCode\noutline &lt;- quakes[chull(quakes$long, quakes$lat),]\n\nmap &lt;- leaflet(quakes) %&gt;%\n  # Base groups\n  addTiles(group = \"OSM (default)\") %&gt;%\n  addProviderTiles(providers$Stamen.Toner, group = \"Toner\") %&gt;%\n  addProviderTiles(providers$Stamen.TonerLite, group = \"Toner Lite\") %&gt;%\n  # Overlay groups\n  addCircles(~long, ~lat, ~10^mag/5, stroke = F, group = \"Quakes\") %&gt;%\n  addPolygons(data = outline, lng = ~long, lat = ~lat,\n    fill = F, weight = 2, color = \"#FFFFCC\", group = \"Outline\") %&gt;%\n  # Layers control\n  addLayersControl(\n    baseGroups = c(\"OSM (default)\", \"Toner\", \"Toner Lite\"),\n    overlayGroups = c(\"Quakes\", \"Outline\"),\n    options = layersControlOptions(collapsed = FALSE)\n  )\nmap"
  },
  {
    "objectID": "contents/website/leaflet4r/chapters/ch11_show_hide_layers.html#programmatic-layer-display",
    "href": "contents/website/leaflet4r/chapters/ch11_show_hide_layers.html#programmatic-layer-display",
    "title": "Show/Hide Layers",
    "section": "1.2 Programmatic Layer Display",
    "text": "1.2 Programmatic Layer Display\nshowGroupやhideGroupを使うことでレイヤーの表示、 非表示をプログラムから管理することが可能となる.\nこれは特にShinyから操作するときに意味を持つ.\n\n\nCode\nmap %&gt;% hideGroup(\"Outline\")"
  },
  {
    "objectID": "contents/website/leaflet4r/chapters/ch13_projection.html",
    "href": "contents/website/leaflet4r/chapters/ch13_projection.html",
    "title": "Projections",
    "section": "",
    "text": "Code\nlibrary(here)\nlibrary(shiny)\nlibrary(leaflet)\nlibrary(leafem)\nlibrary(htmltools)\nlibrary(htmlwidgets)\nlibrary(rjson)\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(stars)\nlibrary(terra)\nlibrary(glue)\nlibrary(knitr)\n\ndata_dir &lt;- here(\"contents/website/leaflet4r/data\")\n\n\nleafletではWGS84で特定できる座標値であることが期待されている. 標準では, 3857で表示される. その他の座標系で表示させたいときには Proj4Leafletプラグインを組み込む必要がある.\n\n1 Defining a custom CRS\n\n\nCode\ncrs &lt;- leafletCRS(crsClass = \"L.Proj.CRS\", code = \"ESRI:102003\",\n  proj4def = \"+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=37.5 +lon_0=-96 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs\",\n  resolutions = 1.5^(25:15))\n\n\n\n\n2 Dsiplaying basemap tiles with cusotm projections\nbasemapが対応していないのでレンダリングが出来ない.\n\n\nCode\n\nepsg3006 &lt;- leafletCRS(crsClass = \"L.Proj.CRS\", code = \"EPSG:3006\",\n  proj4def = \"+proj=utm +zone=33 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs\",\n  resolutions = 2^(13:-1), # 8192 down to 0.5\n  origin = c(0, 0)\n)\n\ntile_url &lt;- \"http://api.geosition.com/tile/osm-bright-3006/{z}/{x}/{y}.png\"\ntile_attrib &lt;- \"Map data &copy; &lt;a href='http://www.openstreetmap.org/copyright'&gt;OpenStreetMap contributors&lt;/a&gt;, Imagery &copy; 2013 &lt;a href='http://www.kartena.se/'&gt;Kartena&lt;/a&gt;\"\n\nleaflet(options = leafletOptions(worldCopyJump = F, crs = epsg3006)) %&gt;%\n  setView(11.965053, 57.70451, 13) %&gt;%\n  addTiles(urlTemplate = tile_url,\n    attribution = tile_attrib,\n    options = tileOptions(minZoom = 0, maxZoom = 14, continuousWorld = T)) %&gt;%\n  addMarkers(11.965053, 57.70451)\n\n\n\n\n\n\n\n\nCode\nleaflet() %&gt;%\n  setView(11.965053, 57.70451, 16) %&gt;%\n  addTiles() %&gt;%\n  addMarkers(11.965053, 57.70451)\n\n\n\n\n\n\n\n\n3 Displaying shapes with cusotm projections\n\n\nCode\nlibrary(sp)\nlibrary(albersusa)\n#&gt; Please note that 'maptools' will be retired during October 2023,\n#&gt; plan transition at your earliest convenience (see\n#&gt; https://r-spatial.org/r/2023/05/15/evolution4.html and earlier blogs\n#&gt; for guidance);some functionality will be moved to 'sp'.\n#&gt;  Checking rgeos availability: TRUE\n#&gt; Please note that rgdal will be retired during October 2023,\n#&gt; plan transition to sf/stars/terra functions using GDAL and PROJ\n#&gt; at your earliest convenience.\n#&gt; See https://r-spatial.org/r/2023/05/15/evolution4.html and https://github.com/r-spatial/evolution\n#&gt; rgdal: version: 1.6-7, (SVN revision 1203)\n#&gt; Geospatial Data Abstraction Library extensions to R successfully loaded\n#&gt; Loaded GDAL runtime: GDAL 3.6.2, released 2023/01/02\n#&gt; Path to GDAL shared files: H:/R_USER/R/win-library/4.3/rgdal/gdal\n#&gt;  GDAL does not use iconv for recoding strings.\n#&gt; GDAL binary built with GEOS: TRUE \n#&gt; Loaded PROJ runtime: Rel. 9.2.0, March 1st, 2023, [PJ_VERSION: 920]\n#&gt; Path to PROJ shared files: C:\\Program Files\\PostgreSQL\\12\\share\\contrib\\postgis-3.1\\proj\n#&gt; PROJ CDN enabled: FALSE\n#&gt; Linking to sp version:1.6-1\n#&gt; To mute warnings of possible GDAL/OSR exportToProj4() degradation,\n#&gt; use options(\"rgdal_show_exportToProj4_warnings\"=\"none\") before loading sp or rgdal.\n#&gt; rgeos version: 0.6-3, (SVN revision 696)\n#&gt;  GEOS runtime version: 3.11.2-CAPI-1.17.2 \n#&gt;  Please note that rgeos will be retired during October 2023,\n#&gt; plan transition to sf or terra functions using GEOS at your earliest convenience.\n#&gt; See https://r-spatial.org/r/2023/05/15/evolution4.html for details.\n#&gt;  GEOS using OverlayNG\n#&gt;  Linking to sp version: 2.0-0 \n#&gt;  Polygon checking: TRUE\n\nspdf &lt;- rmapshaper::ms_simplify(usa_sf(), keep = 0.1)\n#&gt; old-style crs object detected; please recreate object with a recent sf::st_crs()\npal &lt;- colorNumeric(\"Blues\", domain = spdf$pop_2014)\nepsg2163 &lt;- leafletCRS(\n  crsClass = \"L.Proj.CRS\",\n  code = \"EPSG:2163\",\n  proj4def = \"+proj=laea +lat_0=45 +lon_0=-100 +x_0=0 +y_0=0 +a=6370997 +b=6370997 +units=m +no_defs\",\n  resolutions = 2^(16:7))\n\nleaflet(spdf, options = leafletOptions(crs = epsg2163)) %&gt;%\n  addPolygons(weight = 1, color = \"#444444\", opacity = 1,\n    fillColor = ~pal(pop_2014), fillOpacity = 0.7, smoothFactor = 0.5,\n    label = ~paste(name, pop_2014),\n    labelOptions = labelOptions(direction = \"auto\"))\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/website/analizeUSCensus/ch07_spatial_analysis_with_us_census_data.html",
    "href": "contents/website/analizeUSCensus/ch07_spatial_analysis_with_us_census_data.html",
    "title": "Spatial analysis with US Census data",
    "section": "",
    "text": "Code\nrenv::activate(here::here())\nCode\nlibrary(here)\nlibrary(tidyverse)\nlibrary(tidycensus)\nlibrary(tigris)\nlibrary(sf)\nlibrary(mapview)\n\ncur_dir &lt;- here()\noptions(tigris_use_cache = TRUE)"
  },
  {
    "objectID": "contents/website/analizeUSCensus/ch07_spatial_analysis_with_us_census_data.html#idenfifying-eometrices-within-a-metropolitan-area",
    "href": "contents/website/analizeUSCensus/ch07_spatial_analysis_with_us_census_data.html#idenfifying-eometrices-within-a-metropolitan-area",
    "title": "Spatial analysis with US Census data",
    "section": "1.1 Idenfifying eometrices within a metropolitan area",
    "text": "1.1 Idenfifying eometrices within a metropolitan area\ntigrisから2020年のデータを取得して処理する事例を試す.\n\n\nCode\nks_mo_tracts &lt;- \n    map_dfr(c(\"KS\", \"MO\"), \\(x) {\n        tracts(x, cb = TRUE, year = 2020)\n    }) |&gt; \n    st_transform(8528)\n\nkc_metro &lt;- \n    core_based_statistical_areas(cb = TRUE, year = 2020) |&gt; \n    filter(str_detect(NAME, \"Kansas City\")) |&gt; \n    st_transform(8528)\n\nggplot() + \n    geom_sf(data = ks_mo_tracts, fill = \"white\", color = \"grey\") + \n    geom_sf(data = kc_metro, fill = NA, color = \"red\") + \n    theme_void()"
  },
  {
    "objectID": "contents/website/analizeUSCensus/ch07_spatial_analysis_with_us_census_data.html#spatial-subsets",
    "href": "contents/website/analizeUSCensus/ch07_spatial_analysis_with_us_census_data.html#spatial-subsets",
    "title": "Spatial analysis with US Census data",
    "section": "1.2 Spatial Subsets",
    "text": "1.2 Spatial Subsets\nSpatial Subsettinghはデータのextentを使う. Spatial predicateが 定義されていることにより、空間部分集合はインデックス記法で記述することが可能である.\n\n\nCode\nkc_tracts &lt;- ks_mo_tracts[kc_metro, ]\n\nggplot() + \n    geom_sf(data = kc_tracts, fill = \"white\", color = \"grey\") + \n    geom_sf(data = kc_metro, fill =NA, color = \"red\") + \n    theme_void()\n\n\n\n\n\n\n\n\n\n上記で抽出対象となるのはinterects演算によるものである.\n\n\n\n\n\n\nNote\n\n\n\nintersectsは交差判定だけなので高速で演算できる. 交差集合を算出するintersectionはそれなりに時間を要する.\n\n\n一般的にはCensusデータ分析において、 あたえた都市領域からデータを抽出する債にはst_withinを使うことが求められる。\n\n\nCode\n# 前述の記法と同じ内容\nkc_tracts_within &lt;- \n    ks_mo_tracts |&gt; \n    st_filter(kc_metro, .predicate = st_within) \n\n\nggplot() + \n    geom_sf(data = kc_tracts_within, fill = \"white\", color = \"grey\") + \n    geom_sf(data = kc_metro, fill =NA, color = \"red\") + \n    theme_void()"
  },
  {
    "objectID": "contents/website/analizeUSCensus/ch07_spatial_analysis_with_us_census_data.html#point-in-polygon",
    "href": "contents/website/analizeUSCensus/ch07_spatial_analysis_with_us_census_data.html#point-in-polygon",
    "title": "Spatial analysis with US Census data",
    "section": "2.1 Point in polygon",
    "text": "2.1 Point in polygon\n\n\nCode\nlibrary(mapview)\n\ngainesville_patients &lt;- tibble(\n  patient_id = 1:10,\n  longitude = c(-82.308131, -82.311972, -82.361748, -82.374377, \n                -82.38177, -82.259461, -82.367436, -82.404031, \n                -82.43289, -82.461844),\n  latitude = c(29.645933, 29.655195, 29.621759, 29.653576, \n               29.677201, 29.674923, 29.71099, 29.711587, \n               29.648227, 29.624037)\n)\n\n\n上記のデータをst_as_sfで地理空間データに変換する. これならポイントのテーブルデータを簡単にGISデータに変換することが可能ですね.\n\n\nCode\ngainesville_sf &lt;- \n    gainesville_patients |&gt; \n    st_as_sf(\n        coords = c(\"longitude\", \"latitude\"), \n        crs = 4326\n    ) |&gt; \n    st_transform(6440)\n\ngainesville_sf\n#&gt; Simple feature collection with 10 features and 1 field\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: 797379.2 ymin: 70862.57 xmax: 816865.2 ymax: 80741.87\n#&gt; Projected CRS: NAD83(2011) / Florida North\n#&gt; # A tibble: 10 × 2\n#&gt;    patient_id            geometry\n#&gt;  *      &lt;int&gt;         &lt;POINT [m]&gt;\n#&gt;  1          1 (812216.7 73640.25)\n#&gt;  2          2 (811825.2 74659.57)\n#&gt;  3          3 (807076.4 70862.57)\n#&gt;  4          4 (805787.7 74365.85)\n#&gt;  5          5  (805023.4 76970.8)\n#&gt;  6          6 (816865.2 76944.63)\n#&gt;  7          7 (806340.6 80741.36)\n#&gt;  8          8   (802799 80741.87)\n#&gt;  9          9 (800134.3 73668.88)\n#&gt; 10         10 (797379.2 70937.49)\n\n\nspatial datasetに変換できたので、 地図上に載せることが可能となる.\n\n\nCode\nmapview(\n    gainesville_sf, \n    col.regions = \"red\", \n    legend = FALSE\n)\n\n\n\n\n\n\n\nポイントが準備できたので、healthデータを準備する.\n\n\nCode\nalachua_insurance &lt;- get_acs(\n  geography = \"tract\",\n  variables = \"DP03_0096P\",\n  state = \"FL\",\n  county = \"Alachua\",\n  year = 2019,\n  geometry = TRUE\n) %&gt;%\n  select(GEOID, pct_insured = estimate, \n         pct_insured_moe = moe) %&gt;%\n  st_transform(6440)\n#&gt; Getting data from the 2015-2019 5-year ACS\n#&gt; Warning: • You have not set a Census API key. Users without a key are limited to 500\n#&gt; queries per day and may experience performance limitations.\n#&gt; ℹ For best results, get a Census API key at\n#&gt; http://api.census.gov/data/key_signup.html and then supply the key to the\n#&gt; `census_api_key()` function to use it throughout your tidycensus session.\n#&gt; This warning is displayed once per session.\n#&gt; Using the ACS Data Profile\n\n\n上記で得られたデータを紐付ける前に、一度地図上で空間関係を確認する.\n\n\nCode\nmapview(\n    alachua_insurance, \n    zcol = \"pct_insured\", \n    layer.name = \"% with health &lt;br/&gt;insurance\"\n) + \n    mapview(\n        gainesville_sf, \n        col.regions = \"red\", \n        legend = FALSE\n    )\n\n\n\n\n\n\n\nmap上ならば関係性が明らかである. これをデータとして紐付ける.\n\n\nCode\npatients_joined &lt;- \n    st_join(\n        gainesville_sf, \n        alachua_insurance\n    )\n\npatients_joined\n#&gt; Simple feature collection with 10 features and 4 fields\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: 797379.2 ymin: 70862.57 xmax: 816865.2 ymax: 80741.87\n#&gt; Projected CRS: NAD83(2011) / Florida North\n#&gt; # A tibble: 10 × 5\n#&gt;    patient_id            geometry GEOID       pct_insured pct_insured_moe\n#&gt;  *      &lt;int&gt;         &lt;POINT [m]&gt; &lt;chr&gt;             &lt;dbl&gt;           &lt;dbl&gt;\n#&gt;  1          1 (812216.7 73640.25) 12001000700        81.6             7  \n#&gt;  2          2 (811825.2 74659.57) 12001000500        91               5.1\n#&gt;  3          3 (807076.4 70862.57) 12001001515        85.2             6.2\n#&gt;  4          4 (805787.7 74365.85) 12001001603        88.3             5.1\n#&gt;  5          5  (805023.4 76970.8) 12001001100        96.2             2.7\n#&gt;  6          6 (816865.2 76944.63) 12001001902        86               5.9\n#&gt;  7          7 (806340.6 80741.36) 12001001803        92.3             4  \n#&gt;  8          8   (802799 80741.87) 12001001813        97.9             1.4\n#&gt;  9          9 (800134.3 73668.88) 12001002207        95.7             2.4\n#&gt; 10         10 (797379.2 70937.49) 12001002205        96.5             1.6"
  },
  {
    "objectID": "contents/website/analizeUSCensus/ch07_spatial_analysis_with_us_census_data.html#spatial-joins-and-group-wise-spatial-analysis",
    "href": "contents/website/analizeUSCensus/ch07_spatial_analysis_with_us_census_data.html#spatial-joins-and-group-wise-spatial-analysis",
    "title": "Spatial analysis with US Census data",
    "section": "2.2 Spatial joins and group-wise spatial analysis",
    "text": "2.2 Spatial joins and group-wise spatial analysis\nポリゴン対ポリゴンの空間結合を行う. ポイント対ポリゴンについては明確であるが、新しい概念であるこの結合では 使用する空間述語には十分に注意すること。\n\n\nCode\ntx_cbsa &lt;- get_acs(\n  geography = \"cbsa\",\n  variables = \"B01003_001\",\n  year = 2019,\n  survey = \"acs1\",\n  geometry = TRUE\n) %&gt;%\n  filter(str_detect(NAME, \"TX\")) %&gt;%\n  slice_max(estimate, n = 4) %&gt;%\n  st_transform(6579)\n#&gt; Getting data from the 2019 1-year ACS\n#&gt; The 1-year ACS provides data for geographies with populations of 65,000 and greater.\n\n\n\n\nCode\npct_hispanic &lt;- get_acs(\n  geography = \"tract\",\n  variables = \"DP05_0071P\",\n  state = \"TX\",\n  year = 2019,\n  geometry = TRUE\n) %&gt;%\n  st_transform(6579)\n#&gt; Getting data from the 2015-2019 5-year ACS\n#&gt; Using the ACS Data Profile\n\n\n上記のデータを結合する. left = FALSEにすることで内部欠尾久になる. つまり, 返値は4つの都市圏に含まれる場合のみが返される.\n\n\nCode\nhispanic_by_metro &lt;- st_join(\n    pct_hispanic, \n    tx_cbsa, \n    join = st_within , \n    suffix = c(\"_tracs\", \"_metro\"), \n    left = FALSE\n)\n\nhispanic_by_metro\n#&gt; Simple feature collection with 3189 features and 10 fields\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: 1538292 ymin: 7167200 xmax: 2045975 ymax: 7705975\n#&gt; Projected CRS: NAD83(2011) / Texas Centric Albers Equal Area\n#&gt; First 10 features:\n#&gt;    GEOID_tracs                                 NAME_tracs variable_tracs\n#&gt; 1  48113019204  Census Tract 192.04, Dallas County, Texas     DP05_0071P\n#&gt; 3  48029190601  Census Tract 1906.01, Bexar County, Texas     DP05_0071P\n#&gt; 8  48201311900    Census Tract 3119, Harris County, Texas     DP05_0071P\n#&gt; 9  48113015500     Census Tract 155, Dallas County, Texas     DP05_0071P\n#&gt; 11 48439102000   Census Tract 1020, Tarrant County, Texas     DP05_0071P\n#&gt; 13 48201450200    Census Tract 4502, Harris County, Texas     DP05_0071P\n#&gt; 14 48201450400    Census Tract 4504, Harris County, Texas     DP05_0071P\n#&gt; 22 48157670300 Census Tract 6703, Fort Bend County, Texas     DP05_0071P\n#&gt; 25 48201554502 Census Tract 5545.02, Harris County, Texas     DP05_0071P\n#&gt; 27 48121020503  Census Tract 205.03, Denton County, Texas     DP05_0071P\n#&gt;    estimate_tracs moe_tracs GEOID_metro\n#&gt; 1            58.1       5.7       19100\n#&gt; 3            86.2       6.7       41700\n#&gt; 8            84.9       5.8       26420\n#&gt; 9            56.6       7.5       19100\n#&gt; 11           15.7       6.4       19100\n#&gt; 13           10.7       3.9       26420\n#&gt; 14           26.8      13.1       26420\n#&gt; 22           27.0       5.8       26420\n#&gt; 25           13.4       3.0       26420\n#&gt; 27           35.3       8.7       19100\n#&gt;                                         NAME_metro variable_metro\n#&gt; 1       Dallas-Fort Worth-Arlington, TX Metro Area     B01003_001\n#&gt; 3         San Antonio-New Braunfels, TX Metro Area     B01003_001\n#&gt; 8  Houston-The Woodlands-Sugar Land, TX Metro Area     B01003_001\n#&gt; 9       Dallas-Fort Worth-Arlington, TX Metro Area     B01003_001\n#&gt; 11      Dallas-Fort Worth-Arlington, TX Metro Area     B01003_001\n#&gt; 13 Houston-The Woodlands-Sugar Land, TX Metro Area     B01003_001\n#&gt; 14 Houston-The Woodlands-Sugar Land, TX Metro Area     B01003_001\n#&gt; 22 Houston-The Woodlands-Sugar Land, TX Metro Area     B01003_001\n#&gt; 25 Houston-The Woodlands-Sugar Land, TX Metro Area     B01003_001\n#&gt; 27      Dallas-Fort Worth-Arlington, TX Metro Area     B01003_001\n#&gt;    estimate_metro moe_metro                       geometry\n#&gt; 1         7573136        NA MULTIPOLYGON (((1801563 765...\n#&gt; 3         2550960        NA MULTIPOLYGON (((1642736 726...\n#&gt; 8         7066140        NA MULTIPOLYGON (((1950592 729...\n#&gt; 9         7573136        NA MULTIPOLYGON (((1778712 763...\n#&gt; 11        7573136        NA MULTIPOLYGON (((1746016 762...\n#&gt; 13        7066140        NA MULTIPOLYGON (((1925521 730...\n#&gt; 14        7066140        NA MULTIPOLYGON (((1922292 730...\n#&gt; 22        7066140        NA MULTIPOLYGON (((1935603 728...\n#&gt; 25        7066140        NA MULTIPOLYGON (((1918552 732...\n#&gt; 27        7573136        NA MULTIPOLYGON (((1766859 768...\n\n\n\n\nCode\nhispanic_by_metro %&gt;%\n  mutate(NAME_metro = str_replace(\n      NAME_metro, \n      \", TX Metro Area\", \n      \"\")) %&gt;%\n  ggplot() + \n  geom_density(\n      aes(x = estimate_tracs), \n      color = \"navy\", \n      fill = \"navy\", \n      alpha = 0.4) + \n  theme_minimal() + \n  facet_wrap(~NAME_metro) + \n  labs(title = \"Distribution of Hispanic/Latino population by Census tract\",\n       subtitle = \"Largest metropolitan areas in Texas\",\n       y = \"Kernel density estimate\",\n       x = \"Percent Hispanic/Latino in Census tract\")\n#&gt; Warning: Removed 9 rows containing non-finite values (`stat_density()`).\n\n\n\n\n\n\n\n\n\nグループWiseなデータ分析を通じて、 より大きな地物としてrolled upされることになる。\n\n\nCode\nmedian_by_metro &lt;- \n  hispanic_by_metro %&gt;%\n  group_by(NAME_metro) %&gt;%\n  summarize(median_hispanic = median(estimate_tracs, na.rm = TRUE))\n\nmedian_by_metro\n#&gt; Simple feature collection with 4 features and 2 fields\n#&gt; Geometry type: GEOMETRY\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: 1538292 ymin: 7167200 xmax: 2045975 ymax: 7705975\n#&gt; Projected CRS: NAD83(2011) / Texas Centric Albers Equal Area\n#&gt; # A tibble: 4 × 3\n#&gt;   NAME_metro                           median_hispanic                  geometry\n#&gt;   &lt;chr&gt;                                          &lt;dbl&gt;            &lt;GEOMETRY [m]&gt;\n#&gt; 1 Austin-Round Rock-Georgetown, TX Me…            25.9 POLYGON ((1700741 730245…\n#&gt; 2 Dallas-Fort Worth-Arlington, TX Met…            22.6 POLYGON ((1737530 756507…\n#&gt; 3 Houston-The Woodlands-Sugar Land, T…            32.4 MULTIPOLYGON (((1901162 …\n#&gt; 4 San Antonio-New Braunfels, TX Metro…            53.5 POLYGON ((1619499 717051…\n\n\n\n\nCode\nplot(median_by_metro |&gt; slice(1) |&gt; pull(geometry))"
  },
  {
    "objectID": "contents/website/analizeUSCensus/ch07_spatial_analysis_with_us_census_data.html#area-weighted-areal-interpolation",
    "href": "contents/website/analizeUSCensus/ch07_spatial_analysis_with_us_census_data.html#area-weighted-areal-interpolation",
    "title": "Spatial analysis with US Census data",
    "section": "3.1 Area-weighted areal interpolation",
    "text": "3.1 Area-weighted areal interpolation\nst_interploate_awを使うことで, Area-weightd areal interpolationを 実施することが可能となる. つまり、「面積加重の面内補間」である。\nwfh15の値をwfh_20の大きさに補間する処理をしている.\n\n\nCode\nwfh_interpolate_aw &lt;- st_interpolate_aw(\n  wfh_15,\n  wfh_20,\n  extensive = TRUE\n) %&gt;%\n  mutate(GEOID = wfh_20$GEOID)\n\n\n\n\nCode\nmapview(wfh_interpolate_aw)\n\n\n\n\n\n\n\n上記の処理方法に対して、Census blocksを利用した例を考える. これにはst_interploate_pwを使う。これにより面積以外の情報を考慮した 回帰をおこなうことが可能となる. ここれでは人口を表す国勢調査ブロックを 重みとした例を計算する\ntidycensusのなかにもinterpolate_pwが実装されている。\n\n\nCode\nmaricopa_blocks &lt;- blocks(\n  state = \"AZ\",\n  county = \"Maricopa\",\n  year = 2020\n)\n\nwfh_interpolate_pw &lt;- interpolate_pw(\n  wfh_15,\n  wfh_20,\n  to_id = \"GEOID\",\n  extensive = TRUE, \n  weights = maricopa_blocks,\n  weight_column = \"POP20\",\n  crs = 26949\n)\n\n\nデータの形状が2020に統一されたので、left_joinにより データの結合が可能となる.\n\n\nCode\nlibrary(mapboxapi)\n#&gt; Usage of the Mapbox APIs is governed by the Mapbox Terms of Service.\n#&gt; Please visit https://www.mapbox.com/legal/tos/ for more information.\n\nwfh_shift &lt;- \n    wfh_20 %&gt;%\n    left_join(\n        st_drop_geometry(wfh_interpolate_pw), \n        by = \"GEOID\",\n        suffix = c(\"_2020\", \"_2015\")) %&gt;%\n    mutate(wfh_shift = estimate_2020 - estimate_2015)\n\n# maricopa_basemap &lt;- layer_static_mapbox(\n#   location = wfh_shift,\n#   style_id = \"dark-v9\",\n#   username = \"mapbox\"\n# )\n\nggplot() + \n  # maricopa_basemap + \n  geom_sf(\n      data = wfh_shift, \n      aes(fill = wfh_shift), \n      color = NA, \n      alpha = 0.8) + \n  scale_fill_distiller(palette = \"PuOr\", direction = -1) + \n  labs(fill = \"Shift, 2011-2015 to\\n2016-2020 ACS\",\n       title = \"Change in work-from-home population\",\n       subtitle = \"Maricopa County, Arizona\") + \n  theme_void()\n\n\n\n\n\n\n\n\n\n一応、ブロック形状を面的補間したデータについて数値を確認する.\n\n\nCode\nwfh_interpolate_pw$estimate |&gt; sum()\n#&gt; [1] 105836\n\n\n\n\nCode\nwfh_15$estimate |&gt; sum()\n#&gt; [1] 105836"
  },
  {
    "objectID": "contents/website/analizeUSCensus/ch07_spatial_analysis_with_us_census_data.html#catchment-areas",
    "href": "contents/website/analizeUSCensus/ch07_spatial_analysis_with_us_census_data.html#catchment-areas",
    "title": "Spatial analysis with US Census data",
    "section": "4.1 Catchment areas",
    "text": "4.1 Catchment areas\n到達圏分析も行うことができる.\n\n\nCode\niowa_methodist &lt;- filter(ia_trauma, ID == \"0009850308\")\n\nbuf5km &lt;- st_buffer(iowa_methodist, dist = 5000) \n\n\niso10min &lt;- mb_isochrone(\n  iowa_methodist, \n  time = 10, \n  profile = \"driving-traffic\"\n)\nwrite_rds(iso10min, here(cur_dir, \"output\", \"ch07_iso10min.rds\"))\n\n\nCode\nlibrary(leaflet)\nlibrary(leafsync)\niso10min &lt;- read_rds(here(cur_dir, \"output\", \"ch07_iso10min.rds\"))\nhospital_icon &lt;- makeAwesomeIcon(icon = \"ios-medical\", \n                                 markerColor = \"red\",\n                                 library = \"ion\")\n\n# The Leaflet package requires data be in CRS 4326\nmap1 &lt;- leaflet() %&gt;% \n  addTiles() %&gt;%\n  addPolygons(data = st_transform(buf5km, 4326)) %&gt;% \n  addAwesomeMarkers(data = st_transform(iowa_methodist, 4326),\n                    icon = hospital_icon)\n\nmap2 &lt;- leaflet() %&gt;% \n  addTiles() %&gt;%\n  addPolygons(data = iso10min) %&gt;% \n  addAwesomeMarkers(data = st_transform(iowa_methodist, 4326),\n                    icon = hospital_icon)\n\nsync(map1, map2)"
  },
  {
    "objectID": "contents/website/analizeUSCensus/ch07_spatial_analysis_with_us_census_data.html#computing-demographic-estimates-for-zones-with-areal-interpolation",
    "href": "contents/website/analizeUSCensus/ch07_spatial_analysis_with_us_census_data.html#computing-demographic-estimates-for-zones-with-areal-interpolation",
    "title": "Spatial analysis with US Census data",
    "section": "4.2 Computing demographic estimates for zones with areal interpolation",
    "text": "4.2 Computing demographic estimates for zones with areal interpolation\n\n\nCode\npolk_poverty &lt;- get_acs(\n  geography = \"block group\",\n  variables = c(poverty_denom = \"B17010_001\",\n                poverty_num = \"B17010_002\"),\n  state = \"IA\",\n  county = \"Polk\",\n  geometry = TRUE,\n  output = \"wide\",\n  year = 2020\n) %&gt;%\n  select(poverty_denomE, poverty_numE) %&gt;%\n  st_transform(26975)\n#&gt; Getting data from the 2016-2020 5-year ACS\n\n\n\n\nCode\nlibrary(glue)\n\npolk_blocks &lt;- blocks(\n  state = \"IA\",\n  county = \"Polk\",\n  year = 2020\n)\n\nbuffer_pov &lt;- interpolate_pw(\n  from = polk_poverty, \n  to = buf5km,\n  extensive = TRUE,\n  weights = polk_blocks,\n  weight_column = \"POP20\",\n  crs = 26975\n) %&gt;%\n  mutate(pct_poverty = 100 * (poverty_numE / poverty_denomE))\n\niso_pov &lt;- interpolate_pw(\n  from = polk_poverty, \n  to = iso10min,\n  extensive = TRUE,\n  weights = polk_blocks,\n  weight_column = \"POP20\",\n  crs = 26975\n) %&gt;%\n  mutate(pct_poverty = 100 * (poverty_numE / poverty_denomE))"
  },
  {
    "objectID": "contents/website/analizeUSCensus/ch07_spatial_analysis_with_us_census_data.html#understanding-spatial-neighborhoods",
    "href": "contents/website/analizeUSCensus/ch07_spatial_analysis_with_us_census_data.html#understanding-spatial-neighborhoods",
    "title": "Spatial analysis with US Census data",
    "section": "6.1 Understanding spatial neighborhoods",
    "text": "6.1 Understanding spatial neighborhoods\n隣接は空間データ分析において非常に重要な概念である. 探索空間データ分析に向いているのはspdepである.\n隣接の概念には次の３つがある.\n\n6.1.1 距離に基づく隣接性（Proximity-based neighbors）：\n隣接するフィーチャーは、何らかの距離の基準に基づいて識別されます。隣接するものとして定義されるのは、与えられた距離のしきい値内にあるもの（例：与えられたフィーチャーから2km以内のすべてのフィーチャー）や、k-最近傍法（例：与えられたフィーチャーに最も近い8つのフィーチャー）です。\n\n\n6.1.2 グラフに基づく隣接性（Graph-based neighbors）：\n隣接関係はネットワーク関係（例：通りのネットワーク沿い）を通じて定義されます。\n\n\n6.1.3 接触に基づく隣接性（Contiguity-based neighbors）：\n地理的なフィーチャーが多角形の場合に使用されます。接触に基づく空間関係のオプションには、クイーンケースの隣接性が含まれ、少なくとも1つの頂点を共有するすべての多角形が隣接とみなされます。また、ルークケースの隣接性もあり、多角形が少なくとも1つの線分を共有する必要があります。"
  },
  {
    "objectID": "contents/website/analizeUSCensus/ch07_spatial_analysis_with_us_census_data.html#example",
    "href": "contents/website/analizeUSCensus/ch07_spatial_analysis_with_us_census_data.html#example",
    "title": "Spatial analysis with US Census data",
    "section": "6.2 Example",
    "text": "6.2 Example\n「queen’s case」」とは２つの多角形が少なくとも１つの頂点を共有している場合に、それらを隣接と見なす方法である。つまり、クイーンケースでは多角形が辺を共有しちえるだけでなく、各（頂点）のみで触れている場合でも隣接しているとみなす。\n\n\nCode\nneighbors &lt;- poly2nb(dfw_tracts, queen = TRUE)\n\nsummary(neighbors)\n#&gt; Neighbour list object:\n#&gt; Number of regions: 1699 \n#&gt; Number of nonzero links: 10930 \n#&gt; Percentage nonzero weights: 0.378646 \n#&gt; Average number of links: 6.433196 \n#&gt; Link number distribution:\n#&gt; \n#&gt;   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17 \n#&gt;   8  52 172 305 396 343 218 112  44  29  11   5   2   1   1 \n#&gt; 8 least connected regions:\n#&gt; 59 438 470 763 1163 1305 1365 1524 with 2 links\n#&gt; 1 most connected region:\n#&gt; 1101 with 17 links\n\n\n\n\nCode\ndfw_coords &lt;- dfw_tracts %&gt;%\n  st_centroid() %&gt;%\n  st_coordinates()\n#&gt; Warning: st_centroid assumes attributes are constant over geometries\n\nplot(dfw_tracts$geometry)\nplot(neighbors, \n     coords = dfw_coords, \n     add = TRUE, \n     col = \"blue\", \n     points = FALSE)"
  },
  {
    "objectID": "contents/website/analizeUSCensus/ch07_spatial_analysis_with_us_census_data.html#generating-the-spatial-weights-matrix",
    "href": "contents/website/analizeUSCensus/ch07_spatial_analysis_with_us_census_data.html#generating-the-spatial-weights-matrix",
    "title": "Spatial analysis with US Census data",
    "section": "6.3 Generating the spatial weights matrix",
    "text": "6.3 Generating the spatial weights matrix\nneighbors listをspatial weightsにすることで、空間データ解析が行えるようになる。 nb2listwを使うｔこで対応することができる. style = wを指定すると行に正則となる.\n\n\nCode\nweights &lt;- nb2listw(neighbors, style = \"W\")\n\nweights$weights[[1]]\n#&gt; [1] 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571"
  },
  {
    "objectID": "contents/website/analizeUSCensus/ch07_spatial_analysis_with_us_census_data.html#moralns-i",
    "href": "contents/website/analizeUSCensus/ch07_spatial_analysis_with_us_census_data.html#moralns-i",
    "title": "Spatial analysis with US Census data",
    "section": "7.1 Moralns I",
    "text": "7.1 Moralns I\n\n\nCode\ndfw_tracts$lag_estimate &lt;- lag.listw(weights, dfw_tracts$estimate)\n\n\n\n\nCode\nggplot(dfw_tracts, aes(x = estimate, y = lag_estimate)) + \n  geom_point(alpha = 0.3) + \n  geom_abline(color = \"red\") + \n  theme_minimal() + \n  labs(title = \"Median age by Census tract, Dallas-Fort Worth TX\",\n       x = \"Median age\",\n       y = \"Spatial lag, median age\", \n       caption = \"Data source: 2016-2020 ACS via the tidycensus R package.\\nSpatial relationships based on queens-case polygon contiguity.\")\n\n\n\n\n\n\n\n\n\n\n\nCode\nmoran.test(dfw_tracts$estimate, weights)\n#&gt; \n#&gt;  Moran I test under randomisation\n#&gt; \n#&gt; data:  dfw_tracts$estimate  \n#&gt; weights: weights    \n#&gt; \n#&gt; Moran I statistic standard deviate = 21.275, p-value &lt; 2.2e-16\n#&gt; alternative hypothesis: greater\n#&gt; sample estimates:\n#&gt; Moran I statistic       Expectation          Variance \n#&gt;      0.2926713016     -0.0005889282      0.0001900099\n\n\nモーランテストの帰無仮説は空間に対してランダムな状態にあるということである。ポジティブのときには空間的なクラスターがあるということになる。\n正規化した分散共分散行列と同じであるので平均に対して正の値が集合しているや、負の値が集合しているということが判定できる。\n\n\n\n\n\n\nNote\n\n\n\nThe Moran’s I statistic of 0.292 is positive, and the small p-value suggests that we reject the null hypothesis of spatial randomness in our dataset. (See Section 8.2.4 for additional discussion of p-values). As the statistic is positive, it suggests that our data are spatially clustered; a negative statistic would suggest spatial uniformity. In a practical sense, this means that Census tracts with older populations tend to be located near one another, and Census tracts with younger populations also tend to be found in the same areas.\n\n\n\n\nCode\n# For Gi*, re-compute the weights with `include.self()`\nlocalg_weights &lt;- nb2listw(include.self(neighbors))\n\ndfw_tracts$localG &lt;- spdep::localG(dfw_tracts$estimate, localg_weights)\n\nggplot(dfw_tracts) + \n  geom_sf(aes(fill = as.numeric(localG)), color = NA) + \n  scale_fill_distiller(palette = \"RdYlBu\") + \n  theme_void() + \n  labs(fill = \"Local Gi* statistic\")\n\n\n\n\n\n\n\n\n\n\n\nCode\ndfw_tracts &lt;- dfw_tracts %&gt;%\n  mutate(hotspot = case_when(\n    localG &gt;= 2.576 ~ \"High cluster\",\n    localG &lt;= -2.576 ~ \"Low cluster\",\n    TRUE ~ \"Not significant\"\n  ))\n\nggplot(dfw_tracts) + \n  geom_sf(aes(fill = hotspot), color = \"grey90\", size = 0.1) + \n  scale_fill_manual(values = c(\"red\", \"blue\", \"grey\")) + \n  theme_void()"
  },
  {
    "objectID": "contents/website/analizeUSCensus/ch07_spatial_analysis_with_us_census_data.html#lisa",
    "href": "contents/website/analizeUSCensus/ch07_spatial_analysis_with_us_census_data.html#lisa",
    "title": "Spatial analysis with US Census data",
    "section": "7.2 LISA",
    "text": "7.2 LISA\n\\[\nI_i = z_i \\sum_{j} w_{ij}z_j\n\\]\n\n\nCode\nset.seed(1983)\n\ndfw_tracts$scaled_estimate &lt;- as.numeric(scale(dfw_tracts$estimate))\n\ndfw_lisa &lt;- localmoran_perm(\n  dfw_tracts$scaled_estimate, \n  weights, \n  nsim = 999L, \n  alternative = \"two.sided\"\n) %&gt;%\n  as_tibble() %&gt;%\n  set_names(c(\"local_i\", \"exp_i\", \"var_i\", \"z_i\", \"p_i\",\n              \"p_i_sim\", \"pi_sim_folded\", \"skewness\", \"kurtosis\"))\n\ndfw_lisa_df &lt;- dfw_tracts %&gt;%\n  select(GEOID, scaled_estimate) %&gt;%\n  mutate(lagged_estimate = lag.listw(weights, scaled_estimate)) %&gt;%\n  bind_cols(dfw_lisa)\n\n\n\n\nCode\ndfw_lisa_clusters &lt;- dfw_lisa_df %&gt;%\n  mutate(lisa_cluster = case_when(\n    p_i &gt;= 0.05 ~ \"Not significant\",\n    scaled_estimate &gt; 0 & local_i &gt; 0 ~ \"High-high\",\n    scaled_estimate &gt; 0 & local_i &lt; 0 ~ \"High-low\",\n    scaled_estimate &lt; 0 & local_i &gt; 0 ~ \"Low-low\",\n    scaled_estimate &lt; 0 & local_i &lt; 0 ~ \"Low-high\"\n  ))\n\n\n\n\nCode\ncolor_values &lt;- c(`High-high` = \"red\", \n                  `High-low` = \"pink\", \n                  `Low-low` = \"blue\", \n                  `Low-high` = \"lightblue\", \n                  `Not significant` = \"white\")\n\nggplot(dfw_lisa_clusters, aes(x = scaled_estimate, \n                              y = lagged_estimate,\n                              fill = lisa_cluster)) + \n  geom_point(color = \"black\", shape = 21, size = 2) + \n  theme_minimal() + \n  geom_hline(yintercept = 0, linetype = \"dashed\") + \n  geom_vline(xintercept = 0, linetype = \"dashed\") + \n  scale_fill_manual(values = color_values) + \n  labs(x = \"Median age (z-score)\",\n       y = \"Spatial lag of median age (z-score)\",\n       fill = \"Cluster type\")\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(dfw_lisa_clusters, aes(fill = lisa_cluster)) + \n  geom_sf(size = 0.1) + \n  theme_void() + \n  scale_fill_manual(values = color_values) + \n  labs(fill = \"Cluster type\")"
  },
  {
    "objectID": "contents/website/graphic_design_with_ggplot2/ch01_concepts_of_the_ggplot2_packages.html",
    "href": "contents/website/graphic_design_with_ggplot2/ch01_concepts_of_the_ggplot2_packages.html",
    "title": "Concepts of the ggplot2 Packages pt 1",
    "section": "",
    "text": "Code\nrenv::activate(here::here())\ncur_dir &lt;- here::here(\"contents/website/graphic_design_with_ggplot2\")\nCode\npackages &lt;- c(\n  \"tidyverse\", \n  \"ggplot2\", \"readr\", \"tibble\", \"tidyr\", \"forcats\", \n  \"stringr\",\n  \"lubridate\", \"here\", \"systemfonts\", \"magick\", \n  \"scales\", \"grid\",\n  \"grDevices\", \"colorspace\", \"viridis\", \n  \"RColorBrewer\", \"rcartocolor\",\n  \"scico\", \"ggsci\", \"ggthemes\", \"nord\", \n  \"MetBrewer\", \"ggrepel\",\n  \"ggforce\", \"ggtext\", \"ggdist\", \"ggbeeswarm\", \n  \"gghalves\", \"patchwork\", \n  \"palmerpenguins\", \"rnaturalearth\", \"sf\", \"rmapshaper\", \"devtools\", \n  \"extrafont\"\n) |&gt; lapply(\\(x) library(x, character.only = TRUE))\nlibrary(cowplot)\nlibrary(colorblindr)"
  },
  {
    "objectID": "contents/website/graphic_design_with_ggplot2/ch01_concepts_of_the_ggplot2_packages.html#the-data",
    "href": "contents/website/graphic_design_with_ggplot2/ch01_concepts_of_the_ggplot2_packages.html#the-data",
    "title": "Concepts of the ggplot2 Packages pt 1",
    "section": "1.1 the data",
    "text": "1.1 the data\n\n\nCode\nbikes &lt;- \n    read_csv(\n        here(\n            cur_dir, \n            \"ggplot2-course-data\", \n            \"london-bikes-custom.csv\"),\n        col_types = \"Dcfffilllddddc\"\n    )\n\nbikes$season &lt;- forcats::fct_inorder(bikes$season)\n\n\nbikes |&gt; \n    head() |&gt; \n    rmarkdown::paged_table()"
  },
  {
    "objectID": "contents/website/graphic_design_with_ggplot2/ch01_concepts_of_the_ggplot2_packages.html#the-group",
    "href": "contents/website/graphic_design_with_ggplot2/ch01_concepts_of_the_ggplot2_packages.html#the-group",
    "title": "Concepts of the ggplot2 Packages pt 1",
    "section": "1.2 the group",
    "text": "1.2 the group\n\n\nCode\nbikes |&gt; \n    ggplot(aes(x = temp_feel, y = count)) + \n    geom_point(aes(color = season), alpah = .5) +\n    geom_smooth(\n        aes(group = day_night), \n        method = \"lm\"\n    )\n#&gt; Warning in geom_point(aes(color = season), alpah = 0.5): Ignoring unknown\n#&gt; parameters: `alpah`\n#&gt; `geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "contents/website/graphic_design_with_ggplot2/ch01_concepts_of_the_ggplot2_packages.html#stat-geom",
    "href": "contents/website/graphic_design_with_ggplot2/ch01_concepts_of_the_ggplot2_packages.html#stat-geom",
    "title": "Concepts of the ggplot2 Packages pt 1",
    "section": "1.3 stat, geom",
    "text": "1.3 stat, geom\n\n\n\n\nCode\nggplot(bikes, aes(x = season)) + \n    stat_count(geom = \"bar\")\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(bikes, aes(x = season)) + \n    geom_bar(stat = \"count\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(bikes, aes(x = date, y = temp_feel)) + \n    stat_identity(geom = \"point\")\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(bikes, aes(x = date, y = temp_feel)) + \n    geom_point(stat = \"identity\")"
  },
  {
    "objectID": "contents/website/graphic_design_with_ggplot2/ch01_concepts_of_the_ggplot2_packages.html#statisitical-summarys",
    "href": "contents/website/graphic_design_with_ggplot2/ch01_concepts_of_the_ggplot2_packages.html#statisitical-summarys",
    "title": "Concepts of the ggplot2 Packages pt 1",
    "section": "1.4 Statisitical Summarys",
    "text": "1.4 Statisitical Summarys\n\n\nCode\nggplot(\n    bikes, \n    aes(x = season , y = temp_feel)\n) + \n    geom_boxplot() + \n    stat_summary(\n        fun = mean, \n        geom = \"point\", \n        color = \"#28a87d\", \n        size = 3\n    )\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(\n    bikes, \n    aes(x = season, y = temp_feel)\n  ) +\n  stat_summary(\n    fun = mean, \n    fun.max = function(y) mean(y) + sd(y), \n    fun.min = function(y) mean(y) - sd(y) \n  )"
  },
  {
    "objectID": "contents/website/graphic_design_with_ggplot2/ch01_concepts_of_the_ggplot2_packages.html#how-to-work-with-aspect-ratios",
    "href": "contents/website/graphic_design_with_ggplot2/ch01_concepts_of_the_ggplot2_packages.html#how-to-work-with-aspect-ratios",
    "title": "Concepts of the ggplot2 Packages pt 1",
    "section": "3.1 How to Work with Aspect Ratios",
    "text": "3.1 How to Work with Aspect Ratios\nRStudioのViewerは、実際にファイルへ出力したときと見た目が異なる。 これに対して１度保存してから確認するということもあるが、chunkのセッティングを調整することもできる. もしくはcamcorderを使うことになる。動かないのでとりあえず無視する.\n\n\nCode\nlibrary(camcorder)\n\n\ngg_record(\n    dir = here(cur_dir, \"output\", \"temp_plots\"), \n    device = \"pdf\", \n    width  =  297, \n    height = 210, \n    units  = \"mm\"\n)\n\ng"
  },
  {
    "objectID": "contents/website/graphic_design_with_ggplot2/ch03_data_communication.html",
    "href": "contents/website/graphic_design_with_ggplot2/ch03_data_communication.html",
    "title": "Data Communication",
    "section": "",
    "text": "Code\nrenv::activate(here::here())\ncur_dir &lt;- here::here(\"contents/website/graphic_design_with_ggplot2\")\n\n\n\n\nCode\npackages &lt;- c(\n  \"tidyverse\", \n  \"ggplot2\", \"readr\", \"tibble\", \"tidyr\", \"forcats\", \n  \"stringr\",\n  \"lubridate\", \"here\", \"systemfonts\", \"magick\", \n  \"scales\", \"grid\",\n  \"grDevices\", \"colorspace\", \"viridis\", \n  \"RColorBrewer\", \"rcartocolor\",\n  \"scico\", \"ggsci\", \"ggthemes\", \"nord\", \n  \"MetBrewer\", \"ggrepel\",\n  \"ggforce\", \"ggtext\", \"ggdist\", \"ggbeeswarm\", \n  \"gghalves\", \"patchwork\", \n  \"palmerpenguins\", \"rnaturalearth\", \"sf\", \"rmapshaper\", \"devtools\", \n  \"extrafont\"\n) |&gt; lapply(\\(x) library(x, character.only = TRUE))\nlibrary(cowplot)\nlibrary(colorblindr)\n\n\nlibrary(showtext)\nshowtext_auto()\nfont_add_google(\"Noto Sans\")\n\n\n\n1 note\n\nOur data is never a perfect reflectionof the real world.\n\n\nonly a subset\ncollected by humans\ncollected by machines\n\n\nThe best use of data is to teach us what isn’t true\n\n\ndont’ formulate a single statement\nconfront yourself with a falsifiable universal statement\n\nデータヴィジュアライゼーションの参考サイトは次です。実務で１番参考になるのは１番上の、From Data to Vizというサイトです。このサイトでは、R、Python、D3、Reactのコードも記載されており、実務ですぐ使えとなります。\n\nfrom Data to Viz\nData Viz Project\nvisualizationuniverse\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/website/graphic_design_with_ggplot2/ch06_working_with_colors.html",
    "href": "contents/website/graphic_design_with_ggplot2/ch06_working_with_colors.html",
    "title": "Working with Colors",
    "section": "",
    "text": "Code\nrenv::activate(here::here())\ncur_dir &lt;- here::here(\"contents/website/graphic_design_with_ggplot2\")\nCode\npackages &lt;- c(\n  \"tidyverse\", \n  \"magick\",\n  \"ggplot2\", \n  \"readr\", \n  \"tibble\", \n  \"tidyr\", \n  \"forcats\", \n  \"stringr\",\n  \"lubridate\", \n  \"here\", \n  \"systemfonts\", \n  \"magick\", \n  \"scales\", \n  \"grid\",\n  \"grDevices\", \n  \"colorspace\", \n  \"viridis\", \n  \"RColorBrewer\", \n  \"rcartocolor\",\n  \"scico\", \n  \"ggsci\", \n  \"ggthemes\", \n  \"nord\", \n  \"MetBrewer\", \n  \"ggrepel\",\n  \"ggforce\",\n  \"ggtext\", \n  \"ggfittext\",\n  \"ggdist\", \n  \"ggbeeswarm\", \n  \"gghalves\", \n  \"patchwork\", \n  \"palmerpenguins\", \n  \"rnaturalearth\", \n  \"sf\", \n  \"rmapshaper\", \n  \"devtools\", \n  \"extrafont\"\n) |&gt; lapply(\\(x) library(x, character.only = TRUE))\nlibrary(cowplot)\nlibrary(colorblindr)\n\n\nlibrary(showtext)\nshowtext_auto()\nfont_add_google(\"Noto Sans\")"
  },
  {
    "objectID": "contents/website/graphic_design_with_ggplot2/ch06_working_with_colors.html#rcartocolor",
    "href": "contents/website/graphic_design_with_ggplot2/ch06_working_with_colors.html#rcartocolor",
    "title": "Working with Colors",
    "section": "2.1 rcartocolor",
    "text": "2.1 rcartocolor\n\n\nCode\n\n# install.packages(\"rcartocolor\")\n\nggplot(\n    bikes, \n    aes(x = day_night, y = count, \n        fill = season)\n  ) +\n  geom_boxplot() +\n  rcartocolor::scale_fill_carto_d(\n    palette = \"Vivid\" \n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\nrcartocolor::display_carto_all(colorblind_friendly = TRUE)"
  },
  {
    "objectID": "contents/website/graphic_design_with_ggplot2/ch06_working_with_colors.html#scico-and-else",
    "href": "contents/website/graphic_design_with_ggplot2/ch06_working_with_colors.html#scico-and-else",
    "title": "Working with Colors",
    "section": "2.2 scico and else",
    "text": "2.2 scico and else\n\n\nCode\n# install.packages(\"scico\")\n\nggplot(\n    bikes, \n    aes(x = day_night, y = count, \n        fill = season)\n  ) +\n  geom_boxplot() +\n  scico::scale_fill_scico_d(\n    palette = \"hawaii\"\n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\n# install.packages(\"ggsci\")\nggplot(\n    bikes, \n    aes(x = day_night, y = count, \n        fill = season)\n  ) +\n  geom_boxplot() +\n  ggsci::scale_fill_npg()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# install.packages(\"ggthemes\")\nggplot(\n    bikes, \n    aes(x = day_night, y = count, \n        fill = season)\n  ) +\n  geom_boxplot() +\n  ggthemes::scale_fill_gdocs()"
  },
  {
    "objectID": "contents/website/graphic_design_with_ggplot2/ch06_working_with_colors.html#emulate-cvd",
    "href": "contents/website/graphic_design_with_ggplot2/ch06_working_with_colors.html#emulate-cvd",
    "title": "Working with Colors",
    "section": "5.1 Emulate CVD",
    "text": "5.1 Emulate CVD\n色盲タイプ別の色チェックということだと思う。\n\n\nCode\ndeut &lt;- \n  colorspace::deutan(\n    viridis::turbo(\n      n = 100, direction = -1\n    )\n  )\n\nggplot(\n    bikes, \n    aes(x = temp_feel, y = count,\n        color = temp_feel)\n  ) +\n  geom_point() +\n  scale_color_gradientn(\n    colors = deut\n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\ng &lt;- \n  ggplot(\n    bikes, \n    aes(x = day_night, y = count, \n        fill = season)\n  ) +\n  geom_boxplot() +\n  scale_fill_manual(\n    values = carto_custom\n  )\n\n# devtools::install_github(\n#   \"clauswilke/colorblindr\"\n# )\n\ncolorblindr::cvd_grid(g)"
  },
  {
    "objectID": "contents/website/graphic_design_with_ggplot2/index.html",
    "href": "contents/website/graphic_design_with_ggplot2/index.html",
    "title": "Graphic Design with ggplot2",
    "section": "",
    "text": "1 はじめに\n\nrstudioによるggplotのワークショップである\nかなり細かいところまでやっており非常に情報量が多い\nChatGPTの世界であるがやはりハンズオン形式で勉強したい\nサイト\nパッケージだけでなくフォントのインストールも忘れずに\n\n\n\nCode\nrenv::activate(here::here())\ncur_dir &lt;- here::here(\"contents/website/graphic_design_with_ggplot2\")\n\n\n\n\nCode\npackages &lt;- c(\n  \"ggplot2\", \"readr\", \"tibble\", \"tidyr\", \"forcats\", \"stringr\",\n  \"lubridate\", \"here\", \"systemfonts\", \"magick\", \"scales\", \"grid\",\n  \"grDevices\", \"colorspace\", \"viridis\", \"RColorBrewer\", \"rcartocolor\",\n  \"scico\", \"ggsci\", \"ggthemes\", \"nord\", \"MetBrewer\", \"ggrepel\",\n  \"ggforce\", \"ggtext\", \"ggdist\", \"ggbeeswarm\", \"gghalves\", \"patchwork\", \n  \"palmerpenguins\", \"rnaturalearth\", \"sf\", \"rmapshaper\", \"devtools\"\n)\n\ninstall.packages(setdiff(packages, rownames(installed.packages())))  \n\n## install {colorblindr} and requirements2\nremotes::install_github(\"wilkelab/cowplot\")\nremotes::install_github(\"clauswilke/colorblindr\")\nremotes::install_git(\"https://git.sr.ht/~hrbrmstr/albersusa\")\n\n\n\n\n2 ggplot2 examples\n\n\nCode\npackages &lt;- c(\n  \"tidyverse\", \n  \"ggplot2\", \"readr\", \"tibble\", \"tidyr\", \"forcats\", \n  \"stringr\",\n  \"lubridate\", \"here\", \"systemfonts\", \"magick\", \n  \"scales\", \"grid\",\n  \"grDevices\", \"colorspace\", \"viridis\", \n  \"RColorBrewer\", \"rcartocolor\",\n  \"scico\", \"ggsci\", \"ggthemes\", \"nord\", \n  \"MetBrewer\", \"ggrepel\",\n  \"ggforce\", \"ggtext\", \"ggdist\", \"ggbeeswarm\", \n  \"gghalves\", \"patchwork\", \n  \"palmerpenguins\", \"rnaturalearth\", \"sf\", \"rmapshaper\", \"devtools\", \n  \"extrafont\"\n) |&gt; lapply(\\(x) library(x, character.only = TRUE))\nlibrary(cowplot)\nlibrary(colorblindr)\n\n\n\n\nCode\n# フォントのデータベースを作成\nfont_import(prompt = FALSE)\n\n\n\n\nCode\n\n# フォントのデータベースをロード\nloadfonts(device = \"win\")\n\n\n\n\nCode\nbikes &lt;- read_csv(here::here(cur_dir,\"ggplot2-course-data/london-bikes-custom.csv\"))\n#&gt; Rows: 1454 Columns: 14\n#&gt; ── Column specification ────────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; chr   (3): day_night, season, weather_type\n#&gt; dbl  (10): year, month, count, is_workday, is_weekend, is_holiday, temp, tem...\n#&gt; date  (1): date\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nbikes\n#&gt; # A tibble: 1,454 × 14\n#&gt;    date       day_night  year month season count is_workday is_weekend\n#&gt;    &lt;date&gt;     &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n#&gt;  1 2015-01-04 day        2015     1 winter  6830          0          1\n#&gt;  2 2015-01-04 night      2015     1 winter  2404          0          1\n#&gt;  3 2015-01-05 day        2015     1 winter 14763          1          0\n#&gt;  4 2015-01-05 night      2015     1 winter  5609          1          0\n#&gt;  5 2015-01-06 day        2015     1 winter 14501          1          0\n#&gt;  6 2015-01-06 night      2015     1 winter  6112          1          0\n#&gt;  7 2015-01-07 day        2015     1 winter 16358          1          0\n#&gt;  8 2015-01-07 night      2015     1 winter  4706          1          0\n#&gt;  9 2015-01-08 day        2015     1 winter  9971          1          0\n#&gt; 10 2015-01-08 night      2015     1 winter  5630          1          0\n#&gt; # ℹ 1,444 more rows\n#&gt; # ℹ 6 more variables: is_holiday &lt;dbl&gt;, temp &lt;dbl&gt;, temp_feel &lt;dbl&gt;,\n#&gt; #   humidity &lt;dbl&gt;, wind_speed &lt;dbl&gt;, weather_type &lt;chr&gt;\n\n\n\n\nCode\ncodes &lt;- c(\n    \"0\" = \"Workday\", \n    \"1\" = \"Weekend or Holiday\"\n)\n\nggplot(bikes, aes(temp_feel, count)) +\n    geom_point(\n        color = \"black\", \n        fill = \"white\", \n        shape = 21, \n        size = 2.8\n    ) + \n    geom_point(\n        color = \"white\", \n        size = 2.2\n    ) + \n    geom_point(\n        aes(color = forcats::fct_relabel(season, str_to_title)), \n        size = 2.2, \n        alpha = .55\n    ) + \n    facet_grid(\n        day_night ~ is_workday, \n        scales = \"free_y\", \n        space = \"free_y\", \n        labeller = labeller(\n            day_night = stringr::str_to_title, \n            is_workday = codes\n        )\n    ) + \n    scale_x_continuous(\n        expand = c(.02, .02), \n        breaks = 0:6 * 5, \n        labels = \\(x) paste0(x, \"°C\")\n    ) + \n    scale_y_continuous(\n        expand = c(.1, .1), \n        limits = c(0, NA), \n        breaks = 0:5 * 10000, \n        labels = scales::comma_format()\n    ) + \n    scale_color_manual(\n        values = c(\"#3c89d9\", \"#1ec99b\", \"#F7B01B\", \"#a26e7c\"), \n        name = NULL,\n        guide = guide_legend(override.aes = list(size = 5))\n\n    ) +\n    labs(\n      x = \"Feels-Like Temperature\", y = NULL,\n      caption = \"Data: TfL (Transport for London), Jan 2015 — Dec 2016\",\n      title = \"Reported bike rents versus feels-like temperature in London per time of day, period, and season.\"\n    ) +\n    theme_light(\n        base_size = 14, \n        base_family = \"Calibri\"\n    ) + \n    theme(\n        plot.title.position = \"plot\", \n        plot.caption.position = \"plot\", \n        plot.title = element_text(face = \"bold\", size = rel(.9)) , \n        # axis.text = element_text(family = \"Tabular\"), \n        axis.title.x = element_text(hjust = 0, color = \"grey30\", margin = margin(t = 12)), \n        strip.text = element_text(face = \"bold\", size = rel(1)), \n        strip.text.y.right = element_text(face = \"bold\", size = rel(.7)), \n        panel.grid.major.x = element_blank(), \n        panel.grid.minor = element_blank(), \n        panel.spacing = unit(1.2, \"lines\"), \n        legend.position = \"top\", \n        legend.text = element_text(size = rel(1)), \n        panel.spacing.x = unit(.1, \"lines\"), \n        panel.spacing.y = unit(.1, \"lines\"),\n        \n        legend.key = element_rect(color = \"#f8f8f8\", fill = \"#f8f8f8\"), \n        legend.background = element_rect(color = \"#f8f8f8f8\", fill = \"#f8f8f8f8\"), \n        plot.background = element_rect(color = \"#f8f8f8\", fill = \"#f8f8f8\")\n        \n    )\n#&gt; Warning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n#&gt; not found in Windows font database\n\n#&gt; Warning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n#&gt; not found in Windows font database\n#&gt; Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\n#&gt; family not found in Windows font database\n#&gt; Warning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n#&gt; not found in Windows font database\n#&gt; Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\n#&gt; family not found in Windows font database\n\n#&gt; Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\n#&gt; family not found in Windows font database\n\n#&gt; Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\n#&gt; family not found in Windows font database\n#&gt; Warning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n#&gt; not found in Windows font database\n#&gt; Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\n#&gt; family not found in Windows font database\n\n#&gt; Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\n#&gt; family not found in Windows font database\n\n#&gt; Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\n#&gt; family not found in Windows font database\n\n#&gt; Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\n#&gt; family not found in Windows font database\n\n#&gt; Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\n#&gt; family not found in Windows font database\n\n#&gt; Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\n#&gt; family not found in Windows font database\n#&gt; Warning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\n#&gt; font family not found in Windows font database\n\n#&gt; Warning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\n#&gt; font family not found in Windows font database\n\n#&gt; Warning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\n#&gt; font family not found in Windows font database\n\n#&gt; Warning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\n#&gt; font family not found in Windows font database\n\n#&gt; Warning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\n#&gt; font family not found in Windows font database\n#&gt; Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\n#&gt; family not found in Windows font database\n\n#&gt; Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\n#&gt; family not found in Windows font database\n\n#&gt; Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\n#&gt; family not found in Windows font database\n\n#&gt; Warning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\n#&gt; family not found in Windows font database\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/libs/DBI/working.html",
    "href": "contents/libs/DBI/working.html",
    "title": "DBI",
    "section": "",
    "text": "Code\nrenv::activate(here::here())\ncur_dir &lt;- here::here(\"contents/libs/DBI\")\nCode\nlibrary(ggplot2)\nlibrary(duckdb)\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(DBI)\nlibrary(dbplyr)\nlibrary(showtext)\nlibrary(arrow)\nlibrary(nanoarrow)\nshowtext_auto()\nfont_add_google(\"Noto Sans\")"
  },
  {
    "objectID": "contents/libs/DBI/working.html#prepare",
    "href": "contents/libs/DBI/working.html#prepare",
    "title": "DBI",
    "section": "3.1 Prepare",
    "text": "3.1 Prepare\n\n\nCode\ncon &lt;- dbConnect(RSQLite::SQLite())\n\ndata &lt;- data.frame(\n  a = 1:3,\n  b = 4.5,\n  c = \"five\"\n)\n\ndbWriteTable(con, \"tbl\", data)"
  },
  {
    "objectID": "contents/libs/DBI/working.html#read-all-rows-from-table",
    "href": "contents/libs/DBI/working.html#read-all-rows-from-table",
    "title": "DBI",
    "section": "3.2 Read all rows from table",
    "text": "3.2 Read all rows from table\n\n\nCode\nstream &lt;- dbReadTableArrow(con, \"tbl\")\nstream\n#&gt; &lt;nanoarrow_array_stream struct&lt;a: int32, b: double, c: string&gt;&gt;\n#&gt;  $ get_schema:function ()  \n#&gt;  $ get_next  :function (schema = x$get_schema(), validate = TRUE)  \n#&gt;  $ release   :function ()\n\n\n\n\nCode\nstream$get_schema()\n#&gt; &lt;nanoarrow_schema struct&gt;\n#&gt;  $ format    : chr \"+s\"\n#&gt;  $ name      : chr \"\"\n#&gt;  $ metadata  : list()\n#&gt;  $ flags     : int 0\n#&gt;  $ children  :List of 3\n#&gt;   ..$ a:&lt;nanoarrow_schema int32&gt;\n#&gt;   .. ..$ format    : chr \"i\"\n#&gt;   .. ..$ name      : chr \"a\"\n#&gt;   .. ..$ metadata  : list()\n#&gt;   .. ..$ flags     : int 2\n#&gt;   .. ..$ children  : list()\n#&gt;   .. ..$ dictionary: NULL\n#&gt;   ..$ b:&lt;nanoarrow_schema double&gt;\n#&gt;   .. ..$ format    : chr \"g\"\n#&gt;   .. ..$ name      : chr \"b\"\n#&gt;   .. ..$ metadata  : list()\n#&gt;   .. ..$ flags     : int 2\n#&gt;   .. ..$ children  : list()\n#&gt;   .. ..$ dictionary: NULL\n#&gt;   ..$ c:&lt;nanoarrow_schema string&gt;\n#&gt;   .. ..$ format    : chr \"u\"\n#&gt;   .. ..$ name      : chr \"c\"\n#&gt;   .. ..$ metadata  : list()\n#&gt;   .. ..$ flags     : int 2\n#&gt;   .. ..$ children  : list()\n#&gt;   .. ..$ dictionary: NULL\n#&gt;  $ dictionary: NULL\n\n\n\n\nCode\nas_tibble(stream)\n#&gt; # A tibble: 3 × 3\n#&gt;       a     b c    \n#&gt;   &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;\n#&gt; 1     1   4.5 five \n#&gt; 2     2   4.5 five \n#&gt; 3     3   4.5 five"
  },
  {
    "objectID": "contents/libs/DBI/working.html#run-queries",
    "href": "contents/libs/DBI/working.html#run-queries",
    "title": "DBI",
    "section": "3.3 Run queries",
    "text": "3.3 Run queries\n\n\nCode\nstream &lt;- dbGetQueryArrow(con, \"SELECT COUNT(*) AS n FROM tbl WHERE a &lt; 3\")\nstream\n#&gt; &lt;nanoarrow_array_stream struct&lt;n: int32&gt;&gt;\n#&gt;  $ get_schema:function ()  \n#&gt;  $ get_next  :function (schema = x$get_schema(), validate = TRUE)  \n#&gt;  $ release   :function ()\n\n\nファイルに書き出す。\n\n\nCode\npath &lt;- tempfile(fileext = \".parquet\")\narrow::write_parquet(arrow::as_record_batch_reader(stream), path)\narrow::read_parquet(path)\n#&gt; # A tibble: 1 × 1\n#&gt;       n\n#&gt;   &lt;int&gt;\n#&gt; 1     2"
  },
  {
    "objectID": "contents/libs/DBI/working.html#prepared-queries",
    "href": "contents/libs/DBI/working.html#prepared-queries",
    "title": "DBI",
    "section": "3.4 Prepared queries",
    "text": "3.4 Prepared queries\nクエリに使うパラメータをデータフレームから渡すことができる。\n\n\nCode\nparams &lt;- data.frame(a = 3L)\nstream &lt;- dbGetQueryArrow(con, \"SELECT $a AS batch, * FROM tbl WHERE a &lt; $a\", params = params)\nas.data.frame(stream)\n#&gt;   batch a   b    c\n#&gt; 1     3 1 4.5 five\n#&gt; 2     3 2 4.5 five\n\n\nパラメータが不足するときには最期の値がrecursiveする。\n\n\nCode\nparams &lt;- data.frame(a = c(2L, 4L))\n# Equivalent to dbBind()\nstream &lt;- dbGetQueryArrow(con, \"SELECT $a AS batch, * FROM tbl WHERE a &lt; $a\", params = params)\nas.data.frame(stream)\n#&gt;   batch a   b    c\n#&gt; 1     2 1 4.5 five\n#&gt; 2     4 1 4.5 five\n#&gt; 3     4 2 4.5 five\n#&gt; 4     4 3 4.5 five"
  },
  {
    "objectID": "contents/libs/DBI/working.html#manual-flow",
    "href": "contents/libs/DBI/working.html#manual-flow",
    "title": "DBI",
    "section": "3.5 Manual flow",
    "text": "3.5 Manual flow\ndbSendQueryArrowを使うとクエリを送付し、dbFetchArrowで結果を取得する。 これらはdbBindArrowを使うことでもできる。処理後は必ずdbClearResultを使いクリアすることになる。\n\n\nCode\nrs &lt;- dbSendQueryArrow(con, \"SELECT $a AS batch, * FROM tbl WHERE a &lt; $a\")\n\nin_arrow &lt;- nanoarrow::as_nanoarrow_array(data.frame(a = 1L))\ndbBindArrow(rs, in_arrow)\nas.data.frame(dbFetchArrow(rs))\n#&gt; [1] batch a     b     c    \n#&gt; &lt;0 rows&gt; (or 0-length row.names)\n\n\n\n\nCode\nin_arrow &lt;- nanoarrow::as_nanoarrow_array(data.frame(a = 2L))\ndbBindArrow(rs, in_arrow)\nas.data.frame(dbFetchArrow(rs))\n#&gt;   batch a   b    c\n#&gt; 1     2 1 4.5 five\n\n\n\n\nCode\nin_arrow &lt;- nanoarrow::as_nanoarrow_array(data.frame(a = 3L))\ndbBindArrow(rs, in_arrow)\nas.data.frame(dbFetchArrow(rs))\n#&gt;   batch a   b    c\n#&gt; 1     3 1 4.5 five\n#&gt; 2     3 2 4.5 five\n\n\n\n\nCode\nin_arrow &lt;- nanoarrow::as_nanoarrow_array(data.frame(a = 1:4L))\ndbBindArrow(rs, in_arrow)\nas.data.frame(dbFetchArrow(rs))\n#&gt;   batch a   b    c\n#&gt; 1     2 1 4.5 five\n#&gt; 2     3 1 4.5 five\n#&gt; 3     3 2 4.5 five\n#&gt; 4     4 1 4.5 five\n#&gt; 5     4 2 4.5 five\n#&gt; 6     4 3 4.5 five"
  },
  {
    "objectID": "contents/libs/DBI/working.html#writing-data",
    "href": "contents/libs/DBI/working.html#writing-data",
    "title": "DBI",
    "section": "3.6 Writing Data",
    "text": "3.6 Writing Data\n\n\nCode\nstream &lt;- dbGetQueryArrow(con, \"SELECT * FROM tbl WHERE a &lt; 3\")\n#&gt; Warning: Closing open result set, pending rows\ndbWriteTableArrow(con, \"tbl_new\", stream)\ndbReadTable(con, \"tbl_new\")\n#&gt;   a   b    c\n#&gt; 1 1 4.5 five\n#&gt; 2 2 4.5 five"
  },
  {
    "objectID": "contents/libs/DBI/working.html#appending-data",
    "href": "contents/libs/DBI/working.html#appending-data",
    "title": "DBI",
    "section": "3.7 Appending Data",
    "text": "3.7 Appending Data\n\n\nCode\nstream &lt;- dbGetQueryArrow(con, \"SELECT * FROM tbl WHERE a &lt; 3\")\ndbCreateTableArrow(con, \"tbl_split\", stream)\ndbAppendTableArrow(con, \"tbl_split\", stream)\n#&gt; [1] 2\n\n\n\n\nCode\nstream &lt;- dbGetQueryArrow(con, \"SELECT * FROM tbl WHERE a &gt;= 3\")\ndbAppendTableArrow(con, \"tbl_split\", stream)\n#&gt; [1] 1\n\n\n\n\nCode\ndbReadTable(con, \"tbl_split\")\n#&gt;   a   b    c\n#&gt; 1 1 4.5 five\n#&gt; 2 2 4.5 five\n#&gt; 3 3 4.5 five"
  },
  {
    "objectID": "contents/libs/DBI/working.html#coculution",
    "href": "contents/libs/DBI/working.html#coculution",
    "title": "DBI",
    "section": "3.8 Coculution",
    "text": "3.8 Coculution\n\n\nCode\ndbDisconnect(con)"
  },
  {
    "objectID": "contents/libs/base/working.html",
    "href": "contents/libs/base/working.html",
    "title": "base",
    "section": "",
    "text": "baseパッケージ関連のノートです。"
  },
  {
    "objectID": "contents/libs/base/working.html#approxapproxxfun",
    "href": "contents/libs/base/working.html#approxapproxxfun",
    "title": "base",
    "section": "2.1 approx/approxxfun",
    "text": "2.1 approx/approxxfun\n\nデータ点から近似関数を作成する\n1次元の他に使うことができる\napproxは直接近似値を返し, approxfunは近似関数を返す\n\n\n\nCode\nx &lt;- seq(0, 2 * pi, length.out = 10)\ny &lt;- sin(x)\nay &lt;- approxfun(x, y)(x)\nplot(x, y, pch = 19, cex = 3)\npoints(x, ay, col = \"blue\", type = \"l\")"
  },
  {
    "objectID": "contents/libs/duckdb/working.html",
    "href": "contents/libs/duckdb/working.html",
    "title": "duckdb",
    "section": "",
    "text": "Code\nrenv::activate(here::here())\ncur_dir &lt;- here::here(\"contents/libs/duckdb\")\nCode\nlibrary(ggplot2)\nlibrary(duckdb)\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(DBI)\nlibrary(dbplyr)\nlibrary(showtext)\nshowtext_auto()\nfont_add_google(\"Noto Sans\")"
  },
  {
    "objectID": "contents/libs/duckdb/working.html#startup-shutdown",
    "href": "contents/libs/duckdb/working.html#startup-shutdown",
    "title": "duckdb",
    "section": "2.1 Startup & Shutdown",
    "text": "2.1 Startup & Shutdown\nduckdbのファイル拡張子は、.dbか.duckdbである。 :memory:とするとin-memory databaseとして使うことが可能である。この場合、Rの終了と合わせてデータが破棄される。 read-onlyパラメータを使うことで書き込み制限ができる。\n\n\nCode\n# to start an in-memory database\ncon &lt;- dbConnect(duckdb())\n# or\ncon &lt;- dbConnect(duckdb(), dbdir = \":memory:\")\n# to use a database file (not shared between processes)\ncon &lt;- dbConnect(duckdb(), dbdir = \"my-db.duckdb\", read_only = FALSE)\n# to use a database file (shared between processes)\ncon &lt;- dbConnect(duckdb(), dbdir = \"my-db.duckdb\", read_only = TRUE)"
  },
  {
    "objectID": "contents/libs/duckdb/working.html#querying",
    "href": "contents/libs/duckdb/working.html#querying",
    "title": "duckdb",
    "section": "2.2 Querying",
    "text": "2.2 Querying\ndbExecuteはCREATE TABLEやUPDATEのように返値を期待したいクエリの際に使う。 dbGetQueryはSELECTのように返値を期待するクエリに対して使う。\n\n\nCode\ncon &lt;- dbConnect(duckdb(\":memory:\"))\n\n\n\n\nCode\ndbExecute(con, \"CREATE TABLE items (item VARCHAR, value DECIMAL(10, 2), count INTEGER)\")\n#&gt; [1] 0\ndbExecute(con, \"INSERT INTO items VALUES ('jeans', 20.0, 1), ('hammer', 42.2, 2)\")\n#&gt; [1] 2\nres &lt;- dbGetQuery(con, \"SELECT * FROM items\")\nprint(res)\n#&gt;     item value count\n#&gt; 1  jeans  20.0     1\n#&gt; 2 hammer  42.2     2"
  },
  {
    "objectID": "contents/libs/duckdb/working.html#efficient-transfer",
    "href": "contents/libs/duckdb/working.html#efficient-transfer",
    "title": "duckdb",
    "section": "2.3 Efficient Transfer",
    "text": "2.3 Efficient Transfer\ndbWriteTableを使うことでRのデータフレームをduckdbに書き込むことができる。\n\n\nCode\ndbWriteTable(con, \"iris_table\", iris)\nres &lt;- dbGetQuery(con, \"SELECT * FROM iris_table LIMIT 1\")\nprint(res)\n#&gt;   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n#&gt; 1          5.1         3.5          1.4         0.2  setosa\n\n\n\n\nCode\niris_tibble &lt;- as_tibble(iris)\ndbWriteTable(con, \"iris_tibble_table\", iris_tibble)\nres &lt;- dbGetQuery(con, \"SELECT * FROM iris_tibble_table LIMIT 1\")\nprint(res)\n#&gt;   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n#&gt; 1          5.1         3.5          1.4         0.2  setosa\n\n\n\n\nCode\ndbDisconnect(con)"
  },
  {
    "objectID": "contents/libs/duckdb/working.html#dbplyr",
    "href": "contents/libs/duckdb/working.html#dbplyr",
    "title": "duckdb",
    "section": "2.4 dbplyr",
    "text": "2.4 dbplyr\n\n\nCode\ncon &lt;- dbConnect(duckdb())\nduckdb_register(con, \"flights\", nycflights13::flights)\n\n\ntbl(con, \"flights\") |&gt;\n  group_by(dest) |&gt;\n  summarise(delay = mean(dep_time, na.rm = TRUE)) |&gt;\n  collect()\n#&gt; # A tibble: 105 × 2\n#&gt;    dest  delay\n#&gt;    &lt;chr&gt; &lt;dbl&gt;\n#&gt;  1 FLL   1327.\n#&gt;  2 RSW   1209.\n#&gt;  3 ROC   1473.\n#&gt;  4 SYR   1474.\n#&gt;  5 CMH   1421.\n#&gt;  6 CHS   1299.\n#&gt;  7 STL   1344.\n#&gt;  8 STT    830.\n#&gt;  9 OMA   1388.\n#&gt; 10 OKC   1996.\n#&gt; # ℹ 95 more rows\n\n\ndbplyrを使っているときは、csvやparquertのファイル群をdbplyr::tbl関数を使うことで読み込むことが可能である。\n\n\nCode\nwrite_csv(mtcars, \"mtcars.csv\")\n\n\nquery &lt;- \n  tbl(con, \"mtcars.csv\", check_from = FALSE) |&gt; \n  group_by(cyl) |&gt; \n  summarise(across(disp:wt, .fns = mean)) \n\nquery\n#&gt; Warning: Missing values are always removed in SQL aggregation functions.\n#&gt; Use `na.rm = TRUE` to silence this warning\n#&gt; This warning is displayed once every 8 hours.\n#&gt; # Source:   SQL [3 x 5]\n#&gt; # Database: DuckDB v0.10.0 [suzuk@Windows 10 x64:R 4.3.1/:memory:]\n#&gt;     cyl  disp    hp  drat    wt\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     8  353. 209.   3.23  4.00\n#&gt; 2     6  183. 122.   3.59  3.12\n#&gt; 3     4  105.  82.6  4.07  2.29\n\n\n\n\nCode\ncollect(query)\n#&gt; # A tibble: 3 × 5\n#&gt;     cyl  disp    hp  drat    wt\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     4  105.  82.6  4.07  2.29\n#&gt; 2     6  183. 122.   3.59  3.12\n#&gt; 3     8  353. 209.   3.23  4.00\n\n\nparquetファイルに書き出すことも可能である。\n\n\nCode\ndbExecute(con, \"COPY flights TO 'dataset' (FORMAT PARQUET, PARTITION_BY (year, month), OVERWRITE_OR_IGNORE)\")\n#&gt; [1] 0\n\n\nparquetに書き出したファイルにを対象にしてインメモリで集計する。読み出しを含めて爆速で集計できるのがわかる。\n\n\nCode\nbench::mark(\n  tbl(con, \"read_parquet('dataset/**/*.parquet', hive_partitioning = true)\") |&gt;\n    filter(month == 3) |&gt;\n    summarise(delay = mean(dep_time, na.rm = TRUE)) |&gt;\n    collect()\n)\n#&gt; # A tibble: 1 × 6\n#&gt;   expression                             min median `itr/sec` mem_alloc `gc/sec`\n#&gt;   &lt;bch:expr&gt;                           &lt;bch&gt; &lt;bch:&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt;\n#&gt; 1 \"collect(summarise(filter(tbl(con, … 108ms  109ms      9.20     573KB     13.8\n\n\n\n\nCode\ndbDisconnect(con)"
  },
  {
    "objectID": "contents/libs/ggfittext/working.html",
    "href": "contents/libs/ggfittext/working.html",
    "title": "ggfittext",
    "section": "",
    "text": "Code\nrenv::activate(here::here())\ncur_dir &lt;- here::here(\"contents/libs/ggfit\")\nCode\npackages &lt;- c(\n  \"tidyverse\", \n  \"magick\",\n  \"ggplot2\", \n  \"readr\", \n  \"tibble\", \n  \"tidyr\", \n  \"forcats\", \n  \"stringr\",\n  \"lubridate\", \n  \"here\", \n  \"systemfonts\", \n  \"magick\", \n  \"scales\", \n  \"grid\",\n  \"grDevices\", \n  \"colorspace\", \n  \"viridis\", \n  \"RColorBrewer\", \n  \"rcartocolor\",\n  \"scico\", \n  \"ggsci\", \n  \"ggthemes\", \n  \"nord\", \n  \"MetBrewer\", \n  \"ggrepel\",\n  \"ggforce\",\n  \"ggtext\", \n  \"ggfittext\",\n  \"ggdist\", \n  \"ggbeeswarm\", \n  \"gghalves\", \n  \"patchwork\", \n  \"palmerpenguins\", \n  \"rnaturalearth\", \n  \"sf\", \n  \"rmapshaper\", \n  \"devtools\", \n  \"extrafont\"\n) |&gt; lapply(\\(x) library(x, character.only = TRUE))\nlibrary(cowplot)\nlibrary(colorblindr)\n\n\nlibrary(showtext)\nshowtext_auto()\nfont_add_google(\"Noto Sans\")"
  },
  {
    "objectID": "contents/libs/ggfittext/working.html#fitting-text-inside-a-box",
    "href": "contents/libs/ggfittext/working.html#fitting-text-inside-a-box",
    "title": "ggfittext",
    "section": "2.1 Fitting text inside a box",
    "text": "2.1 Fitting text inside a box\n\n\nCode\n\nggplot(animals, aes(x = type, y = flies, label = animal)) +\n  geom_tile(fill = \"white\", colour = \"black\") +\n  geom_fit_text()"
  },
  {
    "objectID": "contents/libs/ggfittext/working.html#reflowing-text",
    "href": "contents/libs/ggfittext/working.html#reflowing-text",
    "title": "ggfittext",
    "section": "2.2 Reflowing text",
    "text": "2.2 Reflowing text\n\n\nCode\nggplot(animals, aes(x = type, y = flies, label = animal)) +\n  geom_tile(fill = \"white\", colour = \"black\") +\n  geom_fit_text(reflow = TRUE)"
  },
  {
    "objectID": "contents/libs/ggfittext/working.html#growing-text",
    "href": "contents/libs/ggfittext/working.html#growing-text",
    "title": "ggfittext",
    "section": "2.3 Growing text",
    "text": "2.3 Growing text\n\n\nCode\n\nggplot(animals, aes(x = type, y = flies, label = animal)) +\n  geom_tile(fill = \"white\", colour = \"black\") +\n  geom_fit_text(reflow = TRUE, grow = TRUE)"
  },
  {
    "objectID": "contents/libs/ggfittext/working.html#placing-text",
    "href": "contents/libs/ggfittext/working.html#placing-text",
    "title": "ggfittext",
    "section": "2.4 Placing text",
    "text": "2.4 Placing text\n\n\nCode\nggplot(animals, aes(x = type, y = flies, label = animal)) +\n  geom_tile(fill = \"white\", colour = \"black\") +\n  geom_fit_text(place = \"topleft\", reflow = TRUE)"
  },
  {
    "objectID": "contents/libs/ggfittext/working.html#bar-plots",
    "href": "contents/libs/ggfittext/working.html#bar-plots",
    "title": "ggfittext",
    "section": "2.5 Bar plots",
    "text": "2.5 Bar plots\ngeom_bar_textを使うだけで簡単に作成することができてしまう。\n\n\nCode\n\nggplot(altitudes, aes(x = craft, y = altitude, label = altitude)) +\n  geom_col() +\n  geom_bar_text()\n\n\n\n\n\n\n\n\n\n\n\nCode\n\nggplot(beverages, aes(x = beverage, y = proportion, label = ingredient,\n                    fill = ingredient)) +\n  geom_col(position = \"stack\") +\n  geom_bar_text(position = \"stack\", reflow = TRUE)\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(beverages, aes(x = beverage, y = proportion, label = ingredient,\n                    fill = ingredient)) +\n  geom_col(position = \"dodge\") +\n  geom_bar_text(position = \"dodge\", grow = TRUE, reflow = TRUE, \n                place = \"left\") +\n  coord_flip()\n\n\n\n\n\n\n\n\n\nリッチなテクストを配置することも可能である。\n\n\nCode\nggplot(animals_rich, aes(x = type, y = flies, label = animal)) +\n  geom_tile(fill = \"white\", colour = \"black\") +\n  geom_fit_text(reflow = TRUE, grow = TRUE, rich = TRUE)"
  },
  {
    "objectID": "contents/libs/ggfittext/working.html#specifying-the-box-limits",
    "href": "contents/libs/ggfittext/working.html#specifying-the-box-limits",
    "title": "ggfittext",
    "section": "2.6 Specifying the box limits",
    "text": "2.6 Specifying the box limits\n\n\nCode\nggplot(presidential, aes(ymin = start, ymax = end, x = party, label = name)) +\n  geom_fit_text(grow = TRUE) +\n  geom_errorbar(alpha = 0.5)"
  },
  {
    "objectID": "contents/libs/ggfittext/working.html#experimental-feaure-text-inpolar-coordinates",
    "href": "contents/libs/ggfittext/working.html#experimental-feaure-text-inpolar-coordinates",
    "title": "ggfittext",
    "section": "2.7 Experimental feaure: text inpolar coordinates",
    "text": "2.7 Experimental feaure: text inpolar coordinates\n\n\nCode\np &lt;- ggplot(gold, aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, \n                 fill = linenumber, label = line)) +\n  coord_polar() +\n  geom_rect() +\n  scale_fill_gradient(low = \"#fee391\", high = \"#238443\")\n\np + geom_fit_text(min.size = 0, grow = TRUE)"
  },
  {
    "objectID": "contents/libs/ggfittext/working.html#other-useful-arguments",
    "href": "contents/libs/ggfittext/working.html#other-useful-arguments",
    "title": "ggfittext",
    "section": "2.8 Other useful arguments",
    "text": "2.8 Other useful arguments\ncontrastパラメータは自動でテキストの色を反転させることができる。\n\n\nCode\n\nggplot(animals, aes(x = type, y = flies, fill = mass, label = animal)) +\n  geom_tile() +\n  geom_fit_text(reflow = TRUE, grow = TRUE, contrast = TRUE)"
  },
  {
    "objectID": "contents/libs/ggspatial/working.html",
    "href": "contents/libs/ggspatial/working.html",
    "title": "ggspatial",
    "section": "",
    "text": "Code\nrenv::activate(here::here())\ncur_dir &lt;- here::here(\"contents/libs/ggspatial\")\n\n\n\n\nCode\nlibrary(ggspatial)\nlibrary(ggplot2)\n\n\nlibrary(showtext)\nshowtext_auto()\nfont_add_google(\"Noto Sans\")\n\n\n\n1 はじめに\n地理データのグラフ化をリッチにすることができる。\ngithubが開発サイトである。\n\n\n2 イントロダクション\n\n\nCode\nlibrary(ggplot2)\nlibrary(ggspatial)\nload_longlake_data()\n\nggplot() +\n  # loads background map tiles from a tile source\n  annotation_map_tile(zoomin = -1) +\n  \n  # annotation_spatial() layers don't train the scales, so data stays central\n  annotation_spatial(longlake_roadsdf, size = 2, col = \"black\") +\n  annotation_spatial(longlake_roadsdf, size = 1.6, col = \"white\") +\n\n  # raster layers train scales and get projected automatically\n  layer_spatial(longlake_depth_raster, aes(color = after_stat(band1))) +\n  # make no data values transparent\n  scale_fill_viridis_c(na.value = NA) +\n  \n  # layer_spatial trains the scales\n  layer_spatial(longlake_depthdf, aes(fill = DEPTH_M)) +\n  \n  # spatial-aware automagic scale bar\n  annotation_scale(location = \"tl\") +\n\n  # spatial-aware automagic north arrow\n  annotation_north_arrow(location = \"br\", which_north = \"true\")\n#&gt; Warning in layer_spatial(longlake_depth_raster, aes(color =\n#&gt; after_stat(band1))): Ignoring unknown aesthetics: colour\n#&gt; Zoom: 14\n#&gt; Warning: Removed 9122 rows containing missing values (`geom_raster()`).\n\n\n\n\n\n\n\n\n\nCode\n\n  \n  labs(caption = \"\\U00a9 OpenStreetMap contributors\")\n#&gt; $caption\n#&gt; [1] \"© OpenStreetMap contributors\"\n#&gt; \n#&gt; attr(,\"class\")\n#&gt; [1] \"labels\"\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/libs/igraph/index.html",
    "href": "contents/libs/igraph/index.html",
    "title": "igraph",
    "section": "",
    "text": "Code\nrenv::activate(here::here())\ncur_dir &lt;- here::here(\"contents/libs/igraph\")\n\n\n\n\nCode\nbox::use(\n  igraph[...],\n  ggplot2[...],\n  cowplot[...], \n  showtext[showtext_auto], \n  sysfonts[font_add_google],\n)\nshowtext_auto()\nfont_add_google(\"Noto Sans\")\n\n\n\n1 はじめに\nigraphはグラフ構造の解析を行うためのオープンソースのパッケージである。 RだけでなくPython, Mathmaticaでも使うことができる。\nここでは、Rでのigraphの使い方を学ぶこととする。\n\nR interface\nR reference\nigraph\n\nRでコマンド：ネットワークの描写は「igraph」パッケージがやっぱり便利ですを見るとラスターデータもプロット可能である。これを使えばツリー表現も簡単になる気がする。\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/libs/patchwork/working.html",
    "href": "contents/libs/patchwork/working.html",
    "title": "patchwork",
    "section": "",
    "text": "Code\nrenv::activate(here::here())\ncur_dir &lt;- here::here(\"contents/libs/patchwork\")\nCode\npackages &lt;- c(\n  \"tidyverse\", \n  \"magick\",\n  \"ggplot2\", \n  \"readr\", \n  \"tibble\", \n  \"tidyr\", \n  \"forcats\", \n  \"stringr\",\n  \"lubridate\", \n  \"here\", \n  \"systemfonts\", \n  \"magick\", \n  \"scales\", \n  \"grid\",\n  \"grDevices\", \n  \"colorspace\", \n  \"viridis\", \n  \"RColorBrewer\", \n  \"rcartocolor\",\n  \"scico\", \n  \"ggsci\", \n  \"ggthemes\", \n  \"nord\", \n  \"MetBrewer\", \n  \"ggrepel\",\n  \"ggforce\",\n  \"ggtext\", \n  \"ggfittext\",\n  \"ggdist\", \n  \"ggbeeswarm\", \n  \"gghalves\", \n  \"patchwork\", \n  \"palmerpenguins\", \n  \"rnaturalearth\", \n  \"sf\", \n  \"rmapshaper\", \n  \"devtools\", \n  \"extrafont\"\n) |&gt; lapply(\\(x) library(x, character.only = TRUE))\nlibrary(cowplot)\nlibrary(colorblindr)\n\n\nlibrary(showtext)\nshowtext_auto()\nfont_add_google(\"Noto Sans\")"
  },
  {
    "objectID": "contents/libs/patchwork/working.html#controlling-layout",
    "href": "contents/libs/patchwork/working.html#controlling-layout",
    "title": "patchwork",
    "section": "3.1 Controlling layout",
    "text": "3.1 Controlling layout\n通常は自動で、カラム数が２のレイアウトになる。\n\n\nCode\np1 + p2 + p3 + p4\n\n\n\n\n\n\n\n\n\n\n\nCode\np1 + p2 + p3 + p4 + plot_layout(nrow = 3, byrow = FALSE)"
  },
  {
    "objectID": "contents/libs/patchwork/working.html#stacking-and-packing-plots",
    "href": "contents/libs/patchwork/working.html#stacking-and-packing-plots",
    "title": "patchwork",
    "section": "3.2 Stacking and packing plots",
    "text": "3.2 Stacking and packing plots\n1行や1列のレイアウトを指定することにより、グラフの大きさを他のグラフと変更することも可能である。 もしくはレイアウトのショートカットとして|や/を使うこともできる。\n/の方が先に演算されているように見える。\n\n\nCode\np1 | (p2 | p3) / p4\n\n\n\n\n\n\n\n\n\n\n\nCode\np1 | p2 | p3 / p4"
  },
  {
    "objectID": "contents/libs/patchwork/working.html#annotating-the-composition",
    "href": "contents/libs/patchwork/working.html#annotating-the-composition",
    "title": "patchwork",
    "section": "3.3 Annotating the composition",
    "text": "3.3 Annotating the composition\nplot_annotationを使うことで、結合したプロット全体に対するアノテーションを与えることが可能である\n\n\nCode\n(p1 | (p2 / p3)) + \n  plot_annotation(title = \"The surprising story about mtcars\")\n\n\n\n\n\n\n\n\n\nプロットそれぞれにタグを与えることが可能である。 これによりサブプロットの見分けが付きやすくなる。\n\n\nCode\np1 + p2 + p3 + plot_annotation(tag_levels = \"I\")"
  },
  {
    "objectID": "contents/libs/patchwork/working.html#controlling-guides",
    "href": "contents/libs/patchwork/working.html#controlling-guides",
    "title": "patchwork",
    "section": "3.4 Controlling guides",
    "text": "3.4 Controlling guides\nplot_layoutのguides引数を使うことで、凡例の制御が可能である。 そのままプロットするとサブプロットごとの位置に凡例が表示されるが、guidesを使うことで、 プロット全体に対することがわかりやすい位置に配置される。\n\n\nCode\np1 + p2 + p3 + p4\n\n\n\n\n\n\n\n\n\n\n\nCode\np1 + p2 + p3 + p4 + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\n\n初期設定の設定はautoである。keepにすると、かならずサブプロットのプロット領域に凡例が配置されることになる。\n次は複数の凡例を有する場合のプロットである。\n\n\nCode\np1a &lt;- ggplot(mtcars) + geom_point(aes(mpg, disp, colour = mpg, size = wt)) + \n  ggtitle(\"PLot 1a\")\n\np1a | (p2 / p3)\n\n\n\n\n\n\n\n\n\n上記の状態でguidesをcollectにすると、凡例がプロット全体に配置される。\n\n\nCode\n(p1a | (p2 / p3)) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\n\n凡例を凡例だけの場所を準備してそこにプロットすることも可能である。\n\n\nCode\np1 + p2 + p3 + guide_area() + plot_layout(guides = \"collect\")"
  },
  {
    "objectID": "contents/libs/patchwork/working.html#controlling-scales",
    "href": "contents/libs/patchwork/working.html#controlling-scales",
    "title": "patchwork",
    "section": "3.5 Controlling scales",
    "text": "3.5 Controlling scales\nplot_layoutのaxes=collect引数を使うことで、スケールの制御が可能である。\n通常の+では軸は同期された表現にならないが、上記の設定により同期された表現となる。\n\n\nCode\np1 + p2 + plot_layout(axes = \"collect\")\n\n\n\n\n\n\n\n\n\n同期はするが、ラベルを消さないことも可能である。\n\n\nCode\np1 + (p2 + scale_y_continuous(position = \"right\")) + plot_layout(axis_titles = \"collect\")"
  },
  {
    "objectID": "contents/libs/patchwork/working.html#adding-empty-area",
    "href": "contents/libs/patchwork/working.html#adding-empty-area",
    "title": "patchwork",
    "section": "3.6 Adding empty area",
    "text": "3.6 Adding empty area\n\n\nCode\np1 + plot_spacer() + p2 + plot_spacer() + p3 + plot_spacer()\n\n\n\n\n\n\n\n\n\n\n\nCode\n(p1 + plot_spacer() + p2) / (plot_spacer() + p3 + plot_spacer())"
  },
  {
    "objectID": "contents/libs/patchwork/working.html#controlling-the-grid",
    "href": "contents/libs/patchwork/working.html#controlling-the-grid",
    "title": "patchwork",
    "section": "3.7 Controlling the grid",
    "text": "3.7 Controlling the grid\n\n\nCode\np1 + p2 + p3 + p4 + \n  plot_layout(widths = c(2, 1), byrow = FALSE, ncol = 2)"
  },
  {
    "objectID": "contents/libs/patchwork/working.html#moving-beyond-the-grid",
    "href": "contents/libs/patchwork/working.html#moving-beyond-the-grid",
    "title": "patchwork",
    "section": "3.8 Moving beyond the grid",
    "text": "3.8 Moving beyond the grid\nより柔軟なレイアウトの指定方法である\n\n\nCode\nlayout &lt;- \"\n##BBBB\nAACCDD\n##CCDD\n\"\np1 + p2 + p3 + p4 + \n  plot_layout(design = layout)\n\n\n\n\n\n\n\n\n\nareaconstructorを使うことでさらにプログラミックなものを作成することが可能である。\n\n\nCode\nlayout &lt;- c(\n  area(t = 2, l = 1, b = 5, r = 4),\n  area(t = 1, l = 3, b = 3, r = 5), \n  area(t = 3, l = 2, b = 4, r = 2.5)\n)\np1 + p2 + p3 + \n  plot_layout(design = layout)"
  },
  {
    "objectID": "contents/libs/patchwork/working.html#fixed-aspect-plots",
    "href": "contents/libs/patchwork/working.html#fixed-aspect-plots",
    "title": "patchwork",
    "section": "3.9 Fixed aspect plots",
    "text": "3.9 Fixed aspect plots\n固定軸でのプロットアセンブリは特別なケースである。coord_fixed, coord_polar, coord_sf。\nデフォルトな固定軸に合わせられる。\n\n\nCode\np_fixed &lt;- ggplot(mtcars) + \n  geom_point(aes(hp, disp)) + \n  ggtitle('Plot F') + \n  coord_fixed()\np_fixed + p1 + p2 + p3\n\n\n\n\n\n\n\n\n\n合わせたくないときには、幅を指定すればよい。アスペクト比が維持されていることがわかるｓｓ\n\n\nCode\np_fixed + p1 + p2 + p3 + plot_layout(widths = 1)"
  },
  {
    "objectID": "contents/libs/patchwork/working.html#avoiding-alignment",
    "href": "contents/libs/patchwork/working.html#avoiding-alignment",
    "title": "patchwork",
    "section": "3.10 Avoiding alignment",
    "text": "3.10 Avoiding alignment\nたとえば、captionが長いがそれに合わせて他のグラフについて、余白を調整したくないときがある。 そのときには次のような処理をおこなう。\n\n\nCode\np2mod &lt;- p2 + labs(x = \"This is such a long\\nand important label that\\nit has to span many lines\")\np1 | p2mod\n\n\n\n\n\n\n\n\n\n\n\nCode\nfree(p1) | p2mod\n\n\n\n\n\n\n\n\n\n\n\nCode\np1 + inset_element(p2, left = 0.6, bottom = 0.6, right = 1, top = 1)"
  },
  {
    "objectID": "contents/libs/patchwork/working.html#insets",
    "href": "contents/libs/patchwork/working.html#insets",
    "title": "patchwork",
    "section": "3.11 Insets",
    "text": "3.11 Insets\n\n\nCode\np1 + inset_element(p2, left = 0.6, bottom = 0.6, right = 1, top = 1)\n\n\n\n\n\n\n\n\n\nnpcという変数を使うことで、エリアの座標を0, 1にした相対値で指定することが可能となる\n\n\nCode\n\np1 + inset_element(\n  p2, \n  left = 0.5, \n  bottom = 0.5, \n  right = unit(1, 'npc') - unit(1, 'cm'), \n  top = unit(1, 'npc') - unit(1, 'cm')\n)"
  },
  {
    "objectID": "contents/libs/patchwork/working.html#adding-non-ggplot-content",
    "href": "contents/libs/patchwork/working.html#adding-non-ggplot-content",
    "title": "patchwork",
    "section": "4.1 Adding non-ggplot content",
    "text": "4.1 Adding non-ggplot content\n\n\nCode\np1 + grid::textGrob('Some really important text')"
  },
  {
    "objectID": "contents/libs/patchwork/working.html#stacking-and-packing",
    "href": "contents/libs/patchwork/working.html#stacking-and-packing",
    "title": "patchwork",
    "section": "4.2 Stacking and packing",
    "text": "4.2 Stacking and packing\n\n\nCode\np1 + gridExtra::tableGrob(mtcars[1:10, c('mpg', 'disp')])\n\n\n\n\n\n\n\n\n\n通常のプロットでも組合せていいみたい。\n\n\nCode\np1 + ~plot(mtcars$mpg, mtcars$disp, main = 'Plot 2')"
  },
  {
    "objectID": "contents/libs/patchwork/working.html#modfiying-patches",
    "href": "contents/libs/patchwork/working.html#modfiying-patches",
    "title": "patchwork",
    "section": "4.3 Modfiying patches",
    "text": "4.3 Modfiying patches\nグラフ全体でテーマを変換するときに\n\n\nCode\npatchwork &lt;- p3 / (p1 | p2)\npatchwork & theme_minimal()"
  },
  {
    "objectID": "contents/libs/treemapify/working.html",
    "href": "contents/libs/treemapify/working.html",
    "title": "treemapify",
    "section": "",
    "text": "Code\nrenv::activate(here::here())\ncur_dir &lt;- here::here(\"contents/libs/treemapify\")\nCode\nlibrary(treemapify)\nlibrary(showtext)\nlibrary(dplyr)\nlibrary(ggplot2)\nshowtext_auto()\nfont_add_google(\"Noto Sans\")"
  },
  {
    "objectID": "contents/libs/treemapify/working.html#sample-data",
    "href": "contents/libs/treemapify/working.html#sample-data",
    "title": "treemapify",
    "section": "2.1 sample data",
    "text": "2.1 sample data\n\n\nCode\ngroup &lt;- paste(\"Group\", 1:9)\nsubgroup &lt;- c(\"A\", \"C\", \"B\", \"A\", \"A\",\n              \"C\", \"C\", \"B\", \"B\")\nvalue &lt;- c(7, 25, 50, 5, 16,\n           18, 30, 12, 41)\n\ndf &lt;- data.frame(group, subgroup, value) \ndf\n#&gt;     group subgroup value\n#&gt; 1 Group 1        A     7\n#&gt; 2 Group 2        C    25\n#&gt; 3 Group 3        B    50\n#&gt; 4 Group 4        A     5\n#&gt; 5 Group 5        A    16\n#&gt; 6 Group 6        C    18\n#&gt; 7 Group 7        C    30\n#&gt; 8 Group 8        B    12\n#&gt; 9 Group 9        B    41"
  },
  {
    "objectID": "contents/libs/treemapify/working.html#fill-by-categorical",
    "href": "contents/libs/treemapify/working.html#fill-by-categorical",
    "title": "treemapify",
    "section": "2.2 Fill by categorical",
    "text": "2.2 Fill by categorical\n\n\nCode\nggplot(df, aes(area = value, fill = group)) +\n  geom_treemap()"
  },
  {
    "objectID": "contents/libs/treemapify/working.html#fill-by-the-numerical-variable",
    "href": "contents/libs/treemapify/working.html#fill-by-the-numerical-variable",
    "title": "treemapify",
    "section": "2.3 Fill by the numerical variable",
    "text": "2.3 Fill by the numerical variable\n\n\nCode\n\nggplot(df, aes(area = value, fill = value)) +\n  geom_treemap()"
  },
  {
    "objectID": "contents/libs/treemapify/working.html#with-label",
    "href": "contents/libs/treemapify/working.html#with-label",
    "title": "treemapify",
    "section": "2.4 with label",
    "text": "2.4 with label\n\n\nCode\nggplot(df, aes(area = value, fill = group, label = value)) +\n  geom_treemap() +\n  geom_treemap_text(colour = \"white\",\n                    place = \"centre\",\n                    size = 15)"
  },
  {
    "objectID": "contents/libs/treemapify/working.html#label-grow",
    "href": "contents/libs/treemapify/working.html#label-grow",
    "title": "treemapify",
    "section": "2.5 label grow",
    "text": "2.5 label grow\n\n\nCode\nggplot(df, aes(area = value, fill = value, label = group)) +\n  geom_treemap() +\n  geom_treemap_text(colour = \"white\",\n                    place = \"centre\",\n                    size = 15,\n                    grow = TRUE)"
  },
  {
    "objectID": "contents/libs/treemapify/working.html#sub-group",
    "href": "contents/libs/treemapify/working.html#sub-group",
    "title": "treemapify",
    "section": "2.6 sub group",
    "text": "2.6 sub group\n\n\nCode\nggplot(df, aes(area = value, fill = value,\n               label = group, subgroup = subgroup)) +\n  geom_treemap() +\n  geom_treemap_subgroup_border(colour = \"white\", size = 5) +\n  geom_treemap_subgroup_text(place = \"centre\", grow = TRUE,\n                             alpha = 0.25, colour = \"black\",\n                             fontface = \"italic\") +\n  geom_treemap_text(colour = \"white\", place = \"centre\",\n                    size = 15, grow = TRUE)"
  },
  {
    "objectID": "contents/libs/treemapify/working.html#color-customize",
    "href": "contents/libs/treemapify/working.html#color-customize",
    "title": "treemapify",
    "section": "2.7 color customize",
    "text": "2.7 color customize\n\n\nCode\nggplot(df, aes(area = value, fill = group, label = value)) +\n  geom_treemap() +\n  geom_treemap_text(colour = \"white\",\n                    place = \"centre\",\n                    size = 15) +\n  scale_fill_brewer(palette = \"Blues\")"
  },
  {
    "objectID": "contents/books/01_Rによる実証分析_2e/ch02_統計の基礎知識.html#section",
    "href": "contents/books/01_Rによる実証分析_2e/ch02_統計の基礎知識.html#section",
    "title": "ch02 統計の基礎知識",
    "section": "3.1 2.1",
    "text": "3.1 2.1\n\n\nCode\nx &lt;- runif(100)\nprint(mean(x))\n#&gt; [1] 0.4563257\nprint(var(x))\n#&gt; [1] 0.08013847\nprint(sd(x))\n#&gt; [1] 0.2830874\n\n\n\n\nCode\nparams &lt;- tibble(\n    n_sample =  c(1:1000), \n    n_simulate = 1000\n)\nresult &lt;- \n    params |&gt; \n    mutate(res = map2(n_sample, n_simulate, \\(x, y) replicate(y, mean(runif(x))))) |&gt; \n    mutate(mean = map_dbl(res, mean), sd = map_dbl(res, sd))\n\nresult |&gt; \n    ggplot(aes(x = n_sample, y = mean)) + \n    geom_line() + \n    scale_x_log10() + \n    scale_y_continuous(\n        breaks = 0:10 * .1, \n        limits = c(0, 1)) + \n    geom_ribbon(\n        aes(ymin = mean - sd, ymax = mean + sd), fill = \"pink\", alpha = .5) + \n    theme(\n        panel.grid.minor = element_blank()\n    )"
  },
  {
    "objectID": "contents/books/01_Rによる実証分析_2e/ch02_統計の基礎知識.html#section-1",
    "href": "contents/books/01_Rによる実証分析_2e/ch02_統計の基礎知識.html#section-1",
    "title": "ch02 統計の基礎知識",
    "section": "3.2 2.2",
    "text": "3.2 2.2\n\n\nCode\nlibrary(correlation)\n\ndf &lt;- tibble(\n    x = runif(100), \n    y = rnorm(100, 0, 1), \n    z = 1.3 * x - .7 * y\n)\n\nuv &lt;- \n    combn(syms(c(\"x\", \"y\", \"z\")), 2, simplify = FALSE)\n\ngraphs &lt;-\n    uv |&gt; \n    map(\\(x) ggplot(df, aes(!!x[[1]], !!x[[2]])) + geom_point()) |&gt; \n    list_modify(ncol = 1)\n\ndo.call(grid.arrange, graphs)\n\n\n\n\n\n\n\n\n\n\n\nCode\ndf |&gt; \n    correlation()\n#&gt; # Correlation Matrix (pearson-method)\n#&gt; \n#&gt; Parameter1 | Parameter2 |     r |         95% CI |  t(98) |         p\n#&gt; ---------------------------------------------------------------------\n#&gt; x          |          y | -0.24 | [-0.42, -0.05] |  -2.44 | 0.016*   \n#&gt; x          |          z |  0.63 | [ 0.50,  0.74] |   8.07 | &lt; .001***\n#&gt; y          |          z | -0.90 | [-0.93, -0.86] | -20.91 | &lt; .001***\n#&gt; \n#&gt; p-value adjustment method: Holm (1979)\n#&gt; Observations: 100\n\n\n標本サイズと相関係数の関係を確認する。\n\n\nCode\nlibrary(correlation)\n\nparams &lt;- tibble(\n    n_sample =  c(10:1000), \n    n_simulate = 100\n)\nresult &lt;- \n    params |&gt; \n    mutate(res1 = map2(\n        n_sample, \n        n_simulate, \n        \\(x, y) replicate(\n            y, {\n                xx = runif(x)\n                yy = rnorm(x, 0, 1)\n                zz = 1.3 * xx - .7 * yy\n                c(\"xy\" = cor(xx, yy), \"yz\" = cor(yy, zz), \"zx\" = cor(zz, xx))\n            }))) |&gt; \n    mutate(res1 = map(res1, \\(x) as_tibble(t(x)))) |&gt; \n    mutate(res1 = map(res1, \\(x) summarise(x, across(everything(), .fns = list(mean = mean, sd = sd))))) |&gt; \n    unnest(res1)\n\n\n\n\nCode\ncols &lt;- c(\"xy\", \"yz\", \"zx\")\ngraphs &lt;- \n    map(cols, \\(x) {\n        u &lt;- sym(glue::glue(\"{x}_mean\"))\n        v &lt;- sym(glue::glue(\"{x}_sd\"))\n        result |&gt; \n            ggplot(aes(x = n_sample, y = !!u)) + \n            geom_path() + \n            geom_ribbon(\n                aes(ymin = !!u - !!v, ymax = !!u + !!v), fill = \"pink\", alpha = .5)\n    }) |&gt; \n    list_modify(ncol = 1)\n\ndo.call(grid.arrange, graphs)"
  },
  {
    "objectID": "contents/books/01_Rによる実証分析_2e/ch04_回帰分析の基礎.html#気温と電力使用量",
    "href": "contents/books/01_Rによる実証分析_2e/ch04_回帰分析の基礎.html#気温と電力使用量",
    "title": "ch04 回帰分析の基礎",
    "section": "2.1 気温と電力使用量",
    "text": "2.1 気温と電力使用量\n\n\nCode\npath &lt;- here(cur_dir, \"data/R_EmpiricalAnalysis_csv/chap03/temperature.csv\")\ntempdata  &lt;- \n    read_csv(path, show_col_types = FALSE) |&gt; \n    filter(between(strftime(date), strftime(\"2014/8/1\"), strftime(\"2014/8/31\")))\nhead(tempdata)\n#&gt; # A tibble: 6 × 5\n#&gt;   date     time    elec  prec  temp\n#&gt;   &lt;chr&gt;    &lt;time&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 2014/8/1 00:00   3193     0  27.9\n#&gt; 2 2014/8/1 01:00   2960     0  27.9\n#&gt; 3 2014/8/1 02:00   2807     0  27.1\n#&gt; 4 2014/8/1 03:00   2748     0  26.8\n#&gt; 5 2014/8/1 04:00   2735     0  26.9\n#&gt; 6 2014/8/1 05:00   2736     0  27.3\n\n\n\n\nCode\nsummaries &lt;- tempdata |&gt; skim() |&gt; partition()\n\nmap(summaries, paged_table)\n#&gt; $character\n#&gt;   skim_variable n_missing complete_rate min max empty n_unique whitespace\n#&gt; 1          date         0             1   8   9     0       31          0\n#&gt; \n#&gt; $difftime\n#&gt;   skim_variable n_missing complete_rate    min        max     median n_unique\n#&gt; 1          time         0             1 0 secs 82800 secs 41400 secs       24\n#&gt; \n#&gt; $numeric\n#&gt;   skim_variable n_missing complete_rate        mean          sd     p0      p25\n#&gt; 1          elec         0             1 3398.486559 714.3446713 2213.0 2823.500\n#&gt; 2          prec         0             1    0.141129   0.9451167    0.0    0.000\n#&gt; 3          temp         0             1   27.668414   3.5454533   19.8   25.675\n#&gt;      p50      p75   p100  hist\n#&gt; 1 3342.5 3871.500 4980.0 ▆▇▇▃▃\n#&gt; 2    0.0    0.000   17.0 ▇▁▁▁▁\n#&gt; 3   28.0   30.125   35.5 ▃▂▇▅▂\n\n\nまずはデータをプロットしてみる。\n\n\nCode\ntempdata |&gt; \n    filter(between(strftime(date), strftime(\"2014/8/1\"), strftime(\"2014/8/31\"))) |&gt; \n    ggplot(aes(x = time, y = temp)) +\n    geom_point() + \n    xlab(\"時刻\") + \n    ylab(\"気温\") + \n    ggtitle(\"2014年8月における時刻と気温の関係\")\n\n\n\n\n\n\n\n\n\nノンパラメトリック回帰として時刻ごとの平均値を求める。\n\n\nCode\ntempdata |&gt; \n    group_by(time) |&gt; \n    summarise(across(c(temp), .fns = list(mean = mean, sd = sd, max = max, min = min)))\n#&gt; # A tibble: 24 × 5\n#&gt;    time   temp_mean temp_sd temp_max temp_min\n#&gt;    &lt;time&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt;  1 00:00       26.4    2.75     29.3     20.1\n#&gt;  2 01:00       26.1    2.73     29.3     19.8\n#&gt;  3 02:00       25.9    2.69     28.7     19.8\n#&gt;  4 03:00       25.8    2.61     28.3     20.2\n#&gt;  5 04:00       25.7    2.67     28.5     19.9\n#&gt;  6 05:00       25.8    2.76     28.6     20.1\n#&gt;  7 06:00       26.4    3.10     29.8     19.9\n#&gt;  8 07:00       27.3    3.41     31.1     20.2\n#&gt;  9 08:00       28.1    3.54     32.1     20.5\n#&gt; 10 09:00       29.0    3.80     33.5     20.9\n#&gt; # ℹ 14 more rows\n\n\n\n\nCode\ntempdata |&gt; \n    filter(between(strftime(date), strftime(\"2014/8/1\"), strftime(\"2014/8/31\"))) |&gt; \n    ggplot(aes(x = time, y = temp)) + \n    geom_point() + \n    stat_summary(geom = \"line\", fun = \"mean\") + \n    xlab(\"時間\") + \n    ylab(\"気温\") + \n    coord_cartesian()\n\n\n\n\n\n\n\n\n\n相関係数を見てみると、電力と気温には強い正の関係があることがわかる。\n\n\nCode\nlibrary(correlation)\ncorrelation(tempdata)\n#&gt; # Correlation Matrix (pearson-method)\n#&gt; \n#&gt; Parameter1 | Parameter2 |     r |         95% CI | t(742) |         p\n#&gt; ---------------------------------------------------------------------\n#&gt; elec       |       prec | -0.08 | [-0.15, -0.01] |  -2.20 | 0.028*   \n#&gt; elec       |       temp |  0.72 | [ 0.68,  0.75] |  28.25 | &lt; .001***\n#&gt; prec       |       temp | -0.16 | [-0.23, -0.09] |  -4.31 | &lt; .001***\n#&gt; \n#&gt; p-value adjustment method: Holm (1979)\n#&gt; Observations: 744\n\n\n\n\nCode\ntempdata |&gt; \n    ggplot(aes(temp, elec)) + \n    geom_point()\n\n\n\n\n\n\n\n\n\nノンパラメトリック回帰として、気温ごとの平均値を算出する。\n\n\nCode\ntempdata |&gt; \n    transmute(temp = round(temp), elec, time = hour(time)) |&gt; \n    ggplot(aes(x = temp, y = elec)) +\n    geom_point(aes(color = time)) + \n    stat_summary(geom= \"line\", fun = \"mean\", color = \"red\") + \n    theme(panel.grid.minor = element_blank()) + \n    scale_color_viridis_b(\n        breaks = c(0, 6, 12, 18, 24), \n        limits = c(0, 24)\n    )"
  },
  {
    "objectID": "contents/books/01_Rによる実証分析_2e/ch06_相関関係と因果関係.html#疑似相関",
    "href": "contents/books/01_Rによる実証分析_2e/ch06_相関関係と因果関係.html#疑似相関",
    "title": "ch06 相関関係と因果関係",
    "section": "2.1 疑似相関",
    "text": "2.1 疑似相関\n下記のグラフを見ると、ゲーム時間が少ないほど、得点が高いという負の相関が見られる。\nただし本当にこれを因果関係とみるのかは別の問題である。なぜなら、家庭環境などの交絡情報が含まれている可能性が高いためである。 また、実際には点そのものではなく、勉強時間などへの影響をみるべきである。そうでないと、 ゲームの時間を減らしただけで点があがるのかということになる。\nつまり、家庭環境や勉強時間を条件付けた上で、ゲームの時間がテストの点に与える影響を見る必要がある。\n\n\nCode\npath &lt;- here(cur_dir, \"data/R_EmpiricalAnalysis_csv/chap06/video_game.csv\")\nvideodata &lt;- read_csv(path, show_col_types = FALSE)\nvideodata\n#&gt; # A tibble: 500 × 2\n#&gt;    grade hours\n#&gt;    &lt;dbl&gt; &lt;dbl&gt;\n#&gt;  1    81   0  \n#&gt;  2    47   2.4\n#&gt;  3    59   2  \n#&gt;  4    47   2.2\n#&gt;  5    22   2.3\n#&gt;  6    49   1.7\n#&gt;  7    78   0  \n#&gt;  8    59   0  \n#&gt;  9    42   2.2\n#&gt; 10    43   1.6\n#&gt; # ℹ 490 more rows\n\n\n\n\nCode\nvideodata |&gt; \n    ggplot(aes(hours, grade)) + \n    geom_point()"
  },
  {
    "objectID": "contents/books/01_Rによる実証分析_2e/ch06_相関関係と因果関係.html#同時性",
    "href": "contents/books/01_Rによる実証分析_2e/ch06_相関関係と因果関係.html#同時性",
    "title": "ch06 相関関係と因果関係",
    "section": "2.2 同時性",
    "text": "2.2 同時性\n同時性とは「２つの事柄について、お互いがお互いの原因であり同時に結果である」という状態である。 需要と供給で言えば、ニーズが高まれば多く供給されるが、多く供給されることでニーズが減るという、関係性にある。"
  },
  {
    "objectID": "contents/books/01_Rによる実証分析_2e/ch08_ランダム化実験.html",
    "href": "contents/books/01_Rによる実証分析_2e/ch08_ランダム化実験.html",
    "title": "ch08 ランダム化実験",
    "section": "",
    "text": "1 Setup\n\n\n2 はじめに\nまず本当に独立な説明変数であったら、その変数が含まれているのかどうか係数に影響しないことを確認する。 下記から変数にバイアスが生じていないことが確認できる。\n\n\nCode\nn  &lt;- 100\nbeta0 &lt;- 0.5\nbeta1 &lt;- 1\nbeta2 &lt;- 2\n\nresult &lt;- replicate(300, {\n    x1 &lt;- rnorm(n, sd = .8)\n    x2 &lt;- rnorm(n, sd = 1.5) + 3\n    y &lt;- beta0 + beta1 * x1 + beta2 * x2 + rnorm(n)\n    coef(lm(y ~ x1))[2]\n})\n\nhist(result)\n\n\n\n\n\n\n\n\n\n\n\nCode\nsummary(result)\n#&gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#&gt; -0.2883  0.7491  1.0277  1.0248  1.3080  2.6383\n\n\nただし、定数項は別なので注意すること。\n\n\nCode\nn  &lt;- 100\nbeta0 &lt;- 0.5\nbeta1 &lt;- 1\nbeta2 &lt;- 2\n\nresult &lt;- replicate(300, {\n    x1 &lt;- rnorm(n, sd = .8)\n    x2 &lt;- rnorm(n, sd = 1.5) + 3\n    y &lt;- beta0 + beta1 * x1 + beta2 * x2 + rnorm(n)\n    coef(lm(y ~ x1))[1]\n})\n\nhist(result)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/books/01_Rによる実証分析_2e/ch10_回帰不連続デザイン.html",
    "href": "contents/books/01_Rによる実証分析_2e/ch10_回帰不連続デザイン.html",
    "title": "ch10 回帰不連続デザイン",
    "section": "",
    "text": "1 Setup\n\n\n2 はじめに\n「テストの点数が60未満を対象に強制した補講」の学習に与える効果を考える。 ランダムなトリートメントではないためこれまでの比較は困難であるが、 60点前後の人達については実際にはランダムに近い状態にある。 ここではその情報を使って処理を行う。\nもう少し詳しくいうとある変数\\(Z_i\\)がわかればトリートメントの状態が 判断できるというデータセットについて考える。\n「ぎりぎり補講にならなかった学生」と「ぎりぎり補講になった学生」の比較なら、 補講の効果を判断しやすいはずという考えである。\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/books/01_Rによる実証分析_2e/ch12_パネルデータ.html",
    "href": "contents/books/01_Rによる実証分析_2e/ch12_パネルデータ.html",
    "title": "ch12 パネルデータ",
    "section": "",
    "text": "1 Setup\n\n\n2 固定効果モデル\n1997年から2019年の47都道府県別の失業率と自殺死亡率のデータを使う.\n\npref: 都道府県\nyear: 年度\nsuicide: 自殺率\nunemp: 完全失業率\n\n上記のデータに対して、失業などの経済的な不安定が心身の 疲弊を招き、最悪の場合には自殺に至るという考える。\n\n\nCode\npath_to_file &lt;- here(cur_dir, \"data/R_EmpiricalAnalysis_csv/chap12/prefecture.csv\")\nprefdata &lt;- read_csv(path_to_file, show_col_types = FALSE)\nprefdata |&gt; \n    head() |&gt; \n    paged_table()\n\n\n\n\n  \n\n\n\n\n\nCode\nprefdata |&gt; \n    lm(suicide ~ -1 + unemp + pref, data = _) |&gt; \n    tidy() |&gt; \n    select(term, estimate) |&gt; \n    filter(term == \"unemp\")\n#&gt; # A tibble: 1 × 2\n#&gt;   term  estimate\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;\n#&gt; 1 unemp     3.07\n\n\n上記の結果は失業率が１％上昇すると、１０万人あたりの自殺者が３人増えるという結果である。\n次に、被説明変数と説明変数からそれぞれの都道府県別平均を引いた変数を作成して、 within推定を実施する。\n\n\nCode\nprefdata |&gt; \n    group_by(pref) |&gt; \n    mutate(\n        suicidebar = mean(suicide), \n        unempbar = mean(unemp), \n        suicide2 = suicide - suicidebar, \n        unemp2 = unemp - unempbar\n    ) |&gt; \n    lm(suicide2 ~ -1 + unemp2, data = _) |&gt; \n    tidy() |&gt; \n    select(term, estimate)\n#&gt; # A tibble: 1 × 2\n#&gt;   term   estimate\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;\n#&gt; 1 unemp2     3.07\n\n\n上記の結果は、都道府県について固定したモデルである。 ここでさらに、時間について固定した、２方向固定効果モデルについて検討する。\n\n\nCode\nlibrary(fixest)\nprefdata |&gt; \n    feols(suicide ~ unemp | pref + year)\n#&gt; OLS estimation, Dep. Var.: suicide\n#&gt; Observations: 1,081 \n#&gt; Fixed-effects: pref: 47,  year: 23\n#&gt; Standard-errors: Clustered (pref) \n#&gt;       Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; unemp 0.770868   0.298724 2.58054 0.013121 *  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; RMSE: 1.76097     Adj. R2: 0.8622  \n#&gt;                 Within R2: 0.022751\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/books/02_因果推論ミックステープ/ch01_導入.html",
    "href": "contents/books/02_因果推論ミックステープ/ch01_導入.html",
    "title": "ch01 導入",
    "section": "",
    "text": "1 はじめに\n\n本書は因果推論のプログラム的な部分を補間する内容である\n扱っている内容\n\n潜在アウトカムモデル\n実験デザイン\nマッチング\n操作変数法\n回帰不連続デザイン\nパネルデータ\nDAG：非巡回的有向グラフ\n\n扱っていない内容\n\n合成コントロール\nグラフィカルモデル\n\n\n\n\n2 最適化はすべてを内生化する\n\n\n\n\n\n\nCaution\n\n\n\n「因果を発見した」というあらゆる主張には、その正当化のために事前の知識が必要不可欠である。\n\n\n\n\n\n\n\n\nCaution\n\n\n\n信頼できる、価値のある研究をするためには、特定の意図した結果を求めるのではなく、 方法論に則って正しく研究をおこなうことが、より重要でえある。\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/books/02_因果推論ミックステープ/ch03_非巡回的有向グラフ.html",
    "href": "contents/books/02_因果推論ミックステープ/ch03_非巡回的有向グラフ.html",
    "title": "ch03 非巡回的有向グラフ",
    "section": "",
    "text": "DAG記法では因果関係は一方向にしか進まない\nDAGでは需要供給のような同時性を扱うことはできない\n因果関係には2つの生じ方がある\n\n直接働く場合\n第三の変数を媒介する場合\n\nこれをバックドアパスという\n第三の変数が未観測のときバックドアが開いてるという\nバックドアがある状態では因果不明である\nこのような第三因子を交絡因子ともいう\n\n\nDAGはデータが関係あるということを示している\n\n\n\nバックドアとなる変数が観測されているときに、正しく推定ができるのかを確認してみる。次の例は、xがyに直接影響を与える場合と、xがzを経由してyに影響を与えることがわかる。両方とも観測できていれば、それぞれがyに与える影響を正しく推定出来てることがわかる。\n\n\nCode\ndataset &lt;- tibble(\n    x = rnorm(100), \n    z = 2 * x + rnorm(100), \n    y = 1 + x + 3 * z + rnorm(100) \n) \n\nfit &lt;- lm(y ~ x + z, data = dataset)\n\nfit |&gt; \n    summary()\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y ~ x + z, data = dataset)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -2.51787 -0.46488  0.02229  0.55098  2.19908 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  0.89229    0.09707   9.193 7.43e-15 ***\n#&gt; x            1.11262    0.22282   4.993 2.62e-06 ***\n#&gt; z            2.94408    0.09981  29.496  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.9639 on 97 degrees of freedom\n#&gt; Multiple R-squared:  0.9853, Adjusted R-squared:  0.985 \n#&gt; F-statistic:  3262 on 2 and 97 DF,  p-value: &lt; 2.2e-16\n\n\nxがzを経由してyに影響を与えている分もあるので、zを見込まないとバイアスが入ることがわかる。\n\n\nCode\ndataset &lt;- tibble(\n    x = rnorm(100), \n    z = 2 * x + rnorm(100), \n    y = 1 + x + 3 * z + rnorm(100) \n) \n\nfit &lt;- lm(y ~ x, data = dataset)\n\nfit |&gt; \n    summary()\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y ~ x, data = dataset)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -13.3364  -1.4937  -0.0125   2.2119   5.8786 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)   1.0550     0.3245   3.252  0.00157 ** \n#&gt; x             7.1368     0.2835  25.174  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 3.221 on 98 degrees of freedom\n#&gt; Multiple R-squared:  0.8661, Adjusted R-squared:  0.8647 \n#&gt; F-statistic: 633.7 on 1 and 98 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\nバックドアパスが開いているときに、回帰分析をすると、 推定値の符号を反転させるほどの深刻な問題が引き起こされる。 このためデータ分析の際には、バックドアパスを閉じることにする。\nバックドアを閉じる方法は次の２つである。\n\n交絡因子を条件付ける(マッチングなど)\n合流点を作りバックドアを閉じる\n\nすべてのバックドアパスが閉じているときに、そのリサーチデザインはバックドア基準を満たすということになる。\nバックドアの合流点があるときに、その合流点を制御することで、バックドアパスが閉じられることになる。アウトカムとなる変数について、関心がある変数以外の合流点があるときにはその合流点を制御するだけで、バックドア基準を満たすことができる。　\n合流点バイアスの考え方は非常に難しいわ。\n\n\nCode\nlibrary(stargazer)\n\ntb &lt;- tibble(\n    female  = ifelse(runif(10000) &gt; .5, 1, 0), \n    ability = rnorm(10000), \n    discrimination = female, \n    occupation = 1 + 2 * ability + 0 * female - 2 * discrimination  + rnorm(10000), \n    wage       = 1 - 1 * discrimination  + 1 * occupation + 2 * ability + rnorm(10000)\n)\n\nlm_1 &lt;- lm(wage ~ female, tb)\nlm_2 &lt;- lm(wage ~ female + occupation, tb)\nlm_3 &lt;- lm(wage ~ female + occupation + ability, tb)\n\n\n# warningが出るが問題ない\n# chunkで実行する場合にだけwarningが発生してくる\nstargazer(lm_1, lm_2, lm_3, type = \"text\", omit.stat = \"all\", column.labels = c(\"a\", \"b\", \"c\"))\n#&gt; \n#&gt; ========================================\n#&gt;                 Dependent variable:     \n#&gt;            -----------------------------\n#&gt;                        wage             \n#&gt;                a         b         c    \n#&gt;               (1)       (2)       (3)   \n#&gt; ----------------------------------------\n#&gt; female     -2.862***  0.606*** -0.988***\n#&gt;             (0.085)   (0.029)   (0.028) \n#&gt;                                         \n#&gt; occupation            1.817*** 1.014*** \n#&gt;                       (0.006)   (0.010) \n#&gt;                                         \n#&gt; ability                        1.981*** \n#&gt;                                 (0.023) \n#&gt;                                         \n#&gt; Constant    1.946***  0.211*** 1.001*** \n#&gt;             (0.061)   (0.020)   (0.017) \n#&gt;                                         \n#&gt; ========================================\n#&gt; ========================================\n#&gt; Note:        *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nDAGにおいて合流点をコントロールすると、つまり今回の場合には職業をコントロールすると、 差別と賃金の間に、関係全体を歪めるほど強力活誤ったバックドアパスが 開いてしまう。職業と能力をコントロールした場合にのみ、 賃金に対するジェンダーの直接的な因果効果を分離することができるのである。\nバックドアとDAGのノート"
  },
  {
    "objectID": "contents/books/02_因果推論ミックステープ/ch03_非巡回的有向グラフ.html#シミュレーション1",
    "href": "contents/books/02_因果推論ミックステープ/ch03_非巡回的有向グラフ.html#シミュレーション1",
    "title": "ch03 非巡回的有向グラフ",
    "section": "",
    "text": "バックドアとなる変数が観測されているときに、正しく推定ができるのかを確認してみる。次の例は、xがyに直接影響を与える場合と、xがzを経由してyに影響を与えることがわかる。両方とも観測できていれば、それぞれがyに与える影響を正しく推定出来てることがわかる。\n\n\nCode\ndataset &lt;- tibble(\n    x = rnorm(100), \n    z = 2 * x + rnorm(100), \n    y = 1 + x + 3 * z + rnorm(100) \n) \n\nfit &lt;- lm(y ~ x + z, data = dataset)\n\nfit |&gt; \n    summary()\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y ~ x + z, data = dataset)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -2.51787 -0.46488  0.02229  0.55098  2.19908 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  0.89229    0.09707   9.193 7.43e-15 ***\n#&gt; x            1.11262    0.22282   4.993 2.62e-06 ***\n#&gt; z            2.94408    0.09981  29.496  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.9639 on 97 degrees of freedom\n#&gt; Multiple R-squared:  0.9853, Adjusted R-squared:  0.985 \n#&gt; F-statistic:  3262 on 2 and 97 DF,  p-value: &lt; 2.2e-16\n\n\nxがzを経由してyに影響を与えている分もあるので、zを見込まないとバイアスが入ることがわかる。\n\n\nCode\ndataset &lt;- tibble(\n    x = rnorm(100), \n    z = 2 * x + rnorm(100), \n    y = 1 + x + 3 * z + rnorm(100) \n) \n\nfit &lt;- lm(y ~ x, data = dataset)\n\nfit |&gt; \n    summary()\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y ~ x, data = dataset)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -13.3364  -1.4937  -0.0125   2.2119   5.8786 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)   1.0550     0.3245   3.252  0.00157 ** \n#&gt; x             7.1368     0.2835  25.174  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 3.221 on 98 degrees of freedom\n#&gt; Multiple R-squared:  0.8661, Adjusted R-squared:  0.8647 \n#&gt; F-statistic: 633.7 on 1 and 98 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "contents/books/02_因果推論ミックステープ/ch03_非巡回的有向グラフ.html#バックドア基準",
    "href": "contents/books/02_因果推論ミックステープ/ch03_非巡回的有向グラフ.html#バックドア基準",
    "title": "ch03 非巡回的有向グラフ",
    "section": "",
    "text": "バックドアパスが開いているときに、回帰分析をすると、 推定値の符号を反転させるほどの深刻な問題が引き起こされる。 このためデータ分析の際には、バックドアパスを閉じることにする。\nバックドアを閉じる方法は次の２つである。\n\n交絡因子を条件付ける(マッチングなど)\n合流点を作りバックドアを閉じる\n\nすべてのバックドアパスが閉じているときに、そのリサーチデザインはバックドア基準を満たすということになる。\nバックドアの合流点があるときに、その合流点を制御することで、バックドアパスが閉じられることになる。アウトカムとなる変数について、関心がある変数以外の合流点があるときにはその合流点を制御するだけで、バックドア基準を満たすことができる。　\n合流点バイアスの考え方は非常に難しいわ。\n\n\nCode\nlibrary(stargazer)\n\ntb &lt;- tibble(\n    female  = ifelse(runif(10000) &gt; .5, 1, 0), \n    ability = rnorm(10000), \n    discrimination = female, \n    occupation = 1 + 2 * ability + 0 * female - 2 * discrimination  + rnorm(10000), \n    wage       = 1 - 1 * discrimination  + 1 * occupation + 2 * ability + rnorm(10000)\n)\n\nlm_1 &lt;- lm(wage ~ female, tb)\nlm_2 &lt;- lm(wage ~ female + occupation, tb)\nlm_3 &lt;- lm(wage ~ female + occupation + ability, tb)\n\n\n# warningが出るが問題ない\n# chunkで実行する場合にだけwarningが発生してくる\nstargazer(lm_1, lm_2, lm_3, type = \"text\", omit.stat = \"all\", column.labels = c(\"a\", \"b\", \"c\"))\n#&gt; \n#&gt; ========================================\n#&gt;                 Dependent variable:     \n#&gt;            -----------------------------\n#&gt;                        wage             \n#&gt;                a         b         c    \n#&gt;               (1)       (2)       (3)   \n#&gt; ----------------------------------------\n#&gt; female     -2.862***  0.606*** -0.988***\n#&gt;             (0.085)   (0.029)   (0.028) \n#&gt;                                         \n#&gt; occupation            1.817*** 1.014*** \n#&gt;                       (0.006)   (0.010) \n#&gt;                                         \n#&gt; ability                        1.981*** \n#&gt;                                 (0.023) \n#&gt;                                         \n#&gt; Constant    1.946***  0.211*** 1.001*** \n#&gt;             (0.061)   (0.020)   (0.017) \n#&gt;                                         \n#&gt; ========================================\n#&gt; ========================================\n#&gt; Note:        *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nDAGにおいて合流点をコントロールすると、つまり今回の場合には職業をコントロールすると、 差別と賃金の間に、関係全体を歪めるほど強力活誤ったバックドアパスが 開いてしまう。職業と能力をコントロールした場合にのみ、 賃金に対するジェンダーの直接的な因果効果を分離することができるのである。\nバックドアとDAGのノート"
  },
  {
    "objectID": "contents/books/02_因果推論ミックステープ/ch05_マッチングと層別化.html",
    "href": "contents/books/02_因果推論ミックステープ/ch05_マッチングと層別化.html",
    "title": "ch05 マッチングと層別化",
    "section": "",
    "text": "Warning\n\n\n\n全然理解出来ていないので、もう一度読み込むこと。 考え方はわかったが、数式の部分でわかっていない。 誤植がありそうなので別の図書を見た方がよいかもしれない。"
  },
  {
    "objectID": "contents/books/02_因果推論ミックステープ/ch05_マッチングと層別化.html#識別のための仮定",
    "href": "contents/books/02_因果推論ミックステープ/ch05_マッチングと層別化.html#識別のための仮定",
    "title": "ch05 マッチングと層別化",
    "section": "1.1 識別のための仮定",
    "text": "1.1 識別のための仮定\n交絡因子があるときに因果効果を推定するためには、 CIAが成り立つこと、処置の確率が各層で0より大きく1より小さいこと。"
  },
  {
    "objectID": "contents/books/02_因果推論ミックステープ/ch07_操作変数.html",
    "href": "contents/books/02_因果推論ミックステープ/ch07_操作変数.html",
    "title": "ch07 操作変数",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "contents/books/02_因果推論ミックステープ/ch09_差分の差デザイン.html",
    "href": "contents/books/02_因果推論ミックステープ/ch09_差分の差デザイン.html",
    "title": "ch09 差分の差デザイン",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "contents/books/02_因果推論ミックステープ/ch11_結論.html",
    "href": "contents/books/02_因果推論ミックステープ/ch11_結論.html",
    "title": "ch11 結論",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "contents/books/03_数値シミュレーションで身につける統計の仕組み/ch01_本書の狙い.html",
    "href": "contents/books/03_数値シミュレーションで身につける統計の仕組み/ch01_本書の狙い.html",
    "title": "ch01 本書のねらい",
    "section": "",
    "text": "1 シミュレーションでわかること\n「相関係数が0.5のときの２変量確率変数をN個観測したときに実際に得られる相関係数」 についてシミュレーションをおこなう。これを観ると、サンプルサイズが２５では、非常にバラツキが大きいことがわかる。\n\n\nCode\nrho &lt;- .5\nn &lt;- 25\niter &lt;- 1000\n\nr &lt;- rep(0, iter)\n\nset.seed(123)\nfor (i in 1:iter) {\n  Y1 &lt;- rnorm(n, 0, 1)\n  Y2 &lt;- Y1 * rho + rnorm(n, 0, (1 - rho^2)^.5)\n  r[i] &lt;- cor(Y1, Y2)\n}\n\n\nhist(r)\n\n\n\n\n\n\n\n\n\nサンプルサイズを増やすと推定値のバラツキが小さくなることがわかる。\n\n\nCode\nrho &lt;- .5\nn &lt;- 100\niter &lt;- 1000\n\nr &lt;- rep(0, iter)\n\nset.seed(123)\nfor (i in 1:iter) {\n  Y1 &lt;- rnorm(n, 0, 1)\n  Y2 &lt;- Y1 * rho + rnorm(n, 0, (1 - rho^2)^.5)\n  r[i] &lt;- cor(Y1, Y2)\n}\n\n\nhist(r)\n\n\n\n\n\n\n\n\n\nさらに検定もおこなう. ここでは無相関検定\\(\\rho = 0\\)をおこなう。 具体的には無相関検定をおこなってp値を求める。求めたp値が、0.05を下回る 回数の割合を求める.\nこの結果を見ると仮定が正しいときに、p値が0.05を下回る確率は5%であることがわかる。\n\n\nCode\nrho &lt;- .0\nn &lt;- 25\niter &lt;- 10000\n\nr &lt;- rep(0, iter)\n\nset.seed(123)\nfor (i in 1:iter) {\n  Y1 &lt;- rnorm(n, 0, 1)\n  Y2 &lt;- Y1 * rho + rnorm(n, 0, (1 - rho^2)^.5)\n  r[i] &lt;- cor.test(Y1, Y2)$p.value\n}\n\nifelse(r &lt;= .05, 1, 0) |&gt; mean()\n#&gt; [1] 0.0488\n\n\n検定が適切におこなわれれば、p値は一様分布にしたがう。\n\n\nCode\nhist(r)\n\n\n\n\n\n\n\n\n\nまた、正しく検定がおこわれればp値はサンプルサイズに依らない。\n\n\nCode\nrho &lt;- .0\nn &lt;- 2500\niter &lt;- 10000\n\nr &lt;- rep(0, iter)\n\nset.seed(123)\nfor (i in 1:iter) {\n  Y1 &lt;- rnorm(n, 0, 1)\n  Y2 &lt;- Y1 * rho + rnorm(n, 0, (1 - rho^2)^.5)\n  r[i] &lt;- cor.test(Y1, Y2)$p.value\n}\n\nifelse(r &lt;= .05, 1, 0) |&gt; mean()\n#&gt; [1] 0.0486\n\n\n誤った尾統計分析としてあるのは、検定において データの検定結果を見てから「も少しで有意になるからサンプルサイズをもう少し大きくしよう」とデータを足すことです。\nこれが問題となることをシミュレーションで確認する。このシミュレーションから、後からデータを追加することは、p値のバイアスを生むことがわかる。\n\n\nCode\n## 設定と準備\nrho &lt;- 0\nn &lt;- 25\niter &lt;- 10000\nalpha &lt;- 0.05\n\n# 結果を格納するオブジェクト\np &lt;- rep(0, iter)\n\n## シミュレーション\nset.seed(123)\nfor (i in 1:iter) {\n  # 最初のデータ\n  Y1 &lt;- rnorm(n, 0, 1)\n  Y2 &lt;- Y1 * rho + rnorm(n, 0, (1 - rho^2)^0.5)\n  p[i] &lt;- cor.test(Y1, Y2)$p.value\n  # データ追加\n  count &lt;- 0\n  ## p値が5％を下回るか、データが当初の倍になるまで増やし続ける\n  while (p[i] &gt;= alpha && count &lt; n * 2) {\n    # 有意ではなかったとき、それぞれの変数に1つデータを追加\n    Y1_add &lt;- rnorm(1, 0, 1)\n    Y1 &lt;- c(Y1, Y1_add)\n    Y2 &lt;- c(Y2, Y1_add * rho + rnorm(1, 0, (1 - rho^2)^0.5))\n    p[i] &lt;- cor.test(Y1, Y2)$p.value\n    count &lt;- count + 1\n  }\n}\n\nifelse(p &lt; .05, 1, 0) |&gt; mean()\n#&gt; [1] 0.1791\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/books/03_数値シミュレーションで身につける統計の仕組み/ch03_乱数生成シミュレーションの基礎.html",
    "href": "contents/books/03_数値シミュレーションで身につける統計の仕組み/ch03_乱数生成シミュレーションの基礎.html",
    "title": "ch03 乱数生成シミュレーションの基礎",
    "section": "",
    "text": "「仮にもっと多くのデータがあったなら正確にわかったかもしれないこと」を 推測するには、データの生成モデルを考える必用がある。 「どのようなエータが観測されいあｙすいかは、確率法則に従う」という仮定を 億ことで検討がおこなえる。 これは仮定であるので、本ッにそうであるかどうかはわからない。\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/books/03_数値シミュレーションで身につける統計の仕組み/ch05_統計検定の論理とエラー確率のコントロール - コピー (2).html",
    "href": "contents/books/03_数値シミュレーションで身につける統計の仕組み/ch05_統計検定の論理とエラー確率のコントロール - コピー (2).html",
    "title": "ch05 統計検定の論理",
    "section": "",
    "text": "検定はあらかじめ\\(\\alpha\\)と\\(\\beta\\)を設定しておき、 その確率にタイプⅠ、タイプⅡエラー 確率が抑えられるように手続きを設計することが重要である。\n重要なのは低い\\(\\alpha\\)と\\(\\beta\\)を設定することではなく、 推論のエラー確率が定めた\\(\\alpha\\)と\\(\\beta\\)を下回るように、 手続きを設定することである。"
  },
  {
    "objectID": "contents/books/03_数値シミュレーションで身につける統計の仕組み/ch05_統計検定の論理とエラー確率のコントロール - コピー (2).html#t検定の等分散の仮定からの逸脱",
    "href": "contents/books/03_数値シミュレーションで身につける統計の仕組み/ch05_統計検定の論理とエラー確率のコントロール - コピー (2).html#t検定の等分散の仮定からの逸脱",
    "title": "ch05 統計検定の論理",
    "section": "2.1 \\(t\\)検定の等分散の仮定からの逸脱",
    "text": "2.1 \\(t\\)検定の等分散の仮定からの逸脱\n等分散が満たされないときに、 エラー確率が制御できないことを確認する。\n\n\nCode\nn &lt;- c(40, 20) # サンプルサイズを変えた設定\nsigma1 &lt;- 1\nsigma2 &lt;- c(0.2, 0.5, 0.75, 1, 1.5, 2, 5) # 母標準偏差のパターン\np &lt;- length(sigma2)\niter &lt;- 10000 # シミュレーション回数\nalpha &lt;- 0.05 # 有意水準\nmu &lt;- c(0, 0) # 母平均が等しい設定にする\n# 結果を格納するオブジェクト\npvalue &lt;- array(NA, dim = c(p, iter))\n## シミュレーション\nset.seed(1234)\nfor (i in 1:p) {\n  for (j in 1:iter) {\n    Y1 &lt;- rnorm(n[1], mu[1], sigma1)\n    Y2 &lt;- rnorm(n[2], mu[2], sigma2[i])\n    result &lt;- t.test(Y1, Y2, var.equal = TRUE)\n    pvalue[i, j] &lt;- result$p.value\n  }\n}\n# 結果を格納するオブジェクト\ntype1error_ttest &lt;- rep(0, p)\n\n\nfor (i in 1:p) {\n  type1error_ttest[i] &lt;- mean(pvalue[i, ] &lt; alpha)\n}\n\ntype1error_ttest |&gt; \n  plot(\n    type = \"b\", \n    xaxt = \"n\", \n    ylim = c(0, .2), \n    xlab = \"郡2の母標準偏差\"\n  )\n\naxis(1, at = 1:p, labels = sigma2)\nabline(h = alpha, lty = 2)\n\n\n\n\n\n\n\n\n\n\n\nCode\npvalue[6,] |&gt; hist()\n\n\n\n\n\n\n\n\n\n一方でWeltch検定は等分散を仮定していないので、 制御出来ていることがわかる。\n\n\nCode\nn &lt;- c(40, 20) # サンプルサイズをかえる\nsigma1 &lt;- 1\nsigma2 &lt;- c(.2, .5, .75, 1, 1.5, 2, 5) # 母標準偏差のパターン\np &lt;- length(sigma2)\niter &lt;- 10000\nalpah &lt;- .05\nmu &lt;- c(0, 0)\n\nset.seed(1234)\npvalue &lt;- array(NA, dim = c(p, iter))\nfor (i in 1:p) {\n  for (j in 1:iter) {\n    Y1 &lt;- rnorm(n[1], mu[1], sigma1)\n    Y2 &lt;- rnorm(n[2], mu[2], sigma2[i])\n    result &lt;- t.test(Y1, Y2, var.equal = FALSE)\n    pvalue[i, j] &lt;- result$p.value\n  }\n}\n\ntype1error_welch &lt;- rep(0, p)\nfor (i in 1:p) {\n  type1error_welch[i] &lt;- mean(pvalue[i, ] &lt; alpha)\n}\n\ntype1error_welch |&gt; \n  plot(\n    type = \"b\", \n    xaxt = \"n\", \n    ylim = c(0, .2), \n    xlab = \"群2の母標準偏差\"\n  )\naxis(1, at = 1:p, labels = sigma2)\nabline(h = alpha, lty = 2)"
  },
  {
    "objectID": "contents/books/03_数値シミュレーションで身につける統計の仕組み/ch07_回帰分析とシミュレーション.html",
    "href": "contents/books/03_数値シミュレーションで身につける統計の仕組み/ch07_回帰分析とシミュレーション.html",
    "title": "ch07 回帰分析",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/101_統計的因果推論の基礎の基礎.html",
    "href": "contents/books/05_統計的因果推論の理論と実際/101_統計的因果推論の基礎の基礎.html",
    "title": "基礎の基礎",
    "section": "",
    "text": "因果関係は，原因と結果の関係である．因果関係は目に見えないため，因果推論とは 因果を推し測って考えるということである． 統計的因果推論とは，そのような因果推論をデータに基づいて行うことである.\n因果関係には「効果をもたらした原因」と「原因がもたらす効果」がある． 前者を判定するにはフィールドワークなどの観察により 事象の背景知識を把握することが必要である． 一方で後者はデータにもとづいて定量的に行われることになる． つまり統計的因果推論では「原因Aが結果Bにもたらす効果」を取り扱うことになる．\nなお統計的因果推論では原因のことを「処置」という．\n\n\n\n本書ではRubinの潜在的結果変数の枠組みで統計的因果推論を行う.\n大切だと思うのは常に交絡因子が存在していることであり， 交絡因子について思慮続けることである. 性差が原因だとして，その性差とは具体的には何を表しているのだろうか？ その性差がなぜ結果Bに影響を与えるのだろうか？\n操作無くして因果なしの考えに基づけば，性差は操作ができないものである． つまりある個人が別の性別，性認識での結果は存在しない． 性差と結果の間になにか中間変数があるはずである． 本署の中では性差が治療結果の違いに影響を与えるのは，処置方針という中間変数が存在しているため，という事例が記載されていた.\n\n\n\nグレンジャー因果は予測に役立つという意味であり， 統計的因果推論とは異なるものであることに注意する．"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/101_統計的因果推論の基礎の基礎.html#統計的因果推論とは",
    "href": "contents/books/05_統計的因果推論の理論と実際/101_統計的因果推論の基礎の基礎.html#統計的因果推論とは",
    "title": "基礎の基礎",
    "section": "",
    "text": "因果関係は，原因と結果の関係である．因果関係は目に見えないため，因果推論とは 因果を推し測って考えるということである． 統計的因果推論とは，そのような因果推論をデータに基づいて行うことである.\n因果関係には「効果をもたらした原因」と「原因がもたらす効果」がある． 前者を判定するにはフィールドワークなどの観察により 事象の背景知識を把握することが必要である． 一方で後者はデータにもとづいて定量的に行われることになる． つまり統計的因果推論では「原因Aが結果Bにもたらす効果」を取り扱うことになる．\nなお統計的因果推論では原因のことを「処置」という．"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/101_統計的因果推論の基礎の基礎.html#反事実モデル",
    "href": "contents/books/05_統計的因果推論の理論と実際/101_統計的因果推論の基礎の基礎.html#反事実モデル",
    "title": "基礎の基礎",
    "section": "",
    "text": "本書ではRubinの潜在的結果変数の枠組みで統計的因果推論を行う.\n大切だと思うのは常に交絡因子が存在していることであり， 交絡因子について思慮続けることである. 性差が原因だとして，その性差とは具体的には何を表しているのだろうか？ その性差がなぜ結果Bに影響を与えるのだろうか？\n操作無くして因果なしの考えに基づけば，性差は操作ができないものである． つまりある個人が別の性別，性認識での結果は存在しない． 性差と結果の間になにか中間変数があるはずである． 本署の中では性差が治療結果の違いに影響を与えるのは，処置方針という中間変数が存在しているため，という事例が記載されていた."
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/101_統計的因果推論の基礎の基礎.html#グレンジャー因果",
    "href": "contents/books/05_統計的因果推論の理論と実際/101_統計的因果推論の基礎の基礎.html#グレンジャー因果",
    "title": "基礎の基礎",
    "section": "",
    "text": "グレンジャー因果は予測に役立つという意味であり， 統計的因果推論とは異なるものであることに注意する．"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/103_統計的因果推論における重要な仮定.html",
    "href": "contents/books/05_統計的因果推論の理論と実際/103_統計的因果推論における重要な仮定.html",
    "title": "重要な仮定",
    "section": "",
    "text": "処置の無作為割り付けによって平均処置効果を適切に推定できることを確認した． ここまでは分散分析をはじめとした従来の統計学と同様の論旨である．\nここからは統計的因果推論における重要な仮定と， それを踏まえたうえで無作為割り付けを実行できない観察研究にける統計的因果推論を説明する.\n\n\nStable Unit Treatment Value Assumption\n処置を受ける個体(unit)ごとに処置の値が安定的であるという仮定である． 具体的には次の二つの条件が成り立つ．\n\n相互干渉がない\n個体に対する隠れた処置がない\n\n相互干渉ある場合には相互干渉がなくなるまでunitの単位を変更する. 隠れた処置がない，とはつまり処置以外の属性がランダム化されているという理解で良さそうである． 補習講義を受けた場合でも先生が異なる場合には，A先生の補習講義を受けた，B先生の補習講義を 受けた，補習講義を受けていないなどとして着目した変数以外をランダム化することに努める．\n確率が相互に背反であるとは，集合に重なりがないことであるあため，次式が成立することを指す.\n\\[\nP(A|B)=0\n\\]\n確率が独立であるとは，ある情報で条件づけても確率が変化しないことである．\n\\[\nP(A|B)=P(A)\n\\]\n\n\n\n観測されたデータから母数が一意に満たされていない場合， 標本から母集団への推定ができないということになる． このとき識別性がないという． 特に，ここでは識別性=正値性＋独立性である．\n正値性の条件を課すとunitが処置を受けるかうけないかは， わからない状態，つまりどちらも可能性があるため次の式で表現される.\n\\[\n0&lt;\\textrm{Pr}(T=1) &lt;1\n\\]\n独立性とは処置の割り付けが潜在的結果変数に依存して行われてはいけない，ということである． つまりすべての変量と独立になっており，実験研究ではこの条件が満たされやすい.\n\\[\n{Y(1), Y(0)} \\perp T\n\\]\n改めて観測値\\(Y_i\\)は次の式で表される.\n\\[\nY_i = (1-T_i)Y_i(0) + T_iY_i(1)\n\\]\n\\(Y_i(0), Y_i(1)\\)は潜在的結果変数の組であるため， 個体\\(i\\)に対してはどちらか一方しか観測されない. よって次式により処置効果を求めることは通常不可能である.\n\\[\n\\tau_{ATE}=E[Y_i(1)-Y_i(0)]=E[Y_i(1)]-E[Y_i(0)]\n\\]\n一方でそれぞれの処置で条件付けた場合には平均値の算出が可能であるため， 次式で示したナイーブな推定量を使うことが可能である. しかしこの値は本来推定したいものではない．本来推定したいのは，処置の平均処置効果，処置群の平均処置効果のどちらかである．\n\\[\nE[Y_i|T_i=1]-E[Y_i|T_i=0]\n\\]\n処置の割り付けを表す\\(T_i\\)が潜在的結果変数の組に依存していなければ \\(T_i\\)と\\({Y_i(0), Y_i(1)}\\)とは独立である. 無作為割り付けができる場合には\\(T_I\\)は\\({Y_i(0), Y_i(1)}\\)とも無関係となる. 無作為割り付けの場合には独立性の仮定が満たされることから，常識は\\(T_{ATE}\\)に変換できる.\n\\[\nE[Y_i|T_i=1]=E[Y_i(1)|T_i=1]=E[Y_i(1)]\\\\\nE[Y_i|T_i=0]=E[Y_i(0)|T_i=0]=E[Y_i(0)]\n\\]\n上記から無作為割り付けが出来ていれば，処置平均効果の差分を求めることで，処置効果を推定することが可能となることがわかる. つまり，処置の割り付けの有無をいかに結果変数と独立させるのかが重要である.\n\n\n\n条件BとCを与えたときのAの確率が，条件Cだけを与えたときのAの確率と 一致することを条件付き独立性という．これは\\(A \\perp B|C\\)と各．\n\\[\n\\textrm{Pr}(A|B,C)=\\textrm{Pr}(A|C)\n\\]\nこれは「独立ならば条件付き独立だる」とは限らない．\n統計的因果推論の立場から重要な点は，たとえデータ全体で独立でなかったとしても， 共変量に条件付けた場合には独立とみなし得るという点である．\n\n\n\n観察研究において適切な統計的因果推論を行うためには， 処置群と統制群をいかにして比較可能な状態にするのかが重要である． すなわち比較可能な２つの集団を用意することが出来る.\n共変量とは結果偏す\\(Y_i\\)に影響する変数の中で， 処置の影響を受けていない変数である．この式を\n\\[\nY_i(1), Y_i(0) \\perp T_i|X\n\\]\nまた条件付き正確性は次である.\n\\[\n0 &lt; \\textrm{Pr}(T=1|X) &lt; 1\n\\] 共変量を考慮することで，割り付けと結果変数が独立になる， つまり割り付けによる効果を推定することが可能となる. これは共変量が同じ個体では割り付け確率が同じになる，ということを意味している．\n・・・ということは，共変量が同じであるという条件を加えることで， 推定値を求めることが出来るようになる.\n共変量による条件づけで平均処置効果を算出できるとは，次式の関係があることを指す. \\[\nE[Y_i|T_i=1, X]=E[Y_i(1)|T_i=1, X]=E[Y_i(1)|X]\\\\\nE[Y_i|T_i=0, X]=E[Y_i(0)|T_i=0, X]=E[Y_i(0)|X]\n\\]\nここでは無視可能な割り付けによる算出例を見てみる.\n\n\nCode\npath   &lt;- \"./causality/data03.csv\"\ndata03 &lt;- read_csv(\n    path, \n    locale = locale(encoding = \"UTF-8\"),\n    show_col_types = FALSE\n)\nsummary(data03)\n#&gt;        x1              y3              t1           y0t             y1t       \n#&gt;  Min.   :70.00   Min.   :63.00   Min.   :0.0   Min.   :62.00   Min.   :71.00  \n#&gt;  1st Qu.:73.75   1st Qu.:73.75   1st Qu.:0.0   1st Qu.:66.50   1st Qu.:75.50  \n#&gt;  Median :80.00   Median :77.00   Median :0.5   Median :71.00   Median :81.50  \n#&gt;  Mean   :80.00   Mean   :77.25   Mean   :0.5   Mean   :72.20   Mean   :82.00  \n#&gt;  3rd Qu.:86.25   3rd Qu.:82.00   3rd Qu.:1.0   3rd Qu.:78.75   3rd Qu.:88.75  \n#&gt;  Max.   :90.00   Max.   :91.00   Max.   :1.0   Max.   :82.00   Max.   :92.00\n\n\n\n\nCode\nprint(head(data03))\n#&gt; # A tibble: 6 × 5\n#&gt;      x1    y3    t1   y0t   y1t\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1    70    74     1    62    74\n#&gt; 2    70    63     0    63    74\n#&gt; 3    70    73     1    62    73\n#&gt; 4    70    71     1    65    71\n#&gt; 5    70    74     1    63    74\n#&gt; 6    75    67     0    67    77\n\n\n\n\nCode\nwith(data03, {\n    mean(y3[t1==1])-mean(y3[t1==0])\n})\n#&gt; [1] 3.3\n\n\n\n\nCode\n# 真値\nwith(data03, {\n    mean(y1t)-mean(y0t)\n})\n#&gt; [1] 9.8\n\n\n上記の数値の違いからわかることは 「無視可能な割り付け」とはナイーブな推定量によって文字どおりに 「割り付けを無視して解析してよい」ということを意味していない．\n\n\n\n\n\nCode\nmodel1 &lt;- lm(y3 ~ x1 + t1, data = data03)\nsummary(model1)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y3 ~ x1 + t1, data = data03)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -1.84950 -0.54042  0.07711  0.38619  1.18781 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) -2.12562    2.27423  -0.935    0.363    \n#&gt; x1           0.93085    0.02704  34.422  &lt; 2e-16 ***\n#&gt; t1           9.81592    0.42757  22.957 3.11e-14 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.8573 on 17 degrees of freedom\n#&gt; Multiple R-squared:  0.9867, Adjusted R-squared:  0.9851 \n#&gt; F-statistic: 629.5 on 2 and 17 DF,  p-value: &lt; 2.2e-16\n\n\n\n\nCode\nconfint(model1, level = .95)\n#&gt;                  2.5 %     97.5 %\n#&gt; (Intercept) -6.9238192  2.6725754\n#&gt; x1           0.8737921  0.9878995\n#&gt; t1           8.9138219 10.7180189\n\n\n無視可能な割り付けであれば，共変量による条件づけることで解析が行える. グラフィカルモデルで言えば共変量と処置変数"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/103_統計的因果推論における重要な仮定.html#sutva",
    "href": "contents/books/05_統計的因果推論の理論と実際/103_統計的因果推論における重要な仮定.html#sutva",
    "title": "重要な仮定",
    "section": "",
    "text": "Stable Unit Treatment Value Assumption\n処置を受ける個体(unit)ごとに処置の値が安定的であるという仮定である． 具体的には次の二つの条件が成り立つ．\n\n相互干渉がない\n個体に対する隠れた処置がない\n\n相互干渉ある場合には相互干渉がなくなるまでunitの単位を変更する. 隠れた処置がない，とはつまり処置以外の属性がランダム化されているという理解で良さそうである． 補習講義を受けた場合でも先生が異なる場合には，A先生の補習講義を受けた，B先生の補習講義を 受けた，補習講義を受けていないなどとして着目した変数以外をランダム化することに努める．\n確率が相互に背反であるとは，集合に重なりがないことであるあため，次式が成立することを指す.\n\\[\nP(A|B)=0\n\\]\n確率が独立であるとは，ある情報で条件づけても確率が変化しないことである．\n\\[\nP(A|B)=P(A)\n\\]"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/103_統計的因果推論における重要な仮定.html#識別性の条件",
    "href": "contents/books/05_統計的因果推論の理論と実際/103_統計的因果推論における重要な仮定.html#識別性の条件",
    "title": "重要な仮定",
    "section": "",
    "text": "観測されたデータから母数が一意に満たされていない場合， 標本から母集団への推定ができないということになる． このとき識別性がないという． 特に，ここでは識別性=正値性＋独立性である．\n正値性の条件を課すとunitが処置を受けるかうけないかは， わからない状態，つまりどちらも可能性があるため次の式で表現される.\n\\[\n0&lt;\\textrm{Pr}(T=1) &lt;1\n\\]\n独立性とは処置の割り付けが潜在的結果変数に依存して行われてはいけない，ということである． つまりすべての変量と独立になっており，実験研究ではこの条件が満たされやすい.\n\\[\n{Y(1), Y(0)} \\perp T\n\\]\n改めて観測値\\(Y_i\\)は次の式で表される.\n\\[\nY_i = (1-T_i)Y_i(0) + T_iY_i(1)\n\\]\n\\(Y_i(0), Y_i(1)\\)は潜在的結果変数の組であるため， 個体\\(i\\)に対してはどちらか一方しか観測されない. よって次式により処置効果を求めることは通常不可能である.\n\\[\n\\tau_{ATE}=E[Y_i(1)-Y_i(0)]=E[Y_i(1)]-E[Y_i(0)]\n\\]\n一方でそれぞれの処置で条件付けた場合には平均値の算出が可能であるため， 次式で示したナイーブな推定量を使うことが可能である. しかしこの値は本来推定したいものではない．本来推定したいのは，処置の平均処置効果，処置群の平均処置効果のどちらかである．\n\\[\nE[Y_i|T_i=1]-E[Y_i|T_i=0]\n\\]\n処置の割り付けを表す\\(T_i\\)が潜在的結果変数の組に依存していなければ \\(T_i\\)と\\({Y_i(0), Y_i(1)}\\)とは独立である. 無作為割り付けができる場合には\\(T_I\\)は\\({Y_i(0), Y_i(1)}\\)とも無関係となる. 無作為割り付けの場合には独立性の仮定が満たされることから，常識は\\(T_{ATE}\\)に変換できる.\n\\[\nE[Y_i|T_i=1]=E[Y_i(1)|T_i=1]=E[Y_i(1)]\\\\\nE[Y_i|T_i=0]=E[Y_i(0)|T_i=0]=E[Y_i(0)]\n\\]\n上記から無作為割り付けが出来ていれば，処置平均効果の差分を求めることで，処置効果を推定することが可能となることがわかる. つまり，処置の割り付けの有無をいかに結果変数と独立させるのかが重要である."
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/103_統計的因果推論における重要な仮定.html#独立性と条件付き独立性シンプソンのパラドックス",
    "href": "contents/books/05_統計的因果推論の理論と実際/103_統計的因果推論における重要な仮定.html#独立性と条件付き独立性シンプソンのパラドックス",
    "title": "重要な仮定",
    "section": "",
    "text": "条件BとCを与えたときのAの確率が，条件Cだけを与えたときのAの確率と 一致することを条件付き独立性という．これは\\(A \\perp B|C\\)と各．\n\\[\n\\textrm{Pr}(A|B,C)=\\textrm{Pr}(A|C)\n\\]\nこれは「独立ならば条件付き独立だる」とは限らない．\n統計的因果推論の立場から重要な点は，たとえデータ全体で独立でなかったとしても， 共変量に条件付けた場合には独立とみなし得るという点である．"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/103_統計的因果推論における重要な仮定.html#共変量の役割",
    "href": "contents/books/05_統計的因果推論の理論と実際/103_統計的因果推論における重要な仮定.html#共変量の役割",
    "title": "重要な仮定",
    "section": "",
    "text": "観察研究において適切な統計的因果推論を行うためには， 処置群と統制群をいかにして比較可能な状態にするのかが重要である． すなわち比較可能な２つの集団を用意することが出来る.\n共変量とは結果偏す\\(Y_i\\)に影響する変数の中で， 処置の影響を受けていない変数である．この式を\n\\[\nY_i(1), Y_i(0) \\perp T_i|X\n\\]\nまた条件付き正確性は次である.\n\\[\n0 &lt; \\textrm{Pr}(T=1|X) &lt; 1\n\\] 共変量を考慮することで，割り付けと結果変数が独立になる， つまり割り付けによる効果を推定することが可能となる. これは共変量が同じ個体では割り付け確率が同じになる，ということを意味している．\n・・・ということは，共変量が同じであるという条件を加えることで， 推定値を求めることが出来るようになる.\n共変量による条件づけで平均処置効果を算出できるとは，次式の関係があることを指す. \\[\nE[Y_i|T_i=1, X]=E[Y_i(1)|T_i=1, X]=E[Y_i(1)|X]\\\\\nE[Y_i|T_i=0, X]=E[Y_i(0)|T_i=0, X]=E[Y_i(0)|X]\n\\]\nここでは無視可能な割り付けによる算出例を見てみる.\n\n\nCode\npath   &lt;- \"./causality/data03.csv\"\ndata03 &lt;- read_csv(\n    path, \n    locale = locale(encoding = \"UTF-8\"),\n    show_col_types = FALSE\n)\nsummary(data03)\n#&gt;        x1              y3              t1           y0t             y1t       \n#&gt;  Min.   :70.00   Min.   :63.00   Min.   :0.0   Min.   :62.00   Min.   :71.00  \n#&gt;  1st Qu.:73.75   1st Qu.:73.75   1st Qu.:0.0   1st Qu.:66.50   1st Qu.:75.50  \n#&gt;  Median :80.00   Median :77.00   Median :0.5   Median :71.00   Median :81.50  \n#&gt;  Mean   :80.00   Mean   :77.25   Mean   :0.5   Mean   :72.20   Mean   :82.00  \n#&gt;  3rd Qu.:86.25   3rd Qu.:82.00   3rd Qu.:1.0   3rd Qu.:78.75   3rd Qu.:88.75  \n#&gt;  Max.   :90.00   Max.   :91.00   Max.   :1.0   Max.   :82.00   Max.   :92.00\n\n\n\n\nCode\nprint(head(data03))\n#&gt; # A tibble: 6 × 5\n#&gt;      x1    y3    t1   y0t   y1t\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1    70    74     1    62    74\n#&gt; 2    70    63     0    63    74\n#&gt; 3    70    73     1    62    73\n#&gt; 4    70    71     1    65    71\n#&gt; 5    70    74     1    63    74\n#&gt; 6    75    67     0    67    77\n\n\n\n\nCode\nwith(data03, {\n    mean(y3[t1==1])-mean(y3[t1==0])\n})\n#&gt; [1] 3.3\n\n\n\n\nCode\n# 真値\nwith(data03, {\n    mean(y1t)-mean(y0t)\n})\n#&gt; [1] 9.8\n\n\n上記の数値の違いからわかることは 「無視可能な割り付け」とはナイーブな推定量によって文字どおりに 「割り付けを無視して解析してよい」ということを意味していない．"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/103_統計的因果推論における重要な仮定.html#回帰分析と共分散分析",
    "href": "contents/books/05_統計的因果推論の理論と実際/103_統計的因果推論における重要な仮定.html#回帰分析と共分散分析",
    "title": "重要な仮定",
    "section": "",
    "text": "Code\nmodel1 &lt;- lm(y3 ~ x1 + t1, data = data03)\nsummary(model1)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y3 ~ x1 + t1, data = data03)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -1.84950 -0.54042  0.07711  0.38619  1.18781 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) -2.12562    2.27423  -0.935    0.363    \n#&gt; x1           0.93085    0.02704  34.422  &lt; 2e-16 ***\n#&gt; t1           9.81592    0.42757  22.957 3.11e-14 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.8573 on 17 degrees of freedom\n#&gt; Multiple R-squared:  0.9867, Adjusted R-squared:  0.9851 \n#&gt; F-statistic: 629.5 on 2 and 17 DF,  p-value: &lt; 2.2e-16\n\n\n\n\nCode\nconfint(model1, level = .95)\n#&gt;                  2.5 %     97.5 %\n#&gt; (Intercept) -6.9238192  2.6725754\n#&gt; x1           0.8737921  0.9878995\n#&gt; t1           8.9138219 10.7180189\n\n\n無視可能な割り付けであれば，共変量による条件づけることで解析が行える. グラフィカルモデルで言えば共変量と処置変数"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/105_回帰分析の基礎.html",
    "href": "contents/books/05_統計的因果推論の理論と実際/105_回帰分析の基礎.html",
    "title": "回帰分析の基礎",
    "section": "",
    "text": "1 回帰分析の基礎\n共変量Xによって条件付けることで無視可能な割り付けとみなせるとき， 回帰分析によって平均処置効果を推定することができるた． このような条件が満たされない場合には回帰係数は必ずしも因果関係を表さないことに注意する．\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/107_最小二乗法による重回帰モデルの仮定と診断1.html",
    "href": "contents/books/05_統計的因果推論の理論と実際/107_最小二乗法による重回帰モデルの仮定と診断1.html",
    "title": "最小二乗法の仮定と診断1",
    "section": "",
    "text": "最小二乗法による重回帰モデルでは６つの仮定が置かれている． ここでは次に示す３つの仮定について解説する.\n\n誤差項の平均値がゼロ\nパラメータの線形性\n誤差項の条件付き期待値がゼロ\n\n\n\n切片項があれば誤差項がゼロでなくて， 切片項に平均値分を持たせることが出来るので， 通常はこの仮定を満たすことが出来る.\nつまり，回帰係数の不偏性には影響しない.\n\n\n\n最小二乗法による重回帰モデルのパラメータ推定が， 不偏性を持つために必要な条件となる.\n例えば次の二つの式を考える．このうち，１つ目の式は対数変換を 行おうことで適切にモデル化することができる．一方で， 二つ目の式にはそのような変換が存在しない． これはパラメータの線形性と変数の非線形性という少し解釈が難しい話題である.\n\\[\n\\begin{align}\nY_i &= \\beta_0X_1^{\\beta_1}X_2^{\\beta_2}\\exp{\\epsilon_i}\\\\\nY_i &= \\beta_0X_1^{\\beta_1}X_2^{\\beta_2} + \\epsilon_i\n\\end{align}\n\\]\n．．．とはいいつつもデータの非線形性はよいが， パラメータについてはいつも線形であると理解しておけばよさそう.\n\n\n共変量が多変量になる場合には他の共変量を統制した場合の効果， つまり偏回帰係数に興味がある． これは二変量の散布図では適切な関数系を示すことが出来ないため， 成分プラス残差プロットを私用することが推奨されている.\n\n\n\n\n下記の式で表される条件である．これはつまり，統制すべき交絡因子が十分に モデルに含まれていることを指している． しかし，そのことを診断する方法はない.\n\\[\nE[\\epsilon_i|X]=E[\\epsilon_i]=0\n\\]\n統計的因果論の立場で考えると， 観測された共変量の値が同じ個体同士では，処置の割り付けは 無作為になっていると考えて良いという仮定を指す．\n\\[\n\\text{Pr}(T_i|Y_i(1), Y_i(0),X) = \\text{Pr}(T_i|X)\n\\]\nこの仮定を満たすことを考えるためには，できるだけ 多くの変数をモデルに取り入れて必要な共変量を取りこぼす可能性を下げることである． このとき検討する項目は次の２点である.\n\n不要な変数を取り込んだことの影響\n因果関係の間に位置する変数の取り扱い\n\n\n\n説明変数に「多重共線性」が生じていなければ不偏性には問題ない． ただしパラメータの標準誤差が大きくなる.\n\n\nCode\nbeta0 &lt;- 1.\nbeta1 &lt;- 1.5\nbeta2 &lt;- 1.2\ndata &lt;- tibble(\n    x1 = rnorm(n = 100, mean = 1), \n    x2 = rnorm(n = 100, mean = 3), \n    x3 = rnorm(100),\n    y  = 1 + beta1 * x1 + beta2 * x2  + rnorm(100)\n)\n\nmodels &lt;- \n    tibble(\n        formula = c(\n            \"y ~ x1\", \n            \"y ~ x1 + x2\", \n            \"y ~ x1 + x2 + x3\"\n        )\n    ) |&gt; \n    mutate(\n        reg = map(formula, ~ lm(., data = data))\n    )\n\n\n余計な変数を入れても不偏性には影響しない.\n\n\nCode\nmodels$reg \n#&gt; [[1]]\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = ., data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           x1  \n#&gt;       4.634        1.409  \n#&gt; \n#&gt; \n#&gt; [[2]]\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = ., data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           x1           x2  \n#&gt;      0.9523       1.5342       1.1703  \n#&gt; \n#&gt; \n#&gt; [[3]]\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = ., data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           x1           x2           x3  \n#&gt;    0.952686     1.533826     1.170225    -0.001641\n\n\nただしパラメータ推定の分散は大きくなる\n\n\nCode\nmodels$reg |&gt; lapply(confint)\n#&gt; [[1]]\n#&gt;                2.5 %   97.5 %\n#&gt; (Intercept) 4.214445 5.054522\n#&gt; x1          1.132469 1.685788\n#&gt; \n#&gt; [[2]]\n#&gt;                 2.5 %   97.5 %\n#&gt; (Intercept) 0.3004943 1.604135\n#&gt; x1          1.3589493 1.709550\n#&gt; x2          0.9808976 1.359608\n#&gt; \n#&gt; [[3]]\n#&gt;                  2.5 %    97.5 %\n#&gt; (Intercept)  0.2962068 1.6091652\n#&gt; x1           1.3519278 1.7157247\n#&gt; x2           0.9798373 1.3606120\n#&gt; x3          -0.1762091 0.1729263\n\n\n\n\n\n「因果関係の間に位置する変数」の問題を考える。 結論的にいえばそのような変数を含めてはならない.\n\n\nCode\ndata &lt;- tibble(\n    x1 = rnorm(n = 100, mean = 1), \n    x2 = 1 + 1.5 * x1 + rnorm(n = 100), \n    y  = 1 + 1.2 * x1 + 1.6 * x2  + rnorm(100)\n)\n\nmodels &lt;- \n    tibble(\n        formula = c(\n            \"y ~ x1\", \n            \"y ~ x1 + x2\"\n        )\n    ) |&gt; \n    mutate(\n        reg = map(formula, ~ lm(., data = data))\n    )\n\n\n上記のサンプルデータの場合、x1がyに与える影響は \\(1.2 + 1.5 * 1.6 = 3.6\\)なので中間変数であるx2を含まない方がよい推定である ことがわかる.\n\n\nCode\nmodels$reg\n#&gt; [[1]]\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = ., data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           x1  \n#&gt;       2.682        3.463  \n#&gt; \n#&gt; \n#&gt; [[2]]\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = ., data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           x1           x2  \n#&gt;      0.8675       1.4104       1.5806\n\n\n\n\nCode\nmodels$reg |&gt; lapply(confint)\n#&gt; [[1]]\n#&gt;                2.5 %   97.5 %\n#&gt; (Intercept) 2.109008 3.255472\n#&gt; x1          3.085248 3.840094\n#&gt; \n#&gt; [[2]]\n#&gt;                2.5 %   97.5 %\n#&gt; (Intercept) 0.488317 1.246698\n#&gt; x1          1.085086 1.735793\n#&gt; x2          1.382953 1.778201"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/107_最小二乗法による重回帰モデルの仮定と診断1.html#誤差項の期待値ゼロ",
    "href": "contents/books/05_統計的因果推論の理論と実際/107_最小二乗法による重回帰モデルの仮定と診断1.html#誤差項の期待値ゼロ",
    "title": "最小二乗法の仮定と診断1",
    "section": "",
    "text": "切片項があれば誤差項がゼロでなくて， 切片項に平均値分を持たせることが出来るので， 通常はこの仮定を満たすことが出来る.\nつまり，回帰係数の不偏性には影響しない."
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/107_最小二乗法による重回帰モデルの仮定と診断1.html#パラメータにおける線形性",
    "href": "contents/books/05_統計的因果推論の理論と実際/107_最小二乗法による重回帰モデルの仮定と診断1.html#パラメータにおける線形性",
    "title": "最小二乗法の仮定と診断1",
    "section": "",
    "text": "最小二乗法による重回帰モデルのパラメータ推定が， 不偏性を持つために必要な条件となる.\n例えば次の二つの式を考える．このうち，１つ目の式は対数変換を 行おうことで適切にモデル化することができる．一方で， 二つ目の式にはそのような変換が存在しない． これはパラメータの線形性と変数の非線形性という少し解釈が難しい話題である.\n\\[\n\\begin{align}\nY_i &= \\beta_0X_1^{\\beta_1}X_2^{\\beta_2}\\exp{\\epsilon_i}\\\\\nY_i &= \\beta_0X_1^{\\beta_1}X_2^{\\beta_2} + \\epsilon_i\n\\end{align}\n\\]\n．．．とはいいつつもデータの非線形性はよいが， パラメータについてはいつも線形であると理解しておけばよさそう.\n\n\n共変量が多変量になる場合には他の共変量を統制した場合の効果， つまり偏回帰係数に興味がある． これは二変量の散布図では適切な関数系を示すことが出来ないため， 成分プラス残差プロットを私用することが推奨されている."
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/107_最小二乗法による重回帰モデルの仮定と診断1.html#誤差項の条件付き期待値ゼロ",
    "href": "contents/books/05_統計的因果推論の理論と実際/107_最小二乗法による重回帰モデルの仮定と診断1.html#誤差項の条件付き期待値ゼロ",
    "title": "最小二乗法の仮定と診断1",
    "section": "",
    "text": "下記の式で表される条件である．これはつまり，統制すべき交絡因子が十分に モデルに含まれていることを指している． しかし，そのことを診断する方法はない.\n\\[\nE[\\epsilon_i|X]=E[\\epsilon_i]=0\n\\]\n統計的因果論の立場で考えると， 観測された共変量の値が同じ個体同士では，処置の割り付けは 無作為になっていると考えて良いという仮定を指す．\n\\[\n\\text{Pr}(T_i|Y_i(1), Y_i(0),X) = \\text{Pr}(T_i|X)\n\\]\nこの仮定を満たすことを考えるためには，できるだけ 多くの変数をモデルに取り入れて必要な共変量を取りこぼす可能性を下げることである． このとき検討する項目は次の２点である.\n\n不要な変数を取り込んだことの影響\n因果関係の間に位置する変数の取り扱い\n\n\n\n説明変数に「多重共線性」が生じていなければ不偏性には問題ない． ただしパラメータの標準誤差が大きくなる.\n\n\nCode\nbeta0 &lt;- 1.\nbeta1 &lt;- 1.5\nbeta2 &lt;- 1.2\ndata &lt;- tibble(\n    x1 = rnorm(n = 100, mean = 1), \n    x2 = rnorm(n = 100, mean = 3), \n    x3 = rnorm(100),\n    y  = 1 + beta1 * x1 + beta2 * x2  + rnorm(100)\n)\n\nmodels &lt;- \n    tibble(\n        formula = c(\n            \"y ~ x1\", \n            \"y ~ x1 + x2\", \n            \"y ~ x1 + x2 + x3\"\n        )\n    ) |&gt; \n    mutate(\n        reg = map(formula, ~ lm(., data = data))\n    )\n\n\n余計な変数を入れても不偏性には影響しない.\n\n\nCode\nmodels$reg \n#&gt; [[1]]\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = ., data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           x1  \n#&gt;       4.634        1.409  \n#&gt; \n#&gt; \n#&gt; [[2]]\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = ., data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           x1           x2  \n#&gt;      0.9523       1.5342       1.1703  \n#&gt; \n#&gt; \n#&gt; [[3]]\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = ., data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           x1           x2           x3  \n#&gt;    0.952686     1.533826     1.170225    -0.001641\n\n\nただしパラメータ推定の分散は大きくなる\n\n\nCode\nmodels$reg |&gt; lapply(confint)\n#&gt; [[1]]\n#&gt;                2.5 %   97.5 %\n#&gt; (Intercept) 4.214445 5.054522\n#&gt; x1          1.132469 1.685788\n#&gt; \n#&gt; [[2]]\n#&gt;                 2.5 %   97.5 %\n#&gt; (Intercept) 0.3004943 1.604135\n#&gt; x1          1.3589493 1.709550\n#&gt; x2          0.9808976 1.359608\n#&gt; \n#&gt; [[3]]\n#&gt;                  2.5 %    97.5 %\n#&gt; (Intercept)  0.2962068 1.6091652\n#&gt; x1           1.3519278 1.7157247\n#&gt; x2           0.9798373 1.3606120\n#&gt; x3          -0.1762091 0.1729263\n\n\n\n\n\n「因果関係の間に位置する変数」の問題を考える。 結論的にいえばそのような変数を含めてはならない.\n\n\nCode\ndata &lt;- tibble(\n    x1 = rnorm(n = 100, mean = 1), \n    x2 = 1 + 1.5 * x1 + rnorm(n = 100), \n    y  = 1 + 1.2 * x1 + 1.6 * x2  + rnorm(100)\n)\n\nmodels &lt;- \n    tibble(\n        formula = c(\n            \"y ~ x1\", \n            \"y ~ x1 + x2\"\n        )\n    ) |&gt; \n    mutate(\n        reg = map(formula, ~ lm(., data = data))\n    )\n\n\n上記のサンプルデータの場合、x1がyに与える影響は \\(1.2 + 1.5 * 1.6 = 3.6\\)なので中間変数であるx2を含まない方がよい推定である ことがわかる.\n\n\nCode\nmodels$reg\n#&gt; [[1]]\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = ., data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           x1  \n#&gt;       2.682        3.463  \n#&gt; \n#&gt; \n#&gt; [[2]]\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = ., data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           x1           x2  \n#&gt;      0.8675       1.4104       1.5806\n\n\n\n\nCode\nmodels$reg |&gt; lapply(confint)\n#&gt; [[1]]\n#&gt;                2.5 %   97.5 %\n#&gt; (Intercept) 2.109008 3.255472\n#&gt; x1          3.085248 3.840094\n#&gt; \n#&gt; [[2]]\n#&gt;                2.5 %   97.5 %\n#&gt; (Intercept) 0.488317 1.246698\n#&gt; x1          1.085086 1.735793\n#&gt; x2          1.382953 1.778201"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/109_交互作用項のある共分散分析.html",
    "href": "contents/books/05_統計的因果推論の理論と実際/109_交互作用項のある共分散分析.html",
    "title": "交互作用項のある共分散分析",
    "section": "",
    "text": "共分散分析のモデル次式に示す． ダミー変数を含む重回帰モデルであり， 共変量によるデータの偏りを調整したうえで処置の影響を算出する有力なモデルである．\n\\[\nY_i = \\beta_0 + \\beta_1X_{i1}+\\beta_2T_i+\\epsilon_i\n\\]\n\\[\nT_i =\n\\begin{cases}\n1 \\\\\n0\n\\end{cases}\n\\]\n重回帰モデルであるため共分散分析では，これまでの仮定を満たす必要がある． さらに処置変数によらず共変量が目的変数に与える影響が同じ， つまり\\(\\beta_1\\)が共通という仮定がある.\nこの仮定が満たされない場合には，交互作用項を見込んだモデルを作成する必要がある.\n\\[\nY_i = \\beta_0 + \\beta_1X_{i1}+\\beta_2T_i+\\beta_3X_{i1}T_i+\\epsilon_i\n\\]\nこのモデルを使うことより説明変数が目的変数に与える影響は， \\(\\beta_3\\)だけ処置群間で異なることがわかる.\n\\[\nY_i = \\beta_0 + (\\beta_1+\\beta_3T_i)X_{i1}+\\beta_2T_i+\\epsilon_i\n\\]\nこのようなモデルが必要になるのは, 説明変数で条件づけたときに， 処置の割り付け確率が異なるということが影響している． これにより潜在的結果変数と処置が独立でなくなる.\n\n\n\n\\[\nY_i(T_i=0) = \\beta_0 + \\beta_1X_{i}+\\epsilon_i\n\\]\n\\[\nY_i(T_i=1) = (\\beta_0 + \\beta_2) + (\\beta_1+\\beta_3)X_{i}+\\epsilon_i\n\\]\n\n\n個体別効果は潜在的結果変数\\(Y_i(1)\\)と\\(Y_i(0)\\)の差であるから， これは次式で表されることになる.\n\\[\n\\tau_i=Y_i(1)-Y_i(0)=\\beta_2+\\beta_3X_i\n\\]\nまた実際に推定すべきは個別効果の期待値である． つまり，\\(\\beta_2\\)に\\(\\beta_3\\)と\\(X_i\\)の平均値の積を加えた値である. これは実際に計算してみると共分散分析で求めることが可能となる.\n\\[\n\\tau_{ATE}=E[Y_i(1)-Y_i(0)]\\\\\n\\tau_{ATE}=\\beta_2+\\beta_3E[X_i]\n\\]\n\n\n\n\\(\\tau_{\\text{ATE}}\\)の標準誤差は lmの結果からは求めることが出来ないので注意． 詳細は省略するが\\(var(\\tau_{\\text{ATE}})\\)を求める必要がある.\n\n\n\n\n\n結果変数には影響するが，処置変数とは関連のない共変量は，モデルに入れても偏りに悪影響はない．ただし，モデルの説明量を改善できるため，そのような変数が存在する場合には積極的に活用すること.\n結果変数に影響を与えており，処置変数とも関連のある共変量は偏りに悪影響を及ぼすため，モデルにふくめなければならない．このような変数のことを「交絡因子」と呼ぶ\n処置変数とは関連あるが，結果変数に影響のない共変量は，標準誤差を大きくするため含めない方が望ましい．\n処置変数と結果変数の因果のパスの間に存在する中間辺陬はモデルに入れてはならない\n２以上の共変量間に強い多重共線性があってもそのままモデルに入れてよい\nあまり重要でない共変量はまとめて誤差のとして扱うのが現実的な場合もある.\nもし処置群と統制群とで回帰の傾きが平行でないと考えられるならば，モデルに交互作用項を入れる必要がある\n\n\n\n\n共変量が多変量のときに作業が膨大になる. 平均処置効果，つまり処置があった場合となかった場合の「差」を推定することは可能であるが， 処置群の平均処置効果を推定することが出来ない．\n\n\n\n傾向スコアとは共変量\\(X\\)が与えられたとき， 処置に割り付けられる確率である."
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/109_交互作用項のある共分散分析.html#共分散分析の仮定",
    "href": "contents/books/05_統計的因果推論の理論と実際/109_交互作用項のある共分散分析.html#共分散分析の仮定",
    "title": "交互作用項のある共分散分析",
    "section": "",
    "text": "共分散分析のモデル次式に示す． ダミー変数を含む重回帰モデルであり， 共変量によるデータの偏りを調整したうえで処置の影響を算出する有力なモデルである．\n\\[\nY_i = \\beta_0 + \\beta_1X_{i1}+\\beta_2T_i+\\epsilon_i\n\\]\n\\[\nT_i =\n\\begin{cases}\n1 \\\\\n0\n\\end{cases}\n\\]\n重回帰モデルであるため共分散分析では，これまでの仮定を満たす必要がある． さらに処置変数によらず共変量が目的変数に与える影響が同じ， つまり\\(\\beta_1\\)が共通という仮定がある.\nこの仮定が満たされない場合には，交互作用項を見込んだモデルを作成する必要がある.\n\\[\nY_i = \\beta_0 + \\beta_1X_{i1}+\\beta_2T_i+\\beta_3X_{i1}T_i+\\epsilon_i\n\\]\nこのモデルを使うことより説明変数が目的変数に与える影響は， \\(\\beta_3\\)だけ処置群間で異なることがわかる.\n\\[\nY_i = \\beta_0 + (\\beta_1+\\beta_3T_i)X_{i1}+\\beta_2T_i+\\epsilon_i\n\\]\nこのようなモデルが必要になるのは, 説明変数で条件づけたときに， 処置の割り付け確率が異なるということが影響している． これにより潜在的結果変数と処置が独立でなくなる."
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/109_交互作用項のある共分散分析.html#交互作用項のある共分散分析-1",
    "href": "contents/books/05_統計的因果推論の理論と実際/109_交互作用項のある共分散分析.html#交互作用項のある共分散分析-1",
    "title": "交互作用項のある共分散分析",
    "section": "",
    "text": "\\[\nY_i(T_i=0) = \\beta_0 + \\beta_1X_{i}+\\epsilon_i\n\\]\n\\[\nY_i(T_i=1) = (\\beta_0 + \\beta_2) + (\\beta_1+\\beta_3)X_{i}+\\epsilon_i\n\\]\n\n\n個体別効果は潜在的結果変数\\(Y_i(1)\\)と\\(Y_i(0)\\)の差であるから， これは次式で表されることになる.\n\\[\n\\tau_i=Y_i(1)-Y_i(0)=\\beta_2+\\beta_3X_i\n\\]\nまた実際に推定すべきは個別効果の期待値である． つまり，\\(\\beta_2\\)に\\(\\beta_3\\)と\\(X_i\\)の平均値の積を加えた値である. これは実際に計算してみると共分散分析で求めることが可能となる.\n\\[\n\\tau_{ATE}=E[Y_i(1)-Y_i(0)]\\\\\n\\tau_{ATE}=\\beta_2+\\beta_3E[X_i]\n\\]\n\n\n\n\\(\\tau_{\\text{ATE}}\\)の標準誤差は lmの結果からは求めることが出来ないので注意． 詳細は省略するが\\(var(\\tau_{\\text{ATE}})\\)を求める必要がある."
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/109_交互作用項のある共分散分析.html#統制すべき共変量に関するまとめ",
    "href": "contents/books/05_統計的因果推論の理論と実際/109_交互作用項のある共分散分析.html#統制すべき共変量に関するまとめ",
    "title": "交互作用項のある共分散分析",
    "section": "",
    "text": "結果変数には影響するが，処置変数とは関連のない共変量は，モデルに入れても偏りに悪影響はない．ただし，モデルの説明量を改善できるため，そのような変数が存在する場合には積極的に活用すること.\n結果変数に影響を与えており，処置変数とも関連のある共変量は偏りに悪影響を及ぼすため，モデルにふくめなければならない．このような変数のことを「交絡因子」と呼ぶ\n処置変数とは関連あるが，結果変数に影響のない共変量は，標準誤差を大きくするため含めない方が望ましい．\n処置変数と結果変数の因果のパスの間に存在する中間辺陬はモデルに入れてはならない\n２以上の共変量間に強い多重共線性があってもそのままモデルに入れてよい\nあまり重要でない共変量はまとめて誤差のとして扱うのが現実的な場合もある.\nもし処置群と統制群とで回帰の傾きが平行でないと考えられるならば，モデルに交互作用項を入れる必要がある"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/109_交互作用項のある共分散分析.html#共分散分析の限界",
    "href": "contents/books/05_統計的因果推論の理論と実際/109_交互作用項のある共分散分析.html#共分散分析の限界",
    "title": "交互作用項のある共分散分析",
    "section": "",
    "text": "共変量が多変量のときに作業が膨大になる. 平均処置効果，つまり処置があった場合となかった場合の「差」を推定することは可能であるが， 処置群の平均処置効果を推定することが出来ない．"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/109_交互作用項のある共分散分析.html#傾向スコアと共分散分析の優劣",
    "href": "contents/books/05_統計的因果推論の理論と実際/109_交互作用項のある共分散分析.html#傾向スコアと共分散分析の優劣",
    "title": "交互作用項のある共分散分析",
    "section": "",
    "text": "傾向スコアとは共変量\\(X\\)が与えられたとき， 処置に割り付けられる確率である."
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/111_傾向スコアマッチング.html",
    "href": "contents/books/05_統計的因果推論の理論と実際/111_傾向スコアマッチング.html",
    "title": "傾向スコアマッチング",
    "section": "",
    "text": "よく似たデザインは，文化や政治体制，教育，社会保障などが似た 二つの国を対象にして，ある変数を比較することである． しかし，この方法は完全に一致することはないので，厳密にはどの変数が影響しているのかを 判断することは難しい．\n\n\n\n同じ個体に対して，ある処置を行った場合，行っていない場合の二つの結果を得るのは不可能である．\nこのため実験研究では，無作為に処置の割り付けをした処置群と統制群の二つの群間で， 結果を比較する方法を開発してきた．これにより平均処置効果(ATE)を推定することが可能となった.\n観察研究では無作為の割り付けが困難であるため， 共変量を使ったマッチング方法が開発されて， 事実上同じ個体であると扱うことで因果推論を行うことが出来た．\n交絡因子の検証を行うことで，処置効果を推定することが可能となる． マッチング後にこのような考察を行うには， 繰り返しになるが「未確認の交絡因子がない」という仮定である\n\n\n\n統計的因果推論では，平均処置効果(ATE)，処置群の平均処置効果(ATT)が主な推定対象である.\n\\[\n\\begin{align}\n\\tau_{ATE}&=E[Y_i(1)-Y_i(0)]=E[Y_i(1)]-E[Y_i(0)] \\\\\n\\tau_{ATT}&=E[Y_i(1)-Y_i(0)|T_i=1]=E[Y_i(1)|T_i=1]-E[Y_i(0)|T_i=1]\n\\end{align}\n\\]\nマッチングにおける推定対象は，ATTだけである． なぜなら，処置群における個体に対して，対照群からマッチングする候補を選んでくるため， マッチング後のデータは処置群の個体を中心として構成されているからである．\nまた共分散分析ではATEを推定することは出来るが，ATTを推定することができない． ATTを推定する場合には傾向スコアマッチング，ATEを推定する場合には傾向スコアによる 層化解析，傾向スコアによる重み付け方法を用いる．\n\n\n\n使用するデータは多変量対数正規分布である． このデータの説明変数はテプリッツ行列を相関係数行列して設定している. テプリッツ行列は対称行列であり，斜め成分の値が一致である．\n\n\nCode\ndata11 &lt;- read_csv(\"./causality/data11.csv\", show_col_types = FALSE)\ncor((select(data11, starts_with(\"x\"))))\n#&gt;             x1         x2         x3        x4         x5          x6\n#&gt; x1  1.00000000 0.49291889 0.23515110 0.1042767 0.01814199 -0.01702065\n#&gt; x2  0.49291889 1.00000000 0.50415434 0.2381513 0.08718005  0.02007256\n#&gt; x3  0.23515110 0.50415434 1.00000000 0.5155681 0.21899658  0.09432731\n#&gt; x4  0.10427668 0.23815132 0.51556809 1.0000000 0.49573573  0.28363283\n#&gt; x5  0.01814199 0.08718005 0.21899658 0.4957357 1.00000000  0.53941181\n#&gt; x6 -0.01702065 0.02007256 0.09432731 0.2836328 0.53941181  1.00000000\n\n\n\n\nCode\n# 設定した相関係数行列\ntoeplitz(0.5^(0:5))\n#&gt;         [,1]   [,2]  [,3]  [,4]   [,5]    [,6]\n#&gt; [1,] 1.00000 0.5000 0.250 0.125 0.0625 0.03125\n#&gt; [2,] 0.50000 1.0000 0.500 0.250 0.1250 0.06250\n#&gt; [3,] 0.25000 0.5000 1.000 0.500 0.2500 0.12500\n#&gt; [4,] 0.12500 0.2500 0.500 1.000 0.5000 0.25000\n#&gt; [5,] 0.06250 0.1250 0.250 0.500 1.0000 0.50000\n#&gt; [6,] 0.03125 0.0625 0.125 0.250 0.5000 1.00000\n\n\n\n\nCode\n#ATE\nwith(data11, {\n    print(mean(y1t) - mean(y0t))\n})\n#&gt; [1] 3.755947\n\n\n\n\nCode\n#ATT\nwith(data11, {\n    print(mean(y1t[t1==1]) - mean(y0t[t1==1]))\n})\n#&gt; [1] 2.888651\n\n\n\n\n\nナイーブな比較では\\(t_1\\)の係数が15となっており，ATT，ATEとどちらもも大きく離れていることがわかる．\n\n\nCode\n# ナイーブ\nlm( y3 ~ t1, data = data11) |&gt; \n    summary()\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y3 ~ t1, data = data11)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -62.190 -13.494  -1.613  15.272  69.376 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  26.2678     0.9065   28.98   &lt;2e-16 ***\n#&gt; t1           15.8099     1.4534   10.88   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 22.41 on 998 degrees of freedom\n#&gt; Multiple R-squared:  0.106,  Adjusted R-squared:  0.1051 \n#&gt; F-statistic: 118.3 on 1 and 998 DF,  p-value: &lt; 2.2e-16\n\n\n共分散分析の結果ではATT値とは当然異なるが， ATE値を見ても異なることがわかる． これは全ての交差項が含まれていないため，正しくモデリングできていないことによる． （もともとのデータで共変量の傾きが処置群と統制群で共通でないものを作成している）．\n\n\nCode\n# 共分散分析\nlm( y3 ~ t1 + x1 + x2 + x3 + x4 + x5 + x6, data = data11) |&gt; \n    summary()\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y3 ~ t1 + x1 + x2 + x3 + x4 + x5 + x6, data = data11)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -18.9525  -3.0228  -0.1244   3.1150  17.4160 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)   1.0519     0.3086   3.409 0.000678 ***\n#&gt; t1            3.4741     0.3266  10.637  &lt; 2e-16 ***\n#&gt; x1            1.3928     0.1841   7.566 8.77e-14 ***\n#&gt; x2           -0.2920     0.1942  -1.504 0.132947    \n#&gt; x3            0.4540     0.1943   2.337 0.019663 *  \n#&gt; x4            7.4736     0.2046  36.531  &lt; 2e-16 ***\n#&gt; x5            9.6599     0.1967  49.101  &lt; 2e-16 ***\n#&gt; x6           11.1501     0.1873  59.545  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 4.836 on 992 degrees of freedom\n#&gt; Multiple R-squared:  0.9586, Adjusted R-squared:  0.9583 \n#&gt; F-statistic:  3282 on 7 and 992 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n個体をペアと見なす傾向マッチングでは， 復元抽出であるか，非復元抽出であるのかを決める必要がある. とりあえず復元抽出の方が情報を抽出しやすいということを覚えておく．\n\n\n\n傾向スコアの算出はロジスティックス回帰である必要はない． 個体間の距離が\\(|e_j-e_i|\\)がスカラーで算出するだけでよい．\nマッチング方法も様々ある.\n\n\n\n\n\nCode\nlibrary(MatchIt)\n#&gt; Warning: package 'MatchIt' was built under R version 4.3.2\n\nm.out1 &lt;- matchit(\n    t1 ~ x1 + x2 + x3 + x4 + x5 + x6, \n    data = data11, \n    replace = TRUE, \n    distance = \"glm\", \n    method = \"nearest\"\n)\n\n# マッチング後のデータを抽出\nm.data1 &lt;- match.data(m.out1)\nmodel1  &lt;- lm(y3 ~ t1, data = m.data1, weights = weights)\nmodel2  &lt;- lm(y3 ~ t1 + x1 + x2 + x3 + x4 + x5 + x6, data = m.data1, weights = weights)\n\n\n\n\nCode\nm.data1\n#&gt; # A tibble: 618 × 12\n#&gt;       y0t   y1t     y3    t1     x1     x2      x3    x4      x5     x6 distance\n#&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n#&gt;  1 61.6   64.7  64.7       1  0.640 -1.20  -0.0539 1.67   2.11    2.47     0.618\n#&gt;  2 -0.275 -1.97 -0.275     0 -0.473  0.747  0.961  0.956  0.223  -1.06     0.210\n#&gt;  3 46.8   48.3  48.3       1  0.846 -0.855  0.159  1.05   1.29    2.05     0.515\n#&gt;  4 31.0   34.6  34.6       1  0.680 -0.106  0.304  0.362  1.66    0.992    0.427\n#&gt;  5 53.3   54.3  54.3       1  1.70   2.02   2.23   2.88   1.58    1.22     0.481\n#&gt;  6 23.6   20.6  23.6       0 -0.752 -0.567  0.440  1.56   0.686   0.263    0.348\n#&gt;  7 49.5   56.3  49.5       0  2.13   2.11   1.72   1.66   1.27    1.94     0.467\n#&gt;  8 54.5   44.1  54.5       0  1.40  -0.291  1.67   1.58   0.982   2.05     0.549\n#&gt;  9 15.1   30.3  30.3       1  1.48   2.36   0.775  0.918 -0.0192  0.808    0.245\n#&gt; 10 24.4   42.3  42.3       1  0.357  1.47  -0.0248 0.435  1.79    0.733    0.341\n#&gt; # ℹ 608 more rows\n#&gt; # ℹ 1 more variable: weights &lt;dbl&gt;\n\n\n\n\nCode\nmodel1 |&gt; summary()\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y3 ~ t1, data = m.data1, weights = weights)\n#&gt; \n#&gt; Weighted Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -75.717 -14.327  -1.654  13.604  83.700 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)   39.484      1.464  26.968   &lt;2e-16 ***\n#&gt; t1             2.594      1.845   1.406     0.16    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 22.16 on 616 degrees of freedom\n#&gt; Multiple R-squared:  0.003197,   Adjusted R-squared:  0.001579 \n#&gt; F-statistic: 1.976 on 1 and 616 DF,  p-value: 0.1603\n\n\n\n\nCode\nmodel2 |&gt; summary()\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y3 ~ t1 + x1 + x2 + x3 + x4 + x5 + x6, data = m.data1, \n#&gt;     weights = weights)\n#&gt; \n#&gt; Weighted Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -19.7535  -2.9321  -0.1799   2.7255  19.9425 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)   1.8485     0.5049   3.661 0.000273 ***\n#&gt; t1            2.9174     0.4026   7.247 1.29e-12 ***\n#&gt; x1            1.7283     0.2465   7.010 6.32e-12 ***\n#&gt; x2            1.0956     0.2480   4.417 1.18e-05 ***\n#&gt; x3           -2.1161     0.2437  -8.683  &lt; 2e-16 ***\n#&gt; x4            7.8469     0.2553  30.731  &lt; 2e-16 ***\n#&gt; x5            9.9916     0.2479  40.306  &lt; 2e-16 ***\n#&gt; x6           11.2766     0.2413  46.742  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 4.83 on 610 degrees of freedom\n#&gt; Multiple R-squared:  0.9531, Adjusted R-squared:  0.9526 \n#&gt; F-statistic:  1771 on 7 and 610 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n一応作法があるので注意\n\n\n\nVar.Ratioの値が１に近いとバランスが取れている．\n\n\nCode\nsummary(m.out1)\n#&gt; \n#&gt; Call:\n#&gt; matchit(formula = t1 ~ x1 + x2 + x3 + x4 + x5 + x6, data = data11, \n#&gt;     method = \"nearest\", distance = \"glm\", replace = TRUE)\n#&gt; \n#&gt; Summary of Balance for All Data:\n#&gt;          Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance        0.4371        0.3584          0.6022     0.9897    0.1755\n#&gt; x1              0.9655        0.9919         -0.0297     0.7966    0.0210\n#&gt; x2              0.9596        0.9810         -0.0217     0.8841    0.0200\n#&gt; x3              1.1451        0.9162          0.2196     1.0303    0.0616\n#&gt; x4              1.2246        0.8986          0.3429     0.9352    0.1017\n#&gt; x5              1.2874        0.7913          0.4963     1.0065    0.1461\n#&gt; x6              1.2896        0.8382          0.4860     0.9166    0.1376\n#&gt;          eCDF Max\n#&gt; distance   0.3232\n#&gt; x1         0.0540\n#&gt; x2         0.0524\n#&gt; x3         0.1002\n#&gt; x4         0.1797\n#&gt; x5         0.2387\n#&gt; x6         0.2212\n#&gt; \n#&gt; Summary of Balance for Matched Data:\n#&gt;          Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance        0.4371        0.4369          0.0012     1.0028    0.0014\n#&gt; x1              0.9655        0.9759         -0.0117     0.7990    0.0241\n#&gt; x2              0.9596        0.9644         -0.0049     0.8047    0.0273\n#&gt; x3              1.1451        1.1281          0.0162     0.9851    0.0100\n#&gt; x4              1.2246        1.2465         -0.0231     0.8135    0.0241\n#&gt; x5              1.2874        1.2614          0.0260     1.0968    0.0121\n#&gt; x6              1.2896        1.3208         -0.0336     0.9959    0.0120\n#&gt;          eCDF Max Std. Pair Dist.\n#&gt; distance   0.0129          0.0076\n#&gt; x1         0.0668          1.2125\n#&gt; x2         0.0771          1.2002\n#&gt; x3         0.0386          1.0269\n#&gt; x4         0.0566          0.9933\n#&gt; x5         0.0540          0.6018\n#&gt; x6         0.0488          0.6997\n#&gt; \n#&gt; Sample Sizes:\n#&gt;               Control Treated\n#&gt; All            611.       389\n#&gt; Matched (ESS)  167.21     389\n#&gt; Matched        229.       389\n#&gt; Unmatched      382.         0\n#&gt; Discarded        0.         0\n\n\nラブプロットという図を書いてすべてが0.1以下になるように， 共変量や高次項などを調整していく. ラブプロットを記述するライブラリも存在しているが，ここでは スクラッチで実装する．これは後に再利用するためである．\n\n\nCode\ndiffa &lt;- abs(summary(m.out1)$sum.all[,3])\ndiffb &lt;- abs(summary(m.out1)$sum.matched[,3])\ndiff1 &lt;- rev(diffa)\ndiff2 &lt;- rev(diffb)\n\nmaxx    &lt;- max(diff1, diff2)\nlabels0 &lt;- rownames(summary(m.out1)$sum.all)\nlabels1 &lt;- rev(labels0)\n\ndotchart(diff1, xlim = c(0, maxx), labels = c(labels1))\nabline(v = .0, col = 8)\nabline(v = .1, col = 8)\nabline(v = .05, lty = 2, col = 8)\n\npar(new = TRUE)\ndotchart(diff2, xlim = c(0, maxx), labels = c(labels1), \n         pch = 16, xlab = \"Absolute Standardized Mean Difference\")"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/111_傾向スコアマッチング.html#比較政治学におけるよく似たシスステムデザイン",
    "href": "contents/books/05_統計的因果推論の理論と実際/111_傾向スコアマッチング.html#比較政治学におけるよく似たシスステムデザイン",
    "title": "傾向スコアマッチング",
    "section": "",
    "text": "よく似たデザインは，文化や政治体制，教育，社会保障などが似た 二つの国を対象にして，ある変数を比較することである． しかし，この方法は完全に一致することはないので，厳密にはどの変数が影響しているのかを 判断することは難しい．"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/111_傾向スコアマッチング.html#統計的因果推論におけるマッチング",
    "href": "contents/books/05_統計的因果推論の理論と実際/111_傾向スコアマッチング.html#統計的因果推論におけるマッチング",
    "title": "傾向スコアマッチング",
    "section": "",
    "text": "同じ個体に対して，ある処置を行った場合，行っていない場合の二つの結果を得るのは不可能である．\nこのため実験研究では，無作為に処置の割り付けをした処置群と統制群の二つの群間で， 結果を比較する方法を開発してきた．これにより平均処置効果(ATE)を推定することが可能となった.\n観察研究では無作為の割り付けが困難であるため， 共変量を使ったマッチング方法が開発されて， 事実上同じ個体であると扱うことで因果推論を行うことが出来た．\n交絡因子の検証を行うことで，処置効果を推定することが可能となる． マッチング後にこのような考察を行うには， 繰り返しになるが「未確認の交絡因子がない」という仮定である"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/111_傾向スコアマッチング.html#推定対象",
    "href": "contents/books/05_統計的因果推論の理論と実際/111_傾向スコアマッチング.html#推定対象",
    "title": "傾向スコアマッチング",
    "section": "",
    "text": "統計的因果推論では，平均処置効果(ATE)，処置群の平均処置効果(ATT)が主な推定対象である.\n\\[\n\\begin{align}\n\\tau_{ATE}&=E[Y_i(1)-Y_i(0)]=E[Y_i(1)]-E[Y_i(0)] \\\\\n\\tau_{ATT}&=E[Y_i(1)-Y_i(0)|T_i=1]=E[Y_i(1)|T_i=1]-E[Y_i(0)|T_i=1]\n\\end{align}\n\\]\nマッチングにおける推定対象は，ATTだけである． なぜなら，処置群における個体に対して，対照群からマッチングする候補を選んでくるため， マッチング後のデータは処置群の個体を中心として構成されているからである．\nまた共分散分析ではATEを推定することは出来るが，ATTを推定することができない． ATTを推定する場合には傾向スコアマッチング，ATEを推定する場合には傾向スコアによる 層化解析，傾向スコアによる重み付け方法を用いる．"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/111_傾向スコアマッチング.html#使用するデータ",
    "href": "contents/books/05_統計的因果推論の理論と実際/111_傾向スコアマッチング.html#使用するデータ",
    "title": "傾向スコアマッチング",
    "section": "",
    "text": "使用するデータは多変量対数正規分布である． このデータの説明変数はテプリッツ行列を相関係数行列して設定している. テプリッツ行列は対称行列であり，斜め成分の値が一致である．\n\n\nCode\ndata11 &lt;- read_csv(\"./causality/data11.csv\", show_col_types = FALSE)\ncor((select(data11, starts_with(\"x\"))))\n#&gt;             x1         x2         x3        x4         x5          x6\n#&gt; x1  1.00000000 0.49291889 0.23515110 0.1042767 0.01814199 -0.01702065\n#&gt; x2  0.49291889 1.00000000 0.50415434 0.2381513 0.08718005  0.02007256\n#&gt; x3  0.23515110 0.50415434 1.00000000 0.5155681 0.21899658  0.09432731\n#&gt; x4  0.10427668 0.23815132 0.51556809 1.0000000 0.49573573  0.28363283\n#&gt; x5  0.01814199 0.08718005 0.21899658 0.4957357 1.00000000  0.53941181\n#&gt; x6 -0.01702065 0.02007256 0.09432731 0.2836328 0.53941181  1.00000000\n\n\n\n\nCode\n# 設定した相関係数行列\ntoeplitz(0.5^(0:5))\n#&gt;         [,1]   [,2]  [,3]  [,4]   [,5]    [,6]\n#&gt; [1,] 1.00000 0.5000 0.250 0.125 0.0625 0.03125\n#&gt; [2,] 0.50000 1.0000 0.500 0.250 0.1250 0.06250\n#&gt; [3,] 0.25000 0.5000 1.000 0.500 0.2500 0.12500\n#&gt; [4,] 0.12500 0.2500 0.500 1.000 0.5000 0.25000\n#&gt; [5,] 0.06250 0.1250 0.250 0.500 1.0000 0.50000\n#&gt; [6,] 0.03125 0.0625 0.125 0.250 0.5000 1.00000\n\n\n\n\nCode\n#ATE\nwith(data11, {\n    print(mean(y1t) - mean(y0t))\n})\n#&gt; [1] 3.755947\n\n\n\n\nCode\n#ATT\nwith(data11, {\n    print(mean(y1t[t1==1]) - mean(y0t[t1==1]))\n})\n#&gt; [1] 2.888651"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/111_傾向スコアマッチング.html#ナイーブな比較と共分散分析",
    "href": "contents/books/05_統計的因果推論の理論と実際/111_傾向スコアマッチング.html#ナイーブな比較と共分散分析",
    "title": "傾向スコアマッチング",
    "section": "",
    "text": "ナイーブな比較では\\(t_1\\)の係数が15となっており，ATT，ATEとどちらもも大きく離れていることがわかる．\n\n\nCode\n# ナイーブ\nlm( y3 ~ t1, data = data11) |&gt; \n    summary()\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y3 ~ t1, data = data11)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -62.190 -13.494  -1.613  15.272  69.376 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  26.2678     0.9065   28.98   &lt;2e-16 ***\n#&gt; t1           15.8099     1.4534   10.88   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 22.41 on 998 degrees of freedom\n#&gt; Multiple R-squared:  0.106,  Adjusted R-squared:  0.1051 \n#&gt; F-statistic: 118.3 on 1 and 998 DF,  p-value: &lt; 2.2e-16\n\n\n共分散分析の結果ではATT値とは当然異なるが， ATE値を見ても異なることがわかる． これは全ての交差項が含まれていないため，正しくモデリングできていないことによる． （もともとのデータで共変量の傾きが処置群と統制群で共通でないものを作成している）．\n\n\nCode\n# 共分散分析\nlm( y3 ~ t1 + x1 + x2 + x3 + x4 + x5 + x6, data = data11) |&gt; \n    summary()\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y3 ~ t1 + x1 + x2 + x3 + x4 + x5 + x6, data = data11)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -18.9525  -3.0228  -0.1244   3.1150  17.4160 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)   1.0519     0.3086   3.409 0.000678 ***\n#&gt; t1            3.4741     0.3266  10.637  &lt; 2e-16 ***\n#&gt; x1            1.3928     0.1841   7.566 8.77e-14 ***\n#&gt; x2           -0.2920     0.1942  -1.504 0.132947    \n#&gt; x3            0.4540     0.1943   2.337 0.019663 *  \n#&gt; x4            7.4736     0.2046  36.531  &lt; 2e-16 ***\n#&gt; x5            9.6599     0.1967  49.101  &lt; 2e-16 ***\n#&gt; x6           11.1501     0.1873  59.545  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 4.836 on 992 degrees of freedom\n#&gt; Multiple R-squared:  0.9586, Adjusted R-squared:  0.9583 \n#&gt; F-statistic:  3282 on 7 and 992 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/111_傾向スコアマッチング.html#復元によるマッチングと非復元によるマッチング",
    "href": "contents/books/05_統計的因果推論の理論と実際/111_傾向スコアマッチング.html#復元によるマッチングと非復元によるマッチング",
    "title": "傾向スコアマッチング",
    "section": "",
    "text": "個体をペアと見なす傾向マッチングでは， 復元抽出であるか，非復元抽出であるのかを決める必要がある. とりあえず復元抽出の方が情報を抽出しやすいということを覚えておく．"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/111_傾向スコアマッチング.html#距離",
    "href": "contents/books/05_統計的因果推論の理論と実際/111_傾向スコアマッチング.html#距離",
    "title": "傾向スコアマッチング",
    "section": "",
    "text": "傾向スコアの算出はロジスティックス回帰である必要はない． 個体間の距離が\\(|e_j-e_i|\\)がスカラーで算出するだけでよい．\nマッチング方法も様々ある."
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/111_傾向スコアマッチング.html#rによる復元抽出の傾向スコアマッチングattの推定",
    "href": "contents/books/05_統計的因果推論の理論と実際/111_傾向スコアマッチング.html#rによる復元抽出の傾向スコアマッチングattの推定",
    "title": "傾向スコアマッチング",
    "section": "",
    "text": "Code\nlibrary(MatchIt)\n#&gt; Warning: package 'MatchIt' was built under R version 4.3.2\n\nm.out1 &lt;- matchit(\n    t1 ~ x1 + x2 + x3 + x4 + x5 + x6, \n    data = data11, \n    replace = TRUE, \n    distance = \"glm\", \n    method = \"nearest\"\n)\n\n# マッチング後のデータを抽出\nm.data1 &lt;- match.data(m.out1)\nmodel1  &lt;- lm(y3 ~ t1, data = m.data1, weights = weights)\nmodel2  &lt;- lm(y3 ~ t1 + x1 + x2 + x3 + x4 + x5 + x6, data = m.data1, weights = weights)\n\n\n\n\nCode\nm.data1\n#&gt; # A tibble: 618 × 12\n#&gt;       y0t   y1t     y3    t1     x1     x2      x3    x4      x5     x6 distance\n#&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n#&gt;  1 61.6   64.7  64.7       1  0.640 -1.20  -0.0539 1.67   2.11    2.47     0.618\n#&gt;  2 -0.275 -1.97 -0.275     0 -0.473  0.747  0.961  0.956  0.223  -1.06     0.210\n#&gt;  3 46.8   48.3  48.3       1  0.846 -0.855  0.159  1.05   1.29    2.05     0.515\n#&gt;  4 31.0   34.6  34.6       1  0.680 -0.106  0.304  0.362  1.66    0.992    0.427\n#&gt;  5 53.3   54.3  54.3       1  1.70   2.02   2.23   2.88   1.58    1.22     0.481\n#&gt;  6 23.6   20.6  23.6       0 -0.752 -0.567  0.440  1.56   0.686   0.263    0.348\n#&gt;  7 49.5   56.3  49.5       0  2.13   2.11   1.72   1.66   1.27    1.94     0.467\n#&gt;  8 54.5   44.1  54.5       0  1.40  -0.291  1.67   1.58   0.982   2.05     0.549\n#&gt;  9 15.1   30.3  30.3       1  1.48   2.36   0.775  0.918 -0.0192  0.808    0.245\n#&gt; 10 24.4   42.3  42.3       1  0.357  1.47  -0.0248 0.435  1.79    0.733    0.341\n#&gt; # ℹ 608 more rows\n#&gt; # ℹ 1 more variable: weights &lt;dbl&gt;\n\n\n\n\nCode\nmodel1 |&gt; summary()\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y3 ~ t1, data = m.data1, weights = weights)\n#&gt; \n#&gt; Weighted Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -75.717 -14.327  -1.654  13.604  83.700 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)   39.484      1.464  26.968   &lt;2e-16 ***\n#&gt; t1             2.594      1.845   1.406     0.16    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 22.16 on 616 degrees of freedom\n#&gt; Multiple R-squared:  0.003197,   Adjusted R-squared:  0.001579 \n#&gt; F-statistic: 1.976 on 1 and 616 DF,  p-value: 0.1603\n\n\n\n\nCode\nmodel2 |&gt; summary()\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y3 ~ t1 + x1 + x2 + x3 + x4 + x5 + x6, data = m.data1, \n#&gt;     weights = weights)\n#&gt; \n#&gt; Weighted Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -19.7535  -2.9321  -0.1799   2.7255  19.9425 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)   1.8485     0.5049   3.661 0.000273 ***\n#&gt; t1            2.9174     0.4026   7.247 1.29e-12 ***\n#&gt; x1            1.7283     0.2465   7.010 6.32e-12 ***\n#&gt; x2            1.0956     0.2480   4.417 1.18e-05 ***\n#&gt; x3           -2.1161     0.2437  -8.683  &lt; 2e-16 ***\n#&gt; x4            7.8469     0.2553  30.731  &lt; 2e-16 ***\n#&gt; x5            9.9916     0.2479  40.306  &lt; 2e-16 ***\n#&gt; x6           11.2766     0.2413  46.742  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 4.83 on 610 degrees of freedom\n#&gt; Multiple R-squared:  0.9531, Adjusted R-squared:  0.9526 \n#&gt; F-statistic:  1771 on 7 and 610 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/111_傾向スコアマッチング.html#標準誤差",
    "href": "contents/books/05_統計的因果推論の理論と実際/111_傾向スコアマッチング.html#標準誤差",
    "title": "傾向スコアマッチング",
    "section": "",
    "text": "一応作法があるので注意"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/111_傾向スコアマッチング.html#バランシングの評価",
    "href": "contents/books/05_統計的因果推論の理論と実際/111_傾向スコアマッチング.html#バランシングの評価",
    "title": "傾向スコアマッチング",
    "section": "",
    "text": "Var.Ratioの値が１に近いとバランスが取れている．\n\n\nCode\nsummary(m.out1)\n#&gt; \n#&gt; Call:\n#&gt; matchit(formula = t1 ~ x1 + x2 + x3 + x4 + x5 + x6, data = data11, \n#&gt;     method = \"nearest\", distance = \"glm\", replace = TRUE)\n#&gt; \n#&gt; Summary of Balance for All Data:\n#&gt;          Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance        0.4371        0.3584          0.6022     0.9897    0.1755\n#&gt; x1              0.9655        0.9919         -0.0297     0.7966    0.0210\n#&gt; x2              0.9596        0.9810         -0.0217     0.8841    0.0200\n#&gt; x3              1.1451        0.9162          0.2196     1.0303    0.0616\n#&gt; x4              1.2246        0.8986          0.3429     0.9352    0.1017\n#&gt; x5              1.2874        0.7913          0.4963     1.0065    0.1461\n#&gt; x6              1.2896        0.8382          0.4860     0.9166    0.1376\n#&gt;          eCDF Max\n#&gt; distance   0.3232\n#&gt; x1         0.0540\n#&gt; x2         0.0524\n#&gt; x3         0.1002\n#&gt; x4         0.1797\n#&gt; x5         0.2387\n#&gt; x6         0.2212\n#&gt; \n#&gt; Summary of Balance for Matched Data:\n#&gt;          Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; distance        0.4371        0.4369          0.0012     1.0028    0.0014\n#&gt; x1              0.9655        0.9759         -0.0117     0.7990    0.0241\n#&gt; x2              0.9596        0.9644         -0.0049     0.8047    0.0273\n#&gt; x3              1.1451        1.1281          0.0162     0.9851    0.0100\n#&gt; x4              1.2246        1.2465         -0.0231     0.8135    0.0241\n#&gt; x5              1.2874        1.2614          0.0260     1.0968    0.0121\n#&gt; x6              1.2896        1.3208         -0.0336     0.9959    0.0120\n#&gt;          eCDF Max Std. Pair Dist.\n#&gt; distance   0.0129          0.0076\n#&gt; x1         0.0668          1.2125\n#&gt; x2         0.0771          1.2002\n#&gt; x3         0.0386          1.0269\n#&gt; x4         0.0566          0.9933\n#&gt; x5         0.0540          0.6018\n#&gt; x6         0.0488          0.6997\n#&gt; \n#&gt; Sample Sizes:\n#&gt;               Control Treated\n#&gt; All            611.       389\n#&gt; Matched (ESS)  167.21     389\n#&gt; Matched        229.       389\n#&gt; Unmatched      382.         0\n#&gt; Discarded        0.         0\n\n\nラブプロットという図を書いてすべてが0.1以下になるように， 共変量や高次項などを調整していく. ラブプロットを記述するライブラリも存在しているが，ここでは スクラッチで実装する．これは後に再利用するためである．\n\n\nCode\ndiffa &lt;- abs(summary(m.out1)$sum.all[,3])\ndiffb &lt;- abs(summary(m.out1)$sum.matched[,3])\ndiff1 &lt;- rev(diffa)\ndiff2 &lt;- rev(diffb)\n\nmaxx    &lt;- max(diff1, diff2)\nlabels0 &lt;- rownames(summary(m.out1)$sum.all)\nlabels1 &lt;- rev(labels0)\n\ndotchart(diff1, xlim = c(0, maxx), labels = c(labels1))\nabline(v = .0, col = 8)\nabline(v = .1, col = 8)\nabline(v = .05, lty = 2, col = 8)\n\npar(new = TRUE)\ndotchart(diff2, xlim = c(0, maxx), labels = c(labels1), \n         pch = 16, xlab = \"Absolute Standardized Mean Difference\")"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/113_操作変数法の基礎.html",
    "href": "contents/books/05_統計的因果推論の理論と実際/113_操作変数法の基礎.html",
    "title": "操作変数法の基礎",
    "section": "",
    "text": "これまでは共変量を調整することで交絡を無視することが出来た． 操作変数法では一定の仮定のもとで共変量による調整が出来ない場合， 効かない場合でも信頼のおける因果推論手法となる.\n操作変数法は，二段階最小二乗法，同時方程式モデリング，内生成とったキーワードでも 取り扱われている．\n\n\n\\(Y\\)を結果変数，\\(X\\)が観測さえれる共変量, \\(U\\)を観測されない共変量，とするときこれらの変数の関係は 次の図で表される構造を想定する. この構造において\\(X\\)から\\(Y\\)への効果を推定したいとする.\nなおこの構造は\\(U-&gt;X-&gt;Y\\)という部分で\\(U\\)が交絡しており， \\(X-&gt;U-&gt;Y\\)という原因\\(X\\)の中間変数\\(U\\)があるわけでないことに注意する. この構造は「アイスの売り上げと水難事故の相関における気温」にあたる．\n\n\nCode\ngrViz(\"\ndigraph dot {\n\ngraph [layout = dot, rankdir = TR]\n\nnode [shape = circle,\n      style = filled,\n      color = grey]\n    Y X U\n\nedge [color = black]\n    U -&gt; {Y X}\n    X -&gt; {Y}\n{rank = max; X; Y}\n\n}\")\n\n\n\n\n\n\nモデル式としては次となる. もし\\(U\\)が観測されるならば， これまでと同じように\\(U\\)をモデルに加えることで， 共分散分析や傾向スコアモデリングにより交絡を取り除くことが出来る． (\\(U\\)で\\(Y\\)と\\(X\\)を条件づけることで適切な解析が行える)\n\\[\nY= \\beta_0 + \\beta_1X + \\beta_2U + \\epsilon\n\\] しかし，ここでは\\(U\\)は観測されない共変量であることしており， 除外変数による偏りが不可避に発生しそうである． このような状況に対して観測できる共変量\\(Z\\)があり次のような構造にあると考える.\n\n\nCode\ngrViz(\"\ndigraph dot {\n\ngraph [layout = dot, rankdir = TR]\n\nnode [shape = circle,\n      style = filled,\n      color = grey]\n    Y X U Z\n\nedge [color = black]\n    U -&gt; {Y X}\n    X -&gt; {Y}\n    Z -&gt; {X}\n{rank = max; X; Y; Z}\n\n}\")\n\n\n\n\n\n\nこのような\\(U\\)に依存しておらず\\(X\\)に影響を与える変数を操作変数と呼ぶ. 操作変数を利用することで観測できない交絡因子\\(U\\)の影響を除いた， \\(X\\)から\\(Y\\)への影響を推定することが出来る.\n\n\n\n内生変数とはモデルの依存関係によって解の定まる変数である． 外生変数とは，モデルの依存関係によらず値が決まる変数である.\n結果変数と中間変数は内生変数である．共変量は外生変数である． 処理の割り付けが無作為でおこなわれているならば処置変数は外生変数である． しかし観察研究では処置変数は内生変数である\n\n\n\n結局のところ操作変数として適切な変数を見つけることは容易でない． 「結局は操作変数が解析者による何らかの介入や突発的な災害や事故の前後といった 変数以外では操作変数法の解析結果はあまり信頼されていない」と言われてる．"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/113_操作変数法の基礎.html#操作変数法のイメージ",
    "href": "contents/books/05_統計的因果推論の理論と実際/113_操作変数法の基礎.html#操作変数法のイメージ",
    "title": "操作変数法の基礎",
    "section": "",
    "text": "\\(Y\\)を結果変数，\\(X\\)が観測さえれる共変量, \\(U\\)を観測されない共変量，とするときこれらの変数の関係は 次の図で表される構造を想定する. この構造において\\(X\\)から\\(Y\\)への効果を推定したいとする.\nなおこの構造は\\(U-&gt;X-&gt;Y\\)という部分で\\(U\\)が交絡しており， \\(X-&gt;U-&gt;Y\\)という原因\\(X\\)の中間変数\\(U\\)があるわけでないことに注意する. この構造は「アイスの売り上げと水難事故の相関における気温」にあたる．\n\n\nCode\ngrViz(\"\ndigraph dot {\n\ngraph [layout = dot, rankdir = TR]\n\nnode [shape = circle,\n      style = filled,\n      color = grey]\n    Y X U\n\nedge [color = black]\n    U -&gt; {Y X}\n    X -&gt; {Y}\n{rank = max; X; Y}\n\n}\")\n\n\n\n\n\n\nモデル式としては次となる. もし\\(U\\)が観測されるならば， これまでと同じように\\(U\\)をモデルに加えることで， 共分散分析や傾向スコアモデリングにより交絡を取り除くことが出来る． (\\(U\\)で\\(Y\\)と\\(X\\)を条件づけることで適切な解析が行える)\n\\[\nY= \\beta_0 + \\beta_1X + \\beta_2U + \\epsilon\n\\] しかし，ここでは\\(U\\)は観測されない共変量であることしており， 除外変数による偏りが不可避に発生しそうである． このような状況に対して観測できる共変量\\(Z\\)があり次のような構造にあると考える.\n\n\nCode\ngrViz(\"\ndigraph dot {\n\ngraph [layout = dot, rankdir = TR]\n\nnode [shape = circle,\n      style = filled,\n      color = grey]\n    Y X U Z\n\nedge [color = black]\n    U -&gt; {Y X}\n    X -&gt; {Y}\n    Z -&gt; {X}\n{rank = max; X; Y; Z}\n\n}\")\n\n\n\n\n\n\nこのような\\(U\\)に依存しておらず\\(X\\)に影響を与える変数を操作変数と呼ぶ. 操作変数を利用することで観測できない交絡因子\\(U\\)の影響を除いた， \\(X\\)から\\(Y\\)への影響を推定することが出来る."
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/113_操作変数法の基礎.html#内生変数と外生変数",
    "href": "contents/books/05_統計的因果推論の理論と実際/113_操作変数法の基礎.html#内生変数と外生変数",
    "title": "操作変数法の基礎",
    "section": "",
    "text": "内生変数とはモデルの依存関係によって解の定まる変数である． 外生変数とは，モデルの依存関係によらず値が決まる変数である.\n結果変数と中間変数は内生変数である．共変量は外生変数である． 処理の割り付けが無作為でおこなわれているならば処置変数は外生変数である． しかし観察研究では処置変数は内生変数である"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/113_操作変数法の基礎.html#よくない操作変数",
    "href": "contents/books/05_統計的因果推論の理論と実際/113_操作変数法の基礎.html#よくない操作変数",
    "title": "操作変数法の基礎",
    "section": "",
    "text": "結局のところ操作変数として適切な変数を見つけることは容易でない． 「結局は操作変数が解析者による何らかの介入や突発的な災害や事故の前後といった 変数以外では操作変数法の解析結果はあまり信頼されていない」と言われてる．"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/115_回帰不連続デザインの基礎.html",
    "href": "contents/books/05_統計的因果推論の理論と実際/115_回帰不連続デザインの基礎.html",
    "title": "回帰不連続デザイン",
    "section": "",
    "text": "傾向スコアでは処置群と統制群の間で重なりがあると仮定している． これは処理の割り付けが確率的である場合であることを意味する． 処理の割り付けが確定的な場合，たとえば入学試験で60以下の場合に受ける補習講義の ような場合にはその効果を傾向スコアで測ることは出来ない．\n回帰不連続デザインはこの場合に使える準実験である． つまり，同じグループ内で全員が一斉に何らかの介入を受けている状況を想定している． ある条件を満たしたときの介入がない状況と， ある状況を満たしていないときの介入がない状況に関する情報がない．\n血圧が高い人に処方する薬があるとする．このとき， ナイーブに推定すると薬を処方されると血圧が高まるという結果になってしまう． これは血圧が高いが薬が処方されていない人がいないという，交絡による．\n\n\nひとことでいうと，共分散分析をおこなうと外挿することになる． 血圧が高いが薬が処方されていない人については， 薬が処方されていない人から推定することになる. 共分散分析による外挿モデルでは，線形モデルを仮定することになるが， 線形モデルの妥当性に関する情報はデータから得ることが出来ない．\n\n\n\n上記の話しは「外挿は必要」であるが「外挿をしたくない」という話しである． そこでデータ全体における平均処置効果であるATEの推定を諦めて， 閾値\\(c\\)前後のみで比較することを考える.\n\\[\nE[Y_i(1)-Y_i(0)|X_i=c]=E[Y_i(1)|X_i=c]-E[Y_i(0)|X_i=c]\n\\]\n式の意味で言えば，別々に回帰モデルをつくって説明変数が\\(c\\)のときの値を比較する， という流れになる． 実際には\\(c\\pm h\\)の範囲を抽出して共分散分析をおこなうことになる．"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/115_回帰不連続デザインの基礎.html#平均処置効果と共分散分析",
    "href": "contents/books/05_統計的因果推論の理論と実際/115_回帰不連続デザインの基礎.html#平均処置効果と共分散分析",
    "title": "回帰不連続デザイン",
    "section": "",
    "text": "ひとことでいうと，共分散分析をおこなうと外挿することになる． 血圧が高いが薬が処方されていない人については， 薬が処方されていない人から推定することになる. 共分散分析による外挿モデルでは，線形モデルを仮定することになるが， 線形モデルの妥当性に関する情報はデータから得ることが出来ない．"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/115_回帰不連続デザインの基礎.html#閾値における局所的な平均処置効果",
    "href": "contents/books/05_統計的因果推論の理論と実際/115_回帰不連続デザインの基礎.html#閾値における局所的な平均処置効果",
    "title": "回帰不連続デザイン",
    "section": "",
    "text": "上記の話しは「外挿は必要」であるが「外挿をしたくない」という話しである． そこでデータ全体における平均処置効果であるATEの推定を諦めて， 閾値\\(c\\)前後のみで比較することを考える.\n\\[\nE[Y_i(1)-Y_i(0)|X_i=c]=E[Y_i(1)|X_i=c]-E[Y_i(0)|X_i=c]\n\\]\n式の意味で言えば，別々に回帰モデルをつくって説明変数が\\(c\\)のときの値を比較する， という流れになる． 実際には\\(c\\pm h\\)の範囲を抽出して共分散分析をおこなうことになる．"
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/index.html",
    "href": "contents/books/05_統計的因果推論の理論と実際/index.html",
    "title": "統計的因果推論の理論と実際",
    "section": "",
    "text": "本稿は共立出版の統計的因果推論の理論と実装に関する勉強ノートです. レベルとしては大学レベルの入門統計学を学習したものとされています. 正誤表があるので内容には注意して読むこと．\n\n\n\n\n\n前半部分の回帰分析までは理解できたと思うが， 特に回帰不連続デザインの実装部分からよくわかっていないので， 改めて勉強する必要がある．\nまずは処置群の平均処置効果を知りたいときには 「傾向スコアマッチング」をおこない， 平均処置効果を知りたい場合には「傾向スコアからの層別解析」を おこなうことを知っておくことが重要となる． 共分散分析，傾向スコア，操作変数法，回帰不連続デザインなどは 基本的な考え方はわかった． いずれにしてもデータといかに向き合うのかは重要と言える."
  },
  {
    "objectID": "contents/books/05_統計的因果推論の理論と実際/index.html#概要",
    "href": "contents/books/05_統計的因果推論の理論と実際/index.html#概要",
    "title": "統計的因果推論の理論と実際",
    "section": "",
    "text": "本稿は共立出版の統計的因果推論の理論と実装に関する勉強ノートです. レベルとしては大学レベルの入門統計学を学習したものとされています. 正誤表があるので内容には注意して読むこと．\n\n\n\n\n\n前半部分の回帰分析までは理解できたと思うが， 特に回帰不連続デザインの実装部分からよくわかっていないので， 改めて勉強する必要がある．\nまずは処置群の平均処置効果を知りたいときには 「傾向スコアマッチング」をおこない， 平均処置効果を知りたい場合には「傾向スコアからの層別解析」を おこなうことを知っておくことが重要となる． 共分散分析，傾向スコア，操作変数法，回帰不連続デザインなどは 基本的な考え方はわかった． いずれにしてもデータといかに向き合うのかは重要と言える."
  },
  {
    "objectID": "contents/utils/01_写真GPS/index.html",
    "href": "contents/utils/01_写真GPS/index.html",
    "title": "写真データのGISデータ化",
    "section": "",
    "text": "1 はじめに\niPhoneをはじめとしたスマートフォンで写真を撮ると位置情報が付与されている。 また、ミラーレス一眼レフカメラでもスマートフォンと連携して位置情報が付与される。 現場調査において位置情報というのは非常に重要な情報である。\nここでは、写真データに付与された位置情報をGISデータに変換する方法を紹介する。\n\n\n2 やり方\n大きく４つのステップに分かれている。\n\nJPEGへの変換\nJPEGから位置情報をCSVで出力する\nCSVをGeoJSONに変換する\n画像をサムネイル化する\n\n# convert HEIC to jpg\nmogrify -format jpg *.HEIC\n\n# extract gps coordates from jpgs to output.csv\nexiftool -gpslatitude -gpslongitude -n -csv *.jpg &gt; output.csv\n\n# convert output.csv to geojson\nogr2ogr -f \"GeoJSON\" output.geojson output.csv -oo X_POSSIBLE_NAMES=gpslongitude  -oo Y_POSSIBLE_NAMES=gpslatitude -oo KEEP_GEOM_COLUMNS=NO\n\n# create thumbnails\nmkdir -p thumbnails\nfor file in *.jpg; do \n    filename=$(basename \"$file\")\n    convert \"$file\" -thumbnail 200x \"thumbnails/$filename\"\ndone\nここまで為ておくことで、写真データを地図上に表示することができるようになる。 WebGISはもちろんであるがQGISでも可能である。たとえば、次をTipsに設定することで閲覧が可能となる。 これはプロジェクトフォルダーからの相対パスでファイルを指定している。ファイル名自体はSourceFileという名前の属性で保存されている。\n&lt;a href=\"file:///[% @project_folder %]/../../../09_写真/20231120-21_SiteVisit_Dulkadioglu/suzuki/[% SourceFile %]\"&gt;\n&lt;img src=\"file:///[% @project_folder %]/../../../09_写真/20231120-21_SiteVisit_Dulkadioglu/suzuki/[% SourceFile %]\" alt=\"hoge\" width=\"300\"&gt;\n&lt;/a&gt;\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/test/R/renv.html",
    "href": "contents/test/R/renv.html",
    "title": "renv",
    "section": "",
    "text": "1 renvはどのように指定すればいいか\n\nプロジェクトファイルがあるフォルダで指定するときはそのフォルダになる\nプロジェクトファイルがないフォルダで指定するときはルートフォルダになる\n正確には１番近い親フォルダになっているみたい\nなのでこの場合のhereの挙動には注意する\n\n\n\nCode\nhere::here()\n#&gt; [1] \"H:/Dropbox/R/Workspace/RTipsSite/contents/test/R\"\ncur_dir &lt;- here::here(\"contents\", \"test\", \"R\")\nprint(cur_dir)\n#&gt; [1] \"H:/Dropbox/R/Workspace/RTipsSite/contents/test/R/contents/test/R\"\n# renv::init(cur_dir)\n\nprint(getwd())\n#&gt; [1] \"H:/Dropbox/R/Workspace/RTipsSite/contents/test/R\"\nprint(here::here())\n#&gt; [1] \"H:/Dropbox/R/Workspace/RTipsSite/contents/test/R\"\n\n\n\n\nCode\nrenv::activate()\n\n\n\n\nCode\nprint(getwd())\n#&gt; [1] \"H:/Dropbox/R/Workspace/RTipsSite/contents/test/R\"\nprint(here::here())\n#&gt; [1] \"H:/Dropbox/R/Workspace/RTipsSite/contents/test/R\"\nprint(cur_dir)\n#&gt; [1] \"H:/Dropbox/R/Workspace/RTipsSite/contents/test/R/contents/test/R\"\n\n\n\n\nCode\nlibrary(here)\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/test/bash/run_gdal.html",
    "href": "contents/test/bash/run_gdal.html",
    "title": "GDAL",
    "section": "",
    "text": "1 はじめに\n\ngdalを走らせられるかどうか\n日本語のパスでも問題なく動くには動くことがわかる\n\n\n\n2 works\n\n\nCode\ngdalinfo --version\n#&gt; GDAL 3.4.3, released 2022/04/22\n\n\n\n\nCode\ngdalinfo ./日本語フォルダ/stacking.tif\n#&gt; Driver: GTiff/GeoTIFF\n#&gt; Files: ./日本語フォルダ/stacking.tif\n#&gt; Size is 316, 192\n#&gt; Coordinate System is:\n#&gt; GEOGCRS[\"JGD2000\",\n#&gt;     DATUM[\"Japanese Geodetic Datum 2000\",\n#&gt;         ELLIPSOID[\"GRS 1980\",6378137,298.257222101004,\n#&gt;             LENGTHUNIT[\"metre\",1]],\n#&gt;         ID[\"EPSG\",6612]],\n#&gt;     PRIMEM[\"Greenwich\",0,\n#&gt;         ANGLEUNIT[\"degree\",0.0174532925199433,\n#&gt;             ID[\"EPSG\",9122]]],\n#&gt;     CS[ellipsoidal,2],\n#&gt;         AXIS[\"latitude\",north,\n#&gt;             ORDER[1],\n#&gt;             ANGLEUNIT[\"degree\",0.0174532925199433,\n#&gt;                 ID[\"EPSG\",9122]]],\n#&gt;         AXIS[\"longitude\",east,\n#&gt;             ORDER[2],\n#&gt;             ANGLEUNIT[\"degree\",0.0174532925199433,\n#&gt;                 ID[\"EPSG\",9122]]]]\n#&gt; Data axis to CRS axis mapping: 2,1\n#&gt; Origin = (138.937500000000000,35.899999999999999)\n#&gt; Pixel Size = (0.003125000000000,-0.002083333000000)\n#&gt; Metadata:\n#&gt;   AREA_OR_POINT=Area\n#&gt; Image Structure Metadata:\n#&gt;   COMPRESSION=LZW\n#&gt;   INTERLEAVE=PIXEL\n#&gt; Corner Coordinates:\n#&gt; Upper Left  ( 138.9375000,  35.9000000) (138d56'15.00\"E, 35d54' 0.00\"N)\n#&gt; Lower Left  ( 138.9375000,  35.5000001) (138d56'15.00\"E, 35d30' 0.00\"N)\n#&gt; Upper Right ( 139.9250000,  35.9000000) (139d55'30.00\"E, 35d54' 0.00\"N)\n#&gt; Lower Right ( 139.9250000,  35.5000001) (139d55'30.00\"E, 35d30' 0.00\"N)\n#&gt; Center      ( 139.4312500,  35.7000000) (139d25'52.50\"E, 35d42' 0.00\"N)\n#&gt; Band 1 Block=316x1 Type=Float64, ColorInterp=Gray\n#&gt;   NoData Value=0\n#&gt; Band 2 Block=316x1 Type=Float64, ColorInterp=Undefined\n#&gt;   NoData Value=0\n#&gt; Band 3 Block=316x1 Type=Float64, ColorInterp=Undefined\n#&gt;   NoData Value=0\n#&gt; Band 4 Block=316x1 Type=Float64, ColorInterp=Undefined\n#&gt;   NoData Value=0\n#&gt; Band 5 Block=316x1 Type=Float64, ColorInterp=Undefined\n#&gt;   NoData Value=0\n#&gt; Band 6 Block=316x1 Type=Float64, ColorInterp=Undefined\n#&gt;   NoData Value=0\n#&gt; Band 7 Block=316x1 Type=Float64, ColorInterp=Undefined\n#&gt;   NoData Value=0\n#&gt; Band 8 Block=316x1 Type=Float64, ColorInterp=Undefined\n#&gt;   NoData Value=0\n#&gt; Band 9 Block=316x1 Type=Float64, ColorInterp=Undefined\n#&gt;   NoData Value=0\n#&gt; Band 10 Block=316x1 Type=Float64, ColorInterp=Undefined\n#&gt;   NoData Value=0\n#&gt; Band 11 Block=316x1 Type=Float64, ColorInterp=Undefined\n#&gt;   NoData Value=0\n#&gt; Band 12 Block=316x1 Type=Float64, ColorInterp=Undefined\n#&gt;   NoData Value=0\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/sql/ap-test/index.html",
    "href": "contents/sql/ap-test/index.html",
    "title": "応用情報処理試験",
    "section": "",
    "text": "Code\nrenv::activate(here::here())\ncur_dir &lt;- here::here(\"contents/sql/ap-test\")\nCode\nlibrary(ggplot2)\nlibrary(duckdb)\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(DBI)\nlibrary(dbplyr)\nlibrary(arrow)\nlibrary(showtext)\nshowtext_auto()\nfont_add_google(\"Noto Sans\")"
  },
  {
    "objectID": "contents/sql/ap-test/index.html#セットアップ",
    "href": "contents/sql/ap-test/index.html#セットアップ",
    "title": "応用情報処理試験",
    "section": "2.1 セットアップ",
    "text": "2.1 セットアップ\n\n\nCode\nCREATE OR REPLACE TABLE 社員\n(\n    支社番号 INTEGER NOT NULL,\n    番号 INTEGER PRIMARY KEY,\n    名前 VARCHAR(100) NULL,\n    性別 VARCHAR(10) NULL,\n    住所 TEXT NULL,\n    部署 INTEGER NULL \n);\n\n\nCREATE OR REPLACE SEQUENCE seq_number START 1;\nINSERT INTO 社員 (支社番号, 番号, 名前, 性別, 住所, 部署) VALUES (1, nextval('seq_number'), '石田', '男', '◯◯◯◯', 1);\nINSERT INTO 社員 (支社番号, 番号, 名前, 性別, 住所, 部署) VALUES (1, nextval('seq_number'), '田中', '女', '△△△△', 1);\nINSERT INTO 社員 (支社番号, 番号, 名前, 性別, 住所, 部署) VALUES (1, nextval('seq_number'), '山田', '男', 'あいうえ', 2);\nINSERT INTO 社員 (支社番号, 番号, 名前, 性別, 住所, 部署) VALUES (2, nextval('seq_number'), '高橋', '女', '◯◯◯◯', 2);\nINSERT INTO 社員 (支社番号, 番号, 名前, 性別, 住所, 部署) VALUES (2, nextval('seq_number'), '鈴木', '男', '■■■■', 2);\nINSERT INTO 社員 (支社番号, 番号, 名前, 性別, 住所, 部署) VALUES (2, nextval('seq_number'), '木村', '女', '◯◯◯◯', 8); -- 部署8は存在しないので注意\nINSERT INTO 社員 (支社番号, 番号, 名前, 性別, 住所, 部署) VALUES (2, nextval('seq_number'), '佐藤', '男', '◇◇◇◇', 3);\nINSERT INTO 社員 (支社番号, 番号, 名前, 性別, 住所, 部署) VALUES (3, nextval('seq_number'), '大田', '男', '◯◯◯◯', 3);\nINSERT INTO 社員 (支社番号, 番号, 名前, 性別, 住所, 部署) VALUES (3, nextval('seq_number'), '今村', '男', '☆☆☆☆', 3);\n\n\nCREATE OR REPLACE TABLE 部署\n(\n    番号 INTEGER PRIMARY KEY NOT NULL,\n    名前 VARCHAR(100) NULL,\n    部長 INTEGER REFERENCES 社員 (番号) -- 外部キー\n);\n\nINSERT INTO 部署 (番号, 名前, 部長) VALUES (1, '社長室', 1);\nINSERT INTO 部署 (番号, 名前, 部長) VALUES (2, '営業部', 5);\nINSERT INTO 部署 (番号, 名前, 部長) VALUES (3, '開発部', 7);\nINSERT INTO 部署 (番号, 名前, 部長) VALUES (7, '経理部', 9);\nINSERT INTO 部署 (番号, 名前, 部長) VALUES (8, '秘書室', 9);\n\n\n\n\nCode\nSELECT * FROM 部署 WHERE 番号 BETWEEN 1 AND 5;\n\n\n\n3 records\n\n\n番号\n名前\n部長\n\n\n\n\n1\n社長室\n1\n\n\n2\n営業部\n5\n\n\n3\n開発部\n7\n\n\n\n\n\n\n\nCode\nSELECT * FROM 部署 WHERE 名前 LIKE '%室'\n\n\n\n2 records\n\n\n番号\n名前\n部長\n\n\n\n\n1\n社長室\n1\n\n\n8\n秘書室\n9\n\n\n\n\n\n\n\nCode\nSELECT * FROM 社員 s  \nINNER JOIN 部署 t\nON s.部署 = t.番号\n\n\n\n9 records\n\n\n支社番号\n番号\n名前\n性別\n住所\n部署\n番号\n名前\n部長\n\n\n\n\n1\n1\n石田\n男\n◯◯◯◯\n1\n1\n社長室\n1\n\n\n1\n2\n田中\n女\n△△△△\n1\n1\n社長室\n1\n\n\n1\n3\n山田\n男\nあいうえ\n2\n2\n営業部\n5\n\n\n2\n4\n高橋\n女\n◯◯◯◯\n2\n2\n営業部\n5\n\n\n2\n5\n鈴木\n男\n■■■■\n2\n2\n営業部\n5\n\n\n2\n6\n木村\n女\n◯◯◯◯\n8\n8\n秘書室\n9\n\n\n2\n7\n佐藤\n男\n◇◇◇◇\n3\n3\n開発部\n7\n\n\n3\n8\n大田\n男\n◯◯◯◯\n3\n3\n開発部\n7\n\n\n3\n9\n今村\n男\n☆☆☆☆\n3\n3\n開発部\n7\n\n\n\n\n\n\n\nCode\nSELECT * FROM 社員 s  \nLEFT OUTER JOIN 部署 t\nON s.部署 = t.番号\n\n\n\n9 records\n\n\n支社番号\n番号\n名前\n性別\n住所\n部署\n番号\n名前\n部長\n\n\n\n\n1\n1\n石田\n男\n◯◯◯◯\n1\n1\n社長室\n1\n\n\n1\n2\n田中\n女\n△△△△\n1\n1\n社長室\n1\n\n\n1\n3\n山田\n男\nあいうえ\n2\n2\n営業部\n5\n\n\n2\n4\n高橋\n女\n◯◯◯◯\n2\n2\n営業部\n5\n\n\n2\n5\n鈴木\n男\n■■■■\n2\n2\n営業部\n5\n\n\n2\n6\n木村\n女\n◯◯◯◯\n8\n8\n秘書室\n9\n\n\n2\n7\n佐藤\n男\n◇◇◇◇\n3\n3\n開発部\n7\n\n\n3\n8\n大田\n男\n◯◯◯◯\n3\n3\n開発部\n7\n\n\n3\n9\n今村\n男\n☆☆☆☆\n3\n3\n開発部\n7\n\n\n\n\n\n\n\nCode\nSELECT * FROM 社員 s  \nRIGHT OUTER JOIN 部署 t\nON s.部署 = t.番号\n\n\n\nDisplaying records 1 - 10\n\n\n支社番号\n番号\n名前\n性別\n住所\n部署\n番号\n名前\n部長\n\n\n\n\n1\n2\n田中\n女\n△△△△\n1\n1\n社長室\n1\n\n\n2\n5\n鈴木\n男\n■■■■\n2\n2\n営業部\n5\n\n\n3\n9\n今村\n男\n☆☆☆☆\n3\n3\n開発部\n7\n\n\n2\n6\n木村\n女\n◯◯◯◯\n8\n8\n秘書室\n9\n\n\n1\n1\n石田\n男\n◯◯◯◯\n1\n1\n社長室\n1\n\n\n2\n4\n高橋\n女\n◯◯◯◯\n2\n2\n営業部\n5\n\n\n3\n8\n大田\n男\n◯◯◯◯\n3\n3\n開発部\n7\n\n\n1\n3\n山田\n男\nあいうえ\n2\n2\n営業部\n5\n\n\n2\n7\n佐藤\n男\n◇◇◇◇\n3\n3\n開発部\n7\n\n\nNA\nNA\nNA\nNA\nNA\nNA\n7\n経理部\n9\n\n\n\n\n\n\n\nCode\nSELECT * FROM 社員 s  \nJOIN 部署 t\nON s.部署 = t.番号\n\n\n\n9 records\n\n\n支社番号\n番号\n名前\n性別\n住所\n部署\n番号\n名前\n部長\n\n\n\n\n1\n1\n石田\n男\n◯◯◯◯\n1\n1\n社長室\n1\n\n\n1\n2\n田中\n女\n△△△△\n1\n1\n社長室\n1\n\n\n1\n3\n山田\n男\nあいうえ\n2\n2\n営業部\n5\n\n\n2\n4\n高橋\n女\n◯◯◯◯\n2\n2\n営業部\n5\n\n\n2\n5\n鈴木\n男\n■■■■\n2\n2\n営業部\n5\n\n\n2\n6\n木村\n女\n◯◯◯◯\n8\n8\n秘書室\n9\n\n\n2\n7\n佐藤\n男\n◇◇◇◇\n3\n3\n開発部\n7\n\n\n3\n8\n大田\n男\n◯◯◯◯\n3\n3\n開発部\n7\n\n\n3\n9\n今村\n男\n☆☆☆☆\n3\n3\n開発部\n7\n\n\n\n\n\n\n\nCode\nSELECT * FROM 社員 s, 部署 t\n\n\n\nDisplaying records 1 - 10\n\n\n支社番号\n番号\n名前\n性別\n住所\n部署\n番号\n名前\n部長\n\n\n\n\n1\n1\n石田\n男\n◯◯◯◯\n1\n1\n社長室\n1\n\n\n1\n2\n田中\n女\n△△△△\n1\n1\n社長室\n1\n\n\n1\n3\n山田\n男\nあいうえ\n2\n1\n社長室\n1\n\n\n2\n4\n高橋\n女\n◯◯◯◯\n2\n1\n社長室\n1\n\n\n2\n5\n鈴木\n男\n■■■■\n2\n1\n社長室\n1\n\n\n2\n6\n木村\n女\n◯◯◯◯\n8\n1\n社長室\n1\n\n\n2\n7\n佐藤\n男\n◇◇◇◇\n3\n1\n社長室\n1\n\n\n3\n8\n大田\n男\n◯◯◯◯\n3\n1\n社長室\n1\n\n\n3\n9\n今村\n男\n☆☆☆☆\n3\n1\n社長室\n1\n\n\n1\n1\n石田\n男\n◯◯◯◯\n1\n2\n営業部\n5\n\n\n\n\n\n\n\nCode\nSELECT * FROM 部署 WHERE 名前 IN (SELECT 名前 FROM 部署 WHERE 名前 = '社長室')\n\n\n\n1 records\n\n\n番号\n名前\n部長\n\n\n\n\n1\n社長室\n1\n\n\n\n\n\n\n\nCode\nSELECT * FROM 部署 WHERE 名前 IN (SELECT 名前 FROM 部署 WHERE 名前 LIKE '%室')\n\n\n\n2 records\n\n\n番号\n名前\n部長\n\n\n\n\n1\n社長室\n1\n\n\n8\n秘書室\n9\n\n\n\n\n\nEXISTSを使うと条件となるテーブルが存在するかしないかを条件として、SELECTを制御することが可能である。\n\n\nCode\nSELECT * FROM 部署 WHERE EXISTS (SELECT 名前 FROM 部署 WHERE 名前 LIKE '%室')\n\n\n\n5 records\n\n\n番号\n名前\n部長\n\n\n\n\n1\n社長室\n1\n\n\n2\n営業部\n5\n\n\n3\n開発部\n7\n\n\n7\n経理部\n9\n\n\n8\n秘書室\n9\n\n\n\n\n\nこれは実はフィルターになっている。 つまり、EXISTSでおこなったフィルタが外のクエリのフィルターになっている。\n\n\nCode\nSELECT * FROM 部署 WHERE EXISTS (SELECT 1 FROM 部署 WHERE 名前 LIKE '%室')\n\n\n\n5 records\n\n\n番号\n名前\n部長\n\n\n\n\n1\n社長室\n1\n\n\n2\n営業部\n5\n\n\n3\n開発部\n7\n\n\n7\n経理部\n9\n\n\n8\n秘書室\n9\n\n\n\n\n\n\n\nCode\nSELECT * FROM 部署 USING SAMPLE 5;\n\n\n\n5 records\n\n\n番号\n名前\n部長\n\n\n\n\n1\n社長室\n1\n\n\n2\n営業部\n5\n\n\n3\n開発部\n7\n\n\n7\n経理部\n9\n\n\n8\n秘書室\n9\n\n\n\n\n\n\n\nCode\nSELECT * FROM range(2) t1(x)\nUNION\nSELECT * FROM range(3) t2(x);\n\n\n\n3 records\n\n\nx\n\n\n\n\n1\n\n\n0\n\n\n2\n\n\n\n\n\n\n\nCode\nCREATE OR REPLACE TABLE 社員2 (\n    社員番号 INTEGER PRIMARY KEY,\n    年齢 INTEGER,\n    性別 VARCHAR(10),\n    CONSTRAINT 年齢チェック CHECK (年齢 &gt;= 18), \n    CONSTRAINT 年齢チェック CHECK (性別 IN ('男', '女')), \n);"
  },
  {
    "objectID": "contents/sql/ap-test/index.html#部署",
    "href": "contents/sql/ap-test/index.html#部署",
    "title": "応用情報処理試験",
    "section": "2.2 部署",
    "text": "2.2 部署"
  },
  {
    "objectID": "contents/sql/duckdb/documentaion/guide_01_data_import_export.html",
    "href": "contents/sql/duckdb/documentaion/guide_01_data_import_export.html",
    "title": "Data Import & Export",
    "section": "",
    "text": "Code\nrenv::activate(here::here())\ncur_dir &lt;- here::here(\"contents/sql/duckdb/documentation\")\nCode\nlibrary(ggplot2)\nlibrary(duckdb)\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(DBI)\nlibrary(dbplyr)\nlibrary(arrow)\nlibrary(showtext)\nshowtext_auto()\nfont_add_google(\"Noto Sans\")"
  },
  {
    "objectID": "contents/sql/duckdb/documentaion/guide_01_data_import_export.html#prerequisites",
    "href": "contents/sql/duckdb/documentaion/guide_01_data_import_export.html#prerequisites",
    "title": "Data Import & Export",
    "section": "7.1 Prerequisites",
    "text": "7.1 Prerequisites\n#| connection: con\nINSTALL httpfs;\nLOAD httpfs;"
  },
  {
    "objectID": "contents/sql/duckdb/documentaion/guide_01_data_import_export.html#credentials-and-configuration",
    "href": "contents/sql/duckdb/documentaion/guide_01_data_import_export.html#credentials-and-configuration",
    "title": "Data Import & Export",
    "section": "7.2 Credentials and Configuration",
    "text": "7.2 Credentials and Configuration\n#| connection: con\nCREATE SECRET (\n    TYPE S3,\n    KEY_ID 'AKIAIOSFODNN7EXAMPLE',\n    SECRET 'wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY',\n    REGION 'us-east-1'\n);"
  },
  {
    "objectID": "contents/sql/duckdb/documentaion/guide_01_data_import_export.html#querying",
    "href": "contents/sql/duckdb/documentaion/guide_01_data_import_export.html#querying",
    "title": "Data Import & Export",
    "section": "7.3 Querying",
    "text": "7.3 Querying\n#| connection: con\nSELECT * FROM read_parquet('s3://⟨bucket⟩/⟨file⟩');"
  },
  {
    "objectID": "contents/sql/duckdb/documentaion/guide_04_sql.html",
    "href": "contents/sql/duckdb/documentaion/guide_04_sql.html",
    "title": "SQL",
    "section": "",
    "text": "Code\nrenv::activate(here::here())\ncur_dir &lt;- here::here(\"contents/sql/duckdb/documentation\")\nCode\nlibrary(ggplot2)\nlibrary(duckdb)\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(DBI)\nlibrary(dbplyr)\nlibrary(arrow)\nlibrary(showtext)\nshowtext_auto()\nfont_add_google(\"Noto Sans\")\nポスグレのチュートリアルを参考としたSQLのチュートリアルである。"
  },
  {
    "objectID": "contents/sql/duckdb/documentaion/guide_04_sql.html#populating-a-table-with-rows",
    "href": "contents/sql/duckdb/documentaion/guide_04_sql.html#populating-a-table-with-rows",
    "title": "SQL",
    "section": "2.1 Populating a Table with Rows",
    "text": "2.1 Populating a Table with Rows\nINSERTは行単位でデータを追加するときに使われる。\nINSERT INTO weather\nVALUES ('San Francisco', 46, 50, 0.25, '1994-11-27');\n数値でないときにはシングルクォーテションで値をかこむ必要がある。\nINSERT INTO weather\nVALUES ('San Francisco', 46, 50, 0.25, '1994-11-27');\nインサートするときにカラムの順序は異なっていても大丈夫である。\nINSERT INTO weather (date, city, temp_hi, temp_lo)\nVALUES ('1994-11-29', 'Hayward', 54, 37);\n\nMany developers consider explicitly listing the columns better style than relying on the order implicitly.\n\nバルクロードするときにはCOPYを使うことでより高速になる。\nCOPY weather\nFROM 'weather.csv'"
  },
  {
    "objectID": "contents/sql/duckdb/documentaion/guide_04_sql.html#querying-a-table",
    "href": "contents/sql/duckdb/documentaion/guide_04_sql.html#querying-a-table",
    "title": "SQL",
    "section": "2.2 Querying a Table",
    "text": "2.2 Querying a Table\n\n\nCode\nCREATE OR REPLACE TABLE weather as SELECT * FROM read_csv('weather.csv')\n\n\n\n\nCode\nSELECT *\nFROM weather;\n\n\n\n3 records\n\n\ncity\ntemp_lo\ntemp_hi\nprcp\ndate\n\n\n\n\nSan Francisco\n46\n50\n0.25\n1994-11-27\n\n\nSan Francisco\n43\n57\n0.00\n1994-11-29\n\n\nHayward\n37\n54\nNA\n1994-11-29\n\n\n\n\n\n\n\nCode\nSELECT city, (temp_hi + temp_lo) / 2 AS temp_avg, date\nFROM weather;\n\n\n\n3 records\n\n\ncity\ntemp_avg\ndate\n\n\n\n\nSan Francisco\n48.0\n1994-11-27\n\n\nSan Francisco\n50.0\n1994-11-29\n\n\nHayward\n45.5\n1994-11-29\n\n\n\n\n\n\n\nCode\nSELECT *\nFROM weather\nWHERE city = 'San Francisco' AND prcp &gt; 0.0;\n\n\n\n1 records\n\n\ncity\ntemp_lo\ntemp_hi\nprcp\ndate\n\n\n\n\nSan Francisco\n46\n50\n0.25\n1994-11-27\n\n\n\n\n\n\n\nCode\nSELECT DISTINCT city\nFROM weather;\n\n\n\n2 records\n\n\ncity\n\n\n\n\nHayward\n\n\nSan Francisco\n\n\n\n\n\n\n\nCode\nSELECT DISTINCT city\nFROM weather\nORDER BY city;\n\n\n\n2 records\n\n\ncity\n\n\n\n\nHayward\n\n\nSan Francisco"
  },
  {
    "objectID": "contents/sql/duckdb/documentaion/guide_04_sql.html#joins-between-tables",
    "href": "contents/sql/duckdb/documentaion/guide_04_sql.html#joins-between-tables",
    "title": "SQL",
    "section": "2.3 Joins between Tables",
    "text": "2.3 Joins between Tables\n\n\nCode\nCREATE OR REPLACE TABLE cities as SELECT * FROM read_csv('city.csv')\n\n\n２つのテーブルを組合せる方法として、用意したすべての組合せを考えた上でフィルターをかける方法がある。\n\n\nCode\nSELECT *\nFROM weather, cities\n\n\n\n3 records\n\n\n\n\n\n\n\n\n\n\n\n\ncity\ntemp_lo\ntemp_hi\nprcp\ndate\nname\nlat\nlon\n\n\n\n\nSan Francisco\n46\n50\n0.25\n1994-11-27\nSan Francisco\n-194\n53\n\n\nSan Francisco\n43\n57\n0.00\n1994-11-29\nSan Francisco\n-194\n53\n\n\nHayward\n37\n54\nNA\n1994-11-29\nSan Francisco\n-194\n53\n\n\n\n\n\n\n\nCode\nSELECT *\nFROM weather, cities\nWHERE city = name;\n\n\n\n2 records\n\n\n\n\n\n\n\n\n\n\n\n\ncity\ntemp_lo\ntemp_hi\nprcp\ndate\nname\nlat\nlon\n\n\n\n\nSan Francisco\n46\n50\n0.25\n1994-11-27\nSan Francisco\n-194\n53\n\n\nSan Francisco\n43\n57\n0.00\n1994-11-29\nSan Francisco\n-194\n53\n\n\n\n\n\nもしカラム名が被るときには次のようにテーブル名をつける。 見てわかるようにテーブル名にエイリアスを使うことが可能である。\n\n\nCode\nSELECT t.city, t.temp_lo, t.temp_hi, t.prcp, t.date, cities.lon, cities.lat\nFROM weather t, cities\nWHERE cities.name = t.city;\n\n\n\n2 records\n\n\ncity\ntemp_lo\ntemp_hi\nprcp\ndate\nlon\nlat\n\n\n\n\nSan Francisco\n46\n50\n0.25\n1994-11-27\n53\n-194\n\n\nSan Francisco\n43\n57\n0.00\n1994-11-29\n53\n-194\n\n\n\n\n\n左外部結合を考える。\n\n\nCode\nSELECT *\nFROM weather\nLEFT OUTER JOIN cities ON weather.city = cities.name;\n\n\n\n3 records\n\n\n\n\n\n\n\n\n\n\n\n\ncity\ntemp_lo\ntemp_hi\nprcp\ndate\nname\nlat\nlon\n\n\n\n\nSan Francisco\n46\n50\n0.25\n1994-11-27\nSan Francisco\n-194\n53\n\n\nSan Francisco\n43\n57\n0.00\n1994-11-29\nSan Francisco\n-194\n53\n\n\nHayward\n37\n54\nNA\n1994-11-29\nNA\nNA\nNA"
  },
  {
    "objectID": "contents/sql/duckdb/documentaion/guide_04_sql.html#aggregate-functions",
    "href": "contents/sql/duckdb/documentaion/guide_04_sql.html#aggregate-functions",
    "title": "SQL",
    "section": "2.4 Aggregate Functions",
    "text": "2.4 Aggregate Functions\n\ncount, sum, avg, max, min\n\n\n\nCode\nSELECT max(temp_lo)\nFROM weather;\n\n\n\n1 records\n\n\nmax(temp_lo)\n\n\n\n\n46\n\n\n\n\n\n集約関数は次のようにWHERE句で使えない。 これは集約計算の対象がWHEREで絞った結果であるため。\n-- これはエラーになる\nSELECT city\nFROM weather\nWHERE temp_lo = max(temp_lo);     -- WRONG\nWHERE句で使うにはスカラー値をクエリする必要がある。サブクエリにすることで独立したクエリとして計算が行える。。\n\n\nCode\nSELECT city\nFROM weather\nWHERE temp_lo = (SELECT max(temp_lo) FROM weather);\n\n\n\n1 records\n\n\ncity\n\n\n\n\nSan Francisco\n\n\n\n\n\n\n\nCode\nSELECT city, max(temp_lo)\nFROM weather\nGROUP BY city;\n\n\n\n2 records\n\n\ncity\nmax(temp_lo)\n\n\n\n\nHayward\n37\n\n\nSan Francisco\n46\n\n\n\n\n\n計算結果に対してフィルターすることが可能である。\n\n\nCode\nSELECT city, max(temp_lo) as A\nFROM weather\nGROUP BY city\nHAVING A &lt; 40;\n\n\n\n1 records\n\n\ncity\nA\n\n\n\n\nHayward\n37\n\n\n\n\n\n\n\nCode\nSELECT city, max(temp_lo)\nFROM weather\nWHERE city LIKE 'S%'            -- (1)\nGROUP BY city\nHAVING max(temp_lo) &lt; 40;\n\n\n\n0 records\n\n\ncity\nmax(temp_lo)\n\n\n\n\n\n\n\nHAVINGは常に集約値を使うことに注意する。"
  },
  {
    "objectID": "contents/sql/duckdb/documentaion/guide_04_sql.html#updates",
    "href": "contents/sql/duckdb/documentaion/guide_04_sql.html#updates",
    "title": "SQL",
    "section": "2.5 Updates",
    "text": "2.5 Updates\nUPDATEコマンドを使うことで、既存の行を更新することができる。\n\n\nCode\nUPDATE weather\nSET temp_hi = temp_hi - 2,  temp_lo = temp_lo - 2\nWHERE date &gt; '1994-11-28';\n\n\n\n\nCode\nSELECT *\nFROM weather;\n\n\n\n3 records\n\n\ncity\ntemp_lo\ntemp_hi\nprcp\ndate\n\n\n\n\nSan Francisco\n46\n50\n0.25\n1994-11-27\n\n\nSan Francisco\n41\n55\n0.00\n1994-11-29\n\n\nHayward\n35\n52\nNA\n1994-11-29"
  },
  {
    "objectID": "contents/sql/duckdb/documentaion/guide_04_sql.html#deletions",
    "href": "contents/sql/duckdb/documentaion/guide_04_sql.html#deletions",
    "title": "SQL",
    "section": "2.6 Deletions",
    "text": "2.6 Deletions\n\n\nCode\nDELETE FROM weather\nWHERE city = 'Hayward';\n\n\n\n\nCode\nSELECT *\nFROM weather;\n\n\n\n2 records\n\n\ncity\ntemp_lo\ntemp_hi\nprcp\ndate\n\n\n\n\nSan Francisco\n46\n50\n0.25\n1994-11-27\n\n\nSan Francisco\n41\n55\n0.00\n1994-11-29"
  },
  {
    "objectID": "contents/sql/duckdb/documentaion/guide_04_sql.html#general-purpose-window-functions",
    "href": "contents/sql/duckdb/documentaion/guide_04_sql.html#general-purpose-window-functions",
    "title": "SQL",
    "section": "3.1 General-Purpose Window Functions",
    "text": "3.1 General-Purpose Window Functions\n\ncume_dist\ndense_rank\nfirst_value\nfirst\nlag\nlast_value\nlast\nlead\nnth_value\nntile：区分化\npercent_rank\nrank_dense\nrank\nrow_number\n\nタイル化でデータを分割してみる。\n\n\nCode\nWITH tiled as (\n  SELECT ntile(10) OVER() T, *\n  FROM penguins\n)\nSELECT T, COUNT(*)\nFROM tiled\nGROUP BY T\nORDER BY T\n\n\n\nDisplaying records 1 - 10\n\n\nT\ncount_star()\n\n\n\n\n1\n35\n\n\n2\n35\n\n\n3\n35\n\n\n4\n35\n\n\n5\n34\n\n\n6\n34\n\n\n7\n34\n\n\n8\n34\n\n\n9\n34\n\n\n10\n34"
  },
  {
    "objectID": "contents/sql/duckdb/documentaion/guide_04_sql.html#ignoring-nulls",
    "href": "contents/sql/duckdb/documentaion/guide_04_sql.html#ignoring-nulls",
    "title": "SQL",
    "section": "3.2 Ignoring NULLs",
    "text": "3.2 Ignoring NULLs\n下記の関数はNULLを無視することができる。\n\nlag\nlead\nfirst_value\nlast_value\nnth_value\n\nlag(column, 3 IGNORE NULLS)となる。"
  },
  {
    "objectID": "contents/sql/duckdb/documentaion/guide_04_sql.html#evaluation",
    "href": "contents/sql/duckdb/documentaion/guide_04_sql.html#evaluation",
    "title": "SQL",
    "section": "3.3 Evaluation",
    "text": "3.3 Evaluation\n\n3.3.1 Partition and Ordering\n\n\nCode\nCREATE OR REPLACE TABLE \"Generation History\" AS\n  FROM 'data/csv/power-plant-generation-history.csv';\n\n\n\n\nCode\nSELECT * FROM \"Generation History\" LIMIT 5;\n\n\n\n5 records\n\n\nMWh\nDate\nPlant\n\n\n\n\n564337\n2019-01-02\nBoston\n\n\n507405\n2019-01-03\nBoston\n\n\n528523\n2019-01-04\nBoston\n\n\n469538\n2019-01-05\nBoston\n\n\n474163\n2019-01-06\nBoston\n\n\n\n\n\nまずはrow_numberの挙動をみる。\n\n\nCode\nSELECT\n    \"Plant\",\n    \"Date\",\n    row_number() OVER (PARTITION BY \"Plant\" ORDER  BY \"Date\") AS \"Row\"\nFROM \"Generation History\"\nORDER BY 1, 2;\n\n\n\nDisplaying records 1 - 10\n\n\nPlant\nDate\nRow\n\n\n\n\nBoston\n2019-01-02\n1\n\n\nBoston\n2019-01-03\n2\n\n\nBoston\n2019-01-04\n3\n\n\nBoston\n2019-01-05\n4\n\n\nBoston\n2019-01-06\n5\n\n\nBoston\n2019-01-07\n6\n\n\nBoston\n2019-01-08\n7\n\n\nBoston\n2019-01-09\n8\n\n\nBoston\n2019-01-10\n9\n\n\nBoston\n2019-01-11\n10\n\n\n\n\n\n\n\n3.3.2 Framing\nPRECEDINGやFOLLOWINGを使うことで、相対的な位置関係を使うことが可能である。 この距離はROWSの整数としても指定することができる。 フレームのデフォルト値はUNBOUNDED PRECEDINGからCURRENT ROWである。 EXCLUDE句は使用するうと現在の行の周りの行をフレームから除外することができる。\n\n\n\n\n\nRANGEフレーミングを行う。\n\n\nCode\nSELECT \"Plant\", \"Date\",\n    avg(\"MWh\") OVER (\n        PARTITION BY \"Plant\"\n        ORDER BY \"Date\" ASC\n        RANGE BETWEEN INTERVAL 3 DAYS PRECEDING\n                  AND INTERVAL 3 DAYS FOLLOWING)\n        AS \"MWh 7-day Moving Average\"\nFROM \"Generation History\"\nORDER BY 1, 2;\n\n\n\nDisplaying records 1 - 10\n\n\nPlant\nDate\nMWh 7-day Moving Average\n\n\n\n\nBoston\n2019-01-02\n517450.8\n\n\nBoston\n2019-01-03\n508793.2\n\n\nBoston\n2019-01-04\n508529.8\n\n\nBoston\n2019-01-05\n523459.9\n\n\nBoston\n2019-01-06\n526067.1\n\n\nBoston\n2019-01-07\n524938.7\n\n\nBoston\n2019-01-08\n518294.6\n\n\nBoston\n2019-01-09\n520665.4\n\n\nBoston\n2019-01-10\n528859.0\n\n\nBoston\n2019-01-11\n532466.7\n\n\n\n\n\n範囲がないときにNULLになるようにする。\n\n\nCode\nSELECT \"Plant\", \"Date\",\n    CASE\n        WHEN COUNT(\"MWh\") OVER (\n            PARTITION BY \"Plant\"\n            ORDER BY \"Date\" ASC\n            RANGE BETWEEN INTERVAL 3 DAYS PRECEDING\n                      AND INTERVAL 3 DAYS FOLLOWING\n        ) &gt;= 7 THEN\n            avg(\"MWh\") OVER (\n                PARTITION BY \"Plant\"\n                ORDER BY \"Date\" ASC\n                RANGE BETWEEN INTERVAL 3 DAYS PRECEDING\n                          AND INTERVAL 3 DAYS FOLLOWING\n            )\n        ELSE\n            NULL\n    END AS \"MWh 7-day Moving Average\"\nFROM \"Generation History\"\nORDER BY 1, 2;\n\n\n\nDisplaying records 1 - 10\n\n\nPlant\nDate\nMWh 7-day Moving Average\n\n\n\n\nBoston\n2019-01-02\nNA\n\n\nBoston\n2019-01-03\nNA\n\n\nBoston\n2019-01-04\nNA\n\n\nBoston\n2019-01-05\n523459.9\n\n\nBoston\n2019-01-06\n526067.1\n\n\nBoston\n2019-01-07\n524938.7\n\n\nBoston\n2019-01-08\n518294.6\n\n\nBoston\n2019-01-09\n520665.4\n\n\nBoston\n2019-01-10\n528859.0\n\n\nBoston\n2019-01-11\nNA\n\n\n\n\n\n\n\n3.3.3 WINDOW Clauses\nWINDOWを選言することでマクロのような使い方ができる。\n\n\nCode\nSELECT \"Plant\", \"Date\",\n    min(\"MWh\") OVER seven AS \"MWh 7-day Moving Minimum\",\n    avg(\"MWh\") OVER seven AS \"MWh 7-day Moving Average\",\n    max(\"MWh\") OVER seven AS \"MWh 7-day Moving Maximum\",\n    min(\"MWh\") OVER three AS \"MWh 3-day Moving Minimum\",\n    avg(\"MWh\") OVER three AS \"MWh 3-day Moving Average\",\n    max(\"MWh\") OVER three AS \"MWh 3-day Moving Maximum\"\nFROM \"Generation History\"\nWINDOW\n    seven AS (\n        PARTITION BY \"Plant\"\n        ORDER BY \"Date\" ASC\n        RANGE BETWEEN INTERVAL 3 DAYS PRECEDING\n                  AND INTERVAL 3 DAYS FOLLOWING),\n    three AS (\n        PARTITION BY \"Plant\"\n        ORDER BY \"Date\" ASC\n        RANGE BETWEEN INTERVAL 1 DAYS PRECEDING\n        AND INTERVAL 1 DAYS FOLLOWING)\nORDER BY 1, 2;\n\n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\n\n\n\n\nPlant\nDate\nMWh 7-day Moving Minimum\nMWh 7-day Moving Average\nMWh 7-day Moving Maximum\nMWh 3-day Moving Minimum\nMWh 3-day Moving Average\nMWh 3-day Moving Maximum\n\n\n\n\nBoston\n2019-01-02\n469538\n517450.8\n564337\n507405\n535871.0\n564337\n\n\nBoston\n2019-01-03\n469538\n508793.2\n564337\n507405\n533421.7\n564337\n\n\nBoston\n2019-01-04\n469538\n508529.8\n564337\n469538\n501822.0\n528523\n\n\nBoston\n2019-01-05\n469538\n523459.9\n613040\n469538\n490741.3\n528523\n\n\nBoston\n2019-01-06\n469538\n526067.1\n613040\n469538\n483638.0\n507213\n\n\nBoston\n2019-01-07\n469538\n524938.7\n613040\n474163\n531472.0\n613040\n\n\nBoston\n2019-01-08\n469538\n518294.6\n613040\n507213\n567613.7\n613040\n\n\nBoston\n2019-01-09\n474163\n520665.4\n613040\n499506\n565044.7\n613040\n\n\nBoston\n2019-01-10\n482014\n528859.0\n613040\n482014\n521369.3\n582588\n\n\nBoston\n2019-01-11\n482014\n532466.7\n613040\n482014\n489218.0\n499506\n\n\n\n\n\n\n\n3.3.4 Filtering the Results of Window Functions Using QUALIFY\n\n\nCode\nSELECT \"Plant\", \"Date\",\n    min(\"MWh\") OVER seven AS \"MWh 7-day Moving Minimum\",\n    quantile_cont(\"MWh\", [0.25, 0.5, 0.75]) OVER seven\n        AS \"MWh 7-day Moving IQR\",\n    max(\"MWh\") OVER seven AS \"MWh 7-day Moving Maximum\",\nFROM \"Generation History\"\nWINDOW seven AS (\n    PARTITION BY \"Plant\"\n    ORDER BY \"Date\" ASC\n    RANGE BETWEEN INTERVAL 3 DAYS PRECEDING\n              AND INTERVAL 3 DAYS FOLLOWING)\nORDER BY 1, 2;\n\n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\n\nPlant\nDate\nMWh 7-day Moving Minimum\nMWh 7-day Moving IQR\nMWh 7-day Moving Maximum\n\n\n\n\nBoston\n2019-01-02\n469538\n497938.2, 517964.0, 537476.5\n564337\n\n\nBoston\n2019-01-03\n469538\n474163, 507405, 528523\n564337\n\n\nBoston\n2019-01-04\n469538\n482425.5, 507309.0, 523243.5\n564337\n\n\nBoston\n2019-01-05\n469538\n490688, 507405, 546430\n613040\n\n\nBoston\n2019-01-06\n469538\n490688.0, 507405.0, 555555.5\n613040\n\n\nBoston\n2019-01-07\n469538\n486834.5, 507213.0, 555555.5\n613040\n\n\nBoston\n2019-01-08\n469538\n478088.5, 499506.0, 544900.5\n613040\n\n\nBoston\n2019-01-09\n474163\n484074.0, 499506.0, 544900.5\n613040\n\n\nBoston\n2019-01-10\n482014\n492820, 507213, 557053\n613040\n\n\nBoston\n2019-01-11\n482014\n489477.0, 515512.0, 569820.5\n613040"
  },
  {
    "objectID": "contents/sql/duckdb/mytips/01_.html",
    "href": "contents/sql/duckdb/mytips/01_.html",
    "title": "交差演算",
    "section": "",
    "text": "Code\nrenv::activate(here::here())\n\n\n\n\nCode\ncur_dir &lt;- here::here(\"contents/sql/duckdb/mytips\")\n\nlibrary(ggplot2)\nlibrary(duckdb)\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(DBI)\nlibrary(dbplyr)\nlibrary(arrow)\nlibrary(showtext)\nlibrary(here)\nshowtext_auto()\nfont_add_google(\"Noto Sans\")\n\n\n\n1 Setup\n\n\nCode\ncon &lt;- dbConnect(duckdb(here(cur_dir, \"data.db\")))\n\n\n\n\nCode\nINSTALL icu;\nINSTALL spatial;\nINSTALL httpfs;\nINSTALL json;\n\n\n\n\nCode\nLOAD icu;\nLOAD spatial;\nLOAD httpfs;\nLOAD json;\n\n\n\n\nCode\nSHOW ALL TABLES;\n\n\n\n2 records\n\n\n\n\n\n\n\n\n\n\ndatabase\nschema\nname\ncolumn_names\ncolumn_types\ntemporary\n\n\n\n\ndata\nmain\nag\nMESH_ID , SHICODE , PTN_2015 , HITOKU2020, GASSAN2020, PTN_2020 , PT0_2020 , PT1_2020 , PT2_2020 , PT3_2020 , PT4_2020 , PT5_2020 , PT6_2020 , PT7_2020 , PT8_2020 , PT9_2020 , PT10_2020 , PT11_2020 , PT12_2020 , PT13_2020 , PT14_2020 , PT15_2020 , PT16_2020 , PT17_2020 , PT18_2020 , PT19_2020 , PTA_2020 , PTB_2020 , PTC_2020 , PTD_2020 , PTE_2020 , RTA_2020 , RTB_2020 , RTC_2020 , RTD_2020 , RTE_2020 , HITOKU2025, GASSAN2025, PTN_2025 , PT0_2025 , PT1_2025 , PT2_2025 , PT3_2025 , PT4_2025 , PT5_2025 , PT6_2025 , PT7_2025 , PT8_2025 , PT9_2025 , PT10_2025 , PT11_2025 , PT12_2025 , PT13_2025 , PT14_2025 , PT15_2025 , PT16_2025 , PT17_2025 , PT18_2025 , PT19_2025 , PTA_2025 , PTB_2025 , PTC_2025 , PTD_2025 , PTE_2025 , RTA_2025 , RTB_2025 , RTC_2025 , RTD_2025 , RTE_2025 , HITOKU2030, GASSAN2030, PTN_2030 , PT0_2030 , PT1_2030 , PT2_2030 , PT3_2030 , PT4_2030 , PT5_2030 , PT6_2030 , PT7_2030 , PT8_2030 , PT9_2030 , PT10_2030 , PT11_2030 , PT12_2030 , PT13_2030 , PT14_2030 , PT15_2030 , PT16_2030 , PT17_2030 , PT18_2030 , PT19_2030 , PTA_2030 , PTB_2030 , PTC_2030 , PTD_2030 , PTE_2030 , RTA_2030 , RTB_2030 , RTC_2030 , RTD_2030 , RTE_2030 , HITOKU2035, GASSAN2035, PTN_2035 , PT0_2035 , PT1_2035 , PT2_2035 , PT3_2035 , PT4_2035 , PT5_2035 , PT6_2035 , PT7_2035 , PT8_2035 , PT9_2035 , PT10_2035 , PT11_2035 , PT12_2035 , PT13_2035 , PT14_2035 , PT15_2035 , PT16_2035 , PT17_2035 , PT18_2035 , PT19_2035 , PTA_2035 , PTB_2035 , PTC_2035 , PTD_2035 , PTE_2035 , RTA_2035 , RTB_2035 , RTC_2035 , RTD_2035 , RTE_2035 , HITOKU2040, GASSAN2040, PTN_2040 , PT0_2040 , PT1_2040 , PT2_2040 , PT3_2040 , PT4_2040 , PT5_2040 , PT6_2040 , PT7_2040 , PT8_2040 , PT9_2040 , PT10_2040 , PT11_2040 , PT12_2040 , PT13_2040 , PT14_2040 , PT15_2040 , PT16_2040 , PT17_2040 , PT18_2040 , PT19_2040 , PTA_2040 , PTB_2040 , PTC_2040 , PTD_2040 , PTE_2040 , RTA_2040 , RTB_2040 , RTC_2040 , RTD_2040 , RTE_2040 , HITOKU2045, GASSAN2045, PTN_2045 , PT0_2045 , PT1_2045 , PT2_2045 , PT3_2045 , PT4_2045 , PT5_2045 , PT6_2045 , PT7_2045 , PT8_2045 , PT9_2045 , PT10_2045 , PT11_2045 , PT12_2045 , PT13_2045 , PT14_2045 , PT15_2045 , PT16_2045 , PT17_2045 , PT18_2045 , PT19_2045 , PTA_2045 , PTB_2045 , PTC_2045 , PTD_2045 , PTE_2045 , RTA_2045 , RTB_2045 , RTC_2045 , RTD_2045 , RTE_2045 , HITOKU2050, GASSAN2050, PTN_2050 , PT0_2050 , PT1_2050 , PT2_2050 , PT3_2050 , PT4_2050 , PT5_2050 , PT6_2050 , PT7_2050 , PT8_2050 , PT9_2050 , PT10_2050 , PT11_2050 , PT12_2050 , PT13_2050 , PT14_2050 , PT15_2050 , PT16_2050 , PT17_2050 , PT18_2050 , PT19_2050 , PTA_2050 , PTB_2050 , PTC_2050 , PTD_2050 , PTE_2050 , RTA_2050 , RTB_2050 , RTC_2050 , RTD_2050 , RTE_2050 , geom\nBIGINT , INTEGER , DOUBLE , VARCHAR , BIGINT , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , VARCHAR , BIGINT , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , VARCHAR , BIGINT , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , VARCHAR , BIGINT , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , VARCHAR , BIGINT , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , VARCHAR , BIGINT , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , VARCHAR , BIGINT , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , DOUBLE , GEOMETRY\nFALSE\n\n\ndata\nmain\npref\nN03_001, N03_002, N03_003, N03_004, N03_005, N03_007, geom\nVARCHAR , VARCHAR , VARCHAR , VARCHAR , VARCHAR , VARCHAR , GEOMETRY\nFALSE\n\n\n\n\n\n\n\nCode\nSELECT DISTINCT * FROM duckdb_functions() WHERE function_name LIKE 'st_%' ORDER BY function_name;\n\n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndatabase_name\ndatabase_oid\nschema_name\nfunction_name\nfunction_type\ndescription\ncomment\nreturn_type\nparameters\nparameter_types\nvarargs\nmacro_definition\nhas_side_effects\ninternal\nfunction_oid\nexample\nstability\n\n\n\n\nsystem\n0\nmain\nst_read_meta\ntable\nNA\nNA\nNA\ncol0\nVARCHAR\nNA\nNA\nNA\nTRUE\n1543\nNA\nNA\n\n\nsystem\n0\nmain\nst_read_meta\ntable\nNA\nNA\nNA\ncol0\nVARCHAR[]\nNA\nNA\nNA\nTRUE\n1543\nNA\nNA\n\n\nsystem\n0\nmain\nstarts_with\nscalar\nReturns true if string begins with search_string\nNA\nBOOLEAN\nstring , search_string\nVARCHAR, VARCHAR\nNA\nNA\nFALSE\nTRUE\n934\nstarts_with(‘abc’,‘a’)\nCONSISTENT\n\n\nsystem\n0\nmain\nstats\nscalar\nReturns a string with statistics about the expression. Expression can be a column, constant, or SQL expression\nNA\nVARCHAR\nexpression\nANY\nNA\nNA\nTRUE\nTRUE\n936\nstats(5)\nVOLATILE\n\n\nsystem\n0\nmain\nstddev\naggregate\nReturns the sample standard deviation\nNA\nDOUBLE\nx\nDOUBLE\nNA\nNA\nFALSE\nTRUE\n938\nsqrt(var_samp(x))\nCONSISTENT\n\n\nsystem\n0\nmain\nstddev_pop\naggregate\nReturns the population standard deviation.\nNA\nDOUBLE\nx\nDOUBLE\nNA\nNA\nFALSE\nTRUE\n940\nsqrt(var_pop(x))\nCONSISTENT\n\n\nsystem\n0\nmain\nstddev_samp\naggregate\nReturns the sample standard deviation\nNA\nDOUBLE\nx\nDOUBLE\nNA\nNA\nFALSE\nTRUE\n942\nsqrt(var_samp(x))\nCONSISTENT\n\n\nsystem\n0\nmain\nstorage_info\npragma\nNA\nNA\nNA\ncol0\nVARCHAR\nNA\nNA\nNA\nTRUE\n302\nNA\nNA\n\n\nsystem\n0\nmain\nstr_split\nscalar\nSplits the string along the separator\nNA\nVARCHAR[]\nstring , separator\nVARCHAR, VARCHAR\nNA\nNA\nFALSE\nTRUE\n944\nstring_split(‘hello-world’, ‘-’)\nCONSISTENT\n\n\nsystem\n0\nmain\nstr_split_regex\nscalar\nSplits the string along the regex\nNA\nVARCHAR[]\nstring , separator\nVARCHAR, VARCHAR\nNA\nNA\nFALSE\nTRUE\n946\nstring_split_regex(‘hello␣world; 42’, ‘;?␣’)\nCONSISTENT\n\n\n\n\n\n\n\n2 交差演算\n国土数値情報の行政区域データと農業地域データの交差集合を作成する。\n\n\nCode\nCREATE OR REPLACE TABLE pref AS SELECT * FROM './data/N03-20240101_GML/N03-20240101.shp';\nCREATE OR REPLACE TABLE ag AS (\n  SELECT * FROM './data/ag/1km_mesh_2018_01.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_02.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_03.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_04.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_05.shp'  \n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_06.shp'  \n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_07.shp'  \n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_08.shp'  \n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_09.shp'  \n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_10.shp'  \n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_11.shp'  \n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_12.shp'  \n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_13.shp'  \n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_14.shp'  \n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_15.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_16.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_17.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_18.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_19.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_20.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_21.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_22.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_23.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_24.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_25.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_26.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_27.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_28.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_29.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_30.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_31.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_32.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_33.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_34.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_35.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_36.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_37.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_38.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_39.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_40.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_41.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_42.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_43.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_44.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_45.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_46.shp'\n    UNION ALL\n  SELECT * FROM './data/ag/1km_mesh_2018_47.shp'\n);\n\n\n\n\nCode\ndescribe pref;\n\n\n\n7 records\n\n\ncolumn_name\ncolumn_type\nnull\nkey\ndefault\nextra\n\n\n\n\nN03_001\nVARCHAR\nYES\nNA\nNA\nNA\n\n\nN03_002\nVARCHAR\nYES\nNA\nNA\nNA\n\n\nN03_003\nVARCHAR\nYES\nNA\nNA\nNA\n\n\nN03_004\nVARCHAR\nYES\nNA\nNA\nNA\n\n\nN03_005\nVARCHAR\nYES\nNA\nNA\nNA\n\n\nN03_007\nVARCHAR\nYES\nNA\nNA\nNA\n\n\ngeom\nGEOMETRY\nYES\nNA\nNA\nNA\n\n\n\n\n\n\n\nCode\ndescribe ag;\n\n\n\nDisplaying records 1 - 10\n\n\ncolumn_name\ncolumn_type\nnull\nkey\ndefault\nextra\n\n\n\n\nMESH_ID\nBIGINT\nYES\nNA\nNA\nNA\n\n\nSHICODE\nINTEGER\nYES\nNA\nNA\nNA\n\n\nPTN_2015\nDOUBLE\nYES\nNA\nNA\nNA\n\n\nHITOKU2020\nVARCHAR\nYES\nNA\nNA\nNA\n\n\nGASSAN2020\nBIGINT\nYES\nNA\nNA\nNA\n\n\nPTN_2020\nDOUBLE\nYES\nNA\nNA\nNA\n\n\nPT0_2020\nDOUBLE\nYES\nNA\nNA\nNA\n\n\nPT1_2020\nDOUBLE\nYES\nNA\nNA\nNA\n\n\nPT2_2020\nDOUBLE\nYES\nNA\nNA\nNA\n\n\nPT3_2020\nDOUBLE\nYES\nNA\nNA\nNA\n\n\n\n\n\n\n\nCode\nselect count(*) from pref;\n\n\n\n1 records\n\n\ncount_star()\n\n\n\n\n124134\n\n\n\n\n\n\n\nCode\nselect count(*) from ag;\n\n\n\n1 records\n\n\ncount_star()\n\n\n\n\n178347\n\n\n\n\n\n約10万どおしの演算であるが、数分で処理できる。すごい！\n\n\nCode\nselect\n  COLUMNS(pref.* EXCLUDE(geom)), \n  ag.MESH_ID, \n  ag.SHICODE, \n  ag.PTN_2015,\n  st_astext(st_intersection(pref.geom, ag.geom)) as geom\nfrom pref, ag\nwhere st_intersects(pref.geom, ag.geom)\n;\n\n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nN03_001\nN03_002\nN03_003\nN03_004\nN03_005\nN03_007\nMESH_ID\nSHICODE\nPTN_2015\ngeom\n\n\n\n\n沖縄県\nNA\nNA\n石垣市\nNA\n47207\n36247225\n47207\n14.0109\nPOLYGON ((124.320423774 24.608333333, 124.320448301 24.608313847, 124.32049415 24.608286838, 124.320538923 24.60826255, 124.320585577 24.608239874, 124.320641803 24.608211676, 124.320695642 24.608183396, 124.320746239 24.608157279, 124.320808288 24.608127171, 124.32086786 24.608099054, 124.320916978 24.608073126, 124.320970324 24.608044126, 124.321016978 24.608018658, 124.321062633 24.607992649, 124.321100999 24.607971162, 124.321138184 24.607954108, 124.321182776 24.607934333, 124.321234267 24.60791409, 124.321264656 24.607902198, 124.321302542 24.607885775, 124.321354228 24.607865171, 124.321404254 24.60784755, 124.32144904 24.607829667, 124.321486537 24.607815856, 124.321542088 24.607794162, 124.321585785 24.60777791, 124.321625953 24.607763018, 124.321664034 24.607749297, 124.321706563 24.607734315, 124.321745331 24.607721405, 124.32178332 24.607707694, 124.321829792 24.607690081, 124.321867678 24.607674829, 124.321899339 24.607660676, 124.321928638 24.607649414, 124.321969287 24.607634613, 124.322010532 24.607620171, 124.322054449 24.607605631, 124.322099728 24.60759027, 124.322131414 24.60758, 124.322172957 24.60756718, 124.3222138 24.60755355, 124.322250415 24.607543541, 124.322320182 24.607523081, 124.322409001 24.607500495, 124.322463684 24.607487919, 124.322509689 24.607480144, 124.322562477 24.607464054, 124.322607873 24.607451856, 124.322658106 24.607438477, 124.322714851 24.607423279, 124.322756304 24.607412081, 124.32279607 24.607401252, 124.322830026 24.607393955, 124.322866446 24.607386117, 124.322904449 24.60737827, 124.322939001 24.607371514, 124.322984786 24.607360586, 124.323015383 24.607351667, 124.323044994 24.607344739, 124.323079144 24.60733618, 124.323111219 24.607328892, 124.323139248 24.607323414, 124.323163826 24.607320378, 124.323189507 24.607319153, 124.323240441 24.607312901, 124.323276861 24.607303342, 124.323309728 24.607293793, 124.323340311 24.607285333, 124.323372296 24.607278036, 124.323414241 24.607267838, 124.323448885 24.607260541, 124.323479287 24.607254243, 124.32352262 24.607246117, 124.32355144 24.60724118, 124.32358511 24.607236144, 124.323617289 24.607231468, 124.323674929 24.607220685, 124.32371511 24.607212838, 124.323745901 24.607204919, 124.323786654 24.607191559, 124.323805201 24.607184748, 124.323822374 24.607178838, 124.323833022 24.607175027, 124.323851569 24.607169207, 124.323870921 24.607163117, 124.323894591 24.607155117, 124.323910869 24.607148856, 124.323947276 24.607135054, 124.323961388 24.607130234, 124.324020999 24.607116297, 124.324048833 24.607109189, 124.324089792 24.60709818, 124.324112685 24.607090541, 124.324130337 24.60708464, 124.324152153 24.60707755, 124.324167834 24.607072009, 124.324185888 24.607066099, 124.32420454 24.607059829, 124.324223294 24.607053829, 124.324243619 24.60704918, 124.324263761 24.607044532, 124.324293463 24.607037784, 124.324313606 24.607033234, 124.324335901 24.607028216, 124.324362062 24.607021658, 124.324383969 24.607017099, 124.324405888 24.607012171, 124.324430558 24.607006162, 124.324449014 24.607002153, 124.324476252 24.606996225, 124.32450192 24.606989847, 124.324524319 24.606984108, 124.324547211 24.606977739, 124.324570506 24.606970378, 124.324593398 24.606963649, 124.324610272 24.606958919, 124.324634449 24.606952541, 124.324656654 24.606946901, 124.32468537 24.606938892, 124.324713489 24.606930252, 124.324738457 24.606921802, 124.324806537 24.606900072, 124.324854112 24.606888505, 124.324878988 24.606882045, 124.324906226 24.606876117, 124.324926848 24.606870838, 124.32494166 24.606867279, 124.324963165 24.606862, 124.324989222 24.606855982, 124.325 24.606853459, 124.325 24.6, 124.3125 24.6, 124.3125 24.608333333333334, 124.320423773581 24.608333333333334, 124.320423774 24.608333333))\n\n\n沖縄県\nNA\nNA\n石垣市\nNA\n47207\n36247226\n47207\n22.0197\nPOLYGON ((124.32501607 24.606849694, 124.325046965 24.606841685, 124.32512463 24.606820568, 124.32514013 24.606817378, 124.325177523 24.606807991, 124.325201012 24.606802613, 124.325225992 24.606797054, 124.325241388 24.606794045, 124.325264682 24.606789387, 124.325288859 24.606785, 124.325317289 24.60677745, 124.325338508 24.606772342, 124.325362192 24.606768234, 124.325384708 24.606764117, 124.325411453 24.606757919, 124.325429507 24.606753369, 124.325448067 24.606748991, 124.325465538 24.606745162, 124.325489416 24.606739874, 124.325516161 24.606732955, 124.32553856 24.606727036, 124.32556275 24.606720667, 124.325587419 24.606713568, 124.325612283 24.606707649, 124.325634099 24.606703991, 124.325656511 24.606699964, 124.325672996 24.606696685, 124.32569668 24.606692477, 124.325721751 24.60668827, 124.325740999 24.606684252, 124.32576716 24.606680405, 124.325792231 24.606675928, 124.325814838 24.60667073, 124.325840104 24.606665081, 124.325859157 24.606661523, 124.325883243 24.606657405, 124.325903385 24.606655099, 124.325929844 24.606653604, 124.325950091 24.606652108, 124.325973489 24.606649532, 124.326003009 24.606647126, 124.3260269 24.606645441, 124.326051388 24.606643495, 124.326075279 24.606640009, 124.326095214 24.606636, 124.326121569 24.606630072, 124.326144163 24.606625324, 124.326168158 24.606619676, 124.326186615 24.606615937, 124.326209118 24.606611099, 124.326229844 24.60660618, 124.326253424 24.606601072, 124.326280272 24.606596234, 124.326303281 24.606592748, 124.326328457 24.606589081, 124.326355214 24.606586946, 124.326369922 24.606585658, 124.326395888 24.606581712, 124.32641799 24.606578054, 124.326440298 24.606574757, 124.326463696 24.60657082, 124.326510778 24.606559613, 124.326539105 24.606551793, 124.326566433 24.606544775, 124.32658834 24.606539405, 124.326611634 24.606534027, 124.326641336 24.606525658, 124.326661569 24.606519018, 124.326687523 24.606510297, 124.326716524 24.606501207, 124.32674939 24.606491928, 124.326784125 24.606481829, 124.326808703 24.606474279, 124.326835538 24.606466459, 124.326865837 24.606459441, 124.326894955 24.606451973, 124.326923281 24.606445405, 124.326955655 24.606437216, 124.326982101 24.606429847, 124.327012296 24.606421919, 124.327040921 24.60641473, 124.327067263 24.606407811, 124.327094112 24.606400523, 124.327122335 24.606391982, 124.327149468 24.606383342, 124.327223268 24.606358712, 124.327254553 24.606348532, 124.327271427 24.606343532, 124.327295499 24.606337252, 124.327319287 24.606330874, 124.327340804 24.606326045, 124.327359559 24.606324288, 124.327382659 24.606321171, 124.327405668 24.606318315, 124.32743537 24.606312568, 124.32746035 24.606306919, 124.327487004 24.606303153, 124.327511193 24.606300667, 124.32754061 24.60629645, 124.327570311 24.606291234, 124.327594202 24.606287486, 124.327624617 24.606284162, 124.327656304 24.606279135, 124.327684228 24.606273288, 124.327708223 24.60626827, 124.327737341 24.606262162, 124.327766057 24.606254784, 124.327813139 24.606244477, 124.327842944 24.606238189, 124.327870376 24.606231351, 124.327897328 24.606225604, 124.327954073 24.606212486, 124.327988029 24.60620455, 124.328015759 24.606198171, 124.328045266 24.606191153, 124.328073294 24.606185045, 124.328102711 24.606178937, 124.328130545 24.60617427, 124.328155123 24.606169883, 124.328178418 24.606165856, 124.328204086 24.60616255, 124.328235577 24.606158505, 124.328263619 24.606153297, 124.328287108 24.60615027, 124.328312983 24.606147234, 124.328346355 24.606144991, 124.328374189 24.606142766, 124.328401543 24.606138829, 124.328430065 24.606135423, 124.328460285 24.606131838, 124.328488508 24.606127892, 124.328519507 24.606122225, 124.328547639 24.60611855, 124.328573995 24.606113982, 124.328603217 24.606110126, 124.328632348 24.606107081, 124.328661764 24.606102685, 124.328692361 24.606096928, 124.328715953 24.60609327, 124.328739754 24.606091586, 124.328772724 24.606088811, 124.328801751 24.606085856, 124.328828807 24.606083901, 124.328858716 24.606079865, 124.328886057 24.606074207, 124.328910636 24.606069099, 124.328929494 24.606065351, 124.328957419 24.606060054, 124.328979533 24.606057477, 124.329004125 24.606056072, 124.32902476 24.606054126, 124.329049248 24.606053622, 124.329071077 24.606054027, 124.329098132 24.606054784, 124.329121141 24.606052928, 124.329143152 24.606050081, 124.329171686 24.606047486, 124.329202309 24.606047423, 124.329234397 24.606046631, 124.329262827 24.606043315, 124.329287017 24.60604245, 124.329314877 24.606043649, 124.329343709 24.606045486, 124.329375616 24.606046955, 124.329405253 24.606049505, 124.329434189 24.606050883, 124.329460661 24.606050919, 124.329490195 24.606054739, 124.329517458 24.606057477, 124.329543139 24.606060306, 124.329571492 24.606061874, 124.329603385 24.606062523, 124.329636187 24.606066874, 124.329664241 24.606069072, 124.329694851 24.606070991, 124.329723502 24.606074721, 124.329747808 24.606077288, 124.329780804 24.60608182, 124.329806083 24.606083838, 124.329835019 24.606084495, 124.32986406 24.606085423, 124.32988965 24.606088171, 124.329913554 24.606089649, 124.32992332 24.606090081, 124.329943969 24.606090847, 124.329962827 24.606090991, 124.329980013 24.606089054, 124.329995305 24.606086946, 124.330044086 24.606091748, 124.3300931 24.606096387, 124.330107925 24.606097351, 124.330120363 24.606098495, 124.330132412 24.606100099, 124.330147432 24.606100423, 124.330162931 24.606099396, 124.330180895 24.606097459, 124.330200156 24.606096973, 124.330212594 24.606096216, 124.330220791 24.606095568, 124.33022869 24.606094288, 124.330236394 24.60609355, 124.330247147 24.606092351, 124.33026144 24.606117784, 124.330270272 24.606134378, 124.330275435 24.606143577, 124.330292957 24.606161595, 124.330306109 24.606166622, 124.330315097 24.606168045, 124.330320532 24.606168036, 124.330334643 24.606168, 124.330347004 24.606170775, 124.33035511 24.60617473, 124.330360454 24.606181036, 124.330366511 24.606194207, 124.330367925 24.606201784, 124.330369429 24.606210721, 124.330372023 24.60622155, 124.330383709 24.606236243, 124.330391725 24.606239477, 124.330398846 24.606244514, 124.330407951 24.606251991, 124.330412309 24.606256766, 124.330418262 24.606266414, 124.330422425 24.606273351, 124.330428755 24.606278937, 124.330440519 24.606284604, 124.330452776 24.60628873, 124.330466615 24.606292216, 124.330487173 24.606297865, 124.330502088 24.606301892, 124.330517108 24.606305018, 124.330532036 24.606307964, 124.330552477 24.60630873, 124.330561362 24.606308351, 124.330578119 24.606294775, 124.330584786 24.606278775, 124.330588314 24.606265946, 124.330591543 24.60625691, 124.330596252 24.60624164, 124.330599494 24.606238928, 124.330602853 24.606237568, 124.33060917 24.60623755, 124.330616291 24.606239613, 124.330623606 24.606244468, 124.330632218 24.606249874, 124.330639533 24.606253378, 124.330650402 24.606257955, 124.330661569 24.60626073, 124.330671647 24.606262063, 124.330685383 24.606262126, 124.330710454 24.606257189, 124.330725162 24.606256622, 124.330731881 24.606258685, 124.330738314 24.60626309, 124.330743268 24.606268135, 124.330749805 24.606277694, 124.330767121 24.606290117, 124.330775032 24.60629145, 124.330789935 24.606289072, 124.330811829 24.606280532, 124.330832153 24.606271459, 124.330839261 24.606268288, 124.330845175 24.606265207, 124.330853256 24.606261306, 124.330861245 24.606257045, 124.33088061 24.606261063, 124.330919676 24.606283279, 124.330936187 24.606285766, 124.330946355 24.606286468, 124.33097489 24.606285685, 124.330991388 24.606285108, 124.331004319 24.606284991, 124.331017549 24.606284865, 124.331036122 24.606284378, 124.331047873 24.606285523, 124.331066148 24.606287559, 124.33114655 24.606294243, 124.331181505 24.606292, 124.33120668 24.606290505, 124.331216057 24.606289577, 124.331241738 24.606289432, 124.331258625 24.606288126, 124.331268794 24.606286027, 124.331290804 24.606281018, 124.331304125 24.60627918, 124.331326926 24.606275252, 124.331364241 24.606269658, 124.331383684 24.60626582, 124.331409546 24.606260892, 124.331431167 24.606257234, 124.331450415 24.606254117, 124.331472827 24.606250189, 124.331494643 24.606247613, 124.331524254 24.606245108, 124.33154668 24.606244523, 124.331566524 24.606244568, 124.331617393 24.606247162, 124.331638534 24.60625064, 124.331663722 24.606254009, 124.331679637 24.606256324, 124.331698794 24.606258721, 124.331747004 24.606263036, 124.331790467 24.606266279, 124.331820104 24.60627064, 124.331842218 24.606271856, 124.331858521 24.606273532, 124.331873437 24.606276117, 124.331886978 24.606279162, 124.331901907 24.606284, 124.331915253 24.606289847, 124.331932944 24.606296396, 124.331968016 24.606301459, 124.331989546 24.606302685, 124.332008716 24.606303541, 124.332023424 24.606303595, 124.33204406 24.606301928, 124.332054423 24.60630064, 124.332066174 24.606300162, 124.33208 24.606300495, 124.332095214 24.606300009, 124.332108638 24.606298532, 124.332119001 24.606295802, 124.332129546 24.606288829, 124.332136044 24.606278793, 124.332141543 24.606269027, 124.332148729 24.60625809, 124.332158275 24.606245063, 124.332168807 24.606231775, 124.332181401 24.606216847, 124.332211751 24.606193036, 124.332226641 24.606183793, 124.332241829 24.606174459, 124.33226096 24.606164847, 124.332276252 24.606157946, 124.332294099 24.606149874, 124.332311569 24.606143063, 124.332328638 24.606137973, 124.332349559 24.606134045, 124.332371971 24.606131369, 124.332398327 24.606128333, 124.332418573 24.606127387, 124.332439702 24.606127613, 124.332458573 24.606128018, 124.332472192 24.60612736, 124.33248415 24.606127333, 124.332501336 24.60613064, 124.332519805 24.606132126, 124.33253393 24.606131739, 124.332562374 24.606130324, 124.332580233 24.606128297, 124.332598599 24.60612491, 124.332606991 24.606124261, 124.332616278 24.606125144, 124.332630104 24.606127009, 124.332641375 24.606130144, 124.332654215 24.60613355, 124.332664488 24.606133793, 124.332680182 24.606131505, 124.332698249 24.606126955, 124.332714125 24.606119874, 124.33272655 24.606113883, 124.33273808 24.606105189, 124.332751777 24.606093153, 124.332763204 24.606080126, 124.332775603 24.606065748, 124.332786822 24.60605173, 124.33279786 24.606039153, 124.332812724 24.606022685, 124.332826122 24.606009297, 124.332844449 24.605994541, 124.33286131 24.605982676, 124.332879339 24.60596855, 124.332897769 24.605953613, 124.332919261 24.605938396, 124.332940441 24.605921279, 124.332962023 24.605905432, 124.332980947 24.605891757, 124.33300323 24.60587591, 124.333026109 24.605861955, 124.333046615 24.605849541, 124.333073826 24.605835577, 124.333101543 24.605822784, 124.333130545 24.605809631, 124.33315668 24.605797829, 124.333182815 24.605784505, 124.333208262 24.605771892, 124.333228093 24.60576255, 124.333261725 24.605746766, 124.333289144 24.605733973, 124.333321102 24.605719459, 124.333333333 24.605714135, 124.333344877 24.605709117, 124.333399922 24.605688315, 124.333420545 24.605680955, 124.333444228 24.605672685, 124.333468599 24.605664144, 124.333492374 24.605655874, 124.333519805 24.605646793, 124.33355345 24.605635703, 124.33358275 24.605627144, 124.333610389 24.605619414, 124.333632192 24.605613225, 124.333657354 24.605605676, 124.333684293 24.605598847, 124.333708482 24.60559391, 124.333741453 24.605588063, 124.333771167 24.605587, 124.33379655 24.605585955, 124.333825279 24.605583631, 124.333848975 24.605582676, 124.333876433 24.605580991, 124.333896965 24.605579595, 124.333924903 24.60557709, 124.333947613 24.605574694, 124.333976342 24.605571108, 124.333999844 24.605569162, 124.334022451 24.605567306, 124.334043178 24.60556545, 124.334064514 24.605565405, 124.33408131 24.605566541, 124.334103126 24.605566586, 124.33412297 24.605565009, 124.334147665 24.605564045, 124.334170376 24.60556273, 124.334185875 24.605563063, 124.334210765 24.605561559, 124.334236926 24.605560324, 124.334257069 24.605558928, 124.334275927 24.60555618, 124.334296252 24.605552162, 124.334317873 24.605546063, 124.334339767 24.605538703, 124.334363165 24.605532604, 124.334382101 24.605527324, 124.334403411 24.605519604, 124.334426693 24.605508802, 124.334452529 24.605496378, 124.334473048 24.605486937, 124.334497808 24.605475784, 124.334516161 24.605467523, 124.334556693 24.605449198, 124.334579585 24.605439216, 124.334597341 24.605431856, 124.334625253 24.605419523, 124.334649818 24.605409712, 124.334672205 24.605401901, 124.334693917 24.60539445, 124.334716122 24.605386901, 124.334740973 24.60537764, 124.334759533 24.60537164, 124.33478952 24.605362991, 124.334819624 24.605354982, 124.334835409 24.605350793, 124.334858314 24.605346225, 124.334885953 24.605342739, 124.334906991 24.605341333, 124.334937588 24.605338829, 124.33496751 24.605337135, 124.334994955 24.605334369, 124.335021323 24.605332414, 124.335050246 24.605330631, 124.335077302 24.605328225, 124.335106329 24.60532464, 124.335135357 24.605320514, 124.335169403 24.605315468, 124.335204254 24.605310703, 124.335230117 24.605306937, 124.335260428 24.60530227, 124.335287276 24.605300315, 124.335309689 24.60529818, 124.33533773 24.605293973, 124.335363489 24.605290387, 124.335389857 24.605288162, 124.335416213 24.605287568, 124.335443671 24.605285333, 124.335483658 24.60528145, 124.335498366 24.605281063, 124.335520493 24.60528173, 124.335534708 24.605283505, 124.335527847 24.605302937, 124.335523139 24.605311342, 124.33551882 24.60532291, 124.335520233 24.605333108, 124.335522114 24.605338162, 124.335523606 24.605340865, 124.335526874 24.605344559, 124.335532516 24.605347892, 124.335540623 24.605350667, 124.335550104 24.605351369, 124.335559676 24.605349541, 124.335568054 24.605343928, 124.335573671 24.605337775, 124.33558144 24.605326198, 124.335586641 24.605315622, 124.335590973 24.605308207, 124.335597069 24.60529827, 124.335599715 24.605292477, 124.335602568 24.605287054, 124.335606109 24.605281721, 124.335610246 24.605276928, 124.335656939 24.605271946, 124.335680739 24.605271622, 124.335714021 24.60527209, 124.335730817 24.605273135, 124.335769053 24.605281, 124.335806213 24.605291207, 124.335831323 24.60530009, 124.335843476 24.605304216, 124.335864436 24.605313919, 124.335874916 24.605319315, 124.335892036 24.605328937, 124.335904786 24.605332883, 124.335920687 24.605334108, 124.335937173 24.605333441, 124.335951881 24.605331694, 124.335961167 24.605330315, 124.335978444 24.605328207, 124.335989403 24.60532836, 124.335999274 24.605328883, 124.336011829 24.605330207, 124.336023178 24.605331351, 124.336038794 24.605334297, 124.336054306 24.605337874, 124.336063696 24.605338306, 124.336091543 24.605340775, 124.336102711 24.605343, 124.336108042 24.605344252, 124.336118716 24.605346577, 124.336122892 24.605354063, 124.336119468 24.605366712, 124.336114163 24.60538018, 124.336117263 24.60539245, 124.336122698 24.605394874, 124.336128729 24.605395405, 124.336136433 24.605395658, 124.336143139 24.605396, 124.336149377 24.605399243, 124.336157095 24.605406532, 124.336161958 24.605414649, 124.336164345 24.605422315, 124.336163696 24.605435505, 124.336161946 24.605446883, 124.336158612 24.605454477, 124.336157562 24.605467568, 124.336156991 24.605477234, 124.336158106 24.605486712, 124.336158119 24.605495559, 124.33616022 24.605502955, 124.336157665 24.605508649, 124.336151466 24.605516703, 124.336142296 24.605521234, 124.336137951 24.605523595, 124.336131064 24.605530198, 124.33612773 24.605539144, 124.33612904 24.605548982, 124.336134397 24.605557279, 124.336143684 24.605562946, 124.336154163 24.605566261, 124.336171556 24.605569108, 124.336194073 24.605568973, 124.336213126 24.605568748, 124.336229131 24.605567901, 124.336242659 24.605567595, 124.336256861 24.605563324, 124.336264254 24.605557982, 124.336275863 24.605540982, 124.336282036 24.605524532, 124.336285473 24.605516306, 124.336296887 24.605498405, 124.336308898 24.605485649, 124.336321012 24.605473072, 124.336332244 24.60546564, 124.336345759 24.605459477, 124.336361051 24.605452937, 124.336374955 24.605446676, 124.336384125 24.605442414, 124.3363938 24.605437063, 124.336401764 24.605425676, 124.336405396 24.605417541, 124.336409131 24.605410577, 124.336410765 24.605394505, 124.336415473 24.605380676, 124.336423126 24.605362604, 124.33642725 24.605354198, 124.336432166 24.605345333, 124.33643511 24.60533955, 124.336438444 24.605330784, 124.336439014 24.605323288, 124.336438106 24.605316973, 124.33643572 24.605307865, 124.336451362 24.605286604, 124.336470791 24.605277811, 124.336477406 24.605274811, 124.336497432 24.605268, 124.336514021 24.605265703, 124.336525564 24.605265676, 124.336546796 24.605265721, 124.336561712 24.605266766, 124.336579209 24.605270162, 124.336592049 24.605272928, 124.336603813 24.605276333, 124.336616563 24.60528145, 124.336627639 24.605286847, 124.336644942 24.605296739, 124.336651777 24.605301234, 124.336657808 24.605305018, 124.336665616 24.605307712, 124.336675798 24.605312378, 124.336686874 24.605318586, 124.336679831 24.605343342, 124.336675616 24.605352378, 124.336673061 24.605357712, 124.336669741 24.605372432, 124.33666799 24.605384631, 124.336667328 24.605393297, 124.336664112 24.605408649, 124.336662062 24.605417054, 124.336659429 24.605431144, 124.336659157 24.605439631, 124.336662931 24.605448649, 124.33669799 24.605483964, 124.33671511 24.605496838, 124.336734578 24.605504198, 124.336743165 24.605503099, 124.336749183 24.605499468, 124.336757224 24.605478775, 124.336757082 24.605460811, 124.336756822 24.605439775, 124.336762957 24.605407802, 124.336770999 24.605388189, 124.336781634 24.605373541, 124.336790389 24.605361514, 124.336797562 24.605348225, 124.336803658 24.605337099, 124.336806589 24.60532473, 124.336806835 24.605310189, 124.336804929 24.605295387, 124.336803606 24.605283468, 124.336803891 24.605277694, 124.336802503 24.60527345, 124.336800597 24.605263793, 124.336799274 24.605251072, 124.336797289 24.605244027, 124.336828093 24.605205865, 124.336853826 24.60519091, 124.336884293 24.605175396, 124.336919313 24.605160694, 124.336967458 24.605142892, 124.337021738 24.605129946, 124.337072672 24.605121523, 124.337124215 24.605118523, 124.337164812 24.605121505, 124.337194747 24.605127396, 124.337219948 24.605133928, 124.337264436 24.605149, 124.337239144 24.605182279, 124.337234241 24.605197189, 124.33723214 24.605220577, 124.337231543 24.605257054, 124.337229935 24.605286486, 124.337231193 24.605311135, 124.337242685 24.60532718, 124.337262853 24.605334811, 124.337282802 24.605332604, 124.337295811 24.60532327, 124.337301582 24.605302766, 124.33730428 24.605276667, 124.33730786 24.605250468, 124.33731262 24.605221387, 124.337323333 24.605200775, 124.337341154 24.605181865, 124.337358003 24.605166937, 124.337375642 24.60515236, 124.337391012 24.605139685, 124.337402724 24.605127468, 124.33740952 24.605116351, 124.337469754 24.605116847, 124.3375 24.60511428151517, 124.3375 24.6, 124.325 24.6, 124.325 24.606853459, 124.32501607 24.606849694))\n\n\n沖縄県\nNA\nNA\n石垣市\nNA\n47207\n36247204\n47207\n61.0016\nPOLYGON ((124.304327562 24.583348216, 124.304344994 24.583366514, 124.304330285 24.583370423, 124.304321206 24.583373063, 124.304313709 24.583375604, 124.304305629 24.583379054, 124.304296057 24.583383766, 124.304289066 24.583389468, 124.304283256 24.583397514, 124.304280597 24.583403387, 124.304280026 24.583411793, 124.304285071 24.583416568, 124.304292399 24.583425036, 124.304300233 24.583435315, 124.304310324 24.583446306, 124.304316381 24.583457126, 124.30432035 24.583467414, 124.304325992 24.583475351, 124.304335486 24.583477315, 124.304348314 24.583477739, 124.304360169 24.583479613, 124.304369157 24.583482036, 124.304375188 24.583485631, 124.30437965 24.583492486, 124.304385785 24.583498613, 124.30439428 24.583499045, 124.304401984 24.583499577, 124.304409403 24.583503892, 124.304413852 24.583509748, 124.304418223 24.583520126, 124.304421608 24.583527703, 124.304429728 24.583541135, 124.304441907 24.583552766, 124.304460584 24.583557964, 124.304471543 24.583557577, 124.304478353 24.583556387, 124.304493748 24.583553649, 124.304501245 24.583552279, 124.304509728 24.583549739, 124.304514073 24.583547829, 124.304519792 24.583544928, 124.304527588 24.583541126, 124.304546083 24.583518333, 124.304584034 24.583531162, 124.304583748 24.583533514, 124.304583658 24.583536946, 124.304582192 24.583543541, 124.304580337 24.583551486, 124.304579663 24.583557901, 124.304576822 24.583567568, 124.30457358 24.583576333, 124.304572114 24.583580486, 124.304567886 24.583590793, 124.304563372 24.583603351, 124.304561829 24.58361536, 124.30456441 24.583624477, 124.304572438 24.583635838, 124.304583917 24.583648, 124.304594708 24.583657279, 124.304607173 24.58366673, 124.304620026 24.583673117, 124.304630999 24.583677432, 124.304640376 24.583679396, 124.304652127 24.58368118, 124.304665863 24.583681243, 124.304674643 24.583680135, 124.304691816 24.583677396, 124.304702387 24.583677649, 124.304710584 24.583679973, 124.304716511 24.583683126, 124.304719883 24.583687, 124.304723256 24.583693676, 124.304722283 24.58369873, 124.304717652 24.583706505, 124.304711154 24.583711667, 124.304700415 24.583720541, 124.304694202 24.583726324, 124.304689974 24.583733198, 124.304686537 24.583741243, 124.304682724 24.583753802, 124.304677717 24.583767441, 124.304672412 24.583780901, 124.304664345 24.583790586, 124.304655577 24.583796829, 124.304644228 24.583802541, 124.304632892 24.583807622, 124.304623333 24.583814595, 124.304613191 24.583826802, 124.304609351 24.583835297, 124.304604955 24.583849838, 124.304600233 24.583861495, 124.304593359 24.583874964, 124.304587354 24.583885, 124.304581271 24.583898459, 124.304580013 24.583911198, 124.304580337 24.583920405, 124.304584695 24.583929063, 124.304590636 24.583933207, 124.304601401 24.583936432, 124.304613061 24.583940297, 124.304625525 24.583945054, 124.304639546 24.583947459, 124.304654163 24.583949694, 124.304670661 24.583954441, 124.304684112 24.583959468, 124.304696757 24.583964144, 124.304705551 24.583965207, 124.30471393 24.583962387, 124.304719455 24.583958676, 124.30472585 24.583952072, 124.304733243 24.583945468, 124.304743489 24.583937775, 124.304751077 24.583932162, 124.304762023 24.58392627, 124.304770311 24.58392282, 124.304781556 24.583918099, 124.304787873 24.583915198, 124.304800298 24.583908225, 124.304824345 24.583889847, 124.304851946 24.583871189, 124.304887043 24.583851532, 124.304941842 24.583891595, 124.304970428 24.583911577, 124.304991699 24.583929775, 124.305013684 24.583953748, 124.305038249 24.583989, 124.30508192 24.584041459, 124.305121025 24.584085261, 124.30517013 24.584137441, 124.305213268 24.58417482, 124.305261543 24.584209036, 124.305340169 24.584265847, 124.305408145 24.584324306, 124.305459079 24.584359324, 124.305463372 24.58437773, 124.305464773 24.584383324, 124.305466472 24.584393342, 124.305466991 24.584402369, 124.305466316 24.584409054, 124.305463178 24.58441764, 124.305460921 24.584424775, 124.305458275 24.584434351, 124.305457523 24.584446631, 124.305458923 24.584459, 124.305462218 24.584472541, 124.305466693 24.58448282, 124.305471349 24.584489135, 124.305475201 24.584490748, 124.305479144 24.584489297, 124.305483087 24.584486306, 124.305486342 24.584484135, 124.305491466 24.584479162, 124.30549441 24.58447518, 124.305495785 24.584469847, 124.305491894 24.584450901, 124.30549096 24.584435189, 124.305492425 24.584425973, 124.305496563 24.584423081, 124.305504747 24.584419811, 124.30551096 24.584417541, 124.305516783 24.584416541, 124.305530817 24.584422468, 124.305545564 24.584436342, 124.305553281 24.584443099, 124.3055607 24.584448045, 124.305568612 24.58445309, 124.305571284 24.584454982, 124.305581453 24.584455414, 124.305588067 24.584452505, 124.305610246 24.584441, 124.305623139 24.584459838, 124.305637691 24.584479405, 124.305667185 24.584506613, 124.305703385 24.58453182, 124.305752931 24.584563586, 124.305811077 24.584599946, 124.305809715 24.584611234, 124.305810026 24.584613495, 124.305809248 24.584620991, 124.30580572 24.584631018, 124.30580061 24.584641144, 124.305800246 24.584651342, 124.305804021 24.58466045, 124.305812438 24.584671991, 124.305822231 24.584679198, 124.305837056 24.584686477, 124.305849105 24.584689793, 124.305859883 24.584691946, 124.305872231 24.584695261, 124.305885175 24.584700559, 124.305898119 24.584705405, 124.305914436 24.584711514, 124.30592847 24.584720694, 124.305935214 24.584733234, 124.30593524 24.584742441, 124.305930817 24.584749586, 124.305926083 24.584753568, 124.305921245 24.584755288, 124.30591454 24.584756117, 124.305906252 24.584757937, 124.305897964 24.584761568, 124.30588978 24.584765919, 124.305886732 24.584770441, 124.305889027 24.58478127, 124.305892503 24.584792459, 124.305895486 24.584800577, 124.305894617 24.584809333, 124.305890506 24.584818919, 124.305885188 24.584825514, 124.305875824 24.584833297, 124.305865966 24.584842622, 124.305856913 24.584854288, 124.305852399 24.584867387, 124.305851946 24.584880207, 124.305853152 24.584890856, 124.305857121 24.584899072, 124.305865525 24.584905099, 124.305873437 24.584907973, 124.305881829 24.584909315, 124.305889339 24.584908486, 124.305896732 24.584906477, 124.305907588 24.584902396, 124.305914189 24.584899315, 124.305921595 24.584895144, 124.305930065 24.58488836, 124.305948781 24.584872423, 124.305961102 24.584860306, 124.305970545 24.584844036, 124.305979676 24.584823973, 124.306014877 24.584847919, 124.306057224 24.584882315, 124.306093243 24.584911495, 124.306131712 24.584939054, 124.306181154 24.584968198, 124.306166952 24.584976991, 124.306159754 24.584980883, 124.306152853 24.584984514, 124.306144773 24.584987955, 124.306136589 24.584992306, 124.306130376 24.584997919, 124.306123281 24.585005252, 124.306118664 24.585012297, 124.306115032 24.585021964, 124.306110519 24.585034532, 124.30610476 24.585062441, 124.306102516 24.585073459, 124.306099377 24.585082676, 124.306091401 24.58509109, 124.306079611 24.585115486, 124.306076589 24.585129306, 124.306071297 24.585144937, 124.306067276 24.585160117, 124.306065837 24.585173117, 124.306067445 24.585187018, 124.306073593 24.585195586, 124.306085863 24.585207207, 124.306098418 24.585214766, 124.306111946 24.58521609, 124.306126848 24.585213081, 124.306139274 24.58520809, 124.306151803 24.585201387, 124.306165811 24.585194315, 124.306181401 24.585189946, 124.306194825 24.585188117, 124.306206472 24.58518927, 124.306220597 24.585190144, 124.306236796 24.585190198, 124.306248833 24.585188459, 124.306258988 24.585183919, 124.306277043 24.585175847, 124.30628572 24.585171955, 124.306301505 24.585164694, 124.306317082 24.585157081, 124.306339364 24.585142405, 124.306350402 24.585134622, 124.306363411 24.585125658, 124.30637524 24.585116153, 124.306390013 24.585102757, 124.30639987 24.585093802, 124.30641799 24.585075793, 124.306429131 24.585065658, 124.306443217 24.585052631, 124.306470713 24.585030631, 124.306483619 24.585019595, 124.306528054 24.584982216, 124.306607367 24.585033423, 124.306709857 24.585111225, 124.306808911 24.585200315, 124.306866304 24.585253468, 124.306899377 24.585289793, 124.306880636 24.585299486, 124.306874812 24.585302027, 124.306866628 24.585305658, 124.306859637 24.585312982, 124.30685511 24.585319586, 124.306854241 24.585325459, 124.306857017 24.585331495, 124.306861479 24.585339523, 124.306865344 24.585347009, 124.306861738 24.585364811, 124.30685594 24.585373577, 124.306850726 24.585385234, 124.306845422 24.585393189, 124.306838625 24.585400604, 124.306829948 24.585407306, 124.306818418 24.585415009, 124.306808366 24.585421432, 124.306802153 24.585427315, 124.306799611 24.58543436, 124.306804462 24.585444649, 124.306811997 24.585453928, 124.30682249 24.585464207, 124.306831894 24.585472766, 124.306841595 24.585483216, 124.306851582 24.585493306, 124.306859792 24.585497982, 124.306862568 24.585503757, 124.306864578 24.585517207, 124.306863619 24.585528405, 124.306861958 24.585538162, 124.306866628 24.58554709, 124.306874527 24.585548333, 124.306882827 24.585548586, 124.306895071 24.585550009, 124.306907315 24.585552694, 124.306919961 24.585555018, 124.306935668 24.585558144, 124.30694773 24.58556173, 124.306966213 24.585567829, 124.306983891 24.585572676, 124.306992789 24.585575541, 124.307016096 24.585577568, 124.307023787 24.585575568, 124.307030402 24.585572667, 124.307033748 24.585570135, 124.307046848 24.585558459, 124.307082931 24.58561545, 124.307082257 24.585621045, 124.307079507 24.58562818, 124.307080013 24.585634685, 124.307082996 24.585642441, 124.30708716 24.585650378, 124.307093813 24.585662468, 124.307102036 24.585675631, 124.307107185 24.585681126, 124.307115292 24.58568418, 124.307124073 24.585684162, 124.307132763 24.585681523, 124.307140169 24.585680973, 124.307146783 24.585682396, 124.307152023 24.585684288, 124.30715489 24.585688793, 124.307154812 24.585693126, 124.307152944 24.585700351, 124.307150298 24.585707946, 124.307145694 24.585723396, 124.307142062 24.585730081, 124.307126796 24.585745459, 124.307123256 24.585751613, 124.307117445 24.585758216, 124.307114112 24.585765622, 124.307110182 24.58577773, 124.307109611 24.585786847, 124.307106083 24.585795883, 124.307105512 24.585805459, 124.307109572 24.585809333, 124.307113022 24.585808874, 124.307119235 24.585806063, 124.307126537 24.585802523, 124.307131466 24.585800622, 124.307141141 24.585799423, 124.307145979 24.585800045, 124.307155966 24.585802829, 124.307171881 24.585808568, 124.307176316 24.585809108, 124.307180272 24.585808378, 124.307190713 24.585801495, 124.307199196 24.585794973, 124.307211206 24.585781946, 124.30721716 24.585793126, 124.307224591 24.585806027, 124.307234215 24.585820721, 124.307246304 24.585839477, 124.307255318 24.585852369, 124.307279883 24.58588582, 124.307295032 24.585904117, 124.307316719 24.585928991, 124.307325435 24.58593936, 124.307328106 24.585940162, 124.307336719 24.585950441, 124.307354137 24.585965117, 124.307372646 24.585982414, 124.307395006 24.586002955, 124.307412231 24.586020081, 124.307431738 24.586041162, 124.307447276 24.58605982, 124.307464916 24.58608227, 124.307477095 24.586098315, 124.307489287 24.586114811, 124.307505824 24.586137532, 124.307512659 24.586147721, 124.307528119 24.586171162, 124.30753358 24.586180901, 124.307545785 24.58620345, 124.307553813 24.586218423, 124.307568003 24.586248009, 124.30758607 24.586286793, 124.307607043 24.586344901, 124.307605175 24.586345712, 124.307600739 24.586347892, 124.307594034 24.586351784, 124.307587821 24.586355405, 124.307578353 24.586359495, 124.307568781 24.586361766, 124.307561569 24.586362234, 124.307550713 24.586363883, 124.30753917 24.586367514, 124.307527925 24.586373586, 124.307518262 24.586380108, 124.307510182 24.586386631, 124.307502503 24.586394045, 124.307495409 24.58640282, 124.307484384 24.586415477, 124.307474137 24.586423721, 124.307457782 24.586435667, 124.307444176 24.586447973, 124.307435707 24.586457117, 124.307425875 24.586471396, 124.307414163 24.586488036, 124.307395058 24.586509018, 124.307384799 24.586515, 124.307374643 24.586517279, 124.30736655 24.58651955, 124.307354812 24.586524721, 124.307343865 24.586529622, 124.307334695 24.586533703, 124.307327782 24.586537423, 124.307324137 24.586541937, 124.307325162 24.586556027, 124.307331595 24.586559802, 124.307338703 24.586561955, 124.307345824 24.586562757, 124.307353022 24.586562378, 124.307361219 24.58656182, 124.307366459 24.586561901, 124.30737297 24.586562793, 124.307378016 24.586567018, 124.307380298 24.586572793, 124.307380026 24.586578577, 124.307381712 24.586585793, 124.30738716 24.586589757, 124.307395447 24.586590459, 124.307408885 24.586591514, 124.307420623 24.586588784, 124.307429896 24.586582901, 124.307435616 24.586578189, 124.307438366 24.586572045, 124.307442296 24.58656355, 124.30744869 24.586557036, 124.30745786 24.586550333, 124.307469494 24.586542279, 124.307479546 24.586536387, 124.30749118 24.586529324, 124.307501141 24.586524333, 124.307511297 24.586520252, 124.307517821 24.586521414, 124.307520506 24.586526369, 124.307521012 24.586532964, 124.307519157 24.586541991, 124.3075169 24.586548955, 124.307515447 24.586558342, 124.307516265 24.586569901, 124.30751786 24.586578297, 124.307521634 24.586586685, 124.307528664 24.586596514, 124.307532425 24.586600568, 124.307540246 24.586609306, 124.307553709 24.586619748, 124.307567432 24.586621441, 124.307573061 24.586622153, 124.307600584 24.586610811, 124.307605824 24.586611613, 124.307610765 24.586613045, 124.307616589 24.586615198, 124.307624397 24.586618793, 124.307640233 24.586630955, 124.307652503 24.586642216, 124.307677043 24.586663649, 124.307689805 24.586675631, 124.307713165 24.586696441, 124.307735707 24.586712018, 124.307757756 24.586722802, 124.307788911 24.586740532, 124.30781284 24.58675818, 124.307815914 24.586765126, 124.307818898 24.586773423, 124.307819611 24.586781099, 124.307818936 24.586788505, 124.307820246 24.586796351, 124.307822633 24.586805198, 124.307825136 24.586817198, 124.307824669 24.586827946, 124.307821038 24.586836532, 124.307814436 24.586844937, 124.30780607 24.586855432, 124.307800467 24.586864829, 124.307798612 24.586873685, 124.307800999 24.586881261, 124.307805162 24.586886216, 124.307818197 24.586890532, 124.307825214 24.586892315, 124.30783332 24.586894378, 124.307839546 24.58689518, 124.30784655 24.586893541, 124.307853645 24.586888739, 124.307854929 24.586886297, 124.307856991 24.586881423, 124.307856589 24.586878532, 124.307855979 24.586876, 124.307849546 24.586866991, 124.307853178 24.586857225, 124.307868534 24.586839054, 124.30788882 24.586856162, 124.307901089 24.586865982, 124.307915525 24.586878414, 124.307930869 24.586892919, 124.307943048 24.586906072, 124.307956913 24.586921757, 124.307971764 24.586936802, 124.307987198 24.586951757, 124.308001349 24.58696527, 124.308015396 24.586976802, 124.308032815 24.586993198, 124.308051816 24.587010946, 124.308074384 24.587030036, 124.308094462 24.587045171, 124.308112166 24.587060207, 124.308126913 24.58707318, 124.308142944 24.587086784, 124.308156991 24.587098577, 124.308171543 24.587112, 124.308201933 24.587143541, 124.308214306 24.587157694, 124.308226693 24.587171838, 124.308256291 24.587201667, 124.308269844 24.58721455, 124.308278158 24.587222658, 124.308299546 24.58724582, 124.308323113 24.587272225, 124.308333333 24.587284568, 124.308344994 24.587298631, 124.308363606 24.587320171, 124.308396213 24.587366514, 124.308429715 24.587418811, 124.30845262 24.587458856, 124.308479598 24.587507198, 124.308471518 24.587514162, 124.308468262 24.587516333, 124.308464125 24.587519234, 124.308459689 24.587523126, 124.308456835 24.58752873, 124.308456161 24.587536946, 124.308456485 24.587545973, 124.308456407 24.587556721, 124.308454254 24.587564937, 124.308449844 24.587577775, 124.308446809 24.587587982, 124.30844546 24.587599631, 124.308445396 24.587615252, 124.308445551 24.58763945, 124.308446278 24.587650099, 124.308448962 24.587659577, 124.308452646 24.587669676, 124.308459481 24.587679955, 124.30847284 24.587692568, 124.308496576 24.587708505, 124.308500636 24.587710207, 124.308513268 24.587711631, 124.308516926 24.587710721, 124.308521167 24.587708811, 124.308536835 24.587695874, 124.308549741 24.587725009, 124.308546005 24.587733775, 124.308541284 24.587741369, 124.308535979 24.587749505, 124.308531154 24.587756468, 124.308526822 24.587762703, 124.308519429 24.587767234, 124.308510661 24.587773297, 124.308499909 24.58778118, 124.308489857 24.587787793, 124.308480986 24.587792234, 124.30847537 24.587796486, 124.308472023 24.587800919, 124.308473917 24.587809216, 124.308477082 24.587812189, 124.308483217 24.587816694, 124.308488158 24.587819847, 124.308493891 24.587823261, 124.308500026 24.587825775, 124.308504968 24.587826946, 124.308514047 24.587827018, 124.308524799 24.587823919, 124.308536939 24.587818477, 124.308567588 24.587798009, 124.308576796 24.587808919, 124.308587004 24.587823703, 124.308597613 24.587840928, 124.308607536 24.587857072, 124.308620117 24.587877721, 124.308646589 24.587918477, 124.308659961 24.587935784, 124.308676394 24.587955883, 124.308688288 24.587971117, 124.308702646 24.587989955, 124.308714838 24.58800709, 124.308726031 24.588023946, 124.308736446 24.588041351, 124.308766291 24.588090775, 124.308777198 24.588110703, 124.308789702 24.588136045, 124.308806304 24.588181703, 124.308802853 24.588184775, 124.308797536 24.588189477, 124.308792607 24.588194189, 124.308787393 24.588201423, 124.308782866 24.588210459, 124.308780026 24.588218495, 124.308775019 24.588230423, 124.308762853 24.588263495, 124.308760311 24.588272351, 124.308755694 24.588278865, 124.308751453 24.588282387, 124.308746226 24.588284838, 124.30874406 24.588285838, 124.308741089 24.588286117, 124.308733294 24.588284595, 124.308725979 24.588282351, 124.308719741 24.588276135, 124.30871677 24.58827127, 124.308716355 24.588265486, 124.308716148 24.588259441, 124.308715435 24.588250685, 124.308712646 24.588242568, 124.308707004 24.588237342, 124.308702659 24.588235811, 124.308696433 24.58823664, 124.308690921 24.588239721, 124.308688457 24.588243063, 124.308680986 24.588255631, 124.308674799 24.588267649, 124.308666329 24.588279225, 124.308659248 24.588289081, 124.3086569 24.588297667, 124.308654942 24.588305793, 124.308653385 24.58831591, 124.308656667 24.588324207, 124.308661907 24.588329973, 124.308667938 24.588330234, 124.308674838 24.588328324, 124.308682335 24.588325514, 124.308690726 24.588321342, 124.308699507 24.588317441, 124.308707497 24.588313901, 124.308714099 24.588311, 124.308720117 24.58830927, 124.308726537 24.588310072, 124.308729313 24.588313135, 124.308729715 24.588316568, 124.30873061 24.588321892, 124.308729741 24.588326495, 124.308723463 24.588344297, 124.30872013 24.588352072, 124.308711271 24.58836355, 124.308704851 24.588366459, 124.308698444 24.58836936, 124.308689468 24.588373351, 124.308681582 24.588376883, 124.308672802 24.588380784, 124.308665798 24.588384865, 124.308659987 24.588390288, 124.308656939 24.588398514, 124.308655979 24.588408991, 124.30866035 24.588420721, 124.308667782 24.588428559, 124.308672231 24.58842855, 124.308677847 24.588426369, 124.308684358 24.588423468, 124.308692153 24.588420018, 124.308700726 24.588415757, 124.308717795 24.588407784, 124.308731997 24.588402063, 124.308745318 24.588397072, 124.308759533 24.588394423, 124.308772944 24.588392225, 124.308783204 24.588388234, 124.308790506 24.588381901, 124.308807847 24.588365973, 124.308818067 24.588390694, 124.308825914 24.588407198, 124.30884454 24.588435694, 124.308869805 24.588470126, 124.308897938 24.588503117, 124.308925759 24.588534027, 124.308960026 24.588575306, 124.308955409 24.588587234, 124.308952075 24.588594198, 124.30894537 24.588602153, 124.308935045 24.588617162, 124.308927977 24.588636955, 124.308920817 24.588655838, 124.308917704 24.588673721, 124.308914981 24.588690793, 124.308912763 24.58871418, 124.308911933 24.588733234, 124.308919676 24.58875245, 124.308933061 24.588777162, 124.308946835 24.588797622, 124.308967237 24.588818532, 124.308981971 24.588830144, 124.309000558 24.588837423, 124.309017549 24.588839559, 124.309069974 24.588838631, 124.309083398 24.588877523, 124.30909284 24.588901793, 124.309111907 24.588945721, 124.309132568 24.588994613, 124.309154799 24.589041243, 124.309177121 24.589084541, 124.309174747 24.58908545, 124.309167445 24.58908609, 124.309156096 24.589087919, 124.309141492 24.589089577, 124.309128768 24.589094748, 124.309124825 24.589101171, 124.309128807 24.589112991, 124.309134358 24.589120108, 124.309145512 24.589122973, 124.309162789 24.589121495, 124.309186589 24.58912036, 124.309197419 24.589147063, 124.309209948 24.589185595, 124.309200195 24.589191126, 124.309190623 24.589195568, 124.309178003 24.589200378, 124.309165564 24.589204559, 124.309152451 24.589211261, 124.309142594 24.589219865, 124.309134527 24.589232333, 124.30913358 24.589244622, 124.309142892 24.589258595, 124.30916118 24.589265874, 124.309180649 24.589274946, 124.30919559 24.589287378, 124.309208833 24.589294486, 124.309214565 24.589294108, 124.309215837 24.589288874, 124.309214929 24.589279126, 124.309210752 24.589269919, 124.309207276 24.589263423, 124.309202114 24.589252604, 124.309202789 24.589246009, 124.309211284 24.589244189, 124.309217419 24.589248604, 124.309224137 24.58925355, 124.309231868 24.589262928, 124.309238119 24.589276189, 124.309240713 24.589288189, 124.309242153 24.589308775, 124.309242581 24.589324387, 124.309241933 24.589343171, 124.30924131 24.589366378, 124.309247588 24.589389838, 124.309251595 24.589413396, 124.309242503 24.589413505, 124.309231842 24.589414432, 124.309218236 24.589423757, 124.309215188 24.589427198, 124.309202192 24.589440135, 124.309190934 24.589443766, 124.309184332 24.589445135, 124.309180778 24.589445685, 124.309165863 24.589447793, 124.309144553 24.589451721, 124.309128664 24.589457982, 124.309117925 24.589466306, 124.309110545 24.589479234, 124.309101401 24.589493153, 124.309088119 24.589511243, 124.309068807 24.589530694, 124.309050986 24.589548694, 124.309021349 24.589585414, 124.308997328 24.589614541, 124.308973891 24.589642937, 124.308950078 24.589675577, 124.308938573 24.589695649, 124.30893537 24.589713532, 124.308944682 24.589731027, 124.308967834 24.589748045, 124.308992542 24.589754225, 124.309021167 24.589753622, 124.309045966 24.58975709, 124.309067497 24.589761468, 124.309088846 24.589766306, 124.309110467 24.589769694, 124.309125097 24.589772279, 124.309131323 24.589778405, 124.309134008 24.58978364, 124.309135097 24.589786613, 124.309134721 24.589790315, 124.309132659 24.589795018, 124.309116018 24.589813919, 124.309100752 24.589833, 124.309085707 24.589855874, 124.30906406 24.589888604, 124.3090562 24.589903153, 124.309044086 24.589915459, 124.309029105 24.589926505, 124.309013917 24.589934577, 124.308996861 24.589946982, 124.308988288 24.589956658, 124.30897786 24.589972027, 124.308964669 24.589984874, 124.30894179 24.590000721, 124.308920493 24.590012054, 124.308891102 24.590026919, 124.308873372 24.590041045, 124.308857134 24.590063468, 124.308839598 24.59008382, 124.308817834 24.590105802, 124.308799209 24.590123081, 124.308786615 24.590137288, 124.308787121 24.590146225, 124.308794241 24.590150811, 124.30881489 24.590155288, 124.308838703 24.590159387, 124.308857678 24.590164586, 124.308872412 24.590172685, 124.30888476 24.59017591, 124.308905188 24.590174333, 124.308932218 24.590163441, 124.308969598 24.590144495, 124.30899463 24.590122324, 124.309011271 24.590102874, 124.309030623 24.590066901, 124.309066057 24.590098793, 124.309089131 24.590124658, 124.309123982 24.590165036, 124.309170636 24.590226063, 124.309214241 24.590288631, 124.30926201 24.590360225, 124.309298482 24.590415315, 124.30934022 24.590484207, 124.309374929 24.59054409, 124.309416291 24.590617225, 124.309470143 24.590711559, 124.309513268 24.590781261, 124.309564423 24.590864036, 124.309577315 24.590888027, 124.309587834 24.590910856, 124.309593035 24.590938288, 124.309604267 24.590965081, 124.309620402 24.590982198, 124.309633074 24.590997432, 124.309639624 24.591009432, 124.309644125 24.591031631, 124.309646952 24.59105718, 124.309653722 24.591081541, 124.309667108 24.59110445, 124.30968703 24.591132486, 124.309712192 24.591169721, 124.309763852 24.591252405, 124.309788846 24.591298946, 124.309814047 24.591345757, 124.309834968 24.591384991, 124.30985799 24.591431072, 124.309880817 24.591477441, 124.309906706 24.591526324, 124.309926161 24.591563027, 124.309958495 24.591625982, 124.30998036282082 24.591666666666665, 124.3125 24.591666666666665, 124.3125 24.583333333333332, 124.30430972839943 24.583333333333332, 124.304327562 24.583348216))\n\n\n沖縄県\nNA\nNA\n石垣市\nNA\n47207\n36247205\n47207\n3.9976\nPOLYGON ((124.3125 24.591666666666665, 124.325 24.591666666666665, 124.325 24.583333333333332, 124.3125 24.583333333333332, 124.3125 24.591666666666665))\n\n\n沖縄県\nNA\nNA\n石垣市\nNA\n47207\n36246294\n47207\n3.0070\nPOLYGON ((124.300036316 24.575503667, 124.300093424 24.575566477, 124.300119663 24.575596946, 124.300107445 24.575606991, 124.300090791 24.575616955, 124.300076291 24.575624027, 124.300068016 24.575631721, 124.300057782 24.575645459, 124.300042309 24.575657595, 124.300034137 24.575668532, 124.300030506 24.575678108, 124.300034099 24.57569327, 124.300035603 24.575704559, 124.300029818 24.57572109, 124.300021777 24.575743315, 124.300006433 24.575767991, 124.3 24.57578, 124.3 24.575818982, 124.300008262 24.575831189, 124.300014397 24.575837144, 124.300022892 24.575838117, 124.300029896 24.575836297, 124.300050013 24.575827495, 124.300069935 24.575816802, 124.300081167 24.575809108, 124.300094695 24.575807189, 124.300122088 24.57578582, 124.300168223 24.57583891, 124.30022061 24.575901198, 124.300248145 24.575939694, 124.300276783 24.575985775, 124.300299287 24.57602455, 124.300286563 24.576030811, 124.300276226 24.576038685, 124.300268638 24.576049351, 124.300262646 24.576057306, 124.300252581 24.576063108, 124.300230259 24.576060892, 124.300200558 24.576063937, 124.300191089 24.576072081, 124.300188379 24.576090595, 124.300191751 24.576098441, 124.300195603 24.576098793, 124.300227886 24.57609927, 124.30023668 24.576103405, 124.300238366 24.576106658, 124.300235525 24.576115234, 124.300236329 24.576122189, 124.30024118 24.576127414, 124.300254125 24.576127027, 124.300262192 24.576120153, 124.300277665 24.576108018, 124.300294825 24.576099135, 124.300309027 24.576092883, 124.30032847 24.576089685, 124.300351427 24.576108324, 124.300362529 24.576129432, 124.300384449 24.576168396, 124.300404838 24.57619345, 124.300416252 24.576215099, 124.300425577 24.576235667, 124.300441958 24.57627509, 124.300412451 24.576321378, 124.30039275 24.576340739, 124.300376511 24.576361171, 124.300369624 24.576371568, 124.300361634 24.576375739, 124.300352464 24.576377748, 124.300307626 24.576371423, 124.30029262 24.576374703, 124.300286706 24.576377333, 124.300272127 24.57638973, 124.300235006 24.576432694, 124.300221336 24.576458, 124.300216252 24.576480225, 124.300219728 24.57648536, 124.300229326 24.576493829, 124.300267977 24.576516144, 124.300284786 24.576527396, 124.300308106 24.576535838, 124.300331025 24.576537775, 124.300341089 24.576534685, 124.300351738 24.576528703, 124.30036594 24.57652245, 124.300377769 24.576517279, 124.300387769 24.576569532, 124.300391064 24.576582712, 124.300399092 24.576596514, 124.30041345 24.57661418, 124.300438457 24.576628577, 124.300465253 24.576642063, 124.300447458 24.576673252, 124.300437523 24.576687622, 124.300423139 24.576705892, 124.300399896 24.576725441, 124.30037524 24.576740928, 124.30036332 24.576750162, 124.300357224 24.57676218, 124.300343359 24.576786946, 124.300324163 24.576810009, 124.300308612 24.57682891, 124.300301336 24.576842739, 124.300297315 24.576853126, 124.300305551 24.57686882, 124.30030834 24.576878297, 124.30030559 24.576886883, 124.300309261 24.576893919, 124.300330013 24.576898748, 124.300343061 24.576908387, 124.300351388 24.576921369, 124.300349429 24.576930225, 124.30035096 24.576948189, 124.300357211 24.57696009, 124.30036799 24.576966757, 124.300378846 24.57696664, 124.300386615 24.576956514, 124.300394306 24.576953153, 124.300402892 24.576950072, 124.300410882 24.576945901, 124.300417769 24.576936856, 124.300413502 24.576928739, 124.300413385 24.576918811, 124.300421375 24.57691464, 124.30042869 24.576917423, 124.300443722 24.576930757, 124.300476861 24.576954892, 124.300488418 24.576960459, 124.300500272 24.57695927, 124.300515863 24.576957072, 124.300540623 24.576947541, 124.300552075 24.576949865, 124.300556641 24.576958523, 124.300566057 24.576975027, 124.300587185 24.57701236, 124.300620376 24.577064486, 124.30062249 24.577078198, 124.300630804 24.577088477, 124.30063131 24.577093622, 124.30063786 24.577107423, 124.300634734 24.577119441, 124.300628223 24.577123694, 124.30061917 24.577134279, 124.300613671 24.577147378, 124.300606265 24.577189919, 124.300608366 24.577201018, 124.300613307 24.577206162, 124.300620026 24.577207865, 124.300629494 24.577203685, 124.300634916 24.577198712, 124.300648145 24.577197514, 124.300653178 24.577196054, 124.300657601 24.577190721, 124.300664877 24.577176892, 124.300669287 24.57716027, 124.300665914 24.577153775, 124.300665707 24.577149171, 124.300671608 24.577143928, 124.30068227 24.577139207, 124.300707017 24.577166964, 124.300724462 24.577196009, 124.300741115 24.577223333, 124.300765188 24.577255423, 124.300827665 24.577329964, 124.300869235 24.577377018, 124.300886978 24.577403883, 124.300907704 24.577443387, 124.300916161 24.577466396, 124.300912166 24.577493396, 124.300902802 24.577496216, 124.300891543 24.577498495, 124.30088166 24.57749482, 124.300853982 24.577480964, 124.300841647 24.57747973, 124.300828029 24.57748436, 124.300777562 24.577521207, 124.300770973 24.577529432, 124.300770493 24.577537018, 124.300777639 24.57755055, 124.300788119 24.577557937, 124.30079939 24.577564234, 124.300811829 24.577562856, 124.300820026 24.577563198, 124.300838482 24.577562441, 124.30086 24.577557613, 124.300889598 24.577548703, 124.300906667 24.577545144, 124.300917017 24.577539982, 124.300934565 24.577526216, 124.300975512 24.577556928, 124.300993035 24.577577838, 124.301015551 24.577617973, 124.301055759 24.577673604, 124.301076589 24.577709135, 124.301101725 24.577737432, 124.301141025 24.57777618, 124.301183256 24.577808865, 124.301209663 24.577825883, 124.301203268 24.577838622, 124.30120022 24.577845306, 124.301203113 24.577853432, 124.30121262 24.577864604, 124.30122013 24.577867928, 124.301234332 24.577864378, 124.301248158 24.57786291, 124.301262477 24.577865315, 124.301273463 24.577875135, 124.301278742 24.577897523, 124.301269948 24.577933378, 124.301247445 24.577977937, 124.301227665 24.578005243, 124.301226005 24.578015991, 124.301234838 24.578032766, 124.301246239 24.578054414, 124.301254189 24.578072279, 124.301249572 24.578082937, 124.301237004 24.578114477, 124.3012393 24.578121514, 124.301250571 24.578130523, 124.301253346 24.578137288, 124.301256433 24.578145946, 124.301250726 24.578155802, 124.301240415 24.578176315, 124.301243191 24.578184432, 124.301254306 24.578205541, 124.301266187 24.578218342, 124.301274799 24.578226541, 124.301287056 24.578233108, 124.301308184 24.578233153, 124.301344825 24.578237685, 124.301347406 24.57824391, 124.30134406 24.578250054, 124.30132275 24.578258045, 124.301316757 24.57826609, 124.301315396 24.578277288, 124.301320259 24.578286486, 124.30133192 24.578293414, 124.301358288 24.578296432, 124.301371349 24.578307423, 124.301380765 24.578322577, 124.301400454 24.578340595, 124.301413684 24.578340748, 124.301439339 24.578334099, 124.301455435 24.578334342, 124.301469974 24.578342622, 124.301497834 24.578349784, 124.301510078 24.578351027, 124.301520143 24.578347937, 124.301524968 24.578341784, 124.301530363 24.578331396, 124.301537082 24.57833309, 124.301552516 24.578342991, 124.301593087 24.578379838, 124.30161703 24.578404622, 124.301643385 24.578443667, 124.30161013 24.578448333, 124.301593268 24.578455054, 124.301571453 24.578462045, 124.301565538 24.578464586, 124.30156013 24.578471009, 124.301558859 24.578476883, 124.301568067 24.578491486, 124.3015769 24.578508261, 124.301577821 24.57851982, 124.301567964 24.578528865, 124.301556174 24.578550739, 124.301550804 24.578576396, 124.301553748 24.578611144, 124.301557082 24.578642288, 124.301565227 24.578663405, 124.301575629 24.578676108, 124.301593709 24.578684198, 124.301618392 24.578681351, 124.301632594 24.57867645, 124.301640272 24.578669027, 124.30165013 24.578661333, 124.301664332 24.578655081, 124.301678158 24.578652342, 124.301694137 24.578646712, 124.30171489 24.578655613, 124.301728054 24.578672378, 124.301730169 24.57868745, 124.301702866 24.57870755, 124.301687678 24.578716153, 124.301676861 24.578734234, 124.301667938 24.578756189, 124.301658586 24.578771649, 124.301645396 24.578788108, 124.301629339 24.578800514, 124.301611505 24.57881364, 124.301606083 24.578821414, 124.301608288 24.578831072, 124.301616394 24.578839541, 124.301632542 24.578859099, 124.301636213 24.578867495, 124.301632568 24.578873099, 124.301625175 24.578876991, 124.30160476 24.578887955, 124.301594916 24.57889827, 124.301589715 24.578910559, 124.301591997 24.578916243, 124.301600013 24.578924721, 124.301605175 24.578935811, 124.30160144 24.578944036, 124.301592996 24.578961117, 124.30159607 24.578968423, 124.301603009 24.578978703, 124.301602231 24.578985748, 124.301595564 24.579002009, 124.301572464 24.579049459, 124.301551621 24.579085982, 124.301544734 24.579095018, 124.301533813 24.579111748, 124.301521984 24.579117009, 124.301510246 24.57912082, 124.301500674 24.579127703, 124.301496161 24.579137009, 124.301465616 24.579206414, 124.301455175 24.579217, 124.301442581 24.579231919, 124.301429105 24.579251811, 124.301424358 24.579289919, 124.301421933 24.579311595, 124.301423632 24.57931891, 124.301427601 24.579325126, 124.301435798 24.579326919, 124.301443995 24.579328613, 124.30144677 24.579335378, 124.301453502 24.579341054, 124.301462581 24.579339054, 124.301486848 24.579329793, 124.301491206 24.579333847, 124.301493398 24.579342243, 124.301488405 24.579359045, 124.301498003 24.579367514, 124.30151262 24.57937173, 124.301525045 24.579366288, 124.301536667 24.579353802, 124.301542594 24.579352613, 124.301546355 24.579356946, 124.30155061 24.579362351, 124.301563463 24.579367378, 124.301570571 24.579366919, 124.301580039 24.579362748, 124.30160476 24.579337865, 124.301614721 24.579337486, 124.301618794 24.579345063, 124.301627497 24.579349198, 124.301652542 24.579377495, 124.301634669 24.579416721, 124.301623606 24.579459532, 124.30161655 24.579480676, 124.30162022 24.579489063, 124.301627562 24.579504495, 124.301637873 24.579521261, 124.301647471 24.57952973, 124.301656381 24.579538468, 124.301661362 24.579557604, 124.301652711 24.579570081, 124.301651647 24.579580559, 124.301655707 24.579585423, 124.301663009 24.579585586, 124.301697069 24.579585252, 124.301719377 24.579583396, 124.301738016 24.579574514, 124.301764825 24.579553423, 124.301786887 24.57956909, 124.301815863 24.579592324, 124.301828833 24.579607288, 124.301820298 24.579631054, 124.301825071 24.579641604, 124.301834462 24.579645468, 124.301843541 24.57964482, 124.30185904 24.579645324, 124.30188415 24.579656928, 124.301901647 24.57966664, 124.301917575 24.579680243, 124.301894656 24.579715685, 124.3018862 24.579728703, 124.301878625 24.579741991, 124.301876096 24.579755171, 124.301870298 24.579766378, 124.30185917 24.579782568, 124.30185249 24.579797477, 124.301847419 24.579821054, 124.30184716 24.579837216, 124.301851634 24.579848495, 124.301858781 24.579863378, 124.301867977 24.579874009, 124.301886368 24.579879928, 124.301915694 24.579881676, 124.30192192 24.579883649, 124.301931115 24.579892937, 124.301935979 24.579902135, 124.301936109 24.579912063, 124.301930895 24.579923, 124.301914241 24.579937027, 124.301899948 24.579948613, 124.301887536 24.579955414, 124.301880246 24.579966622, 124.301883126 24.579973297, 124.301883463 24.579986477, 124.301875396 24.579998775, 124.301863372 24.580011982, 124.301856485 24.580021018, 124.301857289 24.580028063, 124.301846291 24.580050207, 124.301839105 24.580062676, 124.301811128 24.580084315, 124.301799624 24.580105378, 124.301799248 24.580112874, 124.30180262 24.58011936, 124.301813593 24.580127829, 124.301826446 24.580135568, 124.30184284 24.580136351, 124.301850752 24.580138856, 124.301853917 24.580144811, 124.301855901 24.580149955, 124.301859572 24.580154279, 124.30186511 24.580156532, 124.301867471 24.580155532, 124.301888573 24.580145559, 124.301909403 24.580142351, 124.301935409 24.580155667, 124.301943126 24.580164856, 124.301943048 24.580172982, 124.301936355 24.580183829, 124.301929287 24.580201, 124.301930402 24.580209847, 124.301934955 24.580217153, 124.301944254 24.580223721, 124.301965201 24.580231811, 124.301996316 24.580238153, 124.302013671 24.58026855, 124.302030233 24.580298577, 124.302038768 24.580317523, 124.302044371 24.580349027, 124.302043528 24.580364009, 124.302005914 24.580369955, 124.301990233 24.580373423, 124.301981946 24.580377135, 124.301973671 24.580384739, 124.301952179 24.580400856, 124.301931777 24.580414532, 124.301921621 24.580421586, 124.301916213 24.580429369, 124.301914514 24.580462054, 124.301904695 24.58048636, 124.301873372 24.580516847, 124.301862555 24.580533577, 124.301856174 24.580547766, 124.301847743 24.580576036, 124.301824877 24.580592153, 124.301813761 24.580606991, 124.301816252 24.580615919, 124.301829092 24.580622306, 124.301844695 24.580620108, 124.30187965 24.580621387, 124.301893165 24.580619468, 124.301909053 24.580615099, 124.301913281 24.580607874, 124.301924527 24.580601622, 124.301933411 24.580601784, 124.301937082 24.580607459, 124.301949754 24.580621883, 124.301962399 24.580625018, 124.301972451 24.580620577, 124.301979261 24.580618216, 124.301993593 24.580620622, 124.302006732 24.580626189, 124.30201594 24.580636739, 124.30200799 24.580656252, 124.302008236 24.580676117, 124.302007082 24.580690658, 124.302014812 24.580703919, 124.302029274 24.580718874, 124.302034423 24.580728613, 124.302024864 24.580736847, 124.302012438 24.580742288, 124.302001206 24.580749901, 124.301994604 24.580756775, 124.301973813 24.580772613, 124.301954073 24.58077527, 124.301949339 24.580778712, 124.301945019 24.580788568, 124.301935331 24.580825514, 124.301918975 24.580840081, 124.301902607 24.580847874, 124.301879118 24.580852892, 124.301859572 24.580857441, 124.301852179 24.580862694, 124.301848547 24.580871009, 124.301841141 24.580909577, 124.30184511 24.580917153, 124.30184917 24.580920667, 124.301866446 24.580923072, 124.301914423 24.580916018, 124.301923982 24.580910495, 124.301927315 24.58090164, 124.301938145 24.58088627, 124.301967808 24.580865171, 124.301984384 24.580860622, 124.301994747 24.580856721, 124.301996602 24.580850577, 124.301999144 24.580836126, 124.302004643 24.58082573, 124.302018846 24.580819477, 124.302027211 24.580810432, 124.302033126 24.580806532, 124.302036174 24.580799847, 124.302043541 24.580783306, 124.302054864 24.580770288, 124.302057017 24.580761973, 124.302060156 24.580751315, 124.30207249 24.580752559, 124.302085927 24.580755955, 124.302097601 24.580762793, 124.302128651 24.580783144, 124.302169507 24.580816559, 124.302244501 24.580881505, 124.302305357 24.580933387, 124.302370467 24.580996099, 124.302439079 24.581071261, 124.302506381 24.58114227, 124.302539351 24.581175793, 124.302559235 24.581195703, 124.302590208 24.58122273, 124.30257808 24.58122745, 124.302570687 24.581235315, 124.302567938 24.581239928, 124.302551946 24.581244207, 124.30254406 24.581247108, 124.302535979 24.581252631, 124.302532931 24.581260586, 124.302535512 24.58126545, 124.30254144 24.58126418, 124.302559689 24.581258811, 124.302571051 24.581263847, 124.302587834 24.581261108, 124.302598482 24.581256477, 124.302612101 24.581250495, 124.302616537 24.581250486, 124.30263166 24.581258486, 124.30264454 24.581273811, 124.302655123 24.58128264, 124.302677977 24.581298577, 124.302697147 24.58131, 124.302710013 24.581318279, 124.302728794 24.581330252, 124.302737302 24.58133827, 124.302750869 24.581351883, 124.302769183 24.581371072, 124.30280192 24.581393937, 124.302800752 24.581403243, 124.302798807 24.581414171, 124.302796161 24.581421486, 124.302793204 24.581425018, 124.30278808 24.581430622, 124.302781984 24.581438135, 124.302779533 24.581446081, 124.302780739 24.581455559, 124.302783917 24.581463676, 124.302787588 24.58146909, 124.302792737 24.581476396, 124.302793152 24.581483883, 124.302795538 24.581491739, 124.302800687 24.581500577, 124.302805538 24.581503901, 124.302814617 24.581502982, 124.302824591 24.581505126, 124.302833593 24.581512333, 124.302841712 24.581521532, 124.302851012 24.581526928, 124.302860597 24.581529973, 124.302870869 24.581530045, 124.302880039 24.581528045, 124.302889416 24.581525676, 124.302896226 24.581524577, 124.302902646 24.581525739, 124.302903748 24.581529802, 124.302903165 24.581535306, 124.302901401 24.581541811, 124.302896381 24.581548505, 124.302887704 24.581554568, 124.302878638 24.581558739, 124.302872036 24.58156336, 124.302866913 24.581570324, 124.302864656 24.581576559, 124.302864981 24.581586036, 124.302867263 24.581594523, 124.302867004 24.581605261, 124.30286642 24.581612216, 124.302864565 24.581618991, 124.302861219 24.581624234, 124.302851673 24.581636622, 124.302844475 24.581643595, 124.302835901 24.581649928, 124.302825357 24.581655099, 124.302810649 24.581659099, 124.302799196 24.581661198, 124.302784202 24.581664117, 124.302777095 24.581664946, 124.302761401 24.581668586, 124.302757263 24.581670405, 124.302750259 24.581673577, 124.302748885 24.58167791, 124.302751375 24.581687387, 124.302756329 24.581695414, 124.302764449 24.581704694, 124.30277642 24.581715955, 124.302788197 24.581724243, 124.302804812 24.581733595, 124.302819144 24.581741063, 124.302829818 24.581745378, 124.302841479 24.581748514, 124.302850363 24.581750027, 124.302876316 24.581745279, 124.302884591 24.581737144, 124.302902711 24.581717514, 124.302926848 24.581695793, 124.302943878 24.581716342, 124.302940791 24.581742892, 124.302939027 24.581747685, 124.302936278 24.581755, 124.302929987 24.581768829, 124.302923307 24.581780306, 124.302916809 24.581789892, 124.302905875 24.581798045, 124.302891284 24.581811432, 124.302880169 24.581824459, 124.30286677 24.581838838, 124.302860272 24.581846622, 124.302852205 24.581860991, 124.302851647 24.581872009, 124.302853748 24.581883468, 124.302858016 24.58189655, 124.302861608 24.58191027, 124.302867069 24.58192082, 124.302874086 24.581925234, 124.302882374 24.581924405, 124.302893139 24.581921676, 124.302898664 24.581921387, 124.302908742 24.581924532, 124.302920415 24.581933622, 124.302936926 24.581941811, 124.302947782 24.581942595, 124.302953217 24.581940423, 124.302959027 24.581937793, 124.302966226 24.58193209, 124.302970649 24.581926477, 124.302987678 24.581905315, 124.303005707 24.581884243, 124.30302441 24.58186164, 124.303040363 24.581847342, 124.303075435 24.581813414, 124.303106226 24.581846937, 124.303102776 24.581850009, 124.303097458 24.581855712, 124.303092633 24.581862495, 124.303088703 24.58186873, 124.303083787 24.581878405, 124.303079857 24.581887351, 124.303073567 24.581899369, 124.30306856 24.581911387, 124.303062477 24.581926748, 124.303056291 24.581939766, 124.303049222 24.581956658, 124.30304393 24.581975541, 124.303037756 24.581994333, 124.30303227 24.582011856, 124.303032412 24.582028568, 124.303038366 24.58204164, 124.30304559 24.582046234, 124.303053982 24.582047117, 124.303063658 24.582046018, 124.303072348 24.58204555, 124.303079351 24.582047793, 124.303086576 24.582054279, 124.303095707 24.582070333, 124.303099079 24.582079081, 124.303102957 24.582088009, 124.303108301 24.582094775, 124.303118288 24.58209827, 124.303122335 24.582097811, 124.303129922 24.582094189, 124.303142815 24.58207791, 124.303147925 24.582067243, 124.303162685 24.582046541, 124.303172827 24.582032342, 124.30318917 24.582011541, 124.303201673 24.582000775, 124.303211038 24.581992811, 124.303221595 24.581987279, 124.303229494 24.581987541, 124.303232659 24.581991324, 124.303235629 24.581997009, 124.303238119 24.582003595, 124.30323725 24.58201091, 124.303236278 24.582020387, 124.303235409 24.582028604, 124.303235435 24.582036369, 124.303235058 24.582046306, 124.30324153 24.582068775, 124.303248366 24.582076523, 124.30325668 24.58208391, 124.303265383 24.582092739, 124.303287523 24.582102, 124.303292594 24.582114081, 124.30330847 24.582146649, 124.303317393 24.582161613, 124.303326304 24.582175595, 124.303337419 24.582195252, 124.303348521 24.58221509, 124.303363891 24.582241153, 124.303378664 24.582268306, 124.303411297 24.582329, 124.303447977 24.582391586, 124.303483463 24.582447766, 124.303473917 24.582463495, 124.303468418 24.582472351, 124.303463891 24.582479045, 124.303458872 24.582486099, 124.303455629 24.582493955, 124.303453372 24.582500279, 124.303451725 24.582509856, 124.303450752 24.582517532, 124.303450078 24.582524306, 124.303449403 24.582534153, 124.303449339 24.582543901, 124.303448949 24.582550766, 124.303450752 24.582556991, 124.303455097 24.582561135, 124.303459844 24.582560225, 124.303464565 24.582557595, 124.303467134 24.582554883, 124.303471362 24.582549721, 124.303475694 24.582543486, 124.303482892 24.582539045, 124.303507549 24.58252609, 124.3035131 24.58253682, 124.303519442 24.582548721, 124.303529754 24.582563153, 124.303544112 24.582582171, 124.303558768 24.582600829, 124.303574721 24.58262473, 124.303592361 24.582649703, 124.303609196 24.582671694, 124.303625045 24.582691712, 124.303641582 24.582712712, 124.303669611 24.582744712, 124.303686732 24.582761829, 124.303707704 24.582781378, 124.30373096 24.58280309, 124.303765603 24.582836432, 124.303790337 24.582857775, 124.303825266 24.582890477, 124.30384952 24.582917243, 124.303863969 24.582930667, 124.303886835 24.582953108, 124.303909403 24.582975811, 124.303928807 24.58299627, 124.303949585 24.583017351, 124.30396939 24.58303682, 124.303990169 24.58305745, 124.304008872 24.583074838, 124.304029559 24.583094748, 124.304045006 24.583111333, 124.304063307 24.583130712, 124.304080843 24.583152252, 124.304097082 24.583170009, 124.304113113 24.583186495, 124.304132218 24.583205955, 124.304144877 24.583215865, 124.304165746 24.583230631, 124.304188301 24.583244937, 124.304204812 24.583255018, 124.304230428 24.583272126, 124.304286706 24.583315441, 124.304305006 24.583329396, 124.304309728 24.583333333, 124.30430972839943 24.583333333333332, 124.3125 24.583333333333332, 124.3125 24.575, 124.3 24.575, 124.3 24.575466027, 124.300036316 24.575503667))\n\n\n沖縄県\nNA\nNA\n石垣市\nNA\n47207\n36246284\n47207\n2.0025\nPOLYGON ((124.3 24.575, 124.3125 24.575, 124.3125 24.566666666666666, 124.3 24.566666666666666, 124.3 24.575))\n\n\n沖縄県\nNA\nNA\n石垣市\nNA\n47207\n36246273\n47207\n22.0274\nPOLYGON ((124.287504604 24.564413162, 124.287525966 24.564427928, 124.287546926 24.564442964, 124.287565123 24.564456748, 124.287582827 24.564470982, 124.287595785 24.564481973, 124.287608353 24.564493234, 124.287649403 24.564531613, 124.287663943 24.564544865, 124.287678988 24.564557748, 124.287692438 24.564568369, 124.287701634 24.564575126, 124.287711219 24.564581703, 124.287721102 24.56458791, 124.287731388 24.564593847, 124.287747601 24.564602126, 124.287758962 24.564607072, 124.287773684 24.56461291, 124.287781686 24.564616955, 124.28778594 24.564620378, 124.287788612 24.564623802, 124.287790208 24.564627144, 124.28779179 24.564632468, 124.287775642 24.564645775, 124.287753256 24.564661342, 124.287745188 24.56467364, 124.287741077 24.564683577, 124.287743606 24.564712559, 124.287735032 24.564721144, 124.287712361 24.56473609, 124.287704968 24.564741432, 124.287699066 24.564748126, 124.287702036 24.564753532, 124.287719909 24.564754135, 124.287752257 24.56473809, 124.287765253 24.564726865, 124.28777144 24.564711324, 124.287780895 24.564701649, 124.287791543 24.564695577, 124.287798042 24.564687261, 124.287803359 24.564679486, 124.287818054 24.564672775, 124.287828911 24.564673928, 124.287860908 24.564677568, 124.287877523 24.564693432, 124.287904799 24.564704577, 124.287931375 24.564714541, 124.28795083 24.564715225, 124.28796406 24.564713847, 124.287980259 24.564719324, 124.287994682 24.564724261, 124.288005253 24.564728847, 124.288013969 24.564740928, 124.288027938 24.564758784, 124.288046433 24.56477518, 124.288056044 24.564788973, 124.288086122 24.564817541, 124.288128547 24.564853937, 124.28816358 24.564887631, 124.288239572 24.564961793, 124.288306615 24.565012586, 124.288344903 24.565046829, 124.288344163 24.565069946, 124.288349118 24.565077694, 124.288355253 24.565086351, 124.288363761 24.565089856, 124.28838192 24.56508964, 124.288392866 24.565085468, 124.288404008 24.565077685, 124.288424034 24.565072676, 124.288431349 24.565075369, 124.288434527 24.565082676, 124.288432399 24.565100378, 124.288441712 24.565117604, 124.288432866 24.565132342, 124.288418677 24.565146721, 124.288416329 24.565155847, 124.288426226 24.565168829, 124.288434643 24.565180369, 124.288436355 24.565191658, 124.288436887 24.565206189, 124.288443022 24.565217468, 124.288451751 24.565230991, 124.28846262 24.565234766, 124.288476433 24.565234559, 124.288488755 24.565227577, 124.288501686 24.565224396, 124.288516096 24.565223919, 124.288520233 24.565219396, 124.288519922 24.565212171, 124.288517121 24.565196018, 124.288505422 24.565175811, 124.288504332 24.565171027, 124.288506394 24.565168045, 124.288516044 24.565160351, 124.288528392 24.565158703, 124.288553359 24.565154775, 124.288577743 24.56515382, 124.288600052 24.565153153, 124.288617938 24.565161784, 124.288639598 24.56517745, 124.288663632 24.565196099, 124.288736706 24.565248775, 124.28879406 24.565289748, 124.288825707 24.565312982, 124.288870182 24.565335739, 124.288929066 24.565358018, 124.2889593 24.565369153, 124.289007549 24.565400207, 124.288978457 24.565414081, 124.28896022 24.565422333, 124.288956368 24.565426036, 124.288949883 24.565435712, 124.288947821 24.565442667, 124.288947147 24.565450973, 124.288954488 24.565463063, 124.288960545 24.565481108, 124.288962244 24.565487063, 124.288967289 24.565490847, 124.288978067 24.565499946, 124.288983632 24.565514198, 124.288987899 24.565523676, 124.289000259 24.565532856, 124.289017237 24.565533189, 124.289026044 24.565541297, 124.28903978 24.565547766, 124.289052412 24.565548108, 124.289057743 24.565544306, 124.289063943 24.565535532, 124.289076939 24.565522955, 124.289085123 24.565517883, 124.289096057 24.565509559, 124.289106615 24.565506108, 124.289111556 24.565509892, 124.289120376 24.565524685, 124.289127912 24.565536045, 124.289143139 24.565546577, 124.289148379 24.565548189, 124.289116848 24.565577865, 124.289081492 24.565611342, 124.289068768 24.565620396, 124.289050532 24.56563, 124.289032594 24.565641505, 124.289016122 24.56565291, 124.288999287 24.565669288, 124.288996641 24.565676514, 124.288998923 24.565683459, 124.289008301 24.565685973, 124.289070519 24.565693973, 124.289105992 24.565705378, 124.289119728 24.565711847, 124.289123204 24.565719703, 124.28912668 24.565730162, 124.289132529 24.565742252, 124.289139844 24.565747658, 124.289152179 24.565746099, 124.289166018 24.565748595, 124.289176187 24.56575264, 124.289184994 24.565762108, 124.289185227 24.56577745, 124.289179857 24.565799946, 124.289183243 24.565814477, 124.289191466 24.565825477, 124.289202633 24.565829874, 124.289209339 24.565828784, 124.289222555 24.565822162, 124.289233774 24.565809054, 124.289245966 24.565788081, 124.289256083 24.565762153, 124.289263515 24.565733964, 124.28926572 24.565704162, 124.289271102 24.565682937, 124.289276783 24.565662252, 124.289286732 24.565655099, 124.289296498 24.56565273, 124.289313489 24.565655676, 124.289329001 24.565661432, 124.289361673 24.565656766, 124.289358586 24.565687559, 124.289351349 24.565720342, 124.289351206 24.565741829, 124.289353217 24.565758982, 124.28936284 24.565778108, 124.289368236 24.565807171, 124.289363748 24.565828577, 124.289345071 24.56586455, 124.28934323 24.565880081, 124.289349663 24.565889279, 124.289402361 24.565924387, 124.289408716 24.565936207, 124.289406291 24.565954721, 124.289407198 24.56596573, 124.289415019 24.565973568, 124.289423009 24.565971928, 124.289444501 24.565958892, 124.289477938 24.565947721, 124.289500558 24.565951559, 124.289509935 24.565952712, 124.289519403 24.56594845, 124.289526706 24.565941757, 124.289539403 24.565927288, 124.289556459 24.565918225, 124.289568288 24.565908901, 124.289569546 24.565898964, 124.289575577 24.565861396, 124.289593878 24.565835721, 124.289631933 24.565854604, 124.289663567 24.565869802, 124.289699935 24.565889505, 124.289741245 24.565907667, 124.28981358 24.565938586, 124.289868638 24.565967279, 124.289867393 24.565985252, 124.289873152 24.566000045, 124.289878703 24.566007622, 124.289886913 24.566011937, 124.28990655 24.566010369, 124.289918093 24.56600718, 124.289934475 24.566002459, 124.289995746 24.566033036, 124.290011556 24.566040595, 124.290019689 24.566051685, 124.290023463 24.566066748, 124.289998145 24.566084856, 124.289986031 24.566100414, 124.289973346 24.566120207, 124.289963515 24.566137378, 124.289952879 24.566154288, 124.289939909 24.566176252, 124.289925655 24.56620409, 124.289916732 24.566233631, 124.289916368 24.56624645, 124.289923904 24.566260523, 124.289933593 24.566266189, 124.289942685 24.566266712, 124.289955305 24.56626173, 124.289974137 24.566253198, 124.289991219 24.56625082, 124.290000506 24.566257306, 124.290022166 24.566271622, 124.290039546 24.56627655, 124.290048923 24.56627355, 124.290061842 24.566266396, 124.290068638 24.566258622, 124.290082231 24.566249838, 124.290101064 24.566237252, 124.290101349 24.566229757, 124.290106446 24.56621873, 124.290115824 24.566214468, 124.290156096 24.566210324, 124.290211284 24.566257081, 124.29026192 24.566295081, 124.290293865 24.566318856, 124.290334215 24.566350198, 124.290360208 24.566364505, 124.290348042 24.566397486, 124.29033799 24.566406081, 124.290325888 24.566422901, 124.290324436 24.566432288, 124.290331971 24.56644627, 124.290338119 24.566458991, 124.29032978 24.566480135, 124.29030904 24.566523063, 124.290286822 24.566563189, 124.290290026 24.566579892, 124.290300428 24.566599279, 124.290309754 24.566616505, 124.290307017 24.566630414, 124.290302296 24.566636568, 124.290291751 24.56664273, 124.290269079 24.566657667, 124.29025958535163 24.566666666666666, 124.29048229611152 24.566666666666666, 124.290495875 24.566626081, 124.290500571 24.566609189, 124.290510091 24.566587414, 124.290520726 24.566575919, 124.290565486 24.566544955, 124.290578703 24.566543667, 124.290586615 24.566548802, 124.290593256 24.566558541, 124.290593787 24.566578396, 124.290569442 24.566637586, 124.29054703025689 24.566666666666666, 124.3 24.566666666666666, 124.3 24.558333333333334, 124.2875 24.558333333333334, 124.2875 24.56441012046675, 124.287504604 24.564413162))\n\n\n沖縄県\nNA\nNA\n石垣市\nNA\n47207\n36246263\n47207\n2.9977\nPOLYGON ((124.292826822 24.550035144, 124.292799092 24.550083054, 124.292773333 24.550125721, 124.292738119 24.550182396, 124.292674877 24.550280297, 124.292650195 24.550317369, 124.292625694 24.550353171, 124.292620169 24.550361063, 124.292614877 24.550368631, 124.292576498 24.550422153, 124.292551505 24.550455793, 124.292526018 24.550488973, 124.292498262 24.550524153, 124.292469909 24.550558874, 124.292441064 24.550593243, 124.292409754 24.550629423, 124.292378054 24.550665144, 124.292343787 24.550702595, 124.292312879 24.550735514, 124.292283424 24.550766, 124.292257328 24.550791964, 124.292230739 24.550817387, 124.29220572 24.550840459, 124.292180104 24.550863081, 124.292156161 24.550883261, 124.292131634 24.550902901, 124.292106602 24.55092191, 124.292083243 24.550938658, 124.292056926 24.550956315, 124.29203249 24.550971712, 124.29200489 24.550987838, 124.291979248 24.551001613, 124.291955486 24.551013216, 124.291933891 24.551022468, 124.291914565 24.55102936, 124.291897497 24.55103409, 124.291888807 24.55103591, 124.291880026 24.551037468, 124.291865123 24.551039027, 124.291850026 24.551039423, 124.291835019 24.551038459, 124.291826226 24.551037207, 124.291820402 24.551035955, 124.291807964 24.551032369, 124.291801038 24.551029676, 124.291795798 24.551027243, 124.291783152 24.551020225, 124.291775837 24.551015459, 124.29176882 24.551010414, 124.291752503 24.550997261, 124.291733502 24.550980505, 124.291683359 24.550934378, 124.291668314 24.550921495, 124.291666667 24.550920189, 124.291652789 24.550909243, 124.291636576 24.550897721, 124.291619767 24.550886739, 124.291600104 24.550874766, 124.291537432 24.550838054, 124.291517951 24.550825631, 124.29150144 24.550814279, 124.291482957 24.550800595, 124.291462776 24.550784649, 124.291403632 24.550735288, 124.291383761 24.550719072, 124.291367938 24.550706829, 124.291351816 24.550694937, 124.291338962 24.550686027, 124.291323152 24.550675766, 124.291308223 24.550666856, 124.291295564 24.550659838, 124.291280052 24.550651739, 124.291266913 24.550645351, 124.291250804 24.550638252, 124.291237263 24.550632685, 124.291215136 24.550624505, 124.29119262 24.550617234, 124.291169792 24.550611054, 124.291149455 24.550606396, 124.291126148 24.550602108, 124.291102542 24.550598811, 124.291078949 24.550596604, 124.291058223 24.550595559, 124.291037484 24.550595414, 124.291016861 24.55059609, 124.290993268 24.550597847, 124.29096978 24.550600514, 124.290946394 24.550603811, 124.290920143 24.550608288, 124.290890947 24.550613847, 124.290853839 24.550621414, 124.290840311 24.550619631, 124.290828171 24.550618577, 124.29081463 24.550609658, 124.290798612 24.550600306, 124.290765979 24.550572378, 124.290743839 24.550562847, 124.290719442 24.550553234, 124.290662633 24.550533207, 124.290610584 24.550518144, 124.290575707 24.550505207, 124.290536589 24.55049273, 124.290508314 24.550477982, 124.290495655 24.55046455, 124.290486939 24.550453459, 124.290474591 24.550448973, 124.290468677 24.550450153, 124.290458119 24.550455955, 124.290451038 24.550464189, 124.290449468 24.550471414, 124.290454228 24.550480252, 124.290462542 24.550488631, 124.290471258 24.550502703, 124.290472672 24.550515613, 124.290465201 24.55052709, 124.290457704 24.550532432, 124.290446472 24.550538054, 124.290434929 24.550544216, 124.290424384 24.550552, 124.290416407 24.550560586, 124.290414643 24.550566459, 124.290410428 24.550574865, 124.29040987 24.55059518, 124.290402905 24.550612261, 124.290377899 24.550642288, 124.290359001 24.550666703, 124.290346316 24.550685144, 124.290318975 24.550727811, 124.290310908 24.550739207, 124.29030214 24.550750054, 124.290296537 24.550756207, 124.290290623 24.550762171, 124.290279987 24.550771225, 124.290265888 24.55078109, 124.29024834 24.550791874, 124.290233346 24.550793883, 124.290186278 24.550801378, 124.290170986 24.55080827, 124.290159066 24.550817505, 124.290149235 24.550831973, 124.290141154 24.550840198, 124.290131102 24.550846, 124.290116693 24.550847739, 124.290092179 24.550834514, 124.290046719 24.550809324, 124.290019157 24.550802153, 124.290000104 24.550801378, 124.289946213 24.550804099, 124.289937626 24.550806559, 124.289929442 24.55080973, 124.289925305 24.550814072, 124.289925707 24.550817955, 124.289928781 24.55082355, 124.289934241 24.550833649, 124.289933074 24.550842766, 124.289925979 24.550847928, 124.289909001 24.550850036, 124.289892127 24.550852234, 124.28988917 24.550855045, 124.289888495 24.550858838, 124.289892659 24.550866505, 124.289904851 24.550889144, 124.289908547 24.55090909, 124.289908949 24.550909991, 124.289894371 24.550923739, 124.289884319 24.550933874, 124.289874877 24.55094427, 124.289867977 24.550953045, 124.289862477 24.55096127, 124.289857847 24.550969315, 124.289852944 24.550979171, 124.289840065 24.55100664, 124.289834669 24.551016315, 124.289828664 24.551025622, 124.289816952 24.551041171, 124.289785837 24.551077712, 124.289770285 24.551097604, 124.289753761 24.551120207, 124.289715383 24.551175, 124.289697082 24.551199595, 124.289681232 24.551219036, 124.289666174 24.551235676, 124.289648054 24.551253586, 124.289628846 24.551270595, 124.289617808 24.551279649, 124.289606472 24.551288342, 124.289597108 24.551295036, 124.289587445 24.551301198, 124.289569805 24.551311252, 124.289528586 24.55133264, 124.289516174 24.551339883, 124.289504047 24.551347676, 124.289492322 24.55135582, 124.289480791 24.551364333, 124.28942856 24.551404613, 124.289403333 24.551422351, 124.289396407 24.551412802, 124.289390272 24.551409468, 124.289384345 24.551409477, 124.289376965 24.55141473, 124.28936585 24.551433712, 124.289363995 24.551442027, 124.289325759 24.55146855, 124.289314617 24.551475793, 124.289301505 24.551483676, 124.289265422 24.551504153, 124.28924275 24.551518189, 124.289228949 24.551527604, 124.289217121 24.551536297, 124.28917476 24.551569153, 124.289165201 24.551575856, 124.289159079 24.551579748, 124.289150506 24.551584369, 124.289145279 24.551586541, 124.289140441 24.55158782, 124.289136109 24.551588099, 124.289132348 24.551587288, 124.289129183 24.551585216, 124.289126706 24.551581793, 124.289124825 24.551576198, 124.28911332 24.551551847, 124.289101816 24.55153155, 124.289098223 24.551513865, 124.289091245 24.55148282, 124.289071414 24.551445568, 124.289055201 24.551434126, 124.289041673 24.551433432, 124.289034578 24.551436604, 124.289025019 24.551446108, 124.289021401 24.551458477, 124.289025798 24.551481856, 124.28902703 24.551502081, 124.289021907 24.551507595, 124.289014319 24.551511045, 124.289006329 24.551515207, 124.289002399 24.551521631, 124.289003191 24.551527315, 124.289006368 24.55153327, 124.289021712 24.551551117, 124.289060674 24.551581919, 124.289038495 24.551595144, 124.288999896 24.551554135, 124.288970921 24.551529631, 124.288966563 24.551521514, 124.288950921 24.551503126, 124.288932335 24.551489982, 124.288918508 24.551490189, 124.288904514 24.551499153, 124.288887847 24.551505685, 124.288868612 24.551512856, 124.288858067 24.551517667, 124.288854929 24.551524081, 124.288848742 24.551538901, 124.288839183 24.551547766, 124.288820843 24.551558541, 124.288803878 24.551564712, 124.288798171 24.551569243, 124.288795914 24.551574306, 124.288801362 24.551584405, 124.288819767 24.551605225, 124.288824319 24.551607658, 124.288827873 24.551607108, 124.288838223 24.551604919, 124.288844643 24.551605541, 124.288851556 24.551607604, 124.288852763 24.55161582, 124.288852581 24.551620243, 124.288851894 24.551623586, 124.288849728 24.551628459, 124.288845006 24.551635423, 124.288835564 24.55164682, 124.288830441 24.551653604, 124.288814799 24.551676468, 124.288808301 24.551685333, 124.288786641 24.551711198, 124.288778288 24.551722315, 124.288772581 24.551731811, 124.28876786 24.551741658, 124.288763943 24.551751874, 124.2887607 24.551762441, 124.288757471 24.551775811, 124.288754747 24.55178936, 124.288750169 24.551818982, 124.288746783 24.551848604, 124.28873965 24.551923919, 124.288734423 24.551969613, 124.288726667 24.552028766, 124.288717237 24.552090541, 124.288706706 24.552152225, 124.288694423 24.552216811, 124.288680649 24.552282928, 124.288665499 24.552349225, 124.288647315 24.552423207, 124.288625486 24.552504694, 124.288587588 24.552638477, 124.288556835 24.55274309, 124.288534293 24.55281609, 124.288512931 24.552880955, 124.288489494 24.552948, 124.28846476 24.553014766, 124.288443956 24.553068351, 124.288421284 24.553124189, 124.288395953 24.55318491, 124.288366796 24.553253045, 124.288304137 24.55339645, 124.288274086 24.553464225, 124.28824668 24.553524225, 124.288221725 24.553576279, 124.288206887 24.553605838, 124.288192931 24.553632766, 124.288178586 24.553659523, 124.288163839 24.553686099, 124.288137393 24.553731559, 124.288095201 24.553799991, 124.288080934 24.553823676, 124.288065798 24.553850153, 124.288051647 24.553877, 124.288042114 24.553896793, 124.288034358 24.553914414, 124.288028171 24.553929685, 124.288015616 24.553963018, 124.288009131 24.553978108, 124.288001362 24.553992667, 124.287981102 24.554026829, 124.287975214 24.554038306, 124.287970597 24.554048252, 124.287965292 24.554060901, 124.287959507 24.554076351, 124.287943035 24.554125586, 124.287935473 24.554146099, 124.287925759 24.554168604, 124.287913476 24.55419309, 124.287905409 24.55420755, 124.287895577 24.55422409, 124.287885149 24.55424055, 124.287874228 24.55425673, 124.287861336 24.554275081, 124.287848054 24.554293252, 124.28781262 24.55434, 124.287794293 24.554352135, 124.287776835 24.554360568, 124.287766109 24.554373315, 124.287739533 24.554409847, 124.28772083 24.554429568, 124.287700713 24.554439802, 124.28767773 24.554448694, 124.287667289 24.554456568, 124.287656654 24.554466703, 124.287638599 24.554475315, 124.287622348 24.554487261, 124.287611907 24.554497847, 124.287588236 24.554511072, 124.287565175 24.554523937, 124.287546757 24.554545559, 124.287528547 24.55456627, 124.287508729 24.554577045, 124.2875 24.554579884927236, 124.2875 24.554629787137078, 124.287504215 24.554634477, 124.287504656 24.554650369, 124.2875 24.554658008939256, 124.2875 24.558333333333334, 124.3 24.558333333333334, 124.3 24.55, 124.292845927 24.55, 124.292826822 24.550035144))\n\n\n沖縄県\nNA\nNA\n石垣市\nNA\n47207\n36246253\n47207\n0.9996\nMULTIPOLYGON (((124.295430467 24.541666667, 124.295430376 24.54166736, 124.29542882 24.541675396, 124.295426576 24.541683261, 124.295423722 24.541690937, 124.295415577 24.541708378, 124.295370272 24.541708559, 124.29534703 24.541688108, 124.295335279 24.541686694, 124.295324617 24.541688694, 124.295299261 24.541694703, 124.295295642 24.541706991, 124.295300713 24.541722153, 124.295307665 24.541737757, 124.295319624 24.541745135, 124.295331868 24.541749081, 124.295358042 24.54175409, 124.295382127 24.541758108, 124.295399792 24.541754279, 124.295424553 24.541747189, 124.295449313 24.541745604, 124.295462244 24.541741153, 124.295471699 24.541734189, 124.295477704 24.541726225, 124.295494358 24.541713468, 124.295513787 24.54170882, 124.295536187 24.541706883, 124.295553645 24.54169845, 124.295568638 24.541696432, 124.295578911 24.541697856, 124.295579494 24.541698036, 124.295582464 24.541698757, 124.295585422 24.541699559, 124.295588288 24.541700279, 124.295591245 24.541700991, 124.295594112 24.541701712, 124.295597082 24.541702432, 124.295600039 24.541703054, 124.295602905 24.541703775, 124.295605863 24.541704396, 124.295608833 24.541704937, 124.295611699 24.541705559, 124.295614656 24.541706009, 124.295617613 24.541706541, 124.29562048 24.541706991, 124.29562345 24.541707342, 124.295626407 24.541707694, 124.295629364 24.541707964, 124.295632335 24.541708225, 124.295635188 24.541708405, 124.295638158 24.541708486, 124.295641115 24.541708568, 124.295644073 24.541708568, 124.295647043 24.541708468, 124.29565 24.541708279, 124.295652957 24.541708009, 124.295655914 24.54170764, 124.295660558 24.541707, 124.295661842 24.54170673, 124.295664799 24.54170609, 124.295667756 24.54170536, 124.295670713 24.541704541, 124.29567358 24.541703631, 124.295676342 24.541702541, 124.295679105 24.54170136, 124.29568166 24.541700009, 124.295684228 24.541698559, 124.295686589 24.541696928, 124.295688859 24.541695117, 124.295691608 24.541692495, 124.295692892 24.541691045, 124.295694565 24.541688694, 124.295696135 24.541686252, 124.295697419 24.541683721, 124.295698495 24.541681099, 124.295699274 24.541678387, 124.295699767 24.541675685, 124.295700052 24.541671261, 124.295699948 24.541670351, 124.29569965 24.541667739, 124.29569939 24.541666667, 124.29569938992306 24.541666666666668, 124.29543046703955 24.541666666666668, 124.295430467 24.541666667)), ((124.295864008 24.541666667, 124.295864488 24.541668135, 124.29586559 24.541673099, 124.295865681 24.54167373, 124.295866083 24.541676532, 124.295866485 24.541679324, 124.295866589 24.541682126, 124.295866693 24.541684838, 124.295866602 24.541687541, 124.29586642 24.541690342, 124.295866122 24.541693054, 124.295865733 24.541695676, 124.295865149 24.541698378, 124.295864371 24.541701, 124.29586358 24.541703622, 124.295862503 24.541706243, 124.295861427 24.541708775, 124.295859857 24.541711847, 124.295858677 24.541713829, 124.295857198 24.54171627, 124.295855525 24.541718802, 124.295853852 24.541721243, 124.295852283 24.541723685, 124.29585061 24.541726126, 124.295849131 24.541728568, 124.295847756 24.541730919, 124.295846576 24.54173336, 124.295845603 24.541735892, 124.295844812 24.541738333, 124.295844228 24.541742847, 124.295844228 24.541743297, 124.295844436 24.54174582, 124.295844929 24.541748441, 124.295845733 24.541750964, 124.295846719 24.541753586, 124.295847912 24.541756108, 124.295849105 24.54175873, 124.295850493 24.541761342, 124.295852179 24.541764676, 124.295853074 24.541766396, 124.295854358 24.541768919, 124.295855551 24.541771441, 124.295856744 24.541773973, 124.295857925 24.541776405, 124.295859118 24.541778838, 124.295860415 24.541781279, 124.295861699 24.541783622, 124.295862983 24.541785964, 124.295864371 24.541788306, 124.295865863 24.541790658, 124.295867445 24.54179291, 124.295869131 24.541795162, 124.295870908 24.541797414, 124.295873281 24.541800117, 124.295874864 24.541801829, 124.295877147 24.541804, 124.29587952 24.541806063, 124.295881894 24.541808045, 124.295884462 24.541809847, 124.295887134 24.541811468, 124.295889805 24.541813, 124.295892464 24.541814171, 124.29589524 24.541815153, 124.295898093 24.541815874, 124.295900856 24.541816315, 124.295904514 24.541816315, 124.295906291 24.541816036, 124.295909053 24.541815396, 124.295911712 24.541814586, 124.295914475 24.541813495, 124.295917237 24.541812405, 124.29592 24.541811315, 124.295922853 24.541810225, 124.295925824 24.541809405, 124.295929079 24.541808766, 124.295931933 24.541808495, 124.295935097 24.541808486, 124.295938054 24.541808928, 124.295942503 24.54181073, 124.295943191 24.54181118, 124.295945266 24.541812982, 124.295946861 24.541815144, 124.295948249 24.541817577, 124.295949339 24.541820288, 124.295950921 24.541825072, 124.295951128 24.541825973, 124.29595192 24.541828766, 124.29595262 24.541831568, 124.29595332 24.54183445, 124.295953917 24.541837252, 124.295954423 24.541840045, 124.295954916 24.541842847, 124.295955318 24.541845559, 124.295955616 24.541848351, 124.295955927 24.541851153, 124.295956226 24.541853856, 124.295956433 24.541856658, 124.295956537 24.541859369, 124.295956641 24.541862072, 124.295956744 24.541864784, 124.295956744 24.541867495, 124.295956654 24.541870198, 124.295956667 24.54187291, 124.295956576 24.541875622, 124.295956381 24.541878324, 124.295956187 24.541880946, 124.295956005 24.541883658, 124.295955707 24.541886369, 124.295955422 24.541888982, 124.295955136 24.541891694, 124.295954747 24.541894315, 124.295954358 24.541897018, 124.295953969 24.54189964, 124.29595358 24.541902261, 124.295953087 24.541904973, 124.295952607 24.541907586, 124.295952114 24.541910207, 124.295951621 24.541912919, 124.295951038 24.541915541, 124.295950558 24.541918153, 124.295949961 24.541920775, 124.295948898 24.541925658, 124.295948794 24.541926108, 124.29594821 24.541928721, 124.295947626 24.541931342, 124.295946939 24.541934054, 124.295946355 24.541936676, 124.295945668 24.541939297, 124.295945084 24.54194191, 124.295944397 24.541944622, 124.295943709 24.541947243, 124.295943126 24.541949865, 124.295942438 24.541952486, 124.295941751 24.541955189, 124.295941077 24.541957811, 124.29594048 24.541960432, 124.295939805 24.541963144, 124.295939118 24.541965757, 124.295938431 24.541968378, 124.295937847 24.54197109, 124.29593716 24.541973712, 124.295936472 24.541976333, 124.295935888 24.541979036, 124.295935201 24.541981658, 124.295934617 24.541984369, 124.295934034 24.541986991, 124.295933346 24.541989613, 124.295932763 24.541992315, 124.295932179 24.541994937, 124.295931595 24.541997649, 124.295931102 24.54200027, 124.295930519 24.542002973, 124.295929935 24.542005595, 124.295929442 24.542008306, 124.295928962 24.542010928, 124.29592847 24.542013631, 124.295927977 24.542016252, 124.295927497 24.542018964, 124.295927108 24.542021586, 124.295926615 24.542024288, 124.295926226 24.542027, 124.295925655 24.542031604, 124.295925551 24.542032333, 124.295925266 24.542035036, 124.295924877 24.542037658, 124.295924578 24.542040369, 124.295924397 24.542043081, 124.295924099 24.542045694, 124.295923917 24.542048405, 124.295923722 24.542051117, 124.295923528 24.54205382, 124.295923333 24.542056441, 124.295923243 24.542059153, 124.295923061 24.542061856, 124.295922957 24.542064568, 124.295922866 24.542067279, 124.295922776 24.542069982, 124.295922789 24.542072694, 124.295922698 24.542075405, 124.295922698 24.542078108, 124.295922607 24.54208082, 124.295922607 24.542083532, 124.29592262 24.542086234, 124.29592262 24.542088946, 124.295922633 24.542091658, 124.295922737 24.54209436, 124.295922737 24.542097162, 124.295922853 24.542099874, 124.295922853 24.542102577, 124.295922957 24.542105288, 124.295923061 24.54210809, 124.295923165 24.542110793, 124.295923268 24.542113595, 124.295923385 24.542116306, 124.295923489 24.542119099, 124.295923489 24.542121811, 124.295923593 24.542124523, 124.295923696 24.542127315, 124.295923709 24.542130027, 124.295923709 24.542132739, 124.295923619 24.542135532, 124.295923528 24.542138243, 124.295923333 24.542140865, 124.295923152 24.542143568, 124.295922853 24.542146279, 124.295922464 24.542148901, 124.295921595 24.542153144, 124.295921401 24.542154135, 124.295920713 24.542156667, 124.295919922 24.542159288, 124.295919144 24.54216182, 124.295918158 24.542164351, 124.295917185 24.542166784, 124.295916096 24.542169315, 124.295914929 24.542171757, 124.295913748 24.542174198, 124.295912568 24.54217673, 124.295911193 24.542179171, 124.295909909 24.542181514, 124.295908534 24.542183955, 124.29590716 24.542186396, 124.295905681 24.542188838, 124.295904215 24.542191189, 124.295902827 24.542193631, 124.295901362 24.542196072, 124.295899883 24.542198423, 124.295898405 24.542200865, 124.295896939 24.542203306, 124.295895551 24.542205748, 124.295894086 24.54220818, 124.295892711 24.542210622, 124.295891336 24.542213063, 124.295888872 24.542217946, 124.295888781 24.542217946, 124.295887601 24.542220477, 124.29588642 24.542223009, 124.29588524 24.542225541, 124.295884163 24.542228063, 124.295883178 24.542230595, 124.295882192 24.542233126, 124.295881219 24.542235748, 124.295880337 24.542238279, 124.295879455 24.542240901, 124.295878664 24.542243514, 124.295877886 24.542246135, 124.295877198 24.542248757, 124.295876511 24.542251378, 124.295875837 24.542254, 124.29587524 24.542256703, 124.295874656 24.542259324, 124.295874073 24.542262036, 124.29587358 24.542264748, 124.2958731 24.54226745, 124.295872607 24.542270072, 124.295872218 24.542272784, 124.295871829 24.542275495, 124.29587144 24.542278198, 124.295871064 24.542281, 124.295870765 24.542283712, 124.29587048 24.542286423, 124.295870285 24.542289126, 124.29587 24.542291928, 124.295869805 24.54229464, 124.295869611 24.542297351, 124.295869429 24.542300144, 124.295869326 24.542302856, 124.295869144 24.542305658, 124.295869053 24.54230836, 124.295868962 24.542311162, 124.295868859 24.542313874, 124.295868872 24.542316667, 124.295868781 24.542319378, 124.295868781 24.54232218, 124.295868794 24.542324883, 124.295868703 24.542327685, 124.295868703 24.542330396, 124.295868716 24.542333189, 124.29586882 24.542335901, 124.29586882 24.542338703, 124.295868833 24.542341405, 124.295868936 24.542344117, 124.295868936 24.542346829, 124.295868949 24.542349622, 124.295869053 24.542352333, 124.295869066 24.542355045, 124.29586917 24.542357748, 124.295869274 24.542362351, 124.295869274 24.542363171, 124.295869287 24.542365874, 124.29586939 24.542368495, 124.29586939 24.542371207, 124.295869494 24.54237391, 124.295869507 24.542376532, 124.295869611 24.542379234, 124.295869611 24.542381856, 124.295869624 24.542384568, 124.295869624 24.54238718, 124.295869637 24.542389892, 124.295869637 24.542392604, 124.29586965 24.542395216, 124.29586965 24.542397928, 124.295869663 24.54240064, 124.295869663 24.542403342, 124.295869572 24.542406054, 124.295869585 24.542408766, 124.295869494 24.542411468, 124.295869494 24.54241418, 124.295869403 24.542416892, 124.295869313 24.542419685, 124.295869222 24.542422396, 124.295869027 24.542425198, 124.295868936 24.542428, 124.295868742 24.542431514, 124.295868651 24.542433685, 124.295868457 24.542436486, 124.295868067 24.542439279, 124.295867678 24.542441991, 124.295867004 24.542444703, 124.295866018 24.542447234, 124.295863852 24.542451027, 124.295863268 24.542451847, 124.295861297 24.542453829, 124.295859027 24.54245573, 124.295856563 24.54245727, 124.295853904 24.542458721, 124.295851051 24.542459811, 124.295845811 24.54246109, 124.295845123 24.54246118, 124.29584227 24.54246145, 124.2958393 24.542461459, 124.295836342 24.542461198, 124.295833476 24.542460748, 124.29583061 24.542460036, 124.295827847 24.542459135, 124.295824981 24.542458054, 124.295822218 24.542456802, 124.295819546 24.54245545, 124.295816783 24.542454009, 124.295814112 24.542452477, 124.295811543 24.542450865, 124.295807393 24.542448162, 124.295806407 24.542447441, 124.29580393 24.54244573, 124.295801556 24.542444018, 124.295799183 24.542442216, 124.295796809 24.542440505, 124.29579454 24.542438703, 124.295792257 24.542436901, 124.295790091 24.542435009, 124.295787912 24.542433207, 124.295785733 24.542431315, 124.295783658 24.542429423, 124.295781582 24.542427532, 124.295779507 24.54242555, 124.295777523 24.542423658, 124.295775538 24.542421676, 124.295773671 24.542419604, 124.29577179 24.542417622, 124.295769909 24.54241555, 124.295768029 24.542413477, 124.295766148 24.542411405, 124.295764358 24.542409243, 124.295762581 24.542407081, 124.295760804 24.54240491, 124.295759118 24.542402748, 124.295757328 24.542400495, 124.295754163 24.542396261, 124.295753969 24.542395991, 124.295752283 24.542393649, 124.295750597 24.542391297, 124.295749014 24.542388955, 124.295747432 24.542386523, 124.295745746 24.54238409, 124.295744254 24.542381649, 124.295742672 24.542379216, 124.295741193 24.542376694, 124.295739702 24.542374162, 124.29573821 24.54237164, 124.295736822 24.542369117, 124.295735435 24.542366595, 124.29573415 24.542363973, 124.295732866 24.54236136, 124.295731569 24.542358739, 124.295730376 24.542356126, 124.295729287 24.542353514, 124.295728197 24.542350892, 124.295727198 24.542348189, 124.295726213 24.542345568, 124.295725214 24.542342865, 124.295724423 24.542340153, 124.295723632 24.542337541, 124.295722931 24.542334838, 124.295722231 24.542332126, 124.295721634 24.542329414, 124.295721128 24.542326712, 124.295720636 24.542324, 124.295720233 24.542321387, 124.295720026 24.542318676, 124.295719728 24.542315973, 124.295719624 24.542313261, 124.295719611 24.54231055, 124.295719611 24.542307937, 124.295719792 24.542305225, 124.295719987 24.542302604, 124.295720285 24.542299901, 124.295720674 24.542297279, 124.295721258 24.542294568, 124.295721842 24.542292036, 124.295722529 24.542289423, 124.295723307 24.542286802, 124.295724189 24.54228418, 124.295725071 24.542281649, 124.295725953 24.542279027, 124.295726939 24.542276495, 124.295728016 24.542273883, 124.295729001 24.542271351, 124.295730078 24.54226873, 124.295731064 24.542266198, 124.29573214 24.542263577, 124.295733126 24.542261045, 124.295734008 24.542258423, 124.29573489 24.542255811, 124.295735772 24.542253189, 124.29573655 24.542250658, 124.295737237 24.542248036, 124.295737821 24.542245324, 124.295738599 24.542240721, 124.29573869 24.54224009, 124.295738988 24.542237378, 124.295739079 24.542234676, 124.29573917 24.542231964, 124.295739066 24.542229252, 124.295738962 24.54222655, 124.295738664 24.542223838, 124.295738353 24.542221126, 124.295737951 24.542218423, 124.295737458 24.542215712, 124.295736861 24.542213009, 124.295736252 24.542210387, 124.295735564 24.542207685, 124.295734565 24.542204342, 124.295733969 24.54220236, 124.295733178 24.542199739, 124.295732283 24.542197126, 124.295731388 24.542194505, 124.295730493 24.542191892, 124.295729598 24.542189369, 124.295728703 24.542186748, 124.295727808 24.542184135, 124.295726913 24.542181604, 124.295726018 24.542178991, 124.295725123 24.542176369, 124.295724332 24.542173847, 124.295723632 24.542171225, 124.295722931 24.542168613, 124.295721842 24.542163919, 124.295721738 24.542163378, 124.295721232 24.542160667, 124.29572083 24.542158054, 124.295720441 24.542155342, 124.295720039 24.54215264, 124.295719637 24.542150018, 124.295719326 24.542147315, 124.295718923 24.542144604, 124.295718431 24.542141892, 124.295717925 24.542139279, 124.295717328 24.542136568, 124.295716628 24.542133955, 124.295714851 24.542128901, 124.295714851 24.542128721, 124.295713658 24.542126108, 124.295712464 24.542123577, 124.295711077 24.542121144, 124.295709494 24.542118712, 124.295707808 24.54211636, 124.295705927 24.542114198, 124.295703943 24.542112126, 124.295701777 24.542110234, 124.295699598 24.542108432, 124.295696329 24.542106369, 124.295694656 24.542105468, 124.295691984 24.542104297, 124.295689222 24.542103306, 124.295686459 24.542102505, 124.295683489 24.542101784, 124.295680532 24.542101252, 124.295677562 24.542100892, 124.295674514 24.542100631, 124.295669079 24.542100459, 124.295668482 24.542100459, 124.295665422 24.542100559, 124.295662464 24.542100658, 124.295659507 24.542100928, 124.295656641 24.542101207, 124.295653684 24.542101667, 124.295650817 24.542102117, 124.29564786 24.542102667, 124.295645006 24.542103216, 124.29564214 24.542103946, 124.295639377 24.542104577, 124.295636511 24.542105396, 124.295633658 24.542106216, 124.295630895 24.542107036, 124.295628029 24.542107946, 124.295625279 24.542108946, 124.295622516 24.542109937, 124.295619754 24.542110937, 124.295616887 24.542111937, 124.295614125 24.542112937, 124.295611362 24.542114027, 124.295608612 24.542115117, 124.29560585 24.542116117, 124.295603087 24.542117198, 124.29560022 24.542118288, 124.295597458 24.542119378, 124.295594695 24.542120468, 124.295591738 24.542121468, 124.295589079 24.542122468, 124.295586226 24.542123468, 124.295583463 24.542124459, 124.295580597 24.542125459, 124.295577743 24.542126369, 124.295574877 24.542127189, 124.295572023 24.542128099, 124.295569157 24.542128919, 124.295566291 24.54212964, 124.295563437 24.542130369, 124.295560571 24.542131099, 124.295557613 24.542131739, 124.295554747 24.542132288, 124.29555179 24.542132829, 124.295548936 24.542133288, 124.295545966 24.542133658, 124.295543009 24.542134027, 124.295540052 24.542134297, 124.295537185 24.542134486, 124.295534228 24.542134676, 124.295531271 24.542134766, 124.295528301 24.542134685, 124.295524851 24.542134604, 124.295522283 24.542134423, 124.295519326 24.542134162, 124.295516355 24.542133802, 124.295513398 24.54213336, 124.295510441 24.54213282, 124.295507471 24.542132198, 124.295504604 24.542131477, 124.295501751 24.542130676, 124.295498885 24.542129775, 124.295496109 24.542128694, 124.295493346 24.542127622, 124.295490674 24.54212636, 124.295488106 24.542125009, 124.29548415 24.542122676, 124.295483165 24.542121955, 124.295480791 24.542120333, 124.295478418 24.542118532, 124.295476148 24.54211673, 124.295473969 24.542114838, 124.295471699 24.542112946, 124.29546952 24.542111054, 124.295467341 24.542109162, 124.295465175 24.54210736, 124.295462892 24.542105559, 124.295460713 24.542103847, 124.295458353 24.542102315, 124.295455979 24.542100784, 124.295453502 24.542099532, 124.295450934 24.54209836, 124.295448366 24.542097369, 124.295445603 24.542096477, 124.29544284 24.542095667, 124.295440065 24.542095036, 124.295437211 24.542094505, 124.295434241 24.542093964, 124.295431284 24.542093523, 124.295428314 24.542093162, 124.295425253 24.542092811, 124.295422296 24.542092459, 124.295419235 24.542092189, 124.295416174 24.542091838, 124.295413217 24.542091387, 124.295410156 24.542091036, 124.295405409 24.542090144, 124.295404228 24.542089964, 124.295401362 24.542089333, 124.295398495 24.542088622, 124.295395629 24.542087811, 124.295392866 24.542086919, 124.29539 24.542086018, 124.295387237 24.542085027, 124.295384565 24.542083955, 124.295381803 24.542082874, 124.295379131 24.542081793, 124.295376472 24.542080631, 124.2953738 24.542079459, 124.295371128 24.542078288, 124.29536847 24.542077036, 124.295365798 24.542075775, 124.295363126 24.542074514, 124.295360558 24.542073342, 124.295357899 24.54207209, 124.295355227 24.542070829, 124.295352555 24.542069568, 124.295349883 24.542068396, 124.295347224 24.542067234, 124.295344553 24.542066063, 124.29533952 24.542064, 124.295339118 24.54206382, 124.295336446 24.542062829, 124.295333684 24.542061838, 124.295330921 24.542060856, 124.295328158 24.542059955, 124.295325292 24.542059153, 124.295322529 24.542058252, 124.295319663 24.542057532, 124.295316796 24.54205673, 124.29531393 24.542056099, 124.295311064 24.542055387, 124.295308197 24.542054757, 124.29530524 24.542054225, 124.295302374 24.542053685, 124.295299416 24.542053153, 124.295296459 24.542052703, 124.295293593 24.542052261, 124.295290623 24.542051811, 124.295287665 24.542051459, 124.295284708 24.542051099, 124.295281647 24.542050838, 124.295278677 24.542050577, 124.29527572 24.542050306, 124.295272763 24.542050135, 124.295269702 24.542049955, 124.295266732 24.542049874, 124.295263671 24.542049703, 124.295260713 24.542049613, 124.295257652 24.542049622, 124.295254695 24.542049631, 124.295251634 24.542049631, 124.295247095 24.54204964, 124.295245616 24.542049739, 124.295242646 24.542049829, 124.295239689 24.542049928, 124.295236628 24.542050117, 124.295233671 24.542050297, 124.29523061 24.542050486, 124.295227652 24.542050766, 124.295224695 24.542050946, 124.295221634 24.542051315, 124.295218664 24.542051595, 124.295215707 24.542051964, 124.29521275 24.542052324, 124.295209792 24.542052694, 124.295206835 24.542053153, 124.295203865 24.542053613, 124.295200908 24.542054153, 124.295197951 24.542054613, 124.295194994 24.542055162, 124.295192127 24.542055802, 124.29518917 24.542056342, 124.295186304 24.542056982, 124.29518345 24.542057712, 124.295180493 24.542058351, 124.295177626 24.542059081, 124.29517476 24.542059892, 124.295171907 24.542060622, 124.295169144 24.542061441, 124.295166278 24.542062351, 124.295163515 24.542063171, 124.295160661 24.542064072, 124.295157899 24.542065072, 124.295155136 24.542065982, 124.295152374 24.542066982, 124.295149611 24.542068072, 124.295146952 24.542069072, 124.295144189 24.542070162, 124.29514153 24.542071333, 124.295138872 24.542072514, 124.295135616 24.542073874, 124.295133541 24.542074874, 124.295130973 24.542076144, 124.295128314 24.542077414, 124.295125759 24.542078685, 124.295123191 24.542080036, 124.295120623 24.542081396, 124.295118067 24.542082757, 124.295115499 24.542084117, 124.295113035 24.542085568, 124.29511048 24.542087018, 124.295108016 24.542088468, 124.295105551 24.542089919, 124.295103087 24.542091459, 124.295100519 24.54209291, 124.295098054 24.542094441, 124.295095694 24.542095982, 124.29509323 24.542097523, 124.295090765 24.542099063, 124.295088301 24.542100604, 124.295085837 24.542102144, 124.295083463 24.542103685, 124.295080999 24.542105225, 124.295078534 24.542106856, 124.295075875 24.542108577, 124.295073709 24.542109937, 124.295071245 24.542111468, 124.295068781 24.542113099, 124.29506642 24.54211464, 124.295063956 24.54211609, 124.295061492 24.542117631, 124.295059027 24.542119081, 124.295056459 24.542120622, 124.295053995 24.542121982, 124.29505144 24.542123432, 124.295048975 24.542124784, 124.295046304 24.542126144, 124.29504118 24.542128685, 124.295038521 24.542129955, 124.295035759 24.542131135, 124.2950331 24.542132225, 124.295030337 24.542133315, 124.295027575 24.542134396, 124.295024812 24.542135306, 124.295022049 24.542136306, 124.295019196 24.542137216, 124.295016329 24.542138036, 124.295013463 24.542138856, 124.29501061 24.542139577, 124.295007743 24.542140306, 124.29500489 24.542140946, 124.295001933 24.542141586, 124.294999066 24.542142135, 124.294996109 24.542142586, 124.294993243 24.542143045, 124.294987821 24.542143775, 124.294987328 24.542143775, 124.294984462 24.542144144, 124.294981505 24.542144333, 124.294978534 24.542144613, 124.294975577 24.542144703, 124.294972724 24.542144802, 124.294969754 24.542144901, 124.294966796 24.542144901, 124.294963839 24.54214491, 124.294960869 24.54214482, 124.294957912 24.542144739, 124.294955045 24.542144658, 124.294952088 24.542144477, 124.294949131 24.542144306, 124.294946161 24.542144036, 124.294943204 24.542143775, 124.294940246 24.542143514, 124.294937276 24.542143153, 124.294934319 24.542142892, 124.294931453 24.542142441, 124.294928495 24.54214209, 124.294925525 24.54214173, 124.294922568 24.542141288, 124.294919611 24.542140838, 124.294916641 24.542140396, 124.294913684 24.542139946, 124.294910713 24.542139414, 124.294907756 24.542138973, 124.294904799 24.542138432, 124.294901829 24.542137901, 124.294898872 24.54213745, 124.294895901 24.542136919, 124.294892944 24.542136378, 124.294889987 24.542135847, 124.294845305 24.542110919, 124.294801064 24.542100622, 124.294773411 24.542095532, 124.294724955 24.542097703, 124.294696044 24.542103901, 124.294684514 24.542109703, 124.294681479 24.54212045, 124.294669689 24.542141514, 124.294661323 24.542155973, 124.294655227 24.542165288, 124.294648249 24.542174054, 124.294643709 24.542178667, 124.294640065 24.542181928, 124.294621842 24.542195775, 124.294613463 24.542203378, 124.294609831 24.542207631, 124.294604812 24.542214324, 124.294592815 24.542233306, 124.294591141 24.542235477, 124.294587302 24.54223945, 124.294582866 24.542242892, 124.294577938 24.542245883, 124.294564423 24.542252135, 124.294558729 24.542262081, 124.294560934 24.542275802, 124.294562542 24.542289793, 124.294554553 24.542292703, 124.294537185 24.54229436, 124.294531868 24.542298072, 124.294535824 24.542305649, 124.294548521 24.542328099, 124.294568392 24.542343324, 124.294571855 24.54234982, 124.294587367 24.542520883, 124.294596083 24.542621, 124.294599053 24.542667036, 124.294599896 24.542688703, 124.294600039 24.542707667, 124.294599883 24.542723919, 124.294599131 24.542741613, 124.29459799 24.542758955, 124.294596446 24.542775117, 124.294592866 24.542804739, 124.294582568 24.542880063, 124.294575032 24.542950135, 124.294571258 24.542979766, 124.294568236 24.54299855, 124.29456463 24.543017153, 124.294560726 24.543033234, 124.294556226 24.543049135, 124.294550039 24.543067477, 124.29454406 24.543083018, 124.29453738 24.543098198, 124.294530013 24.543113108, 124.294521855 24.543127658, 124.294514475 24.543139505, 124.294506511 24.543150892, 124.294498145 24.543162018, 124.294489092 24.543172775, 124.294477769 24.543185261, 124.294466057 24.543197468, 124.294448029 24.543215477, 124.294407964 24.543218622, 124.294372257 24.543228532, 124.294349572 24.543235261, 124.294338418 24.543237631, 124.294329624 24.543234847, 124.294303761 24.543231649, 124.294287484 24.543236829, 124.294270428 24.543244441, 124.294252374 24.54324782, 124.294236952 24.54323927, 124.294201336 24.543243856, 124.294189494 24.543249117, 124.29417965 24.543256811, 124.294177886 24.543261595, 124.294181855 24.543270532, 124.294189377 24.543281892, 124.29420904 24.543289892, 124.294226018 24.543291658, 124.294237108 24.543302748, 124.294241388 24.543364045, 124.294245149 24.543407279, 124.294248885 24.543442396, 124.294258132 24.543518045, 124.294261777 24.543553153, 124.294264319 24.543585568, 124.29426537 24.543612559, 124.294265331 24.54364127, 124.294264112 24.543666459, 124.294261997 24.543693468, 124.294256122 24.543755595, 124.294253839 24.543790811, 124.29425323 24.543826117, 124.294253813 24.543910171, 124.294253372 24.543931757, 124.294252335 24.543953153, 124.294250908 24.543971847, 124.294248677 24.543993252, 124.294242283 24.544041568, 124.294230713 24.544118333, 124.294227588 24.544134775, 124.29422358 24.544150937, 124.294219572 24.544164045, 124.294215642 24.544174162, 124.294211128 24.544184099, 124.294205811 24.544193505, 124.294201297 24.544200369, 124.294194501 24.544209054, 124.294186926 24.544217468, 124.294176978 24.544227595, 124.294150895 24.544219793, 124.294125927 24.544219568, 124.294109948 24.54422664, 124.294097536 24.544236234, 124.294093891 24.544241847, 124.294096991 24.544255829, 124.294105616 24.544272063, 124.294110765 24.544281811, 124.2941007 24.54432282, 124.294096291 24.544338631, 124.294091492 24.544354261, 124.294086978 24.54436718, 124.294082075 24.544379919, 124.294076576 24.544392387, 124.294070493 24.544404676, 124.294062335 24.544419144, 124.294053671 24.544433423, 124.294023087 24.544479892, 124.293998301 24.544519216, 124.293990233 24.544530514, 124.293981375 24.544541459, 124.293973398 24.544550054, 124.293962568 24.544560459, 124.293960895 24.544562631, 124.293959429 24.544565883, 124.293959235 24.544567505, 124.293959429 24.544570126, 124.293960039 24.544572829, 124.293961427 24.544576351, 124.293963502 24.544580775, 124.293966472 24.54458555, 124.293969741 24.544590144, 124.293977069 24.544598532, 124.293994578 24.544616829, 124.294007445 24.544631694, 124.294022996 24.544651532, 124.294037458 24.54467209, 124.294051025 24.544693189, 124.294065097 24.54471709, 124.294078288 24.544741351, 124.294091971 24.544768315, 124.294107237 24.544800703, 124.294121634 24.544833541, 124.294133839 24.544864126, 124.294145071 24.544894982, 124.294154319 24.544923676, 124.294162477 24.544952459, 124.294169455 24.544981613, 124.294175344 24.545010856, 124.294180856 24.545042982, 124.294186472 24.545080622, 124.29419882 24.545169351, 124.294205953 24.545225766, 124.294210493 24.545266207, 124.294214034 24.545304036, 124.294216783 24.545341856, 124.294218742 24.545377072, 124.29422035 24.545428532, 124.29422061 24.545455613, 124.294220467 24.545481261, 124.29421939 24.545526045, 124.294215486 24.545631595, 124.294214864 24.545661396, 124.294214721 24.545685775, 124.294215642 24.545737234, 124.294219313 24.545834649, 124.294220506 24.545877982, 124.294220713 24.545926739, 124.294219754 24.545980919, 124.294217354 24.546051342, 124.294212387 24.546165117, 124.294209351 24.546216495, 124.294205512 24.546262369, 124.294202036 24.546294703, 124.294197769 24.546326946, 124.294179377 24.546444991, 124.294172789 24.546493396, 124.294166783 24.546547216, 124.294157445 24.546647099, 124.294153684 24.546684847, 124.294148651 24.546728009, 124.294143217 24.546768378, 124.294138158 24.546800532, 124.294132516 24.546832595, 124.294126757 24.546861955, 124.294119131 24.546896459, 124.29410594 24.546952099, 124.294080519 24.547054991, 124.294069663 24.547097171, 124.294052335 24.547160505, 124.294045486 24.547186883, 124.294039144 24.547216144, 124.294036796 24.547229514, 124.294034955 24.547242874, 124.29403284 24.547267081, 124.294032283 24.547280622, 124.294032114 24.547296874, 124.294032477 24.547324054, 124.294035045 24.547410721, 124.29403511 24.547435099, 124.294034475 24.547462099, 124.294033165 24.547491901, 124.294030882 24.547527027, 124.294018962 24.547664919, 124.294014708 24.547705378, 124.294010532 24.54773491, 124.294000324 24.547799216, 124.293991582 24.547861081, 124.29398847 24.547879775, 124.293985344 24.547895847, 124.293979092 24.547922225, 124.29396284 24.547982748, 124.293945551 24.54805691, 124.293940856 24.548075432, 124.293936446 24.548091153, 124.293930661 24.548109396, 124.293923891 24.548127288, 124.293916044 24.54814482, 124.293906122 24.548164523, 124.293895305 24.548183865, 124.29388262 24.548205288, 124.293867964 24.548228793, 124.293851245 24.548254468, 124.293841699 24.548268387, 124.29383166 24.548281955, 124.293822802 24.548292802, 124.29381345 24.548303207, 124.293805383 24.548311081, 124.293796809 24.548318495, 124.29379227 24.548322027, 124.293787341 24.548325198, 124.293783696 24.548326739, 124.293778859 24.548327198, 124.293776589 24.548326847, 124.293773424 24.548325676, 124.293771154 24.548324144, 124.293769079 24.548322162, 124.293765422 24.548317477, 124.29376284 24.548313414, 124.293755396 24.548298261, 124.293747004 24.548296928, 124.293737043 24.548298838, 124.293723126 24.548299495, 124.293703982 24.548300532, 124.293681271 24.548297054, 124.293652529 24.548290243, 124.293629818 24.548287856, 124.293616693 24.548286703, 124.293609585 24.548289883, 124.293600713 24.548293784, 124.293582672 24.548303297, 124.293564527 24.548310369, 124.293546368 24.548315378, 124.293528314 24.548318387, 124.2935069 24.548319423, 124.293493074 24.548318009, 124.293472827 24.548311, 124.29345227 24.548300117, 124.29342262 24.548287622, 124.293405253 24.548286847, 124.293388677 24.548289766, 124.293375447 24.548291604, 124.293301245 24.548300505, 124.293262257 24.548303288, 124.293238184 24.548308477, 124.293222905 24.54831582, 124.293192244 24.548333396, 124.293168482 24.548344459, 124.293154371 24.548346748, 124.293137198 24.548347315, 124.293091375 24.548341631, 124.293035603 24.548340838, 124.29300441 24.54833873, 124.292979235 24.548338865, 124.292964929 24.548338712, 124.292960493 24.548340622, 124.292958911 24.548342883, 124.292961297 24.548347297, 124.292966252 24.548356685, 124.292966861 24.548361919, 124.292968547 24.548368144, 124.292971414 24.548370396, 124.29297882 24.548371099, 124.292996096 24.548370441, 124.293001725 24.548372955, 124.293004099 24.548376378, 124.293004994 24.548379, 124.293000078 24.548384243, 124.292984877 24.548386441, 124.292967406 24.548386658, 124.292956654 24.548388027, 124.292950441 24.548389757, 124.292945019 24.54839509, 124.292945422 24.548399973, 124.29294869 24.548405018, 124.292953645 24.548411333, 124.292994968 24.548438604, 124.293018794 24.548454541, 124.29302808 24.548457505, 124.29303904 24.548457568, 124.293047717 24.548454306, 124.293058755 24.548449315, 124.293074137 24.548441072, 124.293110026 24.548423036, 124.293111219 24.548427432, 124.293112412 24.548431874, 124.293129546 24.548494054, 124.293142296 24.548544315, 124.293152464 24.548589441, 124.293156563 24.548610658, 124.293160363 24.548632045, 124.293163567 24.548653432, 124.293166083 24.548672117, 124.293168301 24.548693604, 124.293170026 24.54871518, 124.293171362 24.548736757, 124.293172101 24.548758423, 124.293172451 24.54878009, 124.293172399 24.548801766, 124.293171777 24.548826144, 124.293170739 24.548850613, 124.293169222 24.548875081, 124.293166913 24.548902261, 124.293164215 24.54892936, 124.293161012 24.548956541, 124.293157432 24.548983631, 124.293152957 24.549013441, 124.293148093 24.549043153, 124.293142438 24.549075396, 124.293135914 24.549110261, 124.293128885 24.549145036, 124.293124773 24.54916373, 124.293123346 24.549170441, 124.293121946 24.549177009, 124.293113839 24.549214045, 124.293097315 24.549282784, 124.293087834 24.54931964, 124.293077354 24.549359027, 124.293055136 24.549437622, 124.293030649 24.549518477, 124.293003891 24.549601685, 124.292988197 24.549648396, 124.292972127 24.549694928, 124.292954864 24.549743982, 124.292939857 24.549785189, 124.292927302 24.549818622, 124.292915331 24.549849252, 124.292902866 24.549879703, 124.292890986 24.549907351, 124.29287153 24.549949829, 124.292861803 24.549969523, 124.292850506 24.549991577, 124.292845927 24.55, 124.3 24.55, 124.3 24.541666666666668, 124.29586400788799 24.541666666666668, 124.295864008 24.541666667)))\n\n\n沖縄県\nNA\nNA\n石垣市\nNA\n47207\n36246254\n47207\n46.0631\nPOLYGON ((124.308674695 24.54997536, 124.308642542 24.549947342, 124.308608703 24.549916901, 124.308520947 24.54983627, 124.30849345 24.549811676, 124.308467536 24.549789523, 124.308434397 24.549762495, 124.308396031 24.549732784, 124.308359339 24.549705324, 124.308333333 24.549686207, 124.308269157 24.549639054, 124.308228106 24.549607892, 124.308207938 24.549591955, 124.308188158 24.549575658, 124.308170843 24.549560883, 124.308151855 24.549543856, 124.308133243 24.549526468, 124.30811297 24.549506649, 124.308091089 24.549484477, 124.308069715 24.549461955, 124.308033398 24.549422568, 124.30793917 24.549318117, 124.307910363 24.549287207, 124.30784 24.549213946, 124.307817341 24.549188982, 124.307793385 24.549161495, 124.307757549 24.549118414, 124.307688729 24.549033405, 124.307631608 24.54896391, 124.307608742 24.548935523, 124.307591608 24.548913432, 124.307575162 24.548890892, 124.307560999 24.548870342, 124.307549105 24.548851676, 124.307532257 24.54882309, 124.307498846 24.548762568, 124.30748358 24.548736324, 124.307464656 24.548705667, 124.307425214 24.548645072, 124.307410259 24.548621631, 124.307394591 24.548595477, 124.307382594 24.548573658, 124.307372776 24.548553991, 124.307363943 24.548533964, 124.307355901 24.548513577, 124.307333839 24.548454577, 124.307327588 24.548439324, 124.307319844 24.548421829, 124.30730546 24.548392063, 124.307267173 24.54831864, 124.307236524 24.548257036, 124.307240584 24.54822191, 124.307250739 24.548177919, 124.307254254 24.548162198, 124.307250791 24.548155703, 124.307229572 24.548155297, 124.307218106 24.548150441, 124.307163372 24.548129072, 124.307126213 24.548115784, 124.307090947 24.548101586, 124.307077289 24.548088703, 124.307065409 24.548070946, 124.307048119 24.548065739, 124.307030052 24.548064874, 124.307025201 24.548058018, 124.307028327 24.548045559, 124.307039741 24.54803018, 124.30705703 24.547997099, 124.307052153 24.547982126, 124.307046407 24.547971667, 124.307018223 24.547952306, 124.306941868 24.547929622, 124.306876524 24.547929306, 124.306851764 24.547936577, 124.306817354 24.547950279, 124.306797445 24.547966387, 124.306786835 24.54798736, 124.306746576 24.548035027, 124.306716978 24.548079865, 124.306715655 24.548101631, 124.306720039 24.548117784, 124.306723995 24.54812509, 124.306736368 24.548139595, 124.306744293 24.548148072, 124.30674939 24.548176315, 124.306720233 24.548201297, 124.306681012 24.548226748, 124.306666213 24.548231928, 124.306637315 24.548238126, 124.306603152 24.548237198, 124.306551518 24.548230712, 124.306437289 24.548181108, 124.30629668 24.548081712, 124.30614904 24.547974748, 124.306054527 24.547912378, 124.306049455 24.547895955, 124.306042516 24.547882964, 124.306036381 24.547877018, 124.306029663 24.547873964, 124.306024034 24.547875775, 124.306014384 24.547885009, 124.305912049 24.547815153, 124.305923035 24.547788856, 124.305918638 24.547764126, 124.305905266 24.54774727, 124.305895292 24.547745036, 124.305884047 24.547748667, 124.30586022 24.54777264, 124.305782879 24.547709505, 124.305728379 24.547663658, 124.305681297 24.547622495, 124.305614423 24.547561054, 124.305586913 24.547536459, 124.305558625 24.547512495, 124.305505616 24.54746927, 124.305483658 24.547451072, 124.305453489 24.547425045, 124.305414112 24.54739027, 124.305401686 24.547353009, 124.305373268 24.547316135, 124.305318482 24.547276342, 124.305279079 24.547268387, 124.305244851 24.547275495, 124.305222607 24.547263982, 124.305185927 24.547238865, 124.305173243 24.547217766, 124.305168755 24.54719836, 124.305200947 24.547162631, 124.305197821 24.547134649, 124.305185642 24.547119955, 124.305132879 24.547097856, 124.305092983 24.54708891, 124.305071089 24.547099964, 124.30504869 24.547104523, 124.305032153 24.547081802, 124.305021167 24.547067928, 124.305011946 24.547051964, 124.305001336 24.547033297, 124.304994397 24.547021658, 124.30498856 24.54701355, 124.304973346 24.547006892, 124.30495703 24.546998171, 124.304994384 24.546974892, 124.305003943 24.546965297, 124.305002322 24.546948604, 124.30497594 24.546898811, 124.304968923 24.546896568, 124.304938236 24.546899523, 124.304905512 24.54687927, 124.304896978 24.546860333, 124.304868911 24.546843324, 124.304860285 24.54682709, 124.304828988 24.546787514, 124.304807263 24.546782414, 124.304749533 24.546786685, 124.304732075 24.546792405, 124.304720195 24.546779613, 124.304722724 24.54676755, 124.30471463 24.546761919, 124.304704617 24.546760054, 124.304692659 24.546743018, 124.304670182 24.546751721, 124.304663554 24.546744604, 124.304651958 24.546727018, 124.304637393 24.546705649, 124.30463131 24.546638577, 124.304615409 24.54659482, 124.304623359 24.546573946, 124.304621673 24.546567991, 124.30460179 24.546555387, 124.304570687 24.546546514, 124.304564423 24.546531901, 124.304555201 24.546514586, 124.304545136 24.546514964, 124.304536265 24.546520315, 124.304515136 24.546519, 124.304489857 24.546515532, 124.304481154 24.546504441, 124.304474812 24.546495333, 124.304469559 24.546485775, 124.304465188 24.546475856, 124.304459922 24.546460243, 124.30444847 24.546417649, 124.304443787 24.546401766, 124.304438612 24.546386162, 124.304433152 24.54637064, 124.304426394 24.546352685, 124.304419144 24.546334829, 124.30441061 24.546314622, 124.3043993 24.546289631, 124.304386394 24.546262297, 124.304337601 24.546163622, 124.304316265 24.546118973, 124.304290259 24.546061423, 124.304263165 24.54599845, 124.30424013 24.545942613, 124.304214708 24.545879009, 124.304107237 24.545603306, 124.304081816 24.545536811, 124.304059663 24.545477901, 124.304039987 24.545423946, 124.304019118 24.545364757, 124.303886109 24.544976964, 124.303863632 24.544909568, 124.303844449 24.544849838, 124.303833204 24.544813288, 124.303822348 24.544776748, 124.303812594 24.54474273, 124.303802542 24.54470591, 124.303780817 24.544621532, 124.303734968 24.544436622, 124.303712451 24.544349631, 124.303678988 24.544226099, 124.30360441 24.54395827, 124.303585383 24.543887252, 124.303568651 24.543821279, 124.303552789 24.543755135, 124.303539326 24.543694036, 124.303526732 24.543632847, 124.303497458 24.543486279, 124.303481089 24.543409198, 124.303464527 24.54333764, 124.303429248 24.543194964, 124.303415292 24.543136757, 124.303401115 24.543073036, 124.303382646 24.542984775, 124.303369235 24.542827514, 124.303359092 24.542714135, 124.303349183 24.542611586, 124.303338573 24.542511928, 124.303326874 24.542409568, 124.303313489 24.542299171, 124.303265694 24.541922315, 124.30325773 24.541854973, 124.303251375 24.541795667, 124.303244695 24.541725613, 124.303240156 24.541666667, 124.30324015597428 24.541666666666668, 124.3 24.541666666666668, 124.3 24.55, 124.3087038 24.55, 124.308674695 24.54997536))\n\n\n\n\n\n\n\nCode\nprint(glue::glue(\"{difftime(Sys.time(), s, units = 'secs')} 秒\"))\n#&gt; 126.621687889099 秒\n\n\n計算結果をGeoJSONに書き出す。時間がかかるので未実行です。\n\n\nCode\nCOPY (\n  select\n    COLUMNS(pref.* EXCLUDE(geom)), \n    ag.MESH_ID, \n    ag.SHICODE, \n    ag.PTN_2015,\n    st_intersection(pref.geom, ag.geom) as geom\n  from pref, ag\n  where st_intersects(pref.geom, ag.geom)\n)\nTO './data/intersection_ag_n03.geojson'\nWITH (FORMAT GDAL, DRIVER 'GeoJSON', SRS '4612')\n;\n\n\n\n\n3 Disconnect\n\n\nCode\ndbDisconnect(con, shutdown=TRUE)\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap03_.html",
    "href": "contents/sql/duckdb/sql-bigdata/chap03_.html",
    "title": "データ加工のためのSQL",
    "section": "",
    "text": "Code\nrenv::activate(here::here())\nCode\n\ncur_dir &lt;- here::here(\"contents/sql/duckdb/sql-bigdata\")\n\nlibrary(ggplot2)\nlibrary(duckdb)\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(DBI)\nlibrary(dbplyr)\nlibrary(arrow)\nlibrary(showtext)\nlibrary(here)\nshowtext_auto()\nfont_add_google(\"Noto Sans\")"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap03_.html#コード値をラベルに置き換える",
    "href": "contents/sql/duckdb/sql-bigdata/chap03_.html#コード値をラベルに置き換える",
    "title": "データ加工のためのSQL",
    "section": "2.1 コード値をラベルに置き換える",
    "text": "2.1 コード値をラベルに置き換える\n\n\nCode\nSELECT\n  user_id\n  , CASE \n      WHEN register_device = 1 THEN 'PC'\n      WHEN register_device = 2 THEN 'SP'\n      WHEN register_device = 3 THEN 'アプリ'\n    END device_name\nFROM mst_users;\n\n\n\n3 records\n\n\nuser_id\ndevice_name\n\n\n\n\nU001\nPC\n\n\nU002\nSP\n\n\nU003\nアプリ"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap03_.html#urlから要素を取り出す",
    "href": "contents/sql/duckdb/sql-bigdata/chap03_.html#urlから要素を取り出す",
    "title": "データ加工のためのSQL",
    "section": "2.2 URLから要素を取り出す",
    "text": "2.2 URLから要素を取り出す\n\n\nCode\nSELECT\n  *\nFROM access_log;\n\n\n\n3 records\n\n\n\n\n\n\n\nstamp\nreferrer\nurl\n\n\n\n\n2016-08-26 12:02:00\nhttp://www.other.com/path1/index.php?k1=v1&k2=v2#Ref1\nhttp://www.example.com/video/detail?id=001\n\n\n2016-08-26 12:02:01\nhttp://www.other.net/path1/index.php?k1=v1&k2=v2#Ref1\nhttp://www.example.com/video#ref\n\n\n2016-08-26 12:02:01\nhttps://www.other.com/\nhttp://www.example.com/book/detail?id=002\n\n\n\n\n\n正規表現を使うことが出来る。\n\n\nCode\nSELECT\n  stamp\n  , regexp_extract(referrer , 'https?://([^/]*)') referrer_host\nFROM access_log;\n\n\n\n3 records\n\n\nstamp\nreferrer_host\n\n\n\n\n2016-08-26 12:02:00\nhttp://www.other.com\n\n\n2016-08-26 12:02:01\nhttp://www.other.net\n\n\n2016-08-26 12:02:01\nhttps://www.other.com\n\n\n\n\n\n\n2.2.1 URLからパスやクエリパラメータを取り出す\nインデックスで取り出す必要がある。\n\n\nCode\nSELECT \n  stamp\n  , url\n  , regexp_extract(url, '//[^/]+(?P&lt;name&gt;[^?#]+)', 1) path\n  , regexp_extract(url, 'id=([^&]*)', 1) id\nFROM access_log;\n\n\n\n3 records\n\n\n\n\n\n\n\n\nstamp\nurl\npath\nid\n\n\n\n\n2016-08-26 12:02:00\nhttp://www.example.com/video/detail?id=001\n/video/detail\n001\n\n\n2016-08-26 12:02:01\nhttp://www.example.com/video#ref\n/video\n\n\n\n2016-08-26 12:02:01\nhttp://www.example.com/book/detail?id=002\n/book/detail\n002"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap03_.html#文字列を配列に分解する",
    "href": "contents/sql/duckdb/sql-bigdata/chap03_.html#文字列を配列に分解する",
    "title": "データ加工のためのSQL",
    "section": "2.3 文字列を配列に分解する",
    "text": "2.3 文字列を配列に分解する\nregex_extractでホストと以下の部分を取得して, split_partで分割をおこなう。\n\n\nCode\nSELECT \n  stamp\n  , url\n  , regexp_extract(url, '//[^/]+([^?#]+)', 1) as A\n  , split_part(regexp_extract(url, '//[^/]+([^?#]+)', 1), '/', 2) path1\n  , split_part(regexp_extract(url, '//[^/]+([^?#]+)', 1), '/', 3) path2\nFROM \n  access_log;\n\n\n\n3 records\n\n\n\n\n\n\n\n\n\nstamp\nurl\nA\npath1\npath2\n\n\n\n\n2016-08-26 12:02:00\nhttp://www.example.com/video/detail?id=001\n/video/detail\nvideo\ndetail\n\n\n2016-08-26 12:02:01\nhttp://www.example.com/video#ref\n/video\nvideo\n\n\n\n2016-08-26 12:02:01\nhttp://www.example.com/book/detail?id=002\n/book/detail\nbook\ndetail\n\n\n\n\n\n非効率に見えるので次でもいいと思う。\n\n\nCode\nWITH path_extracted AS (\n  SELECT\n    stamp,\n    url,\n    regexp_extract(url, '//[^/]+([^?#]+)', 1) AS extracted_path\n  FROM\n    access_log\n)\nSELECT\n  stamp,\n  url,\n  extracted_path AS A,\n  split_part(extracted_path, '/', 2) AS path1,\n  split_part(extracted_path, '/', 3) AS path2\nFROM\n  path_extracted;\n\n\n\n3 records\n\n\n\n\n\n\n\n\n\nstamp\nurl\nA\npath1\npath2\n\n\n\n\n2016-08-26 12:02:00\nhttp://www.example.com/video/detail?id=001\n/video/detail\nvideo\ndetail\n\n\n2016-08-26 12:02:01\nhttp://www.example.com/video#ref\n/video\nvideo\n\n\n\n2016-08-26 12:02:01\nhttp://www.example.com/book/detail?id=002\n/book/detail\nbook\ndetail"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap03_.html#日付やタイムスタンプを扱う",
    "href": "contents/sql/duckdb/sql-bigdata/chap03_.html#日付やタイムスタンプを扱う",
    "title": "データ加工のためのSQL",
    "section": "2.4 日付やタイムスタンプを扱う",
    "text": "2.4 日付やタイムスタンプを扱う\nINSTALL icu;\nLOAD icu;\nタイムゾーンの設定はAisa/TokyoだけどTodayなどを使うとUTCの時間が取得される。 現地の時間が欲しければローカルタイムを使うこと。\n\n\nCode\nSELECT * FROM duckdb_settings() WHERE name = 'TimeZone';\n\n\n\n1 records\n\n\nname\nvalue\ndescription\ninput_type\n\n\n\n\nTimeZone\nAsia/Tokyo\nThe current time zone\nVARCHAR\n\n\n\n\n\nタイムゾーンの変更をおこなう。\n\n\nCode\nSET TimeZone='Asia/Tokyo';\n\n\n\n\nCode\nSELECT \n  CURRENT_DATE as dt\n  , CURRENT_TIMESTAMP as stamp\n  , LOCALTIMESTAMP as lstamp\n  , now() as now\n  , today() as tdy\n;\n\n\n\n1 records\n\n\n\n\n\n\n\n\n\ndt\nstamp\nlstamp\nnow\ntdy\n\n\n\n\n2024-03-31\n2024-03-31 06:33:39\n2024-03-31 15:33:39\n2024-03-31 06:33:39\n2024-03-31\n\n\n\n\n\n\n2.4.1 文字列の日付や時刻データを変換する\nCASTのなかのAsは必要なことに注意する。\n\n\nCode\nSELECT\n    -- ■ PostgreSQL, Hive, Redshift, BigQuery, SparkSQLのすべてで、\n    --   「CAST(value AS type)」の形式が利用できる\n    CAST('2016-01-30' AS date) AS dt\n  , CAST('2016-01-30 12:00:00' AS timestamp) AS stamp;\n\n\n\n1 records\n\n\ndt\nstamp\n\n\n\n\n2016-01-30\n2016-01-30 12:00:00\n\n\n\n\n\n\n\nCode\nWITH tmp as (SELECT\n    -- ■ PostgreSQL, Hive, Redshift, BigQuery, SparkSQLのすべてで、\n    --   「CAST(value AS type)」の形式が利用できる\n    strptime('2016-01-30', '%Y-%m-%d') AS dt\n  , strptime('2016-01-30 12:00:00', '%Y-%m-%d %H:%M:%S') AS stamp\n) \nSELECT *\nFROM tmp;\n\n\n\n1 records\n\n\ndt\nstamp\n\n\n\n\n2016-01-30\n2016-01-30 12:00:00\n\n\n\n\n\n\n\nCode\nWITH tmp as (SELECT\n    -- ■ PostgreSQL, Hive, Redshift, BigQuery, SparkSQLのすべてで、\n    --   「CAST(value AS type)」の形式が利用できる\n    '2016-01-30'::date AS dt\n  , '2016-01-30 12:00:00'::timestamp AS stamp\n) \nSELECT *\nFROM tmp;\n\n\n\n1 records\n\n\ndt\nstamp\n\n\n\n\n2016-01-30\n2016-01-30 12:00:00\n\n\n\n\n\n\n\n2.4.2 日付/時刻から特定のフィールドを取り出す\n\n\nCode\nSELECT\n  stamp\n  , EXTRACT(YEAR  FROM stamp) AS year\n  , EXTRACT(MONTH FROM stamp) AS month\n  , EXTRACT(DAY   FROM stamp) AS day\n  , EXTRACT(HOUR  FROM stamp) AS hour\nFROM  (SELECT CAST('2016-01-30 12:00:00' AS timestamp) as stamp) AS t ;\n\n\n\n1 records\n\n\nstamp\nyear\nmonth\nday\nhour\n\n\n\n\n2016-01-30 12:00:00\n2016\n1\n30\n12"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap03_.html#欠損値をデフォルト値に置き換える",
    "href": "contents/sql/duckdb/sql-bigdata/chap03_.html#欠損値をデフォルト値に置き換える",
    "title": "データ加工のためのSQL",
    "section": "2.5 欠損値をデフォルト値に置き換える",
    "text": "2.5 欠損値をデフォルト値に置き換える\n\n\nCode\nSELECT\n  purchase_id\n  , amount\n  , coupon\n  , amount - coupon discount_amount1\n  , amount - COALESCE(coupon, 0) discount_amount2\nFROM \n  purchase_log_with_coupon\n;\n\n\n\n3 records\n\n\npurchase_id\namount\ncoupon\ndiscount_amount1\ndiscount_amount2\n\n\n\n\n10001\n3280\nNA\nNA\n3280\n\n\n10002\n4650\n500\n4150\n4150\n\n\n10003\n3870\nNA\nNA\n3870"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap03_.html#文字列を連結する",
    "href": "contents/sql/duckdb/sql-bigdata/chap03_.html#文字列を連結する",
    "title": "データ加工のためのSQL",
    "section": "3.1 文字列を連結する",
    "text": "3.1 文字列を連結する\n\n\nCode\nSELECT\n  user_id\n  , CONCAT(pref_name, city_name) pref_city\n  , pref_name || city_name pref_city2\n  , CONCAT_WS('/', pref_name, city_name) pref_city3\nFROM\n  mst_user_location\n;\n\n\n\n3 records\n\n\nuser_id\npref_city\npref_city2\npref_city3\n\n\n\n\nU001\n東京都千代田区\n東京都千代田区\n東京都/千代田区\n\n\nU002\n東京都渋谷区\n東京都渋谷区\n東京都/渋谷区\n\n\nU003\n千葉県八千代区\n千葉県八千代区\n千葉県/八千代区"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap03_.html#複数の値を比較する",
    "href": "contents/sql/duckdb/sql-bigdata/chap03_.html#複数の値を比較する",
    "title": "データ加工のためのSQL",
    "section": "3.2 複数の値を比較する",
    "text": "3.2 複数の値を比較する\n横持ちのデータを比較することを考える。\n\n\nCode\nSELECT\n  year\n  , q1\n  , q2\n  , CASE\n      WHEN q1 &lt; q2 THEN '+'\n      WHEN q1 = q2 THEN ' '\n      ELSE '-'\n    END judge_q1_q2\n  , q2-q1 diff_q2_q1\n  , SIGN(q2-q1) sign_q2_q1\nFROM\n  quarterly_sales\nORDER BY\n  year\n;\n\n\n\n3 records\n\n\nyear\nq1\nq2\njudge_q1_q2\ndiff_q2_q1\nsign_q2_q1\n\n\n\n\n2015\n82000\n83000\n+\n1000\n1\n\n\n2016\n85000\n85000\n\n0\n0\n\n\n2017\n92000\n81000\n-\n-11000\n-1\n\n\n\n\n\n\n3.2.1 年間の最大値をを見つける\n\n\nCode\nSELECT\n  year\n  , greatest(q1, q2, q3, q4) greatest_sales\n  , least(q1, q2, q3, q4) least_sales\nFROM\n  quarterly_sales\nORDER BY\n  year\n;\n\n\n\n3 records\n\n\nyear\ngreatest_sales\nleast_sales\n\n\n\n\n2015\n83000\n78000\n\n\n2016\n85000\n80000\n\n\n2017\n92000\n81000\n\n\n\n\n\n\n\n3.2.2 年間の平均四半期売上を計算する\n\n\nCode\nSELECT\n  year\n  , (q1 + q2 + q3 + q4) / 4 average\nFROM\n  quarterly_sales\nORDER BY\n  year\n;\n\n\n\n3 records\n\n\nyear\naverage\n\n\n\n\n2015\n81500\n\n\n2016\n82750\n\n\n2017\nNA\n\n\n\n\n\nこれはだるいのだが・・・？縦持ちに変換できれば出来そうだけど。\n次は行ごとにNULLでないカラムでの平均値を求める。\n\n\nCode\nSELECT\n  year\n  , (COALESCE(q1, 0) + COALESCE(q2, 0) + COALESCE(q3, 0) + COALESCE(q4, 0)) \n    / (SIGN(COALESCE(q1, 0)) + SIGN(COALESCE(q2, 0)) + SIGN(COALESCE(q3, 0)) + SIGN(COALESCE(q4, 0))) average\nFROM\n  quarterly_sales\nORDER BY\n  year\n;\n\n\n\n3 records\n\n\nyear\naverage\n\n\n\n\n2015\n81500\n\n\n2016\n82750\n\n\n2017\n86500\n\n\n\n\n\nduckdbだとPIVOTとUNPIVOTがあるので簡単におこなうことができる。\n\n\nCode\nUNPIVOT quarterly_sales\nON q1, q2, q3, q4\nINTO \n  NAME quarter\n  VALUE sales;\n\n\n\nDisplaying records 1 - 10\n\n\nyear\nquarter\nsales\n\n\n\n\n2015\nq1\n82000\n\n\n2015\nq2\n83000\n\n\n2015\nq3\n78000\n\n\n2015\nq4\n83000\n\n\n2016\nq1\n85000\n\n\n2016\nq2\n85000\n\n\n2016\nq3\n80000\n\n\n2016\nq4\n81000\n\n\n2017\nq1\n92000\n\n\n2017\nq2\n81000\n\n\n\n\n\n正規表現とかを使うことも可能である。\n\n\nCode\nSELECT \n  COLUMNS(*)\nFROM (\n  UNPIVOT quarterly_sales\n  ON COLUMNS('^q\\d')\n  INTO \n    NAME quarter\n    VALUE sales\n);\n\n\n\nDisplaying records 1 - 10\n\n\nyear\nquarter\nsales\n\n\n\n\n2015\nq1\n82000\n\n\n2015\nq2\n83000\n\n\n2015\nq3\n78000\n\n\n2015\nq4\n83000\n\n\n2016\nq1\n85000\n\n\n2016\nq2\n85000\n\n\n2016\nq3\n80000\n\n\n2016\nq4\n81000\n\n\n2017\nq1\n92000\n\n\n2017\nq2\n81000"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap03_.html#つの値の比率を計算する",
    "href": "contents/sql/duckdb/sql-bigdata/chap03_.html#つの値の比率を計算する",
    "title": "データ加工のためのSQL",
    "section": "3.3 2つの値の比率を計算する",
    "text": "3.3 2つの値の比率を計算する\n\n\nCode\nSELECT * FROM advertising_stats;\n\n\n\n6 records\n\n\ndt\nad_id\nimpressions\nclicks\n\n\n\n\n2017-04-01\n001\n100000\n3000\n\n\n2017-04-01\n002\n120000\n1200\n\n\n2017-04-01\n003\n500000\n10000\n\n\n2017-04-02\n001\n0\n0\n\n\n2017-04-02\n002\n130000\n1400\n\n\n2017-04-02\n003\n620000\n15000\n\n\n\n\n\n\n3.3.1 整数型のデータの除算\nCTR(Click Through Rate)を計算する。CTRの定義は「クリック数 / インプレッション数」である。 整数型同士の乗算は事前に実数型に変換しておく必要がある。\n\n\nCode\nSELECT\n  dt\n  , ad_id\n  , clicks / impressions ctr\n  , 100. * clicks / impressions ctr_as_percent\n  , 100  * clicks / impressions ctr_as_percent2\nFROM\n  advertising_stats\nWHERE\n  dt = '2017-04-01'\nORDER BY\n  dt, ad_id\n;\n\n\n\n3 records\n\n\ndt\nad_id\nctr\nctr_as_percent\nctr_as_percent2\n\n\n\n\n2017-04-01\n001\n0.03\n3\n3\n\n\n2017-04-01\n002\n0.01\n1\n1\n\n\n2017-04-01\n003\n0.02\n2\n2\n\n\n\n\n\n\n\n3.3.2 0除算を避ける\n0除算を回避するにはCASE分を用いて分母の数が０かどうかを判定すること、 または、NULLを伝搬させることがある。NULLIF(x, default)は0のときに置き換える演算である。\n\n\nCode\nSELECT\n  dt\n  , ad_id\n  , CASE\n      WHEN impressions &gt; 0 THEN 100. * clicks / impressions\n      END ctr_as_percent_by_case\n  , 100. * clicks / NULLIF(impressions, 0) ctr_as_percent_by_null\nFROM \n  advertising_stats\nORDER BY\n  dt, ad_id\n;\n\n\n\n6 records\n\n\ndt\nad_id\nctr_as_percent_by_case\nctr_as_percent_by_null\n\n\n\n\n2017-04-01\n001\n3.000000\n3.000000\n\n\n2017-04-01\n002\n1.000000\n1.000000\n\n\n2017-04-01\n003\n2.000000\n2.000000\n\n\n2017-04-02\n001\nNA\nNA\n\n\n2017-04-02\n002\n1.076923\n1.076923\n\n\n2017-04-02\n003\n2.419355\n2.419355"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap03_.html#つの値の距離を計算する",
    "href": "contents/sql/duckdb/sql-bigdata/chap03_.html#つの値の距離を計算する",
    "title": "データ加工のためのSQL",
    "section": "3.4 2つの値の距離を計算する",
    "text": "3.4 2つの値の距離を計算する\n\n3.4.1 RMS\n\n\nCode\nSELECT\n  abs(x1-x2) abs\n  , sqrt(power(x1-x2, 2)) rms\nFROM location_1d;\n\n\n\n5 records\n\n\nabs\nrms\n\n\n\n\n5\n5\n\n\n5\n5\n\n\n6\n6\n\n\n0\n0\n\n\n1\n1\n\n\n\n\n\n\n\nCode\nSELECT\n  x1\n  , AVG(x1) OVER()\n  , x1 - AVG(x1) over()\n  , POWER(x1 - AVG(x1) over(), 2)\nFROM location_1d;\n\n\n\n5 records\n\n\n\n\n\n\n\n\nx1\navg(x1) OVER ()\n(x1 - avg(x1) OVER ())\npower((x1 - avg(x1) OVER ()), 2)\n\n\n\n\n5\n3.2\n1.8\n3.24\n\n\n10\n3.2\n6.8\n46.24\n\n\n-2\n3.2\n-5.2\n27.04\n\n\n3\n3.2\n-0.2\n0.04\n\n\n0\n3.2\n-3.2\n10.24\n\n\n\n\n\n\n\n3.4.2 xy平面上で2点間のユークリッド距離を計算する\nなし\n\n\n3.4.3 arrayやlistを持ちいた距離\nDBI経由だと計算できないが、コマンドラインからだと直接演算することが可能である。 どうやらarrayは0.10から追加されて、その後に\n#| connection: con\n\nDROP TABLE IF EXISTS x;\nDROP TABLE IF EXISTS y;\nCREATE TABLE x (i INT, v FLOAT[3]);\nCREATE TABLE y (i INT, v FLOAT[3]);\nINSERT INTO x VALUES (1, array_value(1.0::FLOAT, 2.0::FLOAT, 3.0::FLOAT));\nINSERT INTO y VALUES (1, array_value(2.0::FLOAT, 3.0::FLOAT, 4.0::FLOAT));\n-- compute cross product\nSELECT array_cross_product(x.v, y.v)\nFROM x, y\nWHERE x.i = y.i;\nリストは使えるのでリスで計算すればいいのかもしれない？？？\n\n\nCode\nselect list_value(1,2,3)\n\n\n\n1 records\n\n\nlist_value(1, 2, 3)\n\n\n\n\n1, 2, 3"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap03_.html#日付時刻を計算する",
    "href": "contents/sql/duckdb/sql-bigdata/chap03_.html#日付時刻を計算する",
    "title": "データ加工のためのSQL",
    "section": "3.5 日付・時刻を計算する",
    "text": "3.5 日付・時刻を計算する\n2つの日付・時刻データの差分を計算したり、１時間後の時刻を計算するなど、の手法をみる。\n\n\nCode\nSELECT\n  *\nFROM mst_users_with_birthday;\n\n\n\n3 records\n\n\nuser_id\nregister_stamp\nbirth_date\n\n\n\n\nU001\n2016-02-28 10:00:00\n2000-02-29\n\n\nU002\n2016-02-29 10:00:00\n2000-02-29\n\n\nU003\n2016-03-01 10:00:00\n2000-02-29\n\n\n\n\n\n\n3.5.1 日付・時刻データと定数の足し算・引き算\n\n\nCode\nSELECT\n  user_id\n  , register_stamp::timestamp register_stamp\n  , register_stamp::timestamp + '1 hour'::interval after_1_hour\n  , register_stamp::timestamp - '30 minutes'::interval before_30_minutes\n  , register_stamp::date register_date\n  , (register_stamp::date + '1 day'::interval)::date AS after_1_day\n  , (register_stamp::date - '1 month'::interval)::date AS before_1_month\n  , date_add(register_stamp::date, '1 week'::interval) as after_1_week\n  , date_trunc('month', register_stamp::date) as trunc_month\nFROM mst_users_with_birthday;\n\n\n\n3 records\n\n\n\n\n\n\n\n\n\n\n\n\n\nuser_id\nregister_stamp\nafter_1_hour\nbefore_30_minutes\nregister_date\nafter_1_day\nbefore_1_month\nafter_1_week\ntrunc_month\n\n\n\n\nU001\n2016-02-28 10:00:00\n2016-02-28 11:00:00\n2016-02-28 09:30:00\n2016-02-28\n2016-02-29\n2016-01-28\n2016-03-06\n2016-02-01\n\n\nU002\n2016-02-29 10:00:00\n2016-02-29 11:00:00\n2016-02-29 09:30:00\n2016-02-29\n2016-03-01\n2016-01-29\n2016-03-07\n2016-02-01\n\n\nU003\n2016-03-01 10:00:00\n2016-03-01 11:00:00\n2016-03-01 09:30:00\n2016-03-01\n2016-03-02\n2016-02-01\n2016-03-08\n2016-03-01\n\n\n\n\n\n\n\n3.5.2 日付データ同士の差分を計算する\n\n\nCode\nSELECT\n  user_id\n  , CURRENT_DATE today\n  , register_stamp::date register_date\n  , CURRENT_DATE - register_stamp::date diff_days\nFROM mst_users_with_birthday;\n\n\n\n3 records\n\n\nuser_id\ntoday\nregister_date\ndiff_days\n\n\n\n\nU001\n2024-03-31\n2016-02-28\n2954\n\n\nU002\n2024-03-31\n2016-02-29\n2953\n\n\nU003\n2024-03-31\n2016-03-01\n2952\n\n\n\n\n\n\n\n3.5.3 ユーザーの生年月日から年齢を計算する\n\n\nCode\nSELECT\n  user_id\n  , CURRENT_DATE today\n  , register_stamp::date register_date\n  , birth_date::date birth_date\n  , age(birth_date::date) age\n  , age(register_stamp::date, birth_date::date) age2\n  , EXTRACT(YEAR FROM age(birth_date::date)) current_age\n  , EXTRACT(YEAR FROM age(register_stamp::date, birth_date::date)) register_age\nFROM mst_users_with_birthday;\n\n\n\n3 records\n\n\n\n\n\n\n\n\n\n\n\n\nuser_id\ntoday\nregister_date\nbirth_date\nage\nage2\ncurrent_age\nregister_age\n\n\n\n\nU001\n2024-03-31\n2016-02-28\n2000-02-29\n749284420 secs\n497491200 secs\n24\n15\n\n\nU002\n2024-03-31\n2016-02-29\n2000-02-29\n749284420 secs\n497664000 secs\n24\n16\n\n\nU003\n2024-03-31\n2016-03-01\n2000-02-29\n749284420 secs\n497750400 secs\n24\n16"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap03_.html#ipアドレスを扱う",
    "href": "contents/sql/duckdb/sql-bigdata/chap03_.html#ipアドレスを扱う",
    "title": "データ加工のためのSQL",
    "section": "3.6 IPアドレスを扱う",
    "text": "3.6 IPアドレスを扱う\nduckdbにはinet型はないみたいである。\n#| connection: con\nSELECT\n  CAST('172.16.4.46' as inet) &lt; cast('172.17.49.127' as inet ) as lt;\n\n3.6.1 整数値や文字列としてIPアドレスを扱う\nBIT型が存在しているらしいがここでは使うことができなかった。ｓｓ\n\n\nCode\nSELECT\n  ip\n  , CAST(split_part(ip, '.',  1) AS integer) part_1\n  , CAST(split_part(ip, '.',  2) AS integer) part_2\n  , CAST(split_part(ip, '.',  3) AS integer) part_3\n  , CAST(split_part(ip, '.',  4) AS integer) part_4\n  \n  -- ０パディング\n  , lpad(split_part(ip, '.',  1), 3, '0') part_1\n  , lpad(split_part(ip, '.',  2), 3, '0') part_2\n  , lpad(split_part(ip, '.',  3), 3, '0') part_3\n  , lpad(split_part(ip, '.',  4), 3, '0') part_4\n  \n  -- , CAST(split_part(ip, '.',  1) AS integer) bit_part_1\n  -- , CAST(split_part(ip, '.',  2) AS integer)::BIT bit_part_2\n  -- , CAST(split_part(ip, '.',  3) AS integer)::BIT bit_part_3\n  -- , CAST(split_part(ip, '.',  4) AS integer)::BIT bit_part_4\nFROM (\n  SELECT '192.168.0.1' AS ip\n) as t\n\n\n\n1 records\n\n\n\n\n\n\n\n\n\n\n\n\n\nip\npart_1\npart_2\npart_3\npart_4\npart_1\npart_2\npart_3\npart_4\n\n\n\n\n192.168.0.1\n192\n168\n0\n1\n192\n168\n000\n001"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap03_.html#グループの特徴を捉える",
    "href": "contents/sql/duckdb/sql-bigdata/chap03_.html#グループの特徴を捉える",
    "title": "データ加工のためのSQL",
    "section": "4.1 グループの特徴を捉える。",
    "text": "4.1 グループの特徴を捉える。\n\n\nCode\nSELECT * FROM review;\n\n\n\n9 records\n\n\nuser_id\nproduct_id\nscore\n\n\n\n\nU001\nA001\n4\n\n\nU001\nA002\n5\n\n\nU001\nA003\n5\n\n\nU002\nA001\n3\n\n\nU002\nA002\n3\n\n\nU002\nA003\n4\n\n\nU003\nA001\n5\n\n\nU003\nA002\n4\n\n\nU003\nA003\n4\n\n\n\n\n\n\n4.1.1 テーブル全体の特徴量\n\n\nCode\nSELECT\n  COUNT(*) total_count\n  , COUNT(DISTINCT user_id) user_count\n  , COUNT(DISTINCT product_id) product_count\n  , SUM(score) sum\n  , AVG(score) avg\n  , MIN(score) min\n  , MAX(score) max\n  , LN(SUM(EXP(score))) log_sum_exp\nFROM \n  review\n;\n\n\n\n1 records\n\n\n\n\n\n\n\n\n\n\n\n\ntotal_count\nuser_count\nproduct_count\nsum\navg\nmin\nmax\nlog_sum_exp\n\n\n\n\n9\n3\n3\n37\n4.111111\n3\n5\n6.556499\n\n\n\n\n\n\n\n4.1.2 グルーピングしたテーブル全体の特徴量\n\n\nCode\nSELECT\n  COUNT(*) total_count\n  , COUNT(DISTINCT user_id) user_count\n  , COUNT(DISTINCT product_id) product_count\n  , SUM(score) sum\n  , AVG(score) avg\n  , MIN(score) min\n  , MAX(score) max\n  , LN(SUM(EXP(score))) log_sum_exp\nFROM \n  review\nGROUP BY\n  user_id\n;\n\n\n\n3 records\n\n\n\n\n\n\n\n\n\n\n\n\ntotal_count\nuser_count\nproduct_count\nsum\navg\nmin\nmax\nlog_sum_exp\n\n\n\n\n3\n1\n3\n10\n3.333333\n3\n4\n4.551445\n\n\n3\n1\n3\n13\n4.333333\n4\n5\n5.551445\n\n\n3\n1\n3\n14\n4.666667\n4\n5\n5.861995\n\n\n\n\n\n\n\n4.1.3 集約関数を適用した値と集約前の値を同時に扱う\n\n\nCode\nSELECT\n  user_id\n  , product_id\n  , score\n  , AVG(score) OVER() avg_score\n  , AVG(score) OVER(PARTITION BY user_id) user_avg_score\n  , score - AVG(score) OVER(PARTITION BY user_id) user_avg_score_diff\nFROM \n  review\n;\n\n\n\n9 records\n\n\n\n\n\n\n\n\n\n\nuser_id\nproduct_id\nscore\navg_score\nuser_avg_score\nuser_avg_score_diff\n\n\n\n\nU002\nA001\n3\n4.111111\n3.333333\n-0.3333333\n\n\nU002\nA002\n3\n4.111111\n3.333333\n-0.3333333\n\n\nU002\nA003\n4\n4.111111\n3.333333\n0.6666667\n\n\nU003\nA001\n5\n4.111111\n4.333333\n0.6666667\n\n\nU003\nA002\n4\n4.111111\n4.333333\n-0.3333333\n\n\nU003\nA003\n4\n4.111111\n4.333333\n-0.3333333\n\n\nU001\nA001\n4\n4.111111\n4.666667\n-0.6666667\n\n\nU001\nA002\n5\n4.111111\n4.666667\n0.3333333\n\n\nU001\nA003\n5\n4.111111\n4.666667\n0.3333333"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap03_.html#グループの中での順序を扱う",
    "href": "contents/sql/duckdb/sql-bigdata/chap03_.html#グループの中での順序を扱う",
    "title": "データ加工のためのSQL",
    "section": "4.2 グループの中での順序を扱う",
    "text": "4.2 グループの中での順序を扱う\n\n\nCode\nSELECT * FROM popular_products;\n\n\n\n8 records\n\n\nproduct_id\ncategory\nscore\n\n\n\n\nA001\naction\n94\n\n\nA002\naction\n81\n\n\nA003\naction\n78\n\n\nA004\naction\n64\n\n\nD001\ndrama\n90\n\n\nD002\ndrama\n82\n\n\nD003\ndrama\n78\n\n\nD004\ndrama\n58\n\n\n\n\n\n\n4.2.1 ORDER BYを使う\nウインドウ関数のなかで「ORDER BY」を使う。\n\n\nCode\nSELECT\n  product_id\n  \n  , score\n  \n  , ROW_NUMBER() OVER(ORDER BY score DESC) as row\n  \n  , RANK() OVER(ORDER BY score DESC) as rank\n  \n  , DENSE_RANK() OVER(ORDER BY score DESC) dense_rank\n  \n  , LAG(product_id) OVER(ORDER BY score DESC) lag1\n  \n  , LAG(product_id, 2) OVER(ORDER BY score DESC) lag2\n  \n  , LEAD(product_id) OVER(ORDER BY score DESC) lead1\n  \n  , LEAD(product_id, 2) OVER(ORDER BY score DESC) lead2\n\nFROM popular_products\n\nORDER BY row\n\n;\n\n\n\n8 records\n\n\nproduct_id\nscore\nrow\nrank\ndense_rank\nlag1\nlag2\nlead1\nlead2\n\n\n\n\nA001\n94\n1\n1\n1\nNA\nNA\nD001\nD002\n\n\nD001\n90\n2\n2\n2\nA001\nNA\nD002\nA002\n\n\nD002\n82\n3\n3\n3\nD001\nA001\nA002\nA003\n\n\nA002\n81\n4\n4\n4\nD002\nD001\nA003\nD003\n\n\nA003\n78\n5\n5\n5\nA002\nD002\nD003\nA004\n\n\nD003\n78\n6\n5\n5\nA003\nA002\nA004\nD004\n\n\nA004\n64\n7\n7\n6\nD003\nA003\nD004\nNA\n\n\nD004\n58\n8\n8\n7\nA004\nD003\nNA\nNA\n\n\n\n\n\n\n\n4.2.2 ORDER BYと集約組み合わせる\n\n\nCode\nSELECT\n  product_id\n  \n  , score\n  \n  , ROW_NUMBER() OVER(ORDER BY score DESC) as row\n  \n  , SUM(score) OVER(ORDER BY score DESC\n                    ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) cum_score\n                    \n  , AVG(score) OVER(ORDER BY score DESC \n                    ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING) local_avg\n                    \n  -- ランキング上位の商品IDを取得する\n  , FIRST_VALUE(product_id) OVER(ORDER BY score DESC\n                                 ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) as first_value\nFROM popular_products\nORDER BY row;\n\n\n\n8 records\n\n\nproduct_id\nscore\nrow\ncum_score\nlocal_avg\nfirst_value\n\n\n\n\nA001\n94\n1\n94\n92.00000\nA001\n\n\nD001\n90\n2\n184\n88.66667\nA001\n\n\nD002\n82\n3\n266\n84.33333\nA001\n\n\nA002\n81\n4\n347\n80.33333\nA001\n\n\nA003\n78\n5\n425\n79.00000\nA001\n\n\nD003\n78\n6\n503\n73.33333\nA001\n\n\nA004\n64\n7\n567\n66.66667\nA001\n\n\nD004\n58\n8\n625\n61.00000\nA001\n\n\n\n\n\n商品の集約をおこなおうことも可能である\n\n\nCode\nSELECT\n  product_id\n  \n  , ROW_NUMBER() OVER(ORDER BY score DESC) as row\n  \n  , list(product_id) \n      OVER(ORDER BY score DESC \n           ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) list\n  \nFROM popular_products\nWHERE category = 'action'\nORDER BY row;\n\n\n\n4 records\n\n\nproduct_id\nrow\nlist\n\n\n\n\nA001\n1\nA001, A002, A003, A004\n\n\nA002\n2\nA001, A002, A003, A004\n\n\nA003\n3\nA001, A002, A003, A004\n\n\nA004\n4\nA001, A002, A003, A004\n\n\n\n\n\nDuckdDBだと配列で距離を計算できる。version 0.10以降なのに注意する。\n\n\n4.2.3 PARTITION BY と ORDER BYを組み合わせる\n\n\nCode\nSELECT\n  category\n  , product_id\n  , score\n  , ROW_NUMBER() \n    OVER(\n        PARTITION BY category\n        ORDER BY score DESC) as row\nFROM popular_products\nWHERE category = 'action'\nORDER BY row;\n\n\n\n4 records\n\n\ncategory\nproduct_id\nscore\nrow\n\n\n\n\naction\nA001\n94\n1\n\n\naction\nA002\n81\n2\n\n\naction\nA003\n78\n3\n\n\naction\nA004\n64\n4\n\n\n\n\n\nカテゴリごとに最上位ランクの商品を取り出す。\n\n\nCode\nSELECT DISTINCT \n  category\n  , FIRST_VALUE(product_id)\n      OVER(PARTITION BY category ORDER BY score DESC\n           ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)\n      product_id\nFROM popular_products;\n\n\n\n2 records\n\n\ncategory\nproduct_id\n\n\n\n\ndrama\nD001\n\n\naction\nA001"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap03_.html#縦持ちのデータを横持ちに変換する",
    "href": "contents/sql/duckdb/sql-bigdata/chap03_.html#縦持ちのデータを横持ちに変換する",
    "title": "データ加工のためのSQL",
    "section": "4.3 縦持ちのデータを横持ちに変換する",
    "text": "4.3 縦持ちのデータを横持ちに変換する\nduckdbはPIVOTを使えるので問題ない。他のSQLおこなう方法について示す。\n\n\nCode\nSELECT * FROM daily_kpi;\n\n\n\n6 records\n\n\ndt\nindicator\nval\n\n\n\n\n2017-01-01\nimpressions\n1800\n\n\n2017-01-01\nsessions\n500\n\n\n2017-01-01\nusers\n200\n\n\n2017-01-02\nimpressions\n2000\n\n\n2017-01-02\nsessions\n700\n\n\n2017-01-02\nusers\n250\n\n\n\n\n\n\n\nCode\nSELECT\n  dt\n  , MAX(CASE WHEN indicator = 'impressions' THEN val END) impressions\n  , MAX(CASE WHEN indicator = 'sessions' THEN val END) sessions\n  , MAX(CASE WHEN indicator = 'users' THEN val END) users\nFROM daily_kpi\nGROUP BY dt\nORDER BY dt;\n\n\n\n2 records\n\n\ndt\nimpressions\nsessions\nusers\n\n\n\n\n2017-01-01\n1800\n500\n200\n\n\n2017-01-02\n2000\n700\n250\n\n\n\n\n\n\n4.3.1 行を区切りの文字列に集約する\n\n\nCode\nSELECT * FROM purchase_detail_log;\n\n\n\n6 records\n\n\npurchase_id\nproduct_id\nprice\n\n\n\n\n100001\nA001\n300\n\n\n100001\nA002\n400\n\n\n100001\nA003\n200\n\n\n100002\nD001\n500\n\n\n100002\nD002\n300\n\n\n100003\nA001\n300\n\n\n\n\n\n\n\nCode\nSELECT\n  purchase_id\n  , string_agg(product_id, ',') prudct_ids\nFROM purchase_detail_log\nGROUP BY purchase_id\nORDER BY purchase_id\n\n\n\n3 records\n\n\npurchase_id\nprudct_ids\n\n\n\n\n100001\nA001,A002,A003\n\n\n100002\nD001,D002\n\n\n100003\nA001\n\n\n\n\n\n\n\nCode\nSELECT DISTINCT * FROM duckdb_functions() WHERE function_name LIKE '%nest' ORDER BY function_name;\n\n\n\n1 records\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndatabase_name\ndatabase_oid\nschema_name\nfunction_name\nfunction_type\ndescription\ncomment\nreturn_type\nparameters\nparameter_types\nvarargs\nmacro_definition\nhas_side_effects\ninternal\nfunction_oid\nexample\nstability\n\n\n\n\nsystem\n0\nmain\nunnest\ntable\nNA\nNA\nNA\ncol0\nTABLE\nNA\nNA\nNA\nTRUE\n84\nNA\nNA"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap03_.html#横持ちデータを縦持ちデータに変換する",
    "href": "contents/sql/duckdb/sql-bigdata/chap03_.html#横持ちデータを縦持ちデータに変換する",
    "title": "データ加工のためのSQL",
    "section": "4.4 横持ちデータを縦持ちデータに変換する",
    "text": "4.4 横持ちデータを縦持ちデータに変換する\n組合せを作成しておいて、1つ1つ設定することになる。\nCROSS JOINをしているがつまりは直積集合であるのでFROM A, Bでも大丈夫ななず。\n\n\nCode\nselect\n    q.year\n    , case\n        when p.idx = 1 then 'q1'\n        when p.idx = 2 then 'q2'\n        when p.idx = 3 then 'q3'\n        when p.idx = 4 then 'q4'\n    end as name\n    , case\n        when p.idx = 1 then q.q1\n        when p.idx = 2 then q.q2\n        when p.idx = 3 then q.q3\n        when p.idx = 4 then q.q4\n    end as value\nfrom\n    quarterly_sales as q\n    cross join (\n        select 1 as idx\n        union all select 2 idx\n        union all select 3 idx\n        union all select 4 idx\n    ) as p\n;\n\n\n\nDisplaying records 1 - 10\n\n\nyear\nname\nvalue\n\n\n\n\n2015\nq1\n82000\n\n\n2016\nq1\n85000\n\n\n2017\nq1\n92000\n\n\n2015\nq2\n83000\n\n\n2016\nq2\n85000\n\n\n2017\nq2\n81000\n\n\n2015\nq3\n78000\n\n\n2016\nq3\n80000\n\n\n2017\nq3\nNA\n\n\n2015\nq4\n83000\n\n\n\n\n\n\n4.4.1 任意長の配列を行に展開する\n\n\nCode\nWITH NESTED AS (\n  SELECT\n    purchase_id\n    , string_agg(product_id, ',') prudct_ids\n  FROM purchase_detail_log\n  GROUP BY purchase_id\n  ORDER BY purchase_id\n)\nSELECT\n  purchase_id\n  , UNNEST(string_split(prudct_ids, ',')) product_id\nFROM NESTED;\n\n\n\n6 records\n\n\npurchase_id\nproduct_id\n\n\n\n\n100001\nA001\n\n\n100001\nA002\n\n\n100001\nA003\n\n\n100002\nD001\n\n\n100002\nD002\n\n\n100003\nA001"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap03_.html#縦に並べる",
    "href": "contents/sql/duckdb/sql-bigdata/chap03_.html#縦に並べる",
    "title": "データ加工のためのSQL",
    "section": "5.1 縦に並べる",
    "text": "5.1 縦に並べる\nUNIONかUNION ALL句を使う。\n結合するときには同じカラム構造にしておく必要がある。\n\n\nCode\nSELECT 'app1' AS app_name, user_id, name, email FROM app1_mst_users\nUNION ALL\nSELECT 'app2' AS app_name, user_id, name, NULL AS email FROM app2_mst_users;\n\n\n\n4 records\n\n\napp_name\nuser_id\nname\nemail\n\n\n\n\napp1\nU001\nSato\nsato@example.com\n\n\napp1\nU002\nSuzuki\nsuzuki@example.com\n\n\napp2\nU001\nIto\nNA\n\n\napp2\nU002\nTanaka\nNA"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap03_.html#複数のテーブルを横に並べる",
    "href": "contents/sql/duckdb/sql-bigdata/chap03_.html#複数のテーブルを横に並べる",
    "title": "データ加工のためのSQL",
    "section": "5.2 複数のテーブルを横に並べる",
    "text": "5.2 複数のテーブルを横に並べる\nJOIN句を使う。一般に単にJOINとした場合にはinner JOINがおこなわれる。\n\n\nCode\nSELECT\n  m.category_id\n  , m.name\n  , s.sales\n  , r.product_id sales_product\nFROM\n  mst_categories as m\n  JOIN\n    category_sales as s\n    ON m.category_id = s.category_id\n  JOIN\n    product_sale_ranking as r\n    ON m.category_id = r.category_id\n;\n\n\n\n6 records\n\n\ncategory_id\nname\nsales\nsales_product\n\n\n\n\n1\ndvd\n850000\nD001\n\n\n1\ndvd\n850000\nD002\n\n\n1\ndvd\n850000\nD003\n\n\n2\ncd\n500000\nC001\n\n\n2\ncd\n500000\nC002\n\n\n2\ncd\n500000\nC003\n\n\n\n\n\n相関サブクエリが使える場合には、JOINをも居て複数のテーブルの値を横に並べることが可能である。\n\n\nCode\nSELECT\n  m.category_id\n  , m.name\n  ---相関サブクエリを使いカテゴリー別の売上額を取得\n  , (SELECT s.sales FROM category_sales as s WHERE m.category_id = s.category_id) sales\n  , (SELECT r.product_id FROM product_sale_ranking r WHERE m.category_id = r.category_id\n     ORDER BY sales DESC LIMIT 1) top_sale_product\nFROM\n  mst_categories as m\n;\n\n\n\n3 records\n\n\ncategory_id\nname\nsales\ntop_sale_product\n\n\n\n\n1\ndvd\n850000\nD001\n\n\n2\ncd\n500000\nC001\n\n\n3\nbook\nNA\nNA"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap03_.html#条件のフラグを0-1で表現する",
    "href": "contents/sql/duckdb/sql-bigdata/chap03_.html#条件のフラグを0-1で表現する",
    "title": "データ加工のためのSQL",
    "section": "5.3 条件のフラグを0, 1で表現する",
    "text": "5.3 条件のフラグを0, 1で表現する\nCASE式で場合分けをするのが、SIGN関数で0と1に変換する方法がある。\n\n\nCode\nSELECT * FROM mst_users_with_card_number;\n\n\n\n3 records\n\n\nuser_id\ncard_number\n\n\n\n\nU001\n1234-xxxx-xxxx-xxxx\n\n\nU002\nNA\n\n\nU003\n5678-xxxx-xxxx-xxxx\n\n\n\n\n\n\n\nCode\nSELECT * FROM purchase_log;\n\n\n\n5 records\n\n\npurchase_id\nuser_id\namount\nstamp\n\n\n\n\n10001\nU001\n200\n2017-01-30 10:00:00\n\n\n10002\nU001\n500\n2017-02-10 10:00:00\n\n\n10003\nU001\n200\n2017-02-12 10:00:00\n\n\n10004\nU002\n800\n2017-03-01 10:00:00\n\n\n10005\nU002\n400\n2017-03-02 10:00:00\n\n\n\n\n\n\n\nCode\nSELECT\n  m.user_id\n  , m.card_number\n  , COUNT(p.user_id) as purchase_count\n  , CASE WHEN m.card_number IS NOT NULL THEN 1 ELSE 0 END as has_card\n  , SIGN(COUNT(p.user_id)) as has_purchased\nFROM \n  mst_users_with_card_number as m\n  LEFT JOIN\n    purchase_log as p\n    ON m.user_id = p.user_id\nGROUP BY m.user_id, m.card_number\n\n\n\n3 records\n\n\nuser_id\ncard_number\npurchase_count\nhas_card\nhas_purchased\n\n\n\n\nU003\n5678-xxxx-xxxx-xxxx\n0\n1\n0\n\n\nU002\nNA\n2\n0\n1\n\n\nU001\n1234-xxxx-xxxx-xxxx\n3\n1\n1"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap03_.html#計算したテーブルに名前を付けて再利用する",
    "href": "contents/sql/duckdb/sql-bigdata/chap03_.html#計算したテーブルに名前を付けて再利用する",
    "title": "データ加工のためのSQL",
    "section": "5.4 計算したテーブルに名前を付けて再利用する",
    "text": "5.4 計算したテーブルに名前を付けて再利用する\nSQL99におけるCTE(Common Table Expression)を用いると１つのクエリの中で使える 一時的なテーブルに名前を付けて利用できるため、クエリの可読性が大きく向上する。\n\n\nCode\nSELECT * FROM product_sales;\n\n\n\nDisplaying records 1 - 10\n\n\ncategory_name\nproduct_id\nsales\n\n\n\n\ndvd\nD001\n50000\n\n\ndvd\nD002\n20000\n\n\ndvd\nD003\n10000\n\n\ncd\nC001\n30000\n\n\ncd\nC002\n20000\n\n\ncd\nC003\n10000\n\n\nbook\nB001\n20000\n\n\nbook\nB002\n15000\n\n\nbook\nB003\n10000\n\n\nbook\nB004\n5000\n\n\n\n\n\nカテゴリーごとにランキングを付ける。そして、同じ順位の商品を横並びにする。\n\n\nCode\nWITH\n\nproduct_sale_ranking as (\n  SELECT\n    category_name\n    , product_id\n    , sales\n    , ROW_NUMBER() OVER(PARTITION BY category_name ORDER BY sales DESC) rank\n  FROM \n    product_sales\n)\n, mst_rank as (\n  SELECT DISTINCT rank\n  FROM product_sale_ranking\n)\nSELECT\n  m.rank\n  , r1.product_id as dvd\n  , r1.sales as dvd_sales\n  , r2.product_id as cd\n  , r2.sales as cd_sales\n  , r3.product_id as book\n  , r3.sales as book_sales\nFROM\n  mst_rank as m\n  LEFT JOIN\n    product_sale_ranking r1\n    on m.rank = r1.rank\n    AND r1.category_name = 'dvd'\n  LEFT JOIN\n    product_sale_ranking r2\n    ON m.rank = r2.rank\n    AND r2.category_name = 'cd'\n  LEFT JOIN\n    product_sale_ranking as r3\n    ON m.rank = r3.rank\n    AND r3.category_name = 'book'\nORDER BY m.rank\n\n;\n\n\n\n4 records\n\n\nrank\ndvd\ndvd_sales\ncd\ncd_sales\nbook\nbook_sales\n\n\n\n\n1\nD001\n50000\nC001\n30000\nB001\n20000\n\n\n2\nD002\n20000\nC002\n20000\nB002\n15000\n\n\n3\nD003\n10000\nC003\n10000\nB003\n10000\n\n\n4\nNA\nNA\nNA\nNA\nB004\n5000"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap03_.html#擬似的なテーブルを作成する",
    "href": "contents/sql/duckdb/sql-bigdata/chap03_.html#擬似的なテーブルを作成する",
    "title": "データ加工のためのSQL",
    "section": "5.5 擬似的なテーブルを作成する",
    "text": "5.5 擬似的なテーブルを作成する\nダミーでテーブルを作成して、実際に集計を試す。\n\n5.5.1 任意のレコードを持つ\n\n\nCode\nWITH\nmst_devices as (\n            SELECT 1 as device_id, 'pc' as device_name\n  UNION ALL SELECT 2 as device_id, 'sp' as device_name\n  UNION ALL SELECT 3 as device_id, 'アプリ' as device_name\n)\nSELECT * \nFROM mst_devices;\n\n\n\n3 records\n\n\ndevice_id\ndevice_name\n\n\n\n\n1\npc\n\n\n2\nsp\n\n\n3\nアプリ\n\n\n\n\n\nVALUESで作成することも可能である。 vALUESはINSERTとことなりまとめてロードが行える\n\n\nCode\nWITH\nmst_devices(device_id, device_name) AS(\n  VALUES\n    (1, 'PC')\n)\nSELECT * \nFROM mst_devices;\n\n\n\n1 records\n\n\ndevice_id\ndevice_name\n\n\n\n\n1\nPC\n\n\n\n\n\n配列型テーブル関数を用いた疑似テーブルの作成ができるミドルウェアもある。\n\n\n5.5.2 連番を用いてテーブルを作成する\n\n\nCode\nWITH \nseries as (\n  SELECT unnest(generate_series(1, 5)) idx\n)\nSELECT * \nFROM series;\n\n\n\n5 records\n\n\nidx\n\n\n\n\n1\n\n\n2\n\n\n3\n\n\n4\n\n\n5"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap05_.html",
    "href": "contents/sql/duckdb/sql-bigdata/chap05_.html",
    "title": "ユーザーを把握するためのデータ抽出",
    "section": "",
    "text": "Code\nrenv::activate(here::here())\nCode\n\ncur_dir &lt;- here::here(\"contents/sql/duckdb/sql-bigdata\")\n\nlibrary(ggplot2)\nlibrary(duckdb)\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(DBI)\nlibrary(dbplyr)\nlibrary(arrow)\nlibrary(showtext)\nlibrary(here)\nshowtext_auto()\nfont_add_google(\"Noto Sans\")"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap05_.html#サンプルデータ",
    "href": "contents/sql/duckdb/sql-bigdata/chap05_.html#サンプルデータ",
    "title": "ユーザーを把握するためのデータ抽出",
    "section": "2.1 サンプルデータ",
    "text": "2.1 サンプルデータ\n\n\nCode\nSELECT * FROM mst_users;\n\n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\n\n\nuser_id\nsex\nbirth_date\nregister_date\nregister_device\nwithdraw_date\n\n\n\n\nU001\nM\n1977-06-17\n2016-10-01\npc\nNA\n\n\nU002\nF\n1953-06-12\n2016-10-01\nsp\n2016-10-10\n\n\nU003\nM\n1965-01-06\n2016-10-01\npc\nNA\n\n\nU004\nF\n1954-05-21\n2016-10-05\npc\nNA\n\n\nU005\nM\n1987-11-23\n2016-10-05\nsp\nNA\n\n\nU006\nF\n1950-01-21\n2016-10-10\npc\n2016-10-10\n\n\nU007\nF\n1950-07-18\n2016-10-10\napp\nNA\n\n\nU008\nF\n2006-12-09\n2016-10-10\nsp\nNA\n\n\nU009\nM\n2004-10-23\n2016-10-15\npc\nNA\n\n\nU010\nF\n1987-03-18\n2016-10-16\npc\nNA\n\n\n\n\n\n\n\nCode\nSELECT * FROM action_log;\n\n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\n\n\n\nsession\nuser_id\naction\ncategory\nproducts\namount\nstamp\n\n\n\n\n989004ea\nU001\npurchase\ndrama\nD001,D002\n2000\n2016-10-01 18:10:00\n\n\n989004ea\nU001\nview\nNA\nNA\nNA\n2016-10-01 18:00:00\n\n\n989004ea\nU001\nfavorite\ndrama\nD001\nNA\n2016-10-01 18:00:00\n\n\n989004ea\nU001\nreview\ndrama\nD001\nNA\n2016-10-01 18:00:00\n\n\n989004ea\nU001\nadd_cart\ndrama\nD001\nNA\n2016-10-01 18:00:00\n\n\n989004ea\nU001\nadd_cart\ndrama\nD001\nNA\n2016-10-01 18:00:00\n\n\n989004ea\nU001\nadd_cart\ndrama\nD001\nNA\n2016-10-01 18:00:00\n\n\n989004ea\nU001\nadd_cart\ndrama\nD001\nNA\n2016-10-01 18:00:00\n\n\n989004ea\nU001\nadd_cart\ndrama\nD001\nNA\n2016-10-01 18:00:00\n\n\n989004ea\nU001\nadd_cart\ndrama\nD002\nNA\n2016-10-01 18:01:00"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap05_.html#ユーザーのアクション数を集計",
    "href": "contents/sql/duckdb/sql-bigdata/chap05_.html#ユーザーのアクション数を集計",
    "title": "ユーザーを把握するためのデータ抽出",
    "section": "2.2 ユーザーのアクション数を集計",
    "text": "2.2 ユーザーのアクション数を集計\n\n\nCode\nWITH \nstats as (\n  SELECT COUNT(DISTINCT session) as total_uu\n  FROM action_log\n)\n\nSELECT \n  l.action\n  , count(distinct l.session) as action_uu\n  , count(1) as action_count\n  , s.total_uu\n  , 100. * count(distinct l.session) / s.total_uu as usage_rate\n  , 1. * count(1) / count(distinct l.session) as count_per_user\nFROM \n  action_log as l, \n  stats as s\nGROUP BY\n  l.action, s.total_uu\n;\n\n\n\n5 records\n\n\n\n\n\n\n\n\n\n\naction\naction_uu\naction_count\ntotal_uu\nusage_rate\ncount_per_user\n\n\n\n\nfavorite\n1\n1\n4\n25\n1.000000\n\n\nreview\n1\n1\n4\n25\n1.000000\n\n\nadd_cart\n3\n12\n4\n75\n4.000000\n\n\npurchase\n3\n5\n4\n75\n1.666667\n\n\nview\n1\n1\n4\n25\n1.000000\n\n\n\n\n\n\n2.2.1 ログイン状態を分けて判定する\n\n\nCode\nWITH\naction_log_with_status as (\n  SELECT\n    session\n    , user_id\n    , action\n    , case when coalesce(user_id, '') &lt;&gt; '' THEN 'login' ELSE 'guest' END\n      as login_status\n  FROM action_log\n)\nSELECT * \nFROM action_log_with_status\n;\n\n\n\nDisplaying records 1 - 10\n\n\nsession\nuser_id\naction\nlogin_status\n\n\n\n\n989004ea\nU001\npurchase\nlogin\n\n\n989004ea\nU001\nview\nlogin\n\n\n989004ea\nU001\nfavorite\nlogin\n\n\n989004ea\nU001\nreview\nlogin\n\n\n989004ea\nU001\nadd_cart\nlogin\n\n\n989004ea\nU001\nadd_cart\nlogin\n\n\n989004ea\nU001\nadd_cart\nlogin\n\n\n989004ea\nU001\nadd_cart\nlogin\n\n\n989004ea\nU001\nadd_cart\nlogin\n\n\n989004ea\nU001\nadd_cart\nlogin\n\n\n\n\n\nROLLUPを使って合計・小計を求める。\n\n\nCode\nWITH\naction_log_with_status as (\n  SELECT\n    session\n    , user_id\n    , action\n    , case when coalesce(user_id, '') &lt;&gt; '' THEN 'login' ELSE 'guest' END\n      as login_status\n  FROM action_log\n)\nSELECT\n  coalesce(action, 'all') as action\n  , coalesce(login_status, 'all') as login_status\n  , count(distinct session) as action_uu\n  , count(1) as action_count\nFROM \n  action_log_with_status\nGROUP BY\n  rollup(action, login_status)\n\n\n\nDisplaying records 1 - 10\n\n\naction\nlogin_status\naction_uu\naction_count\n\n\n\n\nreview\nlogin\n1\n1\n\n\nadd_cart\nlogin\n3\n12\n\n\nall\nall\n4\n20\n\n\npurchase\nall\n3\n5\n\n\nfavorite\nall\n1\n1\n\n\nview\nall\n1\n1\n\n\nreview\nall\n1\n1\n\n\nadd_cart\nall\n3\n12\n\n\npurchase\nlogin\n3\n5\n\n\nview\nlogin\n1\n1"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap05_.html#年齢別区分を集計",
    "href": "contents/sql/duckdb/sql-bigdata/chap05_.html#年齢別区分を集計",
    "title": "ユーザーを把握するためのデータ抽出",
    "section": "2.3 年齢別区分を集計",
    "text": "2.3 年齢別区分を集計\n\n\nCode\nWITH\nmst_users_with_int_birth_date as (\n  select \n     *\n    , 20170101 as int_specific_date\n    , cast(replace(substring(birth_date, 1, 10), '-', '') as integer) as int_birth_date\n  from \n    mst_users\n)\n, mst_users_with_age as (\n  select\n    * \n    , floor((int_specific_date - int_birth_date) / 10000) as age\n  from \n    mst_users_with_int_birth_date\n)\nselect \n  user_id, sex, birth_date, age\nfrom \n  mst_users_with_age\n;\n\n\n\nDisplaying records 1 - 10\n\n\nuser_id\nsex\nbirth_date\nage\n\n\n\n\nU001\nM\n1977-06-17\n39\n\n\nU002\nF\n1953-06-12\n63\n\n\nU003\nM\n1965-01-06\n51\n\n\nU004\nF\n1954-05-21\n62\n\n\nU005\nM\n1987-11-23\n29\n\n\nU006\nF\n1950-01-21\n66\n\n\nU007\nF\n1950-07-18\n66\n\n\nU008\nF\n2006-12-09\n10\n\n\nU009\nM\n2004-10-23\n12\n\n\nU010\nF\n1987-03-18\n29\n\n\n\n\n\n現在時刻から年齢を算出する。ageを使えば求められるが、interval型なので秒数に変換されて変えされる。 コマンドラインからだと正しく閲覧できる。\n\n\nCode\nselect\n localtimestamp::date a\n , birth_date::date b\n , datediff('year', birth_date::date, localtimestamp::date) c\n , datediff('year', birth_date::date, '2024-06-17'::date) d\n , age('2024-06-18'::timestamp, birth_date::timestamp) e\nfrom \n  mst_users\n;\n\n\n\nDisplaying records 1 - 10\n\n\na\nb\nc\nd\ne\n\n\n\n\n2024-03-31\n1977-06-17\n47\n47\n1461974400 secs\n\n\n2024-03-31\n1953-06-12\n71\n71\n2208902400 secs\n\n\n2024-03-31\n1965-01-06\n59\n59\n1849132800 secs\n\n\n2024-03-31\n1954-05-21\n70\n70\n2179699200 secs\n\n\n2024-03-31\n1987-11-23\n37\n37\n1137456000 secs\n\n\n2024-03-31\n1950-01-21\n74\n74\n2314483200 secs\n\n\n2024-03-31\n1950-07-18\n74\n74\n2299104000 secs\n\n\n2024-03-31\n2006-12-09\n18\n18\n545097600 secs\n\n\n2024-03-31\n2004-10-23\n20\n20\n611366400 secs\n\n\n2024-03-31\n1987-03-18\n37\n37\n1158624000 secs"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap05_.html#ベン図でユーザーのアクションを集計する",
    "href": "contents/sql/duckdb/sql-bigdata/chap05_.html#ベン図でユーザーのアクションを集計する",
    "title": "ユーザーを把握するためのデータ抽出",
    "section": "2.4 ベン図でユーザーのアクションを集計する",
    "text": "2.4 ベン図でユーザーのアクションを集計する\nユーザーごとに各種機能の利用状況を調べる。\n\n\nCode\nWITH\nuser_action_flag as (\n  select\n    user_id\n    , sign(sum(case when action='purchase' then 1 else 0 end)) as has_purchase\n    , sign(sum(case when action='review' then 1 else 0 end)) as has_review\n    , sign(sum(case when action='favorite' then 1 else 0 end)) as has_favorite\n  from\n    action_log\n  group by\n    user_id\n)\nselect * \nfrom user_action_flag;\n\n\n\n2 records\n\n\nuser_id\nhas_purchase\nhas_review\nhas_favorite\n\n\n\n\nU001\n1\n1\n1\n\n\nU002\n1\n0\n0\n\n\n\n\n\nCUBE句を使うとすべての組合せに対して、集計をおこなうことができる。 パッと見だけどもとからの水準+NULLで組合せを生成しているように見える。 つまり、ROLLUPと機能は似ている。 NULLのところが小計なりなんなりになっている。\n\n\nCode\nwith\nuser_action_flag as (\n  select\n    user_id\n    , sign(sum(case when action='purchase' then 1 else 0 end)) as has_purchase\n    , sign(sum(case when action='review' then 1 else 0 end)) as has_review\n    , sign(sum(case when action='favorite' then 1 else 0 end)) as has_favorite\n  from\n    action_log\n  group by\n    user_id\n), action_venn_diagram as (\n  select\n      has_purchase\n    , has_review\n    , has_favorite\n    , count(1) as users\n  from \n    user_action_flag\n  group by\n    cube(has_purchase, has_review, has_favorite)\n)\n\nselect * \nfrom action_venn_diagram;\n\n\n\nDisplaying records 1 - 10\n\n\nhas_purchase\nhas_review\nhas_favorite\nusers\n\n\n\n\nNA\n1\n1\n1\n\n\nNA\n0\n0\n1\n\n\n1\nNA\nNA\n2\n\n\n1\nNA\n0\n1\n\n\n1\n1\nNA\n1\n\n\n1\n0\nNA\n1\n\n\nNA\nNA\nNA\n2\n\n\n1\n1\n1\n1\n\n\n1\n0\n0\n1\n\n\nNA\nNA\n0\n1"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap05_.html#デシル分析でユーザーを10段階のグループに分ける",
    "href": "contents/sql/duckdb/sql-bigdata/chap05_.html#デシル分析でユーザーを10段階のグループに分ける",
    "title": "ユーザーを把握するためのデータ抽出",
    "section": "2.5 デシル分析でユーザーを10段階のグループに分ける",
    "text": "2.5 デシル分析でユーザーを10段階のグループに分ける\n\n\nCode\nwith\nuser_purchase_amount as (\n  select\n    user_id\n    , sum(amount) as purchase_amount\n  from \n    action_log\n  where\n    action = 'purchase'\n  group by\n    user_id\n), \nusers_with_decile as (\n  select \n    user_id\n    , purchase_amount\n    , ntile(10) over(order by purchase_amount desc) as decile\n  from \n    user_purchase_amount\n)\nselect * \nfrom users_with_decile;\n\n\n\n2 records\n\n\nuser_id\npurchase_amount\ndecile\n\n\n\n\nU001\n4000\n1\n\n\nU002\n3000\n2"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap05_.html#rfm分析",
    "href": "contents/sql/duckdb/sql-bigdata/chap05_.html#rfm分析",
    "title": "ユーザーを把握するためのデータ抽出",
    "section": "2.6 RFM分析",
    "text": "2.6 RFM分析\nRFM分析はユーザーのグループ化の考え方である。 R:最新購入日、F:購入回数、M:購入金額合計の３つである。\n\n\nCode\nwith\npurchase_log as (\n  select\n    user_id\n    , amount\n    , substring(stamp, 1, 10) as dt\n  from \n    action_log\n  where\n    action = 'purchase'\n)\n, user_rfm as (\n  select\n    user_id\n    , max(dt) as recent_date\n    , current_date - max(dt::date) as recency\n    , count(dt) as frequency\n    , sum(amount) as monetary\n  from \n    purchase_log\n  group by\n    user_id\n)\nselect * \nfrom user_rfm;\n\n\n\n2 records\n\n\nuser_id\nrecent_date\nrecency\nfrequency\nmonetary\n\n\n\n\nU001\n2016-11-01\n2707\n2\n4000\n\n\nU002\n2016-12-01\n2677\n3\n3000"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap05_.html#サンプルデータ-1",
    "href": "contents/sql/duckdb/sql-bigdata/chap05_.html#サンプルデータ-1",
    "title": "ユーザーを把握するためのデータ抽出",
    "section": "3.1 サンプルデータ",
    "text": "3.1 サンプルデータ\n\n\nCode\nselect * from mst_users;\n\n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\n\n\nuser_id\nsex\nbirth_date\nregister_date\nregister_device\nwithdraw_date\n\n\n\n\nU001\nM\n1977-06-17\n2016-10-01\npc\nNA\n\n\nU002\nF\n1953-06-12\n2016-10-01\nsp\n2016-10-10\n\n\nU003\nM\n1965-01-06\n2016-10-01\npc\nNA\n\n\nU004\nF\n1954-05-21\n2016-10-05\npc\nNA\n\n\nU005\nM\n1987-11-23\n2016-10-05\nsp\nNA\n\n\nU006\nF\n1950-01-21\n2016-10-10\npc\n2016-10-10\n\n\nU007\nF\n1950-07-18\n2016-10-10\napp\nNA\n\n\nU008\nF\n2006-12-09\n2016-10-10\nsp\nNA\n\n\nU009\nM\n2004-10-23\n2016-10-15\npc\nNA\n\n\nU010\nF\n1987-03-18\n2016-10-16\npc\nNA"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap05_.html#登録数の推移と傾向",
    "href": "contents/sql/duckdb/sql-bigdata/chap05_.html#登録数の推移と傾向",
    "title": "ユーザーを把握するためのデータ抽出",
    "section": "3.2 登録数の推移と傾向",
    "text": "3.2 登録数の推移と傾向\n\n\nCode\nselect\n  register_date\n  , count(distinct user_id) as register_count\nfrom \n  mst_users\ngroup by \n  register_date\norder by \n  register_date\n;\n\n\n\n5 records\n\n\nregister_date\nregister_count\n\n\n\n\n2016-10-01\n3\n\n\n2016-10-05\n2\n\n\n2016-10-10\n3\n\n\n2016-10-15\n1\n\n\n2016-10-16\n1"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap05_.html#デバイスごとの登録数",
    "href": "contents/sql/duckdb/sql-bigdata/chap05_.html#デバイスごとの登録数",
    "title": "ユーザーを把握するためのデータ抽出",
    "section": "3.3 デバイスごとの登録数",
    "text": "3.3 デバイスごとの登録数\n\n\nCode\nwith\nmst_users_with_year_month as (\n  select \n    *\n  , substring(register_date, 1, 7) as year_month\n  from \n    mst_users\n)\n, stats as (\n  select \n    year_month\n    , register_device\n    , count(*) as cnt\n  from\n    mst_users_with_year_month\n  group by\n    year_month, register_device\n)\nselect *\nfrom (\n  pivot stats\n  on register_device\n  using sum(cnt)\n);\n\n\n\n1 records\n\n\nyear_month\napp\npc\nsp\n\n\n\n\n2016-10\n1\n6\n3"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap05_.html#継続率と定着率を評価する",
    "href": "contents/sql/duckdb/sql-bigdata/chap05_.html#継続率と定着率を評価する",
    "title": "ユーザーを把握するためのデータ抽出",
    "section": "3.4 継続率と定着率を評価する",
    "text": "3.4 継続率と定着率を評価する\nある日に登録した人達がN日後に継続しているか、定着率は継続率のうち７日目の指標である。\nまずユーザーごとに登録日とアクションの日付を出す。\n\n\nCode\nwith \naction_log_with_mst_users as (\n  select\n    u.user_id\n    , u.register_date\n    , cast(a.stamp as date) as action_date\n    , max(cast(a.stamp as date)) over() as latest_date\n    \n    -- 登録日の１日後の日付での計算\n    , cast(u.register_date::date + '1 day'::interval as date)\n      as next_day_1\n  from\n    mst_users as u\n    left outer join action_log as a\n    on u.user_id = a.user_id\n)\nselect * \nfrom action_log_with_mst_users\norder by register_date;\n\n\n\nDisplaying records 1 - 10\n\n\nuser_id\nregister_date\naction_date\nlatest_date\nnext_day_1\n\n\n\n\nU001\n2016-10-01\n2016-10-01\n2016-12-01\n2016-10-02\n\n\nU001\n2016-10-01\n2016-10-01\n2016-12-01\n2016-10-02\n\n\nU001\n2016-10-01\n2016-10-01\n2016-12-01\n2016-10-02\n\n\nU001\n2016-10-01\n2016-10-01\n2016-12-01\n2016-10-02\n\n\nU001\n2016-10-01\n2016-10-01\n2016-12-01\n2016-10-02\n\n\nU001\n2016-10-01\n2016-10-01\n2016-12-01\n2016-10-02\n\n\nU001\n2016-10-01\n2016-10-01\n2016-12-01\n2016-10-02\n\n\nU001\n2016-10-01\n2016-10-01\n2016-12-01\n2016-10-02\n\n\nU001\n2016-10-01\n2016-10-01\n2016-12-01\n2016-10-02\n\n\nU001\n2016-10-01\n2016-10-01\n2016-12-01\n2016-10-02\n\n\n\n\n\n上記を集計する。\n\n\nCode\nwith \naction_log_with_mst_users as (\n  select\n    u.user_id\n    , u.register_date\n    , cast(a.stamp as date) as action_date\n    , max(cast(a.stamp as date)) over() as latest_date\n    \n    -- 登録日の１日後の日付での計算\n    , cast(u.register_date::date + '1 day'::interval as date)\n      as next_day_1\n  from\n    mst_users as u\n    left outer join action_log as a\n    on u.user_id = a.user_id\n)\n, user_action_flag as (\n  select\n    user_id\n    , register_date\n    , sign(\n      sum(\n        case when next_day_1 &lt;= latest_date then \n          case when next_day_1 = action_date then 1 \n          else 0 \n          end\n        end\n      )\n    ) as next_1_day_action\n  from \n    action_log_with_mst_users\n  group by\n    user_id, register_date\n)\nselect\n  register_date\n  , avg(100. * next_1_day_action) as repeat_rate_1_day\nfrom \n  user_action_flag\ngroup by \n  register_date\norder by\n  register_date\n;\n\n\n\n5 records\n\n\nregister_date\nrepeat_rate_1_day\n\n\n\n\n2016-10-01\n0\n\n\n2016-10-05\n0\n\n\n2016-10-10\n0\n\n\n2016-10-15\n0\n\n\n2016-10-16\n0"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap07_.html",
    "href": "contents/sql/duckdb/sql-bigdata/chap07_.html",
    "title": "データ活用の精度を高めるための分析術",
    "section": "",
    "text": "Code\nrenv::activate(here::here())\nCode\n\ncur_dir &lt;- here::here(\"contents/sql/duckdb/sql-bigdata\")\n\nlibrary(ggplot2)\nlibrary(duckdb)\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(DBI)\nlibrary(dbplyr)\nlibrary(arrow)\nlibrary(showtext)\nlibrary(here)\nshowtext_auto()\nfont_add_google(\"Noto Sans\")"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap07_.html#マスターデータの重複",
    "href": "contents/sql/duckdb/sql-bigdata/chap07_.html#マスターデータの重複",
    "title": "データ活用の精度を高めるための分析術",
    "section": "2.1 マスターデータの重複",
    "text": "2.1 マスターデータの重複\n\n\nCode\nselect\n  count(1) as total_num\n  , count(distinct id) as key_num\nfrom \n  mst_categories\n;\n\n\n\n1 records\n\n\ntotal_num\nkey_num\n\n\n\n\n8\n7\n\n\n\n\n\n\n2.1.1 キーが重複しているレコードを確認する\n\n\nCode\nselect\n  id\n  , count(*) as record_num\n  , string_agg(name, ',') as name_list\n  , string_agg(stamp, ',') as stamp_list\nfrom \n  mst_categories\ngroup by id\nhaving count(*) &gt; 1\n\n\n\n1 records\n\n\nid\nrecord_num\nname_list\nstamp_list\n\n\n\n\n6\n2\nfood,cooking\n2016-01-01 10:00:00,2016-02-01 10:00:00\n\n\n\n\n\nもとのレコードを保持したまま処理する。\n\n\nCode\nwith\nmst_categories_with_key_num as (\n  select\n    *\n    , count(1) over(partition by id) as key_num\n  from mst_categories\n)\nselect \n  * \nfrom\n  mst_categories_with_key_num\nwhere\n  key_num &gt; 1;;\n\n\n\n2 records\n\n\nid\nname\nstamp\nkey_num\n\n\n\n\n6\nfood\n2016-01-01 10:00:00\n2\n\n\n6\ncooking\n2016-02-01 10:00:00\n2"
  },
  {
    "objectID": "contents/sql/duckdb/sql-bigdata/chap07_.html#ログの重複を検出する",
    "href": "contents/sql/duckdb/sql-bigdata/chap07_.html#ログの重複を検出する",
    "title": "データ活用の精度を高めるための分析術",
    "section": "2.2 ログの重複を検出する",
    "text": "2.2 ログの重複を検出する\nログはマスタと異なり、正常なデータ取得でもデータが重複してしまう倍ｇあある。\n\n2.2.1 サンプルデータ\n\n\nCode\nselect * from dup_action_log;\n\n\n\nDisplaying records 1 - 10\n\n\nstamp\nsession\nuser_id\naction\nproducts\n\n\n\n\n2016-11-03 18:00:00\n989004ea\nU001\nclick\nD001\n\n\n2016-11-03 19:00:00\n47db0370\nU002\nclick\nD002\n\n\n2016-11-03 20:00:00\n1cf7678e\nU003\nclick\nA001\n\n\n2016-11-03 21:00:00\n5eb2e107\nU004\nclick\nA001\n\n\n2016-11-03 21:00:00\nfe05e1d8\nU004\nclick\nD001\n\n\n2016-11-04 18:00:00\n87b5725f\nU001\nclick\nD001\n\n\n2016-11-04 19:00:00\neee2bb21\nU005\nclick\nA001\n\n\n2016-11-04 20:00:00\n5d5b0997\nU006\nclick\nD001\n\n\n2016-11-04 21:00:00\n111f2996\nU007\nclick\nD002\n\n\n2016-11-04 22:00:00\n3efe001c\nU008\nclick\nA001\n\n\n\n\n\n\n\n2.2.2 重複データを各員する\n\n\nCode\nselect\n  user_id\n  , products\n  , string_agg(session, ',') as session_list\n  , string_agg(stamp, ',') as stamp_list\nfrom dup_action_log\ngroup by user_id, products\nhaving count(*) &gt; 1;\n\n\n\n2 records\n\n\n\n\n\n\n\n\nuser_id\nproducts\nsession_list\nstamp_list\n\n\n\n\nU008\nA001\n3efe001c,3efe001c\n2016-11-04 22:00:00,2016-11-04 22:00:10\n\n\nU001\nD001\n989004ea,87b5725f\n2016-11-03 18:00:00,2016-11-04 18:00:00\n\n\n\n\n\n\n\n2.2.3 重複データを削除する\nたとえば１番古いデータを残す。\n\n\nCode\nselect \n  session\n  , user_id\n  , action\n  , products\n  , min(stamp) as stamp\nfrom \n  dup_action_log\ngroup by \n  session, user_id, action, products\n;\n\n\n\nDisplaying records 1 - 10\n\n\nsession\nuser_id\naction\nproducts\nstamp\n\n\n\n\n47db0370\nU002\nclick\nD002\n2016-11-03 19:00:00\n\n\n1cf7678e\nU003\nclick\nA001\n2016-11-03 20:00:00\n\n\nfe05e1d8\nU004\nclick\nD001\n2016-11-03 21:00:00\n\n\neee2bb21\nU005\nclick\nA001\n2016-11-04 19:00:00\n\n\n3efe001c\nU008\nclick\nA001\n2016-11-04 22:00:00\n\n\n989004ea\nU001\nclick\nD001\n2016-11-03 18:00:00\n\n\n87b5725f\nU001\nclick\nD001\n2016-11-04 18:00:00\n\n\n111f2996\nU007\nclick\nD002\n2016-11-04 21:00:00\n\n\n5d5b0997\nU006\nclick\nD001\n2016-11-04 20:00:00\n\n\n5eb2e107\nU004\nclick\nA001\n2016-11-03 21:00:00\n\n\n\n\n\n前回のアクションからの経過時間で同一を判定する。\n\n\nCode\nwith\ndup_action_log_with_lag_seconds as (\n  select\n    user_id\n    , action\n    , products\n    , stamp\n    , extract(\n        epoch from stamp::timestamp - \n        lag(stamp::timestamp)\n        over(partition by user_id, action, products order by stamp)) as lag_seconds\n  from dup_action_log\n)\n-- 30分以内の同一アクションを重複として除外する\nselect\n  user_id\n  , action\n  , products\n  , stamp\nfrom dup_action_log_with_lag_seconds\nwhere (lag_seconds is null or lag_seconds &gt;= 30 * 60)\norder by stamp;\n\n\n\nDisplaying records 1 - 10\n\n\nuser_id\naction\nproducts\nstamp\n\n\n\n\nU001\nclick\nD001\n2016-11-03 18:00:00\n\n\nU002\nclick\nD002\n2016-11-03 19:00:00\n\n\nU003\nclick\nA001\n2016-11-03 20:00:00\n\n\nU004\nclick\nA001\n2016-11-03 21:00:00\n\n\nU004\nclick\nD001\n2016-11-03 21:00:00\n\n\nU001\nclick\nD001\n2016-11-04 18:00:00\n\n\nU005\nclick\nA001\n2016-11-04 19:00:00\n\n\nU006\nclick\nD001\n2016-11-04 20:00:00\n\n\nU007\nclick\nD002\n2016-11-04 21:00:00\n\n\nU008\nclick\nA001\n2016-11-04 22:00:00\n\n\n\n\n\n\n\n2.2.4 変更されたマスタデータをすべて抽出する\nNULLを含めた比較がis distinct fromを使うことで行える。 つまり、どちらかがNULLだと演算が出来ないがわかる。\n\n\nCode\nselect\n    coalesce(new_mst.product_id, old_mst.product_id) as product_id\n  , coalesce(new_mst.name,       old_mst.name) as name\n  , coalesce(new_mst.price,      old_mst.price) as price\n  , coalesce(new_mst.updated_at, old_mst.updated_at) as updated_at\n  , case\n      when old_mst.updated_at is null then 'added'\n      when new_mst.updated_at is null then 'deleted'\n      when new_mst.updated_at &lt;&gt; old_mst.updated_at then 'updated'\n    end as status\nfrom \n  mst_products_20170101 as new_mst\n  full outer join\n    mst_products_20161201 as old_mst\n  on \n    new_mst.product_id = old_mst.product_id\nwhere\n  -- null\n  new_mst.updated_at is distinct from old_mst.updated_at\n\n\n\n3 records\n\n\nproduct_id\nname\nprice\nupdated_at\nstatus\n\n\n\n\nC001\nCCA\n500\n2016-12-04 18:00:00\nupdated\n\n\nB001\nBBB\n500\n2016-11-03 20:00:00\ndeleted\n\n\nD002\nDAD\n500\n2016-12-04 19:00:00\nadded"
  }
]